<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>总复习和常见的并发面试题</title>
    <link href="undefined2020/03/04/%E6%80%BB%E5%A4%8D%E4%B9%A0%E5%92%8C%E5%B8%B8%E8%A7%81%E7%9A%84%E5%B9%B6%E5%8F%91%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <url>2020/03/04/%E6%80%BB%E5%A4%8D%E4%B9%A0%E5%92%8C%E5%B8%B8%E8%A7%81%E7%9A%84%E5%B9%B6%E5%8F%91%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h2 id="总复习和常见并发面试题"><a href="#总复习和常见并发面试题" class="headerlink" title="总复习和常见并发面试题"></a>总复习和常见并发面试题</h2><h3 id="谈面试"><a href="#谈面试" class="headerlink" title="谈面试"></a>谈面试</h3><ol><li><p>面试主要分为两块：一块是考查工程师对基础知识（包括了技术广度、深度、对技术的热情度等）的掌握程度，因为<strong>基础知识决定了一个技术人员发展的上限</strong>；另一块是考察工程师的工程能力，比如：做过哪些项目？遇到最难的问题怎样解决的？说说最有成就感的一项任务？<strong>工程能力是考察工程师当下能为公司带来的利益</strong>。当然还有其它考核方面：抗压性、合作能力。</p></li><li><p>Java只是一门语言，即使是Java工程师也不能局限于Java，要从面向对象语言本身，甚至从整个计算机体系，从工程实际出发看Java。</p></li><li><p>很多知识在一般公司的开发中是用不到的，常有人戏称：“面试造火箭，工作拧螺丝”，但这只是通常情况下公司对程序员的标准——迅速产出，完成任务。所以，工程师为了自己职业的发展不能局限于公司对自己的要求，不能停留在应用层面，要能够很好地掌握基础知识，要多看源码，自己多实践，学成记得产出，比如多为开源社区贡献代码，帮助初学者指路等。</p></li></ol><h3 id="常见面试题"><a href="#常见面试题" class="headerlink" title="常见面试题"></a>常见面试题</h3><ul><li><p>在java中守护线程和用户线程的区别？</p><p>java中的线程分为两种：守护线程（Daemon）和用户线程（User）。</p><p>任何线程都可以设置为守护线程和用户线程，通过方法Thread.setDaemon(bool on)；true则把该线程设置为守护线程，反之则为用户线程。Thread.setDaemon()必须在Thread.start()之前调用，否则运行时会抛出异常。</p><p>两者的区别： </p><p>唯一的区别是判断虚拟机(JVM)何时离开，Daemon是为其他线程提供服务，如果全部的User Thread已经结束，Daemon 没有可服务的线程，JVM关闭。</p><p>扩展：Thread Dump打印出来的线程信息，含有daemon字样的线程即为守护进程</p></li><li><p>线程与进程的区别</p><p>进程是操作系统分配资源的最小单元，线程是操作系统调度的最小单元。</p><p>一个程序至少有一个进程,一个进程至少有一个线程。</p></li><li><p>什么是多线程中的上下文切换</p><p>多线程会共同使用一组计算机上的CPU，而线程数大于给程序分配的CPU数量时，为了让各个线程都有执行的机会，就需要轮转使用CPU。不同的线程切换使用CPU发生的切换数据等就是上下文切换。</p></li><li><p>死锁与活锁的区别，死锁与饥饿的区别？</p><p>死锁：是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。 </p><p>产生死锁的必要条件： </p><p>互斥条件：所谓互斥就是进程在某一时间内独占资源。</p><p>请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 </p><p>不剥夺条件:进程已获得资源，在末使用完之前，不能强行剥夺。 </p><p>循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。</p><p>活锁：任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。</p><p>活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，所谓的“活”， 而处于死锁的实体表现为等待；活锁有可能自行解开，死锁则不能。</p><p>饥饿：一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行的状态。</p></li><li><p>synchronized底层实现原理</p><p>synchronized (this)原理：涉及两条指令：monitorenter，monitorexit；再说同步方法，从同步方法反编译的结果来看，方法的同步并没有通过指令monitorenter和monitorexit来实现，相对于普通方法，其常量池中多了ACC_SYNCHRONIZED标示符。</p><p>JVM就是根据该标示符来实现方法的同步的：当方法被调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。</p><p>注意，这个问题可能会接着追问，java对象头信息，偏向锁，轻量锁，重量级锁及其他们相互间转化。</p></li><li><p>什么是线程组，为什么在Java中不推荐使用？</p><p>ThreadGroup类，可以把线程归属到某一个线程组中，线程组中可以有线程对象，也可以有线程组，组中还可以有线程，这样的组织结构有点类似于树的形式。</p><ol><li>线程组ThreadGroup对象中比较有用的方法是stop、resume、suspend等方法，由于这几个方法会导致线程的安全问题（主要是死锁问题），已经被官方废弃掉了，所以线程组本身的应用价值就大打折扣了。</li><li>线程组ThreadGroup不是线程安全的，这在使用过程中获取的信息并不全是及时有效的，这就降低了它的统计使用价值。</li></ol></li><li><p>什么是Executors框架？为什么使用Executor框架？</p><p>Executor框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架。</p><p>每次执行任务创建线程 new Thread()比较消耗性能，创建一个线程是比较耗时、耗资源的。</p><p>调用 new Thread()创建的线程缺乏管理，而且可以无限制的创建，线程之间的相互竞争会导致过多占用系统资源而导致系统瘫痪，还有线程之间的频繁交替也会消耗很多系统资源。</p><p>接使用new Thread() 启动的线程不利于扩展，比如定时执行、定期执行、定时定期执行、线程中断等都不便实现。</p></li><li><p>在Java中Executor和Executors的区别？</p><p>Executors 工具类的不同方法按照我们的需求创建了不同的线程池，来满足业务的需求。 </p><p>Executor 接口对象能执行我们的线程任务。 </p><p>ExecutorService接口继承了Executor接口并进行了扩展，提供了更多的方法我们能获得任务执行的状态并且可以获取任务的返回值。 </p><p>使用ThreadPoolExecutor 可以创建自定义线程池。</p></li><li><p>什么是原子操作？在Java Concurrency API中有哪些原子类(atomic classes)<strong>？</strong></p><p>原子操作（atomic operation）意为”不可被中断的一个或一系列操作” 。 </p><p>处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。 </p><p>在Java中可以通过锁和循环CAS的方式来实现原子操作。 CAS操作——Compare &amp; Set，或是 Compare &amp; Swap，现在几乎所有的CPU指令都支持CAS的原子操作。</p><p>java.util.concurrent.atomic下提供了大量的原子操作类，比如原子类：AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference ，原子数组：AtomicIntegerArray，AtomicLongArray，AtomicReferenceArray ，原子属性更新器：AtomicLongFieldUpdater，AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater</p></li><li><p>Java Concurrency API中的Lock接口(Lock interface)是什么？对比synchronized它有什么优势？</p><p>Lock接口比同步方法和同步块提供了更具扩展性的锁操作。 </p><p>他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。</p><p>它的优势有：可以使锁更公平，可以使线程在等待锁的时候响应中断，可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间，可以在不同的范围，以不同的顺序获取和释放锁。</p><p>整体上来说Lock是synchronized的扩展版，Lock提供了无条件的、可轮询的(tryLock方法)、定时的(tryLock带参方法)、可中断的(lockInterruptibly)、可多条件队列的(newCondition方法)锁操作。另外Lock的实现类基本都支持非公平锁(默认)和公平锁，synchronized只支持非公平锁，当然，在大部分情况下，非公平锁是高效的选择。</p></li><li><p>什么是阻塞队列？阻塞队列的实现原理是什么？如何使用阻塞队列来实现生产者-消费者模型？</p><p>阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。</p><p>这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。</p><p>阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。</p><p>JDK7提供了7个阻塞队列。在实现上，主要是利用了Condition和Lock的等待通知模式。</p></li><li><p>什么是Callable和Future?</p><p>Callable接口类似于Runnable，从名字就可以看出来了，但是Runnable不会返回结果，并且无法抛出返回结果的异常，而Callable功能更强大一些，被线程执行后，可以返回值，这个返回值可以被Future拿到，也就是说，</p><p>Future可以拿到异步执行任务的返回值，可以认为是带有回调的Runnable。</p><p>Future接口表示异步任务，是还没有完成的任务给出的未来结果。所以说Callable用于产生结果，Future用于获取结果。</p></li><li><p>什么是<strong>FutureTask?</strong></p><p>在Java并发程序中FutureTask表示一个可以取消的异步运算。它有启动和取消运算、查询运算是否完成和取回运算结果等方法。只有当运算完成的时候结果才能取回，如果运算尚未完成get方法将会阻塞。一个FutureTask对象可以对调用了Callable和Runnable的对象进行包装，由于FutureTask也是调用了Runnable接口所以它可以提交给Executor来执行。</p></li><li><p>什么是并发容器的实现？</p><p>何为同步容器：可以简单地理解为通过synchronized来实现同步的容器，如果有多个线程调用同步容器的方法，它们将会串行执行。比如Vector，Hashtable，以及Collections.synchronizedSet，synchronizedList等方法返回的容器。 </p><p>并发容器使用了与同步容器完全不同的加锁策略来提供更高的并发性和伸缩性，例如在ConcurrentHashMap中采用了一种粒度更细的加锁机制，可以称为分段锁，在这种锁机制下，允许任意数量的读线程并发地访问map，并且执行读操作的线程和写操作的线程也可以并发的访问map，同时允许一定数量的写操作线程并发地修改map，所以它可以在并发环境下实现更高的吞吐量。</p></li><li><p>多线程同步和互斥有几种实现方法，都是什么？</p><p>线程同步是指线程之间所具有的一种制约关系，一个线程的执行依赖另一个线程的消息，当它没有得到另一个线程的消息时应等待，直到消息到达时才被唤醒。 </p><p>线程互斥是指对于共享的进程系统资源，在各单个线程访问时的排它性。当有若干个线程都要使用某一共享资源时，任何时刻最多只允许一个线程去使用，其它要使用该资源的线程必须等待，直到占用资源者释放该资源。线程互斥可以看成是一种特殊的线程同步。</p><p>线程间的同步方法大体可分为两类：用户模式和内核模式。顾名思义，内核模式就是指利用系统内核对象的单一性来进行同步，使用时需要切换内核态与用户态，而用户模式就是不需要切换到内核态，只在用户态完成操作。 </p><p>用户模式下的方法有：原子操作（例如一个单一的全局变量），临界区。内核模式下的方法有：事件，信号量，互斥量。</p></li><li><p>什么是竞争条件？</p><p>当多个进程都企图对共享数据进行某种处理，而最后的结果又取决于进程运行的顺序时，则我们认为这发生了竞争条件（race condition）。</p></li><li><p>为什么我们调用start()方法时会执行run()方法，为什么我们不能直接调用run()方法？</p><p>当你调用start()方法时你将创建新的线程，并且执行在run()方法里的代码。 </p><p>但是如果你直接调用run()方法，它不会创建新的线程也不会执行调用线程的代码，只会把run方法当作普通方法去执行。</p></li><li><p>在Java中CycliBarriar和CountdownLatch有什么区别？</p><p>CyclicBarrier可以重复使用，而CountdownLatch不能重复使用。 </p></li><li><p>什么是不可变对象，它对写并发应用有什么帮助？</p><p>不可变对象(Immutable Objects)即对象一旦被创建它的状态（对象的数据，也即对象属性值）就不能改变，反之即为可变对象(Mutable Objects)。 </p><p>不可变对象的类即为不可变类(Immutable Class)。Java平台类库中包含许多不可变类，如String、基本类型的包装类、BigInteger和BigDecimal等。 </p><p>不可变对象天生是线程安全的。它们的常量（域）是在构造函数中创建的。既然它们的状态无法修改，这些常量永远不会变。</p><p>不可变对象永远是线程安全的。 </p><p>只有满足如下状态，一个对象才是不可变的； </p><p>它的状态不能在创建后再被修改； </p><p>所有域都是final类型；</p><p>它被正确创建；</p></li><li><p>notify()和notifyAll()有什么区别？</p><p>当一个线程进入wait之后，就必须等其他线程notify/notifyall,使用notifyall,可以唤醒所有处于wait状态的线程，使其重新进入锁的争夺队列中，而notify只能唤醒一个。</p><p>如果没把握，建议notifyAll，防止notigy因为信号丢失而造成程序异常。</p></li><li><p>什么是可重入锁（ReentrantLock）？谈谈它的实现。</p><p>线程可以重复进入任何一个它已经拥有的锁所同步着的代码块，synchronized、ReentrantLock都是可重入的锁。在实现上，就是线程每次获取锁时判定如果获得锁的线程是它自己时，简单将计数器累积即可，每 释放一次锁，进行计数器累减，直到计算器归零，表示线程已经彻底释放锁。</p></li><li><p>当一个线程进入某个对象的一个synchronized的实例方法后，其它线程是否可进入此对象的其它方法？</p><p>如果其他方法没有synchronized的话，其他线程是可以进入的。所以要开放一个线程安全的对象时，得保证每个方法都是线程安全的。</p></li><li><p>乐观锁和悲观锁的理解及如何实现，有哪些实现方式？</p><p><strong>悲观锁：</strong>总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。Java里面的同步原语synchronized关键字的实现是悲观锁。</p><p><strong>乐观锁：</strong>顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。在Java中j原子变量类就是使用了乐观锁的一种实现方式CAS实现的。</p><p>乐观锁的实现方式： </p><ul><li>使用版本标识来确定读到的数据与提交时的数据是否一致。提交后修改版本标识，不一致时可以采取丢弃和再次尝试的策略。 </li><li>java中的Compare and Swap即CAS ，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。</li></ul></li><li><p>什么是CAS操作，缺点是什么？</p><p>CAS的基本思路就是，如果这个地址上的值和期望的值相等，则给其赋予新值，否则不做任何事儿，但是要返回原值是多少。每一个CAS操作过程都包含三个运算符：一个内存地址V，一个期望的值A和一个新值B，操作的时候如果这个地址上存放的值等于这个期望的值A，则将地址上的值赋为新值B，否则不做任何操作。</p><p>CAS缺点： </p><p>ABA问题：比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但可能存在潜藏的问题。从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。 </p><p>循环时间长开销大： </p><p>对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。 </p><p>只能保证一个共享变量的原子操作： </p><p>当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。</p></li><li><p>SynchronizedMap和ConcurrentHashMap有什么区别？</p><p>SynchronizedMap一次锁住整张表来保证线程安全，所以每次只能有一个线程来访为map。</p><p>ConcurrentHashMap使用分段锁来保证在多线程下的性能。</p></li><li><p>写时复制容器可以用于什么应用场景？</p><p>CopyOnWrite并发容器用于对于绝大部分访问都是读，且<strong>偶尔写</strong>的并发场景。比如白名单，黑名单，商品类目的访问和更新场景。</p><p>透露的思想：</p><p>读写分离</p><p>最终一致性 </p><p>使用另外开辟空间的思路，来解决并发冲突</p></li><li><p>volatile有什么用？能否用一句话说明下volatile的应用场景？</p><p>volatile保证内存可见性和禁止指令重排。</p><p>volatile用于多线程环境下的一写多读，或者无关联的多写。</p></li><li><p>为什么代码会重排序？</p><p>在执行程序时，为了提供性能，处理器和编译器常常会对指令进行重排序，但是不能随意重排序，它需要满足以下两个条件：</p><p>在单线程环境下不能改变程序运行的结果；</p><p>存在数据依赖关系的不允许重排序</p></li><li><p>在java中wait和sleep方法的不同？</p><p>最大的不同是在等待时wait会释放锁，而sleep一直持有锁。Wait通常被用于线程间交互，sleep通常被用于暂停执行。</p></li><li><p>一个线程运行时发生异常会怎样？</p><p>如果异常没有被捕获该线程将会停止执行。Thread.UncaughtExceptionHandler是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。当一个未捕获异常将造成线程中断的时候JVM会使用Thread.getUncaughtExceptionHandler()来查询线程的UncaughtExceptionHandler并将线程和异常作为参数传递给handler的uncaughtException()方法进行处理。</p></li><li><p>为什么wait, notify 和 notifyAll这些方法不在thread类里面？</p><p>JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。如果线程需要等待某些锁那么调用对象中的wait()方法就有意义了。如果wait()方法定义在Thread类中，线程正在等待的是哪个锁就不明显了。简单的说，由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象。</p></li><li><p>什么是ThreadLocal变量？</p><p>ThreadLocal是Java里一种特殊的变量。每个线程都有一个ThreadLocal就是每个线程都拥有了自己独立的一个变量，竞争条件被彻底消除了。</p></li><li><p>Java中interrupted和isInterrupted方法的区别？</p><p>interrupted() 和 isInterrupted()的主要区别是前者会将中断状态清除而后者不会。Java多线程的中断机制是用内部标识来实现的，调用Thread.interrupt()来中断一个线程就会设置中断标识为true。当中断线程调用静态方法Thread.interrupted()来检查中断状态时，中断状态会被清零。而非静态方法isInterrupted()用来查询其它线程的中断状态且不会改变中断状态标识。</p></li><li><p>为什么wait和notify方法要在同步块中调用？</p><p>主要是因为Java API强制要求这样做，如果你不这么做，你的代码会抛出IllegalMonitorStateException异常。</p></li><li><p>为什么你应该在循环中检查等待条件<strong>?</strong></p><p>处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满足结束条件的情况下退出。因此，当一个等待线程醒来时，不能认为它原来的等待状态仍然是有效的，在notify()方法调用之后和等待线程醒来之前这段时间它可能会改变。这就是在循环中使用wait()方法效果更好的原因</p></li><li><p>怎么检测一个线程是否拥有锁？</p><p>在java.lang.Thread中有一个方法叫holdsLock()，它返回true如果当前线程拥有某个具体对象的锁。</p></li><li><p>你如何在Java中获取线程堆栈？</p><p>kill -3 [java pid] 不会在当前终端输出，它会输出到代码执行的或指定的地方去。比如，kill -3 tomcat pid, 输出堆栈到log目录下。</p><p>Jstack [java pid] 这个比较简单，在当前终端显示，也可以重定向到指定文件中。</p><p>或者使用Java提供的拟机线程系统的管理接口ManagementFactory.getThreadMXBean()。</p></li><li><p>Java线程池中submit() <strong>和</strong> execute()方法有什么区别？</p><p>两个方法都可以向线程池提交任务</p><p>execute()方法的返回类型是void，它定义在Executor接口中。</p><p>submit()方法可以返回持有计算结果的Future对象，它定义在ExecutorService接口中，它扩展了Executor接口</p></li><li><p>你对线程优先级的理解是什么？</p><p>每一个线程都是有优先级的，一般来说，高优先级的线程在运行时会具有优先权，但这依赖于线程调度的实现，这个实现是和操作系统相关的(OS dependent)。我们可以定义线程的优先级，但是这并不能保证高优先级的线程会在低优先级的线程前执行。线程优先级是一个int变量(从1-10)，1代表最低优先级，10代表最高优先级。</p><p>java的线程优先级调度会委托给操作系统去处理，所以与具体的操作系统优先级有关，如非特别需要，一般无需设置线程优先级。</p></li><li><p>你如何确保main()方法所在的线程是Java 程序最后结束的线程？</p><p>可以使用Thread类的join()方法（或者CountDownLatch工具类）来确保所有程序创建的线程在main()方法退出前结束。</p></li><li><p>为什么Thread类的sleep()和yield ()方法是静态的？</p><p>Thread类的sleep()和yield()方法将在当前正在执行的线程上运行。所以在其他处于等待状态的线程上调用这些方法是没有意义的。这就是为什么这些方法是静态的。它们可以在当前正在执行的线程中工作，并避免程序员错误的认为可以在其他非运行线程调用这些方法。</p></li><li><p>现在有T1、T2、T3三个线程，你怎样保证T2在T1执行完后执行，T3在T2执行完后执行？</p><p>可以用join方法实现。</p></li><li><p>你需要实现一个高效的缓存，它允许多个用户读，但只允许一个用户写，以此来保持它的完整性，你会怎样去实现它？</p><p>volatile关键字，读写锁，写时复制等等都可以实现。</p></li><li><p>用Java实现阻塞队列</p><p>见作业答案：包cn.enjoyedu.ch5.answer下</p></li><li><p>用Java写代码来解决生产者——消费者问题。</p><p>阻塞队列实现即可，也可以用wait和notify来解决这个问题，或者用Semaphore（信号量）</p></li><li><p>用Java编程一个会导致死锁的程序，你将怎么解决？</p><p> 参见代码cn.enjoyedu.ch7. NormalDeadLock，如何解决死锁，参见笔记。</p></li><li><p>Java中如何停止一个线程？</p><p>使用共享变量的方式 </p><p>在这种方式中，之所以引入共享变量，是因为该变量可以被多个执行相同任务的线程用来作为是否中断的信号，通知中断线程的执行。</p><p>使用interrupt方法终止线程 </p><p>如果一个线程由于等待某些事件的发生而被阻塞，比如当一个线程由于需要等候键盘输入而被阻塞，或者调用Thread.join()方法，或者Thread.sleep()方法，在网络中调用ServerSocket.accept()方法，或者调用了DatagramSocket.receive()方法时，都有可能导致线程阻塞，使线程处于处于不可运行状态时，即使主程序中将该线程的共享变量设置为true，但该线程此时根本无法检查循环标志，当然也就无法立即中断。所以应该尽量使用Thread提供的interrupt()方法，因为该方法虽然不会中断一个正在运行的线程，但是它可以使一个被阻塞的线程抛出一个中断异常，从而使线程提前结束阻塞状态。</p></li><li><p>JVM中哪个参数是用来控制线程的栈堆栈大小的</p><p>-Xss</p></li><li><p>如果同步块内的线程抛出异常锁会释放吗？</p><p>会</p></li><li><p>单例模式的双重检查实现是什么？为什么并不安全？如何在Java中创建线程安全的Singleton？</p><p>实现参见cn.enjoyedu.ch7.dcl. SingleDcl，不安全的根本原因是重排序会导致未初始化完成的对象可以被其他线程看见而导致错误。创建安全的单例模式有：延迟占位模式、在声明的时候就new这个类的实例、枚举</p></li><li><p>写出3条你遵循的多线程最佳实践</p><p>给你的线程起个有意义的名字。 这样可以方便找bug或追踪。OrderProcessor, QuoteProcessor or TradeProcessor 这种名字比 Thread-1. Thread-2 and Thread-3 好多了，给线程起一个和它要完成的任务相关的名字，所有的主要框架甚至JDK都遵循这个最佳实践。</p><p>避免锁定和缩小同步的范围 锁花费的代价高昂且上下文切换更耗费时间空间，试试最低限度的使用同步和锁，缩小临界区。因此相对于同步方法我更喜欢同步块，它给我拥有对锁的绝对控制权。</p><p>多用同步类少用wait 和 notify 首先，CountDownLatch, Semaphore, CyclicBarrier 和 Exchanger 这些同步类简化了编码操作，而用wait和notify很难实现对复杂控制流的控制。其次，这些类是由最好的企业编写和维护在后续的JDK中它们还会不断优化和完善，使用这些更高等级的同步工具你的程序可以不费吹灰之力获得优化。</p><p>多用并发集合少用同步集合 这是另外一个容易遵循且受益巨大的最佳实践，并发集合比同步集合的可扩展性更好，所以在并发编程时使用并发集合效果更好。</p><p>比如并发编程的黄金原则，尽量无锁化编程等等……..</p></li><li><p>请概述线程池的创建参数，怎么样合理配置一个线程池的参数？</p><p>参见笔记中线程池一章的内容</p></li><li><p>请概述锁的公平和非公平，JDK内部是如何实现的。</p><p>公平锁是指所有试图获得锁的线程按照获取锁的顺序依次获得锁，而非公平锁则是当前的锁状态没有被占用时,当前线程可以直接占用,而不需要等待。在实现上，非公平锁逻辑基本跟公平锁一致，唯一的区别是，当前线程不需要判断同步队列中是否有等待线程。</p><p>非公平锁性能高于公平锁性能。首先，在恢复一个被挂起的线程与该线程真正运行之间存在着严重的延迟。而且，非公平锁能更充分的利用cpu的时间片，尽量的减少cpu空闲的状态时间。</p><p>使用场景的话呢，其实还是和他们的属性一一相关，比如：如果业务中线程占用(处理)时间要远长于线程等待，那用非公平锁其实效率并不明显，但是用公平锁可以保证不会有线程被饿死。</p></li><li><p>请概述AQS</p><p>是用来构建锁或者其他同步组件的基础框架，比如ReentrantLock、ReentrantReadWriteLock和CountDownLatch就是基于AQS实现的。它使用了一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作。它是CLH队列锁的一种变体实现。它可以实现2种同步方式：独占式，共享式。</p><p>AQS的主要使用方式是继承，子类通过继承AQS并实现它的抽象方法来管理同步状态，同步器的设计基于模板方法模式，所以如果要实现我们自己的同步工具类就需要覆盖其中几个可重写的方法，如tryAcquire、tryReleaseShared等等。</p><p>这样设计的目的是同步组件（比如锁）是面向使用者的，它定义了使用者与同步组件交互的接口（比如可以允许两个线程并行访问），隐藏了实现细节；同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作。这样就很好地隔离了使用者和实现者所需关注的领域。</p><p>在内部，AQS维护一个共享资源state，通过内置的FIFO来完成获取资源线程的排队工作。该队列由一个一个的Node结点组成，每个Node结点维护一个prev引用和next引用，分别指向自己的前驱和后继结点，构成一个双端双向链表。</p><p>同时与Condition相关的等待队列，节点类型也是Node，构成一个单向链表。</p></li><li><p>请概述volatile</p><p>volatile关键字的作用主要有两点：</p><p>多线程主要围绕可见性和原子性两个特性而展开，使用volatile关键字修饰的变量，保证了其在多线程之间的可见性，即每次读取到volatile变量，一定是最新的数据。但是volatile只能以保证任意单个volatile变量的读/写具有原子性，但类似于++这种复合操作不具有原子性。</p><p>代码底层在执行时为了获取更好的性能会对指令进行重排序，多线程下可能会出现一些意想不到的问题。使用volatile则会对禁止重排序，当然这也一定程度上降低了代码执行效率。</p><p>同时在内存语义上，当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存，当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。</p><p>在Java中对于volatile修饰的变量，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序问题、强制刷新和读取。</p><p>在具体实现上，volatile关键字修饰的变量会存在一个“lock:”的前缀。它不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。</p><p>同时该指令会将当前处理器缓存行的数据直接写会到系统内存中，且这个写回内存的操作会使在其他CPU里缓存了该地址的数据无效。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>并发编程 - 面试题</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>java8新增的特性</title>
    <link href="undefined2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/"/>
    <url>2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/</url>
    
    <content type="html"><![CDATA[<h2 id="新增原子操作"><a href="#新增原子操作" class="headerlink" title="新增原子操作"></a>新增原子操作</h2><h3 id="LongAdder"><a href="#LongAdder" class="headerlink" title="LongAdder"></a>LongAdder</h3><p>JDK1.8时，java.util.concurrent.atomic包中提供了一个新的原子类：LongAdder。<br> 根据Oracle官方文档的介绍，LongAdder在高并发的场景下会比它的前辈AtomicLong 具有更好的性能，代价是消耗更多的内存空间。</p><p><strong>AtomicLong</strong>是利用了底层的CAS操作来提供并发性的，调用了<strong>Unsafe</strong>类的<strong>getAndAddLong</strong>方法，该方法是个<strong>native</strong>方法，它的逻辑是采用自旋的方式不断更新目标值，直到更新成功。</p><p>在并发量较低的环境下，线程冲突的概率比较小，自旋的次数不会很多。但是，高并发环境下，N个线程同时进行自旋操作，会出现大量失败并不断自旋的情况，此时<strong>AtomicLong</strong>的自旋会成为瓶颈。</p><p>这就是<strong>LongAdder</strong>引入的初衷——解决高并发环境下<strong>AtomicLong</strong>的自旋瓶颈问题。</p><p><strong>AtomicLong</strong>中有个内部变量<strong>value</strong>保存着实际的long值，所有的操作都是针对该变量进行。也就是说，高并发环境下，value变量其实是一个热点，也就是N个线程竞争一个热点。</p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic1.png" srcset="/img/loading.gif" class=""><p><strong>LongAdder</strong>的基本思路就是<strong>分散热点</strong>，将value值分散到一个数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行CAS操作，这样热点就被分散了，冲突的概率就小很多。如果要获取真正的long值，只要将各个槽中的变量值累加返回。</p><p>这种做法和ConcurrentHashMap中的“分段锁”其实就是类似的思路。</p><p><strong>LongAdder</strong>提供的API和<strong>AtomicLong</strong>比较接近，两者都能以原子的方式对long型变量进行增减。</p><p>但是<strong>AtomicLong</strong>提供的功能其实更丰富，尤其是<strong>addAndGet</strong>、<strong>decrementAndGet</strong>、<strong>compareAndSet</strong>这些方法。</p><p><strong>addAndGet</strong>、<strong>decrementAndGet</strong>除了单纯的做自增自减外，还可以立即获取增减后的值，而<strong>LongAdder</strong>则需要做同步控制才能精确获取增减后的值。如果业务需求需要精确的控制计数，做计数比较，<strong>AtomicLong</strong>也更合适。</p><p>另外，从空间方面考虑，<strong>LongAdder</strong>其实是一种“空间换时间”的思想，从这一点来讲<strong>AtomicLong</strong>更适合。</p><p>总之，低并发、一般的业务场景下AtomicLong是足够了。如果并发量很多，存在大量写多读少的情况，那LongAdder可能更合适。适合的才是最好的，如果真出现了需要考虑到底用AtomicLong好还是LongAdder的业务场景，那么这样的讨论是没有意义的，因为这种情况下要么进行性能测试，以准确评估在当前业务场景下两者的性能，要么换个思路寻求其它解决方案。</p><p>对于<strong>LongAdder</strong>来说，内部有一个base变量，一个Cell[]数组。</p><p>base变量：非竞态条件下，直接累加到该变量上。</p><p>Cell[]数组：竞态条件下，累加个各个线程自己的槽Cell[i]中。</p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic2.png" srcset="/img/loading.gif" class=""><p>所以，最终结果的计算应该是</p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic3.png" srcset="/img/loading.gif" class=""><p>在实际运用的时候，只有从未出现过并发冲突的时候，base基数才会使用到，一旦出现了并发冲突，之后所有的操作都只针对Cell[]数组中的单元Cell。</p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic4.png" srcset="/img/loading.gif" class=""><p>而LongAdder最终结果的求和，并没有使用全局锁，返回值不是绝对准确的，因为调用这个方法时还有其他线程可能正在进行计数累加，所以只能得到某个时刻的近似值，这也就是<strong>LongAdder</strong>并不能完全替代<strong>LongAtomic</strong>的原因之一。</p><p>而且从测试情况来看，线程数越多，并发操作数越大，LongAdder的优势越大，线程数较小时，AtomicLong的性能还超过了LongAdder。</p><h3 id="其他新增"><a href="#其他新增" class="headerlink" title="其他新增"></a>其他新增</h3><p>除了新引入LongAdder外，还有引入了它的三个兄弟类：<strong>LongAccumulator</strong>、<strong>DoubleAdder</strong>、<strong>DoubleAccumulator</strong>。</p><p>LongAccumulator是LongAdder的增强版。LongAdder只能针对数值的进行加减运算，而LongAccumulator提供了自定义的函数操作。</p><p>通过LongBinaryOperator，可以自定义对入参的任意操作，并返回结果（LongBinaryOperator接收2个long作为参数，并返回1个long）。</p><p>LongAccumulator内部原理和LongAdder几乎完全一样。</p><p>DoubleAdder和DoubleAccumulator用于操作double原始类型。</p><h2 id="新增显示锁"><a href="#新增显示锁" class="headerlink" title="新增显示锁"></a>新增显示锁</h2><h3 id="StampLock"><a href="#StampLock" class="headerlink" title="StampLock"></a>StampLock</h3><p>StampedLock是Java8引入的一种新的所机制,简单的理解,可以认为它是读写锁的一个改进版本,读写锁虽然分离了读和写的功能,使得读与读之间可以完全并发,但是读和写之间依然是冲突的,读锁会完全阻塞写锁,它使用的依然是悲观的锁策略.如果有大量的读线程,他也有可能引起写线程的饥饿。</p><p>而StampedLock则提供了一种乐观的读策略,这种乐观策略的锁非常类似于无锁的操作,使得乐观锁完全不会阻塞写线程。</p><p>它的思想是读写锁中读不仅不阻塞读，同时也不应该阻塞写。</p><h3 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h3><p>在读的时候如果发生了写，则应当重读而不是在读的时候直接阻塞写。即读写之间不会阻塞对方，但是写和写之间还是阻塞的。</p><p>StampedLock的内部实现是基于CLH的。</p><h3 id="CompletableFuture"><a href="#CompletableFuture" class="headerlink" title="CompletableFuture"></a>CompletableFuture</h3><h4 id="Future不足"><a href="#Future不足" class="headerlink" title="Future不足"></a>Future不足</h4><p>Future是Java 5添加的类，用来描述一个异步计算的结果。你可以使用isDone方法检查计算是否完成，或者使用get阻塞住调用线程，直到计算完成返回结果，你也可以使用cancel方法停止任务的执行。</p><p>虽然Future以及相关使用方法提供了异步执行任务的能力，但是对于结果的获取却是很不方便，只能通过阻塞或者轮询的方式得到任务的结果。阻塞的方式显然和我们的异步编程的初衷相违背，轮询的方式又会耗费无谓的CPU资源，而且也不能及时地得到计算结果，为什么不能用观察者设计模式当计算结果完成及时通知监听者呢？。</p><p>Java的一些框架，比如Netty，自己扩展了Java的 Future接口，提供了addListener等多个扩展方法，Google guava也提供了通用的扩展Future:ListenableFuture、SettableFuture 以及辅助类Futures等,方便异步编程。</p><p>同时Future接口很难直接表述多个Future 结果之间的依赖性。实际开发中，我们经常需要达成以下目的：</p><p>将两个异步计算合并为一个——这两个异步计算之间相互独立，同时第二个又依赖于第一个的结果。</p><p>等待 Future 集合中的所有任务都完成。</p><p>仅等待 Future集合中最快结束的任务完成（有可能因为它们试图通过不同的方式计算同一个值），并返回它的结果。</p><p>应对 Future 的完成事件（即当 Future 的完成事件发生时会收到通知，并能使用 Future 计算的结果进行下一步的操作，不只是简单地阻塞等待操作的结果）</p><h4 id="CompletableFuture-1"><a href="#CompletableFuture-1" class="headerlink" title="CompletableFuture"></a>CompletableFuture</h4><p>JDK1.8才新加入的一个实现类CompletableFuture，实现了Future<T>， CompletionStage<T>两个接口。实现了Future接口，意味着可以像以前一样通过阻塞或者轮询的方式获得结果。</p><h5 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h5><p>除了直接new出一个CompletableFuture的实例，还可以通过工厂方法创建CompletableFuture的实例</p><h5 id="工厂方法"><a href="#工厂方法" class="headerlink" title="工厂方法"></a>工厂方法</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic6.png" srcset="/img/loading.gif" class=""><p>Asynsc表示异步,而supplyAsync与runAsync不同在与前者异步返回一个结果,后者是void.第二个函数第二个参数表示是用我们自己创建的线程池,否则采用默认的ForkJoinPool.commonPool()作为它的线程池。</p><h5 id="获得结果的方法"><a href="#获得结果的方法" class="headerlink" title="获得结果的方法"></a>获得结果的方法</h5><p>public T get()</p><p>public T get(long timeout, TimeUnit unit)</p><p>public T getNow(T valueIfAbsent)</p><p>public T join()</p><p>getNow有点特殊，如果结果已经计算完则返回结果或者抛出异常，否则返回给定的valueIfAbsent值。</p><p>join返回计算的结果或者抛出一个unchecked异常(CompletionException)，它和get对抛出的异常的处理有些细微的区别。</p><h5 id="辅助方法"><a href="#辅助方法" class="headerlink" title="辅助方法"></a>辅助方法</h5><p>public static CompletableFuture<Void> allOf(CompletableFuture&lt;?&gt;… cfs)</p><p>public static CompletableFuture<Object> anyOf(CompletableFuture&lt;?&gt;… cfs)</p><p>allOf方法是当所有的CompletableFuture都执行完后执行计算。</p><p>anyOf方法是当任意一个CompletableFuture执行完后就会执行计算，计算的结果相同。</p><p>CompletionStage是一个接口，从命名上看得知是一个完成的阶段，它代表了一个特定的计算的阶段，可以同步或者异步的被完成。你可以把它看成一个计算流水线上的一个单元，并最终会产生一个最终结果，这意味着几个CompletionStage可以串联起来，一个完成的阶段可以触发下一阶段的执行，接着触发下一次，再接着触发下一次。</p><p>总结CompletableFuture几个关键点：</p><ol><li><p>计算可以由 Future ，Consumer 或者 Runnable 接口中的 apply，accept 或者 run等方法表示。</p></li><li><p>计算的执行主要有以下</p><p>a. 默认执行</p><p>b. 使用默认的CompletionStage的异步执行提供者异步执行。这些方法名使用someActionAsync这种格式表示。</p><p>c. 使用 Executor 提供者异步执行。这些方法同样也是someActionAsync这种格式，但是会增加一个Executor 参数。</p></li></ol><p>CompletableFuture中的方法归类</p><h5 id="变换类"><a href="#变换类" class="headerlink" title="变换类"></a>变换类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic7.png" srcset="/img/loading.gif" class=""><p>关键入参是函数式接口Function。它的入参是上一个阶段计算后的结果，返回值是经过转化后结果。</p><h5 id="消费类"><a href="#消费类" class="headerlink" title="消费类"></a>消费类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic8.png" srcset="/img/loading.gif" class=""><p>关键入参是函数式接口Consumer。它的入参是上一个阶段计算后的结果， 没有返回值。</p><h5 id="执行操作类"><a href="#执行操作类" class="headerlink" title="执行操作类"></a>执行操作类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic9.png" srcset="/img/loading.gif" class=""><p>对上一步的计算结果不关心，执行下一个操作，入参是一个Runnable的实例，表示上一步完成后执行的操作。</p><h5 id="结合转化类"><a href="#结合转化类" class="headerlink" title="结合转化类"></a>结合转化类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic10.png" srcset="/img/loading.gif" class=""><p>需要上一步的处理返回值，并且other代表的CompletionStage 有返回值之后，利用这两个返回值，进行转换后返回指定类型的值。</p><p>两个CompletionStage是并行执行的，它们之间并没有先后依赖顺序，other并不会等待先前的CompletableFuture执行完毕后再执行。</p><p><strong>结合转化类</strong></p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic11.png" srcset="/img/loading.gif" class=""><p>对于Compose可以连接两个CompletableFuture，其内部处理逻辑是当第一个CompletableFuture处理没有完成时会合并成一个CompletableFuture,如果处理完成，第二个future会紧接上一个CompletableFuture进行处理。</p><p>第一个CompletableFuture 的处理结果是第二个future需要的输入参数。</p><h5 id="结合消费类"><a href="#结合消费类" class="headerlink" title="结合消费类"></a>结合消费类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic12.png" srcset="/img/loading.gif" class=""><p>需要上一步的处理返回值，并且other代表的CompletionStage 有返回值之后，利用这两个返回值，进行消费</p><h5 id="运行后执行类"><a href="#运行后执行类" class="headerlink" title="运行后执行类"></a>运行后执行类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic13.png" srcset="/img/loading.gif" class=""><p>不关心这两个CompletionStage的结果，只关心这两个CompletionStage都执行完毕，之后再进行操作（Runnable）。</p><h5 id="取最快转换类"><a href="#取最快转换类" class="headerlink" title="取最快转换类"></a>取最快转换类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic14.png" srcset="/img/loading.gif" class=""><p>两个CompletionStage，谁计算的快，我就用那个CompletionStage的结果进行下一步的转化操作。现实开发场景中，总会碰到有两种渠道完成同一个事情，所以就可以调用这个方法，找一个最快的结果进行处理。</p><h5 id="取最快消费类"><a href="#取最快消费类" class="headerlink" title="取最快消费类"></a>取最快消费类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic15.png" srcset="/img/loading.gif" class=""><p>两个CompletionStage，谁计算的快，我就用那个CompletionStage的结果进行下一步的消费操作。</p><h5 id="取最快运行后执行类"><a href="#取最快运行后执行类" class="headerlink" title="取最快运行后执行类"></a>取最快运行后执行类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic16.png" srcset="/img/loading.gif" class=""><p>两个CompletionStage，任何一个完成了都会执行下一步的操作（Runnable）。</p><h5 id="异常补偿类"><a href="#异常补偿类" class="headerlink" title="异常补偿类"></a>异常补偿类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic17.png" srcset="/img/loading.gif" class=""><p>当运行时出现了异常，可以通过exceptionally进行补偿。</p><h5 id="运行后记录结果类"><a href="#运行后记录结果类" class="headerlink" title="运行后记录结果类"></a>运行后记录结果类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic18.png" srcset="/img/loading.gif" class=""><p>action执行完毕后它的结果返回原始的CompletableFuture的计算结果或者返回异常。所以不会对结果产生任何的作用。</p><h5 id="运行后处理结果类"><a href="#运行后处理结果类" class="headerlink" title="运行后处理结果类"></a>运行后处理结果类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic19.png" srcset="/img/loading.gif" class=""><p>运行完成时，对结果的处理。这里的完成时有两种情况，一种是正常执行，返回值。另外一种是遇到异常抛出造成程序的中断。</p><h2 id="Lambda表达式"><a href="#Lambda表达式" class="headerlink" title="Lambda表达式"></a>Lambda表达式</h2><p>在语法上，Lambda表达式包含三个部分，参数列表，箭头，主体，比如：</p><p> <strong>(parameters) -&gt; expression</strong></p><p>或</p><p> <strong>(parameters) -&gt; { statements; }</strong></p><p>Lambda表达式用在函数式接口上，所谓函数式接口，是只定义了一个抽象方法的接口（Interface），接口中是否有默认方法，不影响。注解@FunctionalInterface可以帮助我们在设计函数式接口时防止出错。</p><p><strong>函数描述符</strong>:函数式接口的抽象方法的签名基本上就是Lambda表达式的签名。我们将这种抽象方法叫作函数描述符。Runnable接口可以看作一个什么也不接受什么也不返回（void）的函数的签名，因为它只有一个叫作run的抽象方法，这个方法什么也不接受，什么也不返回（void）。我们可以用 () -&gt; void代表参数列表为空，且返回void的函数。这正是Runnable接口所代表的。我们于是可以称() -&gt; void是Runnable接口的函数描述符。</p><p>而Callable接口和Supplier接口的函数描述符是一样的，都是</p><p>() -&gt; X</p><p>所以同一个Lambda可以同时用在这两个函数式接口上，比如：</p><p>Callable&lt;Integer&gt; = () -&gt; 33;</p><p>Supplier&lt;Integer&gt; = () -&gt; 33;</p><p>我们常用的Runnable,Callable都是函数式接口，JDK8中新增了几个函数式接口：</p><p><strong>Predicate</strong></p><p>包含test方法，接受泛型的T，返回boolean，可以视为断言（检查）接口</p><p><strong>Consumer</strong></p><p>包含accept方法，接受泛型的T，无返回，可以视为数据消费接口</p><p><strong>Function&lt;T,R&gt;</strong></p><p>包含apply方法，接受泛型的T，返回R，可以视为映射转换接口</p><p><strong>Supplier</strong></p><p>包含get方法，无输入，返回T，可以视为创建一个新对象接口</p><p><strong>UnaryOperator</strong></p><p>扩展至Function&lt;T,T&gt;，所以这个本质上也是一个映射转换接口，只不过映射转换后的类型保持不变</p><p><strong>BiFunction</strong></p><p>包含apply方法，接受泛型的T、U，返回R，可以视为复合型映射转换接口</p><p><strong>BinaryOperator</strong></p><p>扩展至Function BiFunction&lt;T,T,T&gt;，所以这个本质上也是一个复合型映射转换接口，只不过映射转换后的类型保持不变</p><p><strong>BiPredicate</strong></p><p>包含test方法，接受泛型的T，U，返回boolean，可以视为复合型断言（检查）接口</p><p><strong>BiConsumer&lt;T,U&gt;</strong></p><p>包含accept方法，接受泛型的T，U，无返回，可以视为复合型数据消费接口</p><h2 id="扩充知识点-Disruptor"><a href="#扩充知识点-Disruptor" class="headerlink" title="扩充知识点- Disruptor"></a>扩充知识点- Disruptor</h2><h3 id="应用背景和介绍"><a href="#应用背景和介绍" class="headerlink" title="应用背景和介绍"></a>应用背景和介绍</h3><p>Disruptor是英国外汇交易公司LMAX开发的一个高性能队列，研发的初衷是解决内部的内存队列的延迟问题，而不是分布式队列。基于Disruptor开发的系统单线程能支撑每秒600万订单，2010年在QCon演讲后，获得了业界关注。</p><p>据目前资料显示：应用Disruptor的知名项目有如下的一些：Storm, Camel, Log4j2,还有目前的美团点评技术团队也有很多不少的应用，或者说有一些借鉴了它的设计机制。 </p><p>Disruptor是一个高性能的线程间异步通信的框架，即在同一个JVM进程中的多线程间消息传递。</p><h3 id="传统队列问题"><a href="#传统队列问题" class="headerlink" title="传统队列问题"></a>传统队列问题</h3><p>在JDK中，Java内部的队列BlockQueue的各种实现，仔细分析可以得知，队列的底层数据结构一般分成三种：数组、链表和堆，堆这里是为了实现带有优先级特性的队列暂且不考虑。 </p><p>在稳定性和性能要求特别高的系统中，为了防止生产者速度过快，导致内存溢出，只能选择有界队列；同时，为了减少Java的垃圾回收对系统性能的影响，会尽量选择 Array格式的数据结构。这样筛选下来，符合条件的队列就只有ArrayBlockingQueue。但是ArrayBlockingQueue是通过<strong>加锁</strong>的方式保证线程安全，而且ArrayBlockingQueue还存在<strong>伪共享</strong>问题，这两个问题严重影响了性能。</p><p>ArrayBlockingQueue的这个伪共享问题存在于哪里呢，分析下核心的部分源码，其中最核心的三个成员变量为</p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic20.png" srcset="/img/loading.gif" class=""><p>是在ArrayBlockingQueue的核心enqueue和dequeue方法中经常会用到的，这三个变量很容易放到同一个缓存行中，进而产生伪共享问题。</p><h3 id="高性能的原理"><a href="#高性能的原理" class="headerlink" title="高性能的原理"></a>高性能的原理</h3><ol><li><p>引入环形的数组结构：数组元素不会被回收，避免频繁的GC，</p></li><li><p>无锁的设计：采用CAS无锁方式，保证线程的安全性</p></li><li><p>属性填充：通过添加额外的无用信息，避免伪共享问题</p></li></ol><p>环形数组结构是整个Disruptor的核心所在。 </p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic21.png" srcset="/img/loading.gif" class=""><p>首先因为是数组，所以要比链表快，而且根据我们对上面缓存行的解释知道，数组中的一个元素加载，相邻的数组元素也是会被预加载的，因此在这样的结构中，cpu无需时不时去主存加载数组中的下一个元素。而且，你可以为数组预先分配内存，使得数组对象一直存在（除非程序终止）。这就意味着不需要花大量的时间用于垃圾回收。此外，不像链表那样，需要为每一个添加到其上面的对象创造节点对象—对应的，当删除节点时，需要执行相应的内存清理操作。环形数组中的元素采用覆盖方式，避免了jvm的GC。 </p><p>其次结构作为环形，数组的大小为2的n次方，这样元素定位可以通过位运算效率会更高，这个跟一致性哈希中的环形策略有点像。在disruptor中，这个牛逼的环形结构就是RingBuffer，既然是数组，那么就有大小，而且这个大小必须是2的n次方</p><p>其实质只是一个普通的数组，只是当放置数据填充满队列（即到达2^n-1位置）之后，再填充数据，就会从0开始，覆盖之前的数据，于是就相当于一个环。</p><p>每个生产者首先通过CAS竞争获取可以写的空间，然后再进行慢慢往里放数据，如果正好这个时候消费者要消费数据，那么每个消费者都需要获取最大可消费的下标。</p><p>同时，Disruptor 不像传统的队列，分为一个队头指针和一个队尾指针，而是只有一个角标（上图的seq），它属于一个volatile变量，同时也是我们能够不用锁操作就能实现Disruptor的原因之一，而且通过缓存行补充，避免伪共享问题。该指针是通过一直自增的方式来获取下一个可写或者可读数据。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JMM和底层实现原理</title>
    <link href="undefined2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
    <url>2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="JMM基础计算机原理"><a href="#JMM基础计算机原理" class="headerlink" title="JMM基础计算机原理"></a>JMM基础计算机原理</h2><p>Java内存模型即Java Memory Model，简称JMM。JMM定义了Java 虚拟机(JVM)在计算机内存(RAM)中的工作方式。JVM是整个计算机虚拟模型，所以JMM是隶属于JVM的。Java1.5版本对其进行了重构，现在的Java仍沿用了Java1.5的版本。Jmm遇到的问题与现代计算机中遇到的问题是差不多的。</p><p>物理计算机中的并发问题，物理机遇到的并发问题与虚拟机中的情况有不少相似之处，物理机对并发的处理方案对于虚拟机的实现也有相当大的参考意义。</p><p>根据《Jeff Dean在Google全体工程大会的报告》我们可以看到</p><table><thead><tr><th>操作</th><th>响应时间</th></tr></thead><tbody><tr><td>打开一个站点</td><td>几秒</td></tr><tr><td>数据库查询一条记录（有索引）</td><td>十几毫秒</td></tr><tr><td>1.6G的CPU执行一条指令</td><td>0.6纳秒</td></tr><tr><td>从机械磁盘顺序读取1M数据</td><td>2-10毫秒</td></tr><tr><td>从机械磁盘顺序读取1M数据</td><td>0.3毫秒</td></tr><tr><td>从机械磁盘顺序读取1M数据</td><td>250微秒</td></tr><tr><td>CPU读取一次内存</td><td>100纳秒</td></tr><tr><td>1G网卡，网络传输2Kb数据</td><td>20微秒</td></tr></tbody></table><p>计算机在做一些我们平时的基本操作时，需要的响应时间是不一样的。</p><p>如果从内存中读取1M的int型数据由CPU进行累加，耗时要多久？</p><p>做个简单的计算，1M的数据，Java里int型为32位，4个字节，共有1024<em>1024/4 = 262144个整数 ，则CPU 计算耗时：262144 *0.6 = 157 286 纳秒，而我们知道从内存读取1M数据需要250000纳秒，两者虽然有差距（当然这个差距并不小，十万纳秒的时间足够CPU执行将近二十万条指令了），但是还在一个数量级上。但是，没有任何缓存机制的情况下，意味着每个数都需要从内存中读取，这样加上CPU读取一次内存需要100纳秒，262144个整数从内存读取到CPU加上计算时间一共需要262144</em>100+250000 = 26 464 400 纳秒，这就存在着数量级上的差异了。</p><p>而且现实情况中绝大多数的运算任务都不可能只靠处理器“计算”就能完成，处理器至少要与内存交互，如读取运算数据、存储运算结果等，这个I/O操作是基本上是无法消除的（无法仅靠寄存器来完成所有运算任务）。早期计算机中cpu和内存的速度是差不多的，但在现代计算机中，cpu的指令速度远超内存的存取速度,由于计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic1.png" srcset="/img/loading.gif" class=""><p>在计算机系统中，寄存器划是L0级缓存，接着依次是L1，L2，L3（接下来是内存，本地磁盘，远程存储）。越往上的缓存存储空间越小，速度越快，成本也更高；越往下的存储空间越大，速度更慢，成本也更低。从上至下，每一层都可以看做是更下一层的缓存，即：L0寄存器是L1一级缓存的缓存，L1是L2的缓存，依次类推；每一层的数据都是来至它的下一层，所以每一层的数据是下一层的数据的子集。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic2.png" srcset="/img/loading.gif" class=""><p>在现代CPU上，一般来说L0， L1，L2，L3都集成在CPU内部，而L1还分为一级数据缓存（Data Cache，D-Cache，L1d）和一级指令缓存（Instruction Cache，I-Cache，L1i），分别用于存放数据和执行数据的指令解码。每个核心拥有独立的运算处理单元、控制器、寄存器、L1、L2缓存，然后一个CPU的多个核心共享最后一层CPU缓存L3</p><h2 id="物理内存模型带来的问题"><a href="#物理内存模型带来的问题" class="headerlink" title="物理内存模型带来的问题"></a>物理内存模型带来的问题</h2><p>基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是也为计算机系统带来更高的复杂度，因为它引入了一个新的问题：缓存一致性（Cache Coherence）。在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（MainMemory）。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic3.png" srcset="/img/loading.gif" class=""><p>现代的处理器使用写缓冲区临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读/写操作的执行顺序，不一定与内存实际发生的读/写操作顺序一致。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic5.png" srcset="/img/loading.gif" class=""><p>处理器A和处理器B按程序的顺序并行执行内存访问，最终可能得到x=y=0的结果。</p><p>处理器A和处理器B可以同时把共享变量写入自己的写缓冲区（步骤A1，B1），然后从内存中读取另一个共享变量（步骤A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（步骤A3，B3）。当以这种时序执行时，程序就可以得到x=y=0的结果。</p><p>从内存操作实际发生的顺序来看，直到处理器A执行A3来刷新自己的写缓存区，写操作A1才算真正执行了。虽然处理器A执行内存操作的顺序为：A1→A2，但内存操作实际发生的顺序却是A2→A1。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic4.png" srcset="/img/loading.gif" class=""><p>如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI（Illinois Protocol）、MOSI、Synapse、Firefly及Dragon Protocol等。</p><h2 id="伪共享"><a href="#伪共享" class="headerlink" title="伪共享"></a>伪共享</h2><p>前面我们已经知道，CPU中有好几级高速缓存。但是CPU缓存系统中是以缓存行（cache line）为单位存储的。目前主流的CPU Cache的Cache Line大小都是64Bytes。Cache Line可以简单的理解为CPU Cache中的最小缓存单位，今天的CPU不再是按字节访问内存，而是以64字节为单位的块(chunk)拿取，称为一个缓存行(cache line)。当读一个特定的内存地址，整个缓存行将从主存换入缓存。</p><p>一个缓存行可以存储多个变量（存满当前缓存行的字节数）；而CPU对缓存的修改又是以缓存行为最小单位的，在多线程情况下，如果同时修改一个缓存行中的变量，就会无意中影响彼此的性能，这就是伪共享（False Sharing）。</p><p>为了避免伪共享，我们可以使用数据填充的方式来避免，即单个数据填充满一个CacheLine。这本质是一种空间换时间的做法。但是这种方式在Java7以后可能失效。</p><p>Java8中已经提供了官方的解决方案，Java8中新增了一个注解@sun.misc.Contended。</p><p>比如JDK的ConcurrentHashMap中就有使用</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic6.png" srcset="/img/loading.gif" class=""><h2 id="Java内存模型（JMM）"><a href="#Java内存模型（JMM）" class="headerlink" title="Java内存模型（JMM）"></a>Java内存模型（JMM）</h2><p>从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic9.png" srcset="/img/loading.gif" class=""><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic7.png" srcset="/img/loading.gif" class=""><h2 id="Java内存模型带来的问题"><a href="#Java内存模型带来的问题" class="headerlink" title="Java内存模型带来的问题"></a>Java内存模型带来的问题</h2><h3 id="可见性问题"><a href="#可见性问题" class="headerlink" title="可见性问题"></a>可见性问题</h3><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic8.png" srcset="/img/loading.gif" class=""><p>左边CPU中运行的线程从主存中拷贝共享对象obj到它的CPU缓存，把对象obj的count变量改为2。但这个变更对运行在右边CPU中的线程不可见，因为这个更改还没有flush到主存中。</p><p>在多线程的环境下，如果某个线程首次读取共享变量，则首先到主内存中获取该变量，然后存入工作内存中，以后只需要在工作内存中读取该变量即可。同样如果对该变量执行了修改的操作，则先将新值写入工作内存中，然后再刷新至主内存中。但是什么时候最新的值会被刷新至主内存中是不太确定，一般来说会很快，但具体时间不知。</p><p>要解决共享对象可见性这个问题，我们可以使用volatile关键字或者是加锁。</p><h3 id="竞争问题"><a href="#竞争问题" class="headerlink" title="竞争问题"></a>竞争问题</h3><p>线程A和线程B共享一个对象obj。假设线程A从主存读取Obj.count变量到自己的CPU缓存，同时，线程B也读取了Obj.count变量到它的CPU缓存，并且这两个线程都对Obj.count做了加1操作。此时，Obj.count加1操作被执行了两次，不过都在不同的CPU缓存中。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic10.png" srcset="/img/loading.gif" class=""><p>如果这两个加1操作是串行执行的，那么Obj.count变量便会在原始值上加2，最终主存中的Obj.count的值会是3。然而图中两个加1操作是并行的，不管是线程A还是线程B先flush计算结果到主存，最终主存中的Obj.count只会增加1次变成2，尽管一共有两次加1操作。 要解决上面的问题我们可以使用java synchronized代码块</p><h3 id="重排序问题"><a href="#重排序问题" class="headerlink" title="重排序问题"></a>重排序问题</h3><h4 id="重排序类型"><a href="#重排序类型" class="headerlink" title="重排序类型"></a>重排序类型</h4><p>除了共享内存和工作内存带来的问题，还存在重排序的问题：在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型。</p><ol><li><p>编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。</p></li><li><p>指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-LevelParallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。</p></li><li><p>内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。</p></li></ol><h4 id="数据依赖性"><a href="#数据依赖性" class="headerlink" title="数据依赖性"></a>数据依赖性</h4><p>数据依赖性：如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分为下列3种类型</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic11.png" srcset="/img/loading.gif" class=""><p>上面3种情况，只要重排序两个操作的执行顺序，程序的执行结果就会被改变。</p><p>例如</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic12.png" srcset="/img/loading.gif" class=""><p>很明显，A和C存在数据依赖，B和C也存在数据依赖，而A和B之间不存在数据依赖，如果重排序了A和C或者B和C的执行顺序，程序的执行结果就会被改变。</p><p>很明显，不管如何重排序，都必须保证代码在单线程下的运行正确，连单线程下都无法正确，更不用讨论多线程并发的情况，所以就提出了一个as-if-serial的概念。</p><p>as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。</p><p>为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。（强调一下，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。）但是，如果操作之间不存在数据依赖关系，这些操作依然可能被编译器和处理器重排序。</p><p>A和C之间存在数据依赖关系，同时B和C之间也存在数据依赖关系。因此在最终执行的指令序列中，C不能被重排序到A和B的前面（C排到A和B的前面，程序的结果将会被改变）。但A和B之间没有数据依赖关系，编译器和处理器可以重排序A和B之间的执行顺序。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic13.png" srcset="/img/loading.gif" class=""><p>as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器、runtime和处理器可以让我们感觉到：单线程程序看起来是按程序的顺序来执行的。asif-serial语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。</p><h4 id="控制依赖性"><a href="#控制依赖性" class="headerlink" title="控制依赖性"></a>控制依赖性</h4><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic14.png" srcset="/img/loading.gif" class=""><p>上述代码中，flag变量是个标记，用来标识变量a是否已被写入，在use方法中变量i的赋值依赖if (flag)的判断，这里就叫控制依赖，如果发生了重排序，结果就不对了。</p><p>操作1和操作2没有数据依赖关系，编译器和处理器可以对这两个操作重排序；同样，操作3和操作4没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。操作3和操作4则存在所谓<strong>控制依赖关系</strong>。</p><p>在程序中，当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算a*a，然后把计算结果临时保存到一个名为重排序缓冲（Reorder Buffer，ROB）的硬件缓存中。当操作3的条件判断为真时，就把该计算结果写入变量i中。猜测执行实质上对操作3和4做了重排序，问题在于这时候，a的值还没被线程A赋值。</p><p>在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是as-if-serial语义允许对存在控制依赖的操作做重排序的原因）。</p><p>但是对多线程来说就完全不同了：这里假设有两个线程A和B，A首先执行init ()方法，随后B线程接着执行use ()方法。线程B在执行操作4时，能否看到线程A在操作1对共享变量a的写入呢？答案是：不一定能看到。</p><p>让我们先来看看，当操作1和操作2重排序，操作3和操作4重排序时，可能会产生什么效果？操作1和操作2做了重排序。程序执行时，线程A首先写标记变量flag，随后线程B读这个变量。由于条件判断为真，线程B将读取变量a。此时，变量a还没有被线程A写入，这时就会发生错误！</p><p>所以在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。</p><h3 id="解决在并发下的问题"><a href="#解决在并发下的问题" class="headerlink" title="解决在并发下的问题"></a>解决在并发下的问题</h3><h4 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h4><p>Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序，从而让程序按我们预想的流程去执行。</p><ol><li><p>保证特定操作的执行顺序。</p></li><li><p>影响某些数据（或则是某条指令的执行结果）的内存可见性。</p></li></ol><p>编译器和CPU能够重排序指令，保证最终相同的结果，尝试优化性能。插入一条Memory Barrier会告诉编译器和CPU：不管什么指令都不能和这条Memory Barrier指令重排序。</p><p>Memory Barrier所做的另外一件事是强制刷出各种CPU cache，如一个Write-Barrier（写入屏障）将刷出所有在Barrier之前写入 cache 的数据，因此，任何CPU上的线程都能读取到这些数据的最新版本。</p><p>JMM把内存屏障指令分为4类</p><table><thead><tr><th>屏障类型</th><th>指令示例</th><th>说明</th></tr></thead><tbody><tr><td>LoadLoad Barriers</td><td>Load1;LoadLoad;Load2</td><td>确保Load1数据的装载，之前于Load2及所有后续装载指令的装载。</td></tr><tr><td>StoreStore Barriers</td><td>Store1;StoreStore;Store2</td><td>确保Store1数据对其他处理器可见（刷新到内存），之前于Store2及所有后续存储指令的存储。</td></tr><tr><td>LoadStore Barriers</td><td>Load1;LoadStore;Store2</td><td>确保Load1数据装载，之前于Store2及所有后续存储指令刷新到内存。</td></tr><tr><td>StoreLoad Barriers</td><td>Store1;StoreLoad;Load2</td><td>确保Strore1数据对其他处理器可见（刷新到内存），之前于Load2及所有后续装载指令的装载。StoreLoad Barriers会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令。</td></tr></tbody></table><p>StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。现代的多处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。</p><h4 id="临界区"><a href="#临界区" class="headerlink" title="临界区"></a>临界区</h4><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic15.png" srcset="/img/loading.gif" class=""><p>JMM会在退出临界区和进入临界区这两个关键时间点做一些特别处理，使得多线程在这两个时间点按某种顺序执行。</p><p>临界区内的代码则可以重排序（但JMM不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。虽然线程A在临界区内做了重排序，但由于监视器互斥执行的特性，这里的线程B根本无法“观察”到线程A在临界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。</p><p>因为临界区内的代码依然会重排序，所以线程安全的单例模式中一般的双重检查并不能保证真正的线程安全。</p><h2 id="Happens-Before"><a href="#Happens-Before" class="headerlink" title="Happens-Before"></a>Happens-Before</h2><p>在Java 规范提案中为让大家理解内存可见性的这个概念，提出了happens-before的概念来阐述操作之间的内存可见性。对应Java程序员来说，理解happens-before是理解JMM的关键。</p><p>JMM这么做的原因是：程序员对于这两个操作是否真的被重排序并不关心，程序员关心的是程序执行时的语义不能被改变（即执行结果不能被改变）。因此，happens-before关系本质上和as-if-serial语义是一回事。as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证<strong>正确同步</strong>的多线程程序的执行结果不被改变。</p><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>用happens-before的概念来阐述操作之间的内存可见性。在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系 。 </p><p>两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）</p><h3 id="加深理解"><a href="#加深理解" class="headerlink" title="加深理解"></a>加深理解</h3><ol><li><p>站在Java程序员的角度来说：JMM保证，如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。</p></li><li><p>站在编译器和处理器的角度来说：JMM允许，两个操作之间存在happens-before关系，不要求Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序是允许的。</p></li></ol><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><pre><code>double x = 0.03;  //Adouble y = 0.01;  //Bdouble z = x*x*y; //C</code></pre><p>此时代码的逻辑顺序：</p><ol><li><p>A happens-before B</p></li><li><p>B happens-before C</p></li><li><p>A happens-before C</p></li></ol><p>但是仔细考察，2、3是必需的，而1并不是必需的，因此JMM对这三个happens-before关系的处理就分为两类：</p><ol><li><p>会改变程序执行结果的重排序</p></li><li><p>不会改变程序执行结果的重排序</p></li></ol><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic16.png" srcset="/img/loading.gif" class=""><p>JMM对这两种不同性质的重排序，采用了不同的策略，如下：</p><ol><li><p>对于会改变程序执行结果的重排序，JMM要求编译器和处理器必须禁止这种重排序；</p></li><li><p>对于不会改变程序执行结果的重排序，JMM对编译器和处理器不做要求。</p></li></ol><p>于是，站在我们程序员的角度，看起来这个三个操作满足了happens-before关系，而站在编译器和处理器的角度，进行了重排序，而排序后的执行结果，也是满足happens-before关系的。</p><h3 id="Happens-Before规则"><a href="#Happens-Before规则" class="headerlink" title="Happens-Before规则"></a>Happens-Before规则</h3><p>JMM为我们提供了以下的Happens-Before规则：</p><ol><li><p>程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。</p></li><li><p>监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。</p></li><li><p>volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。</p></li><li><p>传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。</p></li><li><p>start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。</p></li><li><p>join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。 </p></li><li><p>线程中断规则：对线程interrupt方法的调用happens-before于被中断线程的代码检测到中断事件的发生。</p></li></ol><h2 id="volatile详解"><a href="#volatile详解" class="headerlink" title="volatile详解"></a>volatile详解</h2><h3 id="volatile特性"><a href="#volatile特性" class="headerlink" title="volatile特性"></a>volatile特性</h3><p>可以把对volatile变量的单个读/写，看成是使用同一个锁对这些单个读/写操作做了同步</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic17.png" srcset="/img/loading.gif" class=""><p>可以看成</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic18.png" srcset="/img/loading.gif" class=""><p>所以volatile变量自身具有下列特性：</p><ul><li><p>可见性。对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。</p></li><li><p>原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。</p></li></ul><h3 id="volatile的内存语义"><a href="#volatile的内存语义" class="headerlink" title="volatile的内存语义"></a>volatile的内存语义</h3><p>内存语义：可以简单理解为 volatile，synchronize，atomic，lock 之类的在 JVM 中的内存方面实现原则。</p><p>volatile写的内存语义如下：<br>当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。 </p><p>volatile读的内存语义如下：<br>当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。 </p><p>所以对于代码</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic19.png" srcset="/img/loading.gif" class=""><p>如果我们将<strong>flag</strong>变量以<strong>volatile</strong>关键字修饰，那么实际上：线程A在写flag变量后，本地内存A中被线程A更新过的两个共享变量的值都被刷新到主内存中。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic20.png" srcset="/img/loading.gif" class=""><p>在读flag变量后，本地内存B包含的值已经被置为无效。此时，线程B必须从主内存中读取共享变量。线程B的读取操作将导致本地内存B与主内存中的共享变量的值变成一致。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic21.png" srcset="/img/loading.gif" class=""><p>如果我们把volatile写和volatile读两个步骤综合起来看的话，在读线程B读一个volatile变量后，写线程A在写这个volatile变量之前所有可见的共享变量的值都将立即变得对读线程B可见。</p><h3 id="为何volatile不是线程安全的"><a href="#为何volatile不是线程安全的" class="headerlink" title="为何volatile不是线程安全的"></a>为何volatile不是线程安全的</h3><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic22.png" srcset="/img/loading.gif" class=""><p>由于volatile只对任意单个volatile变量的读/写具有原子性，但volatile++这种复合操作并不具有原子性，所以仅仅依靠volatile而不对使用过程进行同步控制是不能保证线程安全的。</p><h3 id="volatile内存语义的实现"><a href="#volatile内存语义的实现" class="headerlink" title="volatile内存语义的实现"></a>volatile内存语义的实现</h3><h4 id="volatile重排序规则表"><a href="#volatile重排序规则表" class="headerlink" title="volatile重排序规则表"></a>volatile重排序规则表</h4><table><thead><tr><th>第一个操作/第二个操作</th><th>普通读/写</th><th>volatile读</th><th>volatile写</th></tr></thead><tbody><tr><td><strong>普通读/写</strong></td><td></td><td></td><td>不允许</td></tr><tr><td><strong>volatile读</strong></td><td>不允许</td><td>不允许</td><td>不允许</td></tr><tr><td><strong>volatile写</strong></td><td></td><td>不允许</td><td>不允许</td></tr></tbody></table><h4 id="volatile的内存屏障"><a href="#volatile的内存屏障" class="headerlink" title="volatile的内存屏障"></a>volatile的内存屏障</h4><p>在Java中对于volatile修饰的变量，编译器在生成字节码时，会在指令序列中插入<strong>内存屏障</strong>来禁止特定类型的处理器重排序问题。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic23.png" srcset="/img/loading.gif" class=""><p>storestore屏障：对于这样的语句store1;storestore;store2，在store2及后续写入操作执行前，保证store1的写入操作对其它处理器可见。（也就是说如果出现storestore屏障，那么store1指令一定会在store2之前执行，CPU不会store1与store2进行重排序）</p><p>storeload屏障：对于这样的语句store1;storeload;load2，在load2及后续所有读取操作执行前，保证store1的写入对所有处理器可见。（也就是说如果出现storeload屏障，那么store1指令一定会在load2之前执行，CPU不会对store1与load2进行重排序）</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic24.png" srcset="/img/loading.gif" class=""><p>在每个volatile读操作的后面插入LoadLoad屏障、loadstore屏障。</p><p>loadload屏障：对于这样的语句load1; loadload; load2，在load2及后续读取操作要读取的数据被访问前，保证load1要读取的数据被读取完毕。（也就是说，如果出现loadload屏障，那么load1指令一定会在load2之前执行，CPU不会对load1与load2进行重排序） </p><p>loadstore屏障：对于这样的语句load1; loadstore; store2，在store2及后续写入操作被刷出前，保证load1要读取的数据被读取完毕。（也就是说，如果出现loadstore屏障，那么load1指令一定会在store2之前执行，CPU不会对load1与store2进行重排序）</p><h3 id="volatile的实现原理"><a href="#volatile的实现原理" class="headerlink" title="volatile的实现原理"></a>volatile的实现原理</h3><p>通过对OpenJDK中的unsafe.cpp源码的分析，会发现被volatile关键字修饰的变量会存在一个“lock:”的前缀。</p><p>Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。</p><p>同时该指令会将当前处理器缓存行的数据直接写会到系统内存中，且这个写回内存的操作会使在其他CPU里缓存了该地址的数据无效。</p><p>在具体的执行上，它先对总线和缓存加锁，然后执行后面的指令，最后释放锁后会把高速缓存中的脏数据全部刷新回主内存。在Lock锁住总线的时候，其他CPU的读写请求都会被阻塞，直到锁释放。</p><h2 id="final的内存语义"><a href="#final的内存语义" class="headerlink" title="final的内存语义"></a>final的内存语义</h2><h3 id="编译器和处理器要遵守的两个重排序规则"><a href="#编译器和处理器要遵守的两个重排序规则" class="headerlink" title="编译器和处理器要遵守的两个重排序规则"></a>编译器和处理器要遵守的两个重排序规则</h3><ol><li><p><strong>在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。</strong></p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic25.png" srcset="/img/loading.gif" class=""><p>我们假设一个线程A执行writer方法，随后另一个线程B执行reader方法。</p><p>write()方法中只包含一行代码 <em>obj</em> = new FinalMemory();。这一行代码包含两个步骤：</p><ol><li>构造一个FinalMemory类型的对象。</li><li>把这个对象的引用赋值给引用变量obj。</li></ol><p>假设线程B读对象引用（FinalMemory object = obj）与读对象的成员域之间（int a = object.i;int b = object.j）没有重排序，下面的图是一种可能的执行时序：</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic26.png" srcset="/img/loading.gif" class=""><p>从上面可能的时序图中我们可以看到，读普通域被编译器重排序到了构造函数执行之前，读线程B错误的读取了普通变量i初始化之前的值。而写final域的操作，被写final域的重排序规则“限制”到了构造函数之内，读线程B正确读取了final变量初始化之后的值。</p><p>总结：写final域的重排序规则可以确保在对象引用为任意线程可见之前，对象的final域已经被正常的初始化了，而普通域不具有这样的保证。</p></li><li><p><strong>初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。</strong></p><p>在一个线程中，初次读对象引用与初次读该对象包含的final域，JMM禁止处理器重排序这两个操作。编译器会在读final域操作的前面插入一个LoadLoad屏障。</p><p>reader()方法包含3个步骤：</p><ol><li><p>初次读引用变量obj</p></li><li><p>初次读引用变量obj指向对象的普通域 i</p></li><li><p>初次读引用变量obj指向对象的final域 j</p></li></ol><p>我们假设写线程A没有发生任何重排序，则下图是一种可能的时序：</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic27.png" srcset="/img/loading.gif" class=""><p>读对象的普通域的操作被处理器重排序到读对象引用之前。读普通域时，该域还没有被线程A写入，所以上面的是一个错误的读取操作。但是读final域的重排序规则把读对象final域的操作“限定”在读对象引用之后，该final域已经被A线程初始化了，是一个正确的读取操作。</p><p>总结：读final域的重排序规则可以确保在读一个对象的final域之前，一定会先读包含这个final域的对象的引用.</p></li></ol><h3 id="final域为引用类型"><a href="#final域为引用类型" class="headerlink" title="final域为引用类型"></a>final域为引用类型</h3><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic28.png" srcset="/img/loading.gif" class=""><p>在上面的代码中，final域是一个引用类型，它引用了一个int类型的数组，对于引用类型，写final域的重排序规则对编译器和处理器增加了一下的约束：在构造函数内对一个final引用的对象的成员域的写入，与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。</p><p>我们假设线程A先执行write0操作，执行完后线程B执行write1操作，执行完后线程C执行reader操作，下图是一种可能的执行时序：</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic29.png" srcset="/img/loading.gif" class=""><p>1是对final域的写入，2是对这个final域引用的对象的成员域的写入，3是把被构造的对象的引用赋值给某个引用变量。这里除了前面提到的1不能和3重排序外，2和3也不能重排序。</p><p>JMM可以确保读线程C至少能看到写线程A在构造函数中对final引用对象的成员域的写入。即C至少能看到数组下标0的值为1。而写线程B对数组元素的写入，读线程C可能看得到，也可能看不到。JMM不保证线程B的写入对读线程C可见，因为写线程B和读线程C之间存在数据竞争，此时的执行结果不可预知。</p><p>如果想要确保读线程C看到写线程B对数组元素的写入，写线程B和读线程C之间需要使用同步（lock或volatile）来确保内存可见性。</p><h3 id="final引用不能从构造函数内逃逸"><a href="#final引用不能从构造函数内逃逸" class="headerlink" title="final引用不能从构造函数内逃逸"></a>final引用不能从构造函数内逃逸</h3><p>写final域的重排序规则可以确保：在引用变量为任意线程可见之前，该引用变量指向的对象的final域已经在构造函数中被正确初始化过了。其实，要得到这个效果，还需要一个保证：在构造函数内部，不能让这个被构造对象的引用为其他线程所见，也就是对象引用不能在构造函数中逃逸。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic30.png" srcset="/img/loading.gif" class=""><p>假设一个线程A执行writer()方法，另一个线程B执行reader()方法。这里的操作2使得对象还未完成构造前就为线程B可见。即使这里的操作2是构造函数的最后一步，且在程序中操作2排在操作1后面，执行read()方法的线程仍然可能无法看到final域被初始化后的值，因为这里的操作1和操作2之间可能被重排序。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic31.png" srcset="/img/loading.gif" class=""><p>因此在构造函数返回前，被构造对象的引用不能为其他线程所见，因为此时的final域可能还没有被初始化。</p><h3 id="final语义的实现"><a href="#final语义的实现" class="headerlink" title="final语义的实现"></a>final语义的实现</h3><p>会要求编译器在final域的写之后，构造函数return之前插入一个StoreStore障屏。</p><p>读final域的重排序规则要求编译器在读final域的操作前面插入一个LoadLoad屏障</p><h2 id="锁的内存语义"><a href="#锁的内存语义" class="headerlink" title="锁的内存语义"></a>锁的内存语义</h2><p>当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中。</p><p>当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。 </p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic32.png" srcset="/img/loading.gif" class=""><p>如果我们回顾第一章的VolatileCase，我们知道，为了让子线程可以及时看到<em>ready</em>变量的修改，我们需要将ready变量以volatile来修饰。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic33.png" srcset="/img/loading.gif" class=""><p>但是，当我们将程序做如下改造</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic34.png" srcset="/img/loading.gif" class=""><p>我们可以看见子线程同样可以中止，为何？我们观察System.out.println的实现，</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic35.png" srcset="/img/loading.gif" class=""><p>结合前面锁的内存语义，我们可以知道，当进入<strong>synchronized</strong>语句块时，子线程会被强制从主内存中读取共享变量，其中就包括了ready变量，所以子线程同样中止了。</p><h2 id="synchronized的实现原理"><a href="#synchronized的实现原理" class="headerlink" title="synchronized的实现原理"></a>synchronized的实现原理</h2><p>Synchronized在JVM里的实现都是基于进入和退出Monitor对象来实现方法同步和代码块同步，虽然具体实现细节不一样，但是都可以通过成对的MonitorEnter和MonitorExit指令来实现。</p><p>对同步块，MonitorEnter指令插入在同步代码块的开始位置，当代码执行到该指令时，将会尝试获取该对象Monitor的所有权，即尝试获得该对象的锁，而monitorExit指令则插入在方法结束处和异常处，JVM保证每个MonitorEnter必须有对应的MonitorExit。</p><p>对同步方法，从同步方法反编译的结果来看，方法的同步并没有通过指令monitorenter和monitorexit来实现，相对于普通方法，其常量池中多了ACC_SYNCHRONIZED标示符。</p><p>JVM就是根据该标示符来实现方法的同步的：当方法被调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。</p><p>synchronized使用的锁是存放在Java对象头里面。</p><table><thead><tr><th>长度</th><th>内容</th><th>说明</th></tr></thead><tbody><tr><td>32/64bit</td><td>Mark Word</td><td>存储对象的hashCode或锁信息等</td></tr><tr><td>32/64bit</td><td>Class Metadata Address</td><td>存储对象类型的数据的指针</td></tr><tr><td>32/64bit</td><td>Array length</td><td>数组的长度（如果当前对象是数组）</td></tr></tbody></table><p>具体位置是对象头里面的MarkWord，MarkWord里默认数据是存储对象的HashCode等信息，</p><table><thead><tr><th>锁状态</th><th>25bit</th><th>4bit</th><th>1bit是否是偏向锁</th><th>2bit锁标识位</th></tr></thead><tbody><tr><td>无锁状态</td><td>对象的hashCode</td><td>对象分代年龄</td><td>0</td><td>0</td></tr></tbody></table><p>但是会随着对象的运行改变而发生变化，不同的锁状态对应着不同的记录存储方式</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic36.png" srcset="/img/loading.gif" class=""><h2 id="了解各种锁"><a href="#了解各种锁" class="headerlink" title="了解各种锁"></a>了解各种锁</h2><h3 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。</p><p>但是线程自旋是需要消耗CPU的，说白了就是让CPU在做无用功，线程不能一直占用CPU自旋做无用功，所以需要设定一个自旋等待的最大时间。</p><p>如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。</p><h4 id="自旋锁的优缺点"><a href="#自旋锁的优缺点" class="headerlink" title="自旋锁的优缺点"></a>自旋锁的优缺点</h4><p>在锁的竞争不激烈，且占用锁的同步块执行时间非常短的情况下，自旋的消耗小于线程阻塞挂起操作的消耗，这时自旋锁能够尽可能的减少线程的阻塞，提升代码块性能。</p><p>但是如果锁的竞争激烈，或者占用锁的同步块执行时间比较长，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用cpu做无用功，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要cup的线程又不能获取到cpu，造成cpu的浪费。</p><h4 id="自旋锁时间阈值"><a href="#自旋锁时间阈值" class="headerlink" title="自旋锁时间阈值"></a>自旋锁时间阈值</h4><p>自旋锁的目的是为了占着CPU的资源不释放，等到获取到锁立即进行处理。但是如何去选择自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用CPU资源，进而会影响整体系统的性能。因此自旋次数很重要</p><p>JVM对于自旋次数的选择，jdk1.5默认为10次，在1.6引入了适应性自旋锁，适应性自旋锁意味着自旋的时间不在是固定的了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间。</p><p>JDK1.6中-XX:+UseSpinning开启自旋锁； JDK1.7后，去掉此参数，由jvm控制；</p><h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，只有一个线程访问锁，不存在多线程竞争的情况，则线程是不需要触发同步的，减少加锁／解锁的一些CAS操作（比如等待队列的一些CAS操作），这种情况下，就会给线程加一个偏向锁。 如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。它通过消除资源无竞争情况下的同步原语，进一步提高了程序的运行性能。</p><h4 id="引入背景"><a href="#引入背景" class="headerlink" title="引入背景"></a>引入背景</h4><p>大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁，减少不必要的CAS操作。</p><h4 id="锁的状态"><a href="#锁的状态" class="headerlink" title="锁的状态"></a>锁的状态</h4><p>一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，目的是为了提高获得锁和释放锁的效率。</p><h4 id="偏向锁获取过程"><a href="#偏向锁获取过程" class="headerlink" title="偏向锁获取过程"></a>偏向锁获取过程</h4><ol><li><p>访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，确认为可偏向状态。</p></li><li><p>如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤5，否则进入步骤3。</p></li><li><p>如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。</p></li><li><p>如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the word）</p></li><li><p>执行同步代码。</p></li></ol><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic37.png" srcset="/img/loading.gif" class=""><h4 id="偏向锁的释放"><a href="#偏向锁的释放" class="headerlink" title="偏向锁的释放"></a>偏向锁的释放</h4><p>偏向锁的撤销在上述第四步骤中有提到。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放偏向锁，线程不会主动去释放偏向锁。偏向锁的撤销需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。</p><h4 id="偏向锁的适用场景"><a href="#偏向锁的适用场景" class="headerlink" title="偏向锁的适用场景"></a>偏向锁的适用场景</h4><p>始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the word操作； </p><p>在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向所的时候会导致进入安全点，安全点会导致stw，导致性能下降，这种情况下应当禁用。</p><h4 id="jvm开启-关闭偏向锁"><a href="#jvm开启-关闭偏向锁" class="headerlink" title="jvm开启/关闭偏向锁"></a>jvm开启/关闭偏向锁</h4><p>开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0</p><p>关闭偏向锁：-XX:-UseBiasedLocking</p><h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>轻量级锁是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁。</p><h4 id="轻量级锁的加锁过程"><a href="#轻量级锁的加锁过程" class="headerlink" title="轻量级锁的加锁过程"></a>轻量级锁的加锁过程</h4><ol><li><p>在代码进入同步块的时候，如果同步对象锁状态为无锁状态且不允许进行偏向（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。</p></li><li><p>拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock record里的owner指针指向object mark word。</p></li><li><p>如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态</p></li><li><p>如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，当竞争线程尝试占用轻量级锁失败多次之后，轻量级锁就会膨胀为重量级锁，重量级线程指针指向竞争线程，竞争线程也会阻塞，等待轻量级线程释放锁后唤醒他。锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。</p></li></ol><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic38.png" srcset="/img/loading.gif" class=""><h3 id="不同锁的比较"><a href="#不同锁的比较" class="headerlink" title="不同锁的比较"></a>不同锁的比较</h3><table><thead><tr><th>锁</th><th>优点</th><th>缺点</th><th>适用场景</th></tr></thead><tbody><tr><td>偏向锁</td><td>加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。</td><td>如果线程间存在锁竞争,会带来额外的锁撤销的消耗。</td><td>适用于只有一个线程访问同步块场景。</td></tr><tr><td>轻量级锁</td><td>竞争的线程不会阻塞，提高了程序的响应速度。</td><td>如果线程始终得不到锁，使用自旋会消耗CPU。</td><td>追求响应时间。同步块执行速度非常快</td></tr><tr><td>重量级锁</td><td>线程竞争不使用自旋，不会消耗CPU.</td><td>线程阻塞,响应时间缓慢。</td><td>追求吞吐量。同步块执行速度较长。</td></tr></tbody></table><h3 id="JDK对锁的更多优化措施"><a href="#JDK对锁的更多优化措施" class="headerlink" title="JDK对锁的更多优化措施"></a>JDK对锁的更多优化措施</h3><h4 id="逃逸分析"><a href="#逃逸分析" class="headerlink" title="逃逸分析"></a>逃逸分析</h4><p>如果证明一个对象不会逃逸方法外或者线程外，则可针对此变量进行优化。</p><p>同步消除synchronization Elimination，如果一个对象不会逃逸出线程，则对此变量的同步措施可消除。</p><h4 id="锁消除和粗化"><a href="#锁消除和粗化" class="headerlink" title="锁消除和粗化"></a>锁消除和粗化</h4><p>锁消除：虚拟机的运行时编译器在运行时如果检测到一些要求同步的代码上不可能发生共享数据竞争，则会去掉这些锁。</p><p>锁粗化：将临近的代码块用同一个锁合并起来。</p><p>消除无意义的锁获取和释放，可以提高程序运行性能。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>实战项目</title>
    <link href="undefined2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/"/>
    <url>2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/</url>
    
    <content type="html"><![CDATA[<h2 id="可查询进度的并发任务执行框架"><a href="#可查询进度的并发任务执行框架" class="headerlink" title="可查询进度的并发任务执行框架"></a>可查询进度的并发任务执行框架</h2><h3 id="需求的产生和分析"><a href="#需求的产生和分析" class="headerlink" title="需求的产生和分析"></a>需求的产生和分析</h3><p>公司里有两个项目组，考试组有批量的离线文档要生成，题库组则经常有批量的题目进行排重和根据条件批量修改题目的内容。</p><p>架构组通过对实际的上线产品进行用户调查，发现这些功能在实际使用时，用户都反应速度很慢，而且提交任务后，不知道任务的进行情况，做没做？做到哪一步了？有哪些成功？哪些失败了？都一概不知道。</p><p>架构组和实际的开发人员沟通，他们都说，因为前端提交任务到Web后台以后，是一次要处理多个文档和题目，所以速度快不起来。提示用多线程进行改进，实际的开发人员表示多线程没有用过，不知道如何使用，也担心用不好。综合以上情况，架构组决定在公司的基础构件库中提供一个并发任务执行框架，以解决上述用户和业务开发人员的痛点：</p><ol><li><p>对批量型任务提供统一的开发接口</p></li><li><p>在使用上尽可能的对业务开发人员友好  </p></li><li><p>要求可以查询批量任务的执行进度</p></li></ol><h3 id="如何实现"><a href="#如何实现" class="headerlink" title="如何实现"></a>如何实现</h3><p>要实现这么一个批量任务并发执行的框架，我们来分析一下我们要做些什么？</p><ol><li><p>提高批量任务性能。必然的我们要使用java里的多线程，为了在使用上尽可能的对业务开发人员友好和简单，需要屏蔽一些底层java并发编程中的细节，让他们不需要去了解并发容器，阻塞队列，异步任务，线程安全等等方面的知识，只要专心于自己的业务处理即可。</p></li><li><p>每个批量任务拥有自己的上下文环境。因为一个项目组里同时要处理的批量任务可能有多个，比如考试组，可能就会有不同的学校的批量的离线文档生成，而题库组则会不同的学科都会有老师同时进行工作，因此需要一个并发安全的容器保存每个任务的属性信息，</p></li><li><p>自动清除已完成和过期任务。因为要提供进度查询，系统需要在内存中维护每个任务的进度信息以供查询，但是这种查询又是有时间限制的，一个任务完成一段时间后，就不再提供进度查询了，则就需要我们自动清除已完成和过期任务，用定时轮询吗？</p></li></ol><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic1.png" srcset="/img/loading.gif" class=""><h3 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h3><ol><li><p>框架使用者业务方法的执行结果共有三种，成功：按预想的流程出了结果；失败：按预想的流程没出结果；异常：没按预想的流程抛出了预料之外的错误。因此我们定义了一个枚举，表示这三种情况。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic2.png" srcset="/img/loading.gif" class=""><p>业务方法的返回值有很多种可能，基本类型、系统定义的对象类型、框架使用者自定义的对象类型都是存在的，所以需要用泛型来说表示这个结果。如果方法执行失败了，还需要告诉用户或者框架使用者失败的原因，还需要再定义一个任务的执行结束后的返回值类。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic3.png" srcset="/img/loading.gif" class=""></li><li><p>定义执行业务方法的接口，框架就只执行这个方法，框架的使用者都应该来实现这个接口，由于用户业务的数据多样性，方法的参数也应该用泛型。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic4.png" srcset="/img/loading.gif" class=""></li><li><p>提供一种封装机制，让框架使用者可以将用户在前端提交的工作（JOB）提交给这个封装机制，当用户的需要查询进度的时候，也从这个封装机制中取得，同时封装机制内部也要负责清除已完成任务。</p><p>在这个封装机制里我们定义了一个类JobInfo，抽象了对用户工作（JOB）的封装，一个工作可以包含多个子任务（TASK），这个JobInfo中就包括了这个工作的相关信息，比如工作名，用以区分框架中唯一的工作，也可以避免重复提交，也方便查询时快速定位工作，除了工作名以外，工作中任务（TASK）的列表，工作中任务的处理器都在其中定义。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic5.png" srcset="/img/loading.gif" class=""><p>同时JobInfo还有相当多的关于这个工作的方法，比如查询工作进度，查询每个任务的处理结果，记录每个任务的处理结果等等</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic6.png" srcset="/img/loading.gif" class=""><p>负责清除已完成任务，我们则交给CheckJobProcesser类来完成，定时轮询的机制不够优雅，因此我们选用了DelayQueue来实现这个功能</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic7.png" srcset="/img/loading.gif" class=""><p>并且在其中定义了清除已完成任务的Runnable和相关的工作线程。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic8.png" srcset="/img/loading.gif" class=""></li><li><p>框架的主体类则是PendingJobPool，这也是框架使用者主要使用的类。这个类主要负责调度，例如工作（JOB）和任务（TASK）的提交，任务（TASK）的保存，任务（TASK）的并发执行，工作进度的查询接口和任务执行情况的查询等等。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic9.png" srcset="/img/loading.gif" class=""><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic10.png" srcset="/img/loading.gif" class=""></li></ol><h3 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h3><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic11.png" srcset="/img/loading.gif" class=""><p>如果需要spring集成的话，某些单例化的部分就不需要了。</p><h2 id="项目优化"><a href="#项目优化" class="headerlink" title="项目优化"></a>项目优化</h2><h3 id="项目背景和问题"><a href="#项目背景和问题" class="headerlink" title="项目背景和问题"></a>项目背景和问题</h3><p>这个项目来自为电信教育系统设计开发的一套自适应的考试学习系统，面向的用户主要是职业学院的的老师和学生以及短时间脱产学习的在职人员。什么叫自适应呢？就是当时提出一种教育理念，对学员的学习要求经常考试进行检查，学员的成绩出来以后，老师会要求系统根据每个学员的考卷上错误的题目从容量为10万左右的题库中抽取题目，为每个学员生成一套各自个性化的考后复习和练习的离线练习册。所以，每次考完试，特别是比较大型的考试后，要求生成的离线文档数量是比较多的，一个考试2000多人，就要求生成2000多份文档。当时我们在做这个项目的时候，因为时间紧，人员少，很快做出第一版就上线运营了。</p><p>当然，大家可以想到，问题是很多的，但是反应最大，用户最不满意的就是这个离线文档生成的功能，用户最不满意的点：离线文档生成的速度非常慢，慢到什么程度呢？一份离线文档的生成平均时长在50~55秒左右，遇到成绩不好的学生，文档内容多的，生成甚至需要3分钟，大家可以算一下，2000人，平均55秒，全部生成完，需要2000*55=110000秒，大约是30个小时。</p><p>为什么如此之慢？这跟离线文档的生成机制密切相关，对于每一个题目要从保存题库的数据库中找到需要的题目，单个题目的表现形式如图，数据库中存储则采用类html形式保存，对于每个题目而言，解析题目文本，找到需要下载的图片，每道题目都含有大量或大型的图片需要下载，等到文档中所有题目图片下载到本地完成后，整个文档才能继续进行处理。</p><h3 id="分析和改进"><a href="#分析和改进" class="headerlink" title="分析和改进"></a>分析和改进</h3><p>第一版的实现，服务器在接收到老师的请求后，就会把批量生成请求分解为一个个单独的任务，然后串行的完成。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic12.png" srcset="/img/loading.gif" class=""><p>于是在第二版的实现上，首先我们做了个服务拆分，将生成离线文档的功能拆了出来成为了单独的服务，对外提供RPC接口，在WEB服务器接收到了老师们提出的批量生成离线文档的要求以后，将请求拆分后再一一调用离线文档生成RPC服务，这个RPC服务在实现的时候有一个缓冲的机制，会将收到的请求进行缓存，然后迅速返回一个结果给调用者，告诉调用者已经收到了请求，这样WEB服务器也可以很快的对用户的请求进行应答。</p><p>所以我们有了第一次改进，参见cn.enjoyedu.ch8b. RpcServiceWebV1</p><p> 我们看这个离线文档，每份文档的生成独立性是很高的，天生就适用于多线程并发进行。所以在RPC服务实现的时候，使用了生产者消费者模式，RPC接口的实现收到了一个调用方的请求时，会把请求打包放入一个容器，然后会有多个线程进行消费处理，也就是生成每个具体文档。</p><p>当文档生成后，再使用一次生产者消费者模式，投入另一个阻塞队列，由另外的一组线程负责进行上传。当上传成功完成后，由上传线程返回文档的下载地址，表示当前文档已经成功完成。</p><p>文档具体的下载地址则由WEB服务器单独去数据库或者缓存中去查询。</p><p><img src="blob:file:///808f1ea5-3745-41ac-b3fb-dac06fe50317" srcset="/img/loading.gif" alt="pastedGraphic_1.png"></p><p>对于每个离线文档生成本身，我们来看看它的业务，</p><p>1、从容量为10万左右的题库中为每个学生抽取适合他的题目，</p><p>2、每道题目都含有大量的图片需要下载到本地，和文字部分一起渲染。</p><p>但是我们仔细考察整个系统的业务就会发现，我们是在一次考试后为学员生成自适应的练习册，换句话说，不管考试考察的内容如何，学生的成绩如何，每次考试的知识点是有限的，而从这些知识点中可以抽取的相关联的题目数也总是有限的，不同的学生之间所需要的题目会有很大的重复性。</p><p>举个例子我们为甲学生因为他考卷上的错误部分抽取了80个题目，有很大的概率其他学生跟甲学生错误的地方会有重复，相对应的题目也会有重复。对于这部分题目，我们是完全没有必要重复处理的，包括从数据库中重新获取题目、解析和下载图片。这也是我们可供优化的一大突破点。</p><p>其次，一篇练习册是由很多的题目组成的，每个题目相互之间是独立的，我们也可以完全并行的、异步的处理每个题目。</p><p>具体怎么做？要避免重复工作肯定是使用缓存机制，对已处理过的题目进行缓存。我们看看怎么使用缓存机制进行优化。这个业务，毋庸置疑，map肯定是最适合的，因为我们要根据题目的id来找题目的详情，用哪个map？我们现在是在多线程下使用，考虑的是并发安全的concurrentHashMap。</p><p>当我们的服务接收到处理一个题目的请求，首先会在缓存中get一次，没有找到，可以认为这是个新题目，准备向数据库请求题目数据并进行题目的解析，图片的下载。</p><p>这里有一个并发安全的点需要注意，因为是多线程的应用，会发生多个线程在处理多个文档时有同时进行处理相同题目的情况，这种情况下不做控制，一是会造成数据冲突和混乱，比如同时读写同一个磁盘文件，二是会造成计算资源的浪费，同时为了防止文档的生成阻塞在当前题目上，因此每个新题目的处理过程会包装成一个Callable投入一个线程池中 而把处理结果作为一个Future返回，等到线程在实际生成文档时再从Future中get出结果进行处理。因此在每个新题目实际处理前，还会检查当前是否有这个题目的处理任务正在进行。</p><p>如果题目在缓存中被找到，并不是直接引用就可以了，因为题库中的题目因为种种关系存在被修改的可能，比如存在错误，比如可能内容被替换，这个时候缓存中数据其实是失效过期的，所以需要先行检查一次。如何检查？</p><p>我们前面说过题库中的题目平均长度在800个字节左右，直接equals来检查题目正文是否变动过，明显效率比较低，所以我们这里又做了一番处理，什么处理？对题目正文事先做了一次SHA的摘要并保存在数据库，并且要求题库开发小组在处理题目数据入库的时候进行SHA摘要。</p><p>在本机缓存中同样保存了这个摘要信息，在比较题目是否变动过时，首先检查摘要是否一致，摘要一致说明题目不需要更新，摘要不一致时，才需要更新题目文本，将这个题目视为新题目，进入新题目的处理流程，这样的话就减少了数据的传输量，也降低了数据库的压力。</p><p>题目处理的流程就变为：</p><p><img src="blob:file:///5a45d7e5-6994-4eae-9ff7-7feb13186194" srcset="/img/loading.gif" alt="pastedGraphic_2.png"></p><p>所以我们有了第二次改进，</p><p>1、在题目实体类QuestionInDBVo中增加一个</p><p><img src="blob:file:///0d5213fa-8bc0-435c-8088-3bded0d7bd21" srcset="/img/loading.gif" alt="pastedGraphic_3.png"></p><p>2、增加一个题目保存在缓存中的实体类QuestionInCacheVo</p><p><img src="blob:file:///c567de1d-7575-4bd9-8a0b-ec9949b5aacd" srcset="/img/loading.gif" alt="pastedGraphic_4.png"></p><p>3、增加一个并发处理时返回的题目结果实体类TaskResultVo</p><p><img src="blob:file:///658f3823-8257-49ac-a425-0ed1517749e9" srcset="/img/loading.gif" alt="pastedGraphic_5.png"></p><p>按照我们前面的描述，我们可以得知，题目要么已经处理完成，要么正在处理，所以在获取题目结果时，先从questionDetail获取一次，获取为null，则从questionFuture获取。那么这个类的构造方法需要单独处理一下。</p><p><img src="blob:file:///e07738ef-3a22-46fa-9e04-43ce2bad9014" srcset="/img/loading.gif" alt="pastedGraphic_6.png"></p><p>4、在处理文档的服务的类ProduceDocService中增加一个处理文档的新方法makeDocAsyn</p><p><img src="blob:file:///40cc1cc3-ddc5-40ed-95fe-4dc65cfd87ae" srcset="/img/loading.gif" alt="pastedGraphic_7.png"></p><p>在这个方法中，会调用一个并发处理题目的方法。</p><p>5、增加一个优化题目处理的类ParallelQstService，其中提供了并发处理题目的方法，还包括了</p><p><img src="blob:file:///4f69b9df-654b-4d27-b6ca-0eb2ae208a22" srcset="/img/loading.gif" alt="pastedGraphic_8.png"></p><p>主程序参见cn.enjoyedu.ch8b. RpcServiceWebV2</p><p><strong>继续改进</strong></p><p><strong>数据结构的改进</strong></p><p>但是我们仔细分析就会发现，作为一个长期运行的服务，如果我们使用concurrentHashMap，意味着随着时间的推进，缓存对内存的占用会不断的增长。最极端的情况，十万个题目全部被加载到内存，这种情况下会占据多少内存呢？我们做了统计，题库中题目的平均长度在800个字节左右，十万个题目大约会使用75M左右的空间。</p><p>看起来还好，但是有几点，第一，我们除了题目本身还会有其他的一些附属信息需要缓存，比如题目图片在本地磁盘的存储位置等等，那就说，实际缓存的数据内容会远远超过800个字节，</p><p>第二，map类型的的内存使用效率是比较低的，以hashmap为例，内存利用率一般只有20%到40%左右，而concurrentHashMap只会更低，有时候只有hashmap的十分之一到4分之一，这也就是说十万个题目放在concurrentHashMap中会实际占据几百兆的内存空间，是很容易造成内存溢出的，也就是大家常见的OOM。</p><p>考虑到这种情况，我们需要一种数据结构有map的方便但同时可以限制内存的占用大小或者可以根据需要按照某种策略刷新缓存。最后，在实际的工作中，我们选择了ConcurrentLinkedHashMap，这是由Google开源一个线程安全的hashmap，它本身是对ConcurrentHashMap的封装，可以限定最大容量，并实现一个了基于LRU也就是最近最少使用算法策略的进行更新的缓存。很完美的契合了我们的要求，对于已经缓冲的题目，越少使用的就可以认为这个题目离当前考试考察的章节越远，被再次选中的概率就越小，在容量已满，需要腾出空间给新缓冲的题目时，越少使用就会优先被清除。</p><p><strong>线程数的设置</strong></p><p>原来我们设置的线程数按照我们通用的IO密集型任务，两个线程池设置的都是机器的CPU核心数<em>2，但是这个就是最佳的吗？不一定，通过反复试验我们发现，处理文档的线程池线程数设置为CPU核心数</em>4，继续提高线程数并不能带来性能上的提升。而因为我们改进后处理文档的时间和上传文档的时间基本在1：4到1：3的样子，所以处理文档的线程池线程数设置为CPU核心数<em>4</em>3。</p><p>这时我们有了第三次改进，参见cn.enjoyedu.ch8b. RpcServiceWebV3</p><p><strong>缓存的改进</strong></p><p>在这里我们除了本地内存缓存还使用了本地文件存储，启用了一个二级缓存机制。为什么要使用本地文件存储？因为考虑到服务器会升级、会宕机，已经在内存中缓存的数据会丢失，为了避免这一点，我们将相关的数据在本地进行了一个持久化的操作，保存在了本地磁盘。</p><p><strong>改进后的效果</strong></p><p>1、原单WEB串行处理，3个文档耗时</p><p><img src="blob:file:///be0c58ca-0688-4cb3-879c-44286023edc4" srcset="/img/loading.gif" alt="pastedGraphic_9.png"></p><p><strong>平均一个文档耗时**</strong>51<strong>**秒。</strong></p><p>2、服务化，文档生成并行化后，60个文档耗时</p><p><img src="blob:file:///ee6d333f-60d4-4c7e-a816-1b4f7952a0f4" srcset="/img/loading.gif" alt="pastedGraphic_10.png"></p><p><strong>平均一个文档耗时**</strong>3.5<strong><strong>秒，已经比单</strong></strong>WEB<strong>**串行版的实现有了数量级上的提高。</strong></p><p>3、引入缓存避免重复工作、题目处理并行和异步化后，60个文档耗时</p><p><img src="blob:file:///b7138258-6a03-4bf9-adba-85ccf901fa2e" srcset="/img/loading.gif" alt="pastedGraphic_11.png"></p><p><strong>平均一个文档耗时**</strong>0.65<strong>**秒，再次有了数量级上的提高。</strong></p><p>4、调整线程数后，60个文档耗时</p><p><img src="blob:file:///e71d7f5a-2eb8-494a-a6ba-abe801fcef1e" srcset="/img/loading.gif" alt="pastedGraphic_12.png"></p><p><strong>平均一个文档耗时**</strong>0.23<strong><strong>秒，再次提升了</strong></strong>3<strong><strong>倍的速度</strong></strong>,<strong><strong>而相对我们第一版的性能而言，平均一个文档处理性能提升了</strong></strong>51/0.23=221<strong>**倍。</strong></p><p><strong>这就是善用并发编程后威力！</strong></p><p><strong>用户体验的改进</strong></p><p>还可以和我们前面实战的并发任务执行框架中的思想相结合，在前端显示处理进度，給用户带来更好的使用体验。</p><p><strong>启示</strong></p><p>这次项目的优化给我们带来了什么样的启示呢？</p><p>性能优化一定要建立在对业务的深入分析上，比如我们在性能优化的切入点，在缓存数据结构的选择就建立在对业务的深入理解上；</p><p>性能优化要善于利用语言的高并发特性，</p><p>性能优化多多利用缓存，异步任务等机制，正是因为我们使用这些特性和机制，才让我们的应用在性能上有个了质的飞跃；</p><ol><li>引入各种机制的同时要注意避免带来新的不安全因素和瓶颈，比如说缓存数据过期的问题，并发时的线程安全问题，都是需要我们去克服和解决的。</li></ol>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程 - 实战项目</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>并发安全</title>
    <link href="undefined2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/"/>
    <url>2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="线程安全性"><a href="#线程安全性" class="headerlink" title="线程安全性"></a>线程安全性</h2><p>在《Java并发编程实战》中，定义如下：</p><p>当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且在调用代码中不需要任何额外的同步或者协同，这个类都能表现出正确的行为，那么就称这个类是线程安全的。</p><h2 id="线程封闭"><a href="#线程封闭" class="headerlink" title="线程封闭"></a>线程封闭</h2><p>实现好的并发是一件困难的事情，所以很多时候我们都想躲避并发。避免并发最简单的方法就是线程封闭。</p><p>线程封闭就是把对象封装到一个线程里，只有这一个线程能看到此对象。那么这个对象就算不是线程安全的也不会出现任何安全问题。</p><h3 id="ad-hoc线程封闭"><a href="#ad-hoc线程封闭" class="headerlink" title="ad-hoc线程封闭"></a>ad-hoc线程封闭</h3><p>Ad-Hoc线程封闭是完全靠实现者控制的线程封闭，线程封闭完全靠实现者实现。Ad-Hoc线程封闭非常脆弱，应该尽量避免使用。</p><h3 id="栈封闭"><a href="#栈封闭" class="headerlink" title="栈封闭"></a>栈封闭</h3><p>栈封闭是我们编程当中遇到的最多的线程封闭。栈封闭简单的说就是局部变量。多个线程访问一个方法，此方法中的局部变量都会被拷贝一份到线程栈中。所以局部变量是不被多个线程所共享的，也就不会出现并发问题。所以能用局部变量就别用全局的变量，全局变量容易引起并发问题。ThreadLocal本质上是每个线程内部都有一个value副本，相当于将value的副本封闭在栈中，所以使用ThreadLocal不会引发线程安全问题。</p><h3 id="无状态的类"><a href="#无状态的类" class="headerlink" title="无状态的类"></a>无状态的类</h3><p>成员变量被称为类的状态，没有任何成员变量的类，就是无状态的类，这种类一定是线程安全的。</p><p> 即使这个类的方法参数中使用了对象，也是线程安全的，比如：</p><img src="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/pic4.png" srcset="/img/loading.gif" class=""><p>因为多线程下的使用，虽然user这个对象的实例会出现问题，但是它并不被StatelessClass这个类的对象实例所持有，所以Stateless这个类还是线程安全的。如果要避免在使用过程中出现问题的话，可以在user类中实现线程安全。</p><h3 id="让类不可变"><a href="#让类不可变" class="headerlink" title="让类不可变"></a>让类不可变</h3><p>让状态不可变，两种方式：</p><ol><li><p>加final关键字：为该类的所有成员变量都应该加上final关键字，当成员变量是一个对象时，这个对象所对应的类也应该是不可变类，才能保证整个类是不可变的。</p></li><li><p>不提供任何可供修改成员变量的地方，同时成员变量也不作为方法的返回值。</p><p>注：反射不属于正常使用方式，不在考虑范围内</p></li></ol><p>注意：如果类的成员变量中有对象，final关键字是保证对user实例的引用不可变，并不能保证user实例的不可变，在多线程下，对象在堆上的实例是有可能被多个线程同时修改的，没有正确处理的情况下，对象实例在堆中的数据是不可预知的。这就牵涉到了如何安全的发布对象这个问题。</p><h3 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h3><p>并不能保证类的线程安全性，只能保证类的可见性，最适合一个线程写，多个线程读的情景。</p><h3 id="加锁和CAS"><a href="#加锁和CAS" class="headerlink" title="加锁和CAS"></a>加锁和CAS</h3><p>最常使用的保证线程安全的手段，包括使用<strong>synchronized</strong>关键字、使用显式锁、使用各种原子变量、修改数据时使用CAS机制等。</p><h3 id="安全的发布"><a href="#安全的发布" class="headerlink" title="安全的发布"></a>安全的发布</h3><p>类中持有的成员变量，如果是基本类型，可以直接发布出去，此时发布出去的其实是这个变量的一个副本。</p><p>如果类中持有的成员变量是对象的引用，这个成员对象不是线程安全的，通过get等方法发布出去，会造成这个成员对象本身持有的数据在多线程下不正确的修改，从而造成整个类线程不安全的问题。</p><pre><code>/** * 不安全的发布 */public class UnSafePublish {   private List&lt;Integer&gt; list = new ArrayList&lt;&gt;(3);    public UnSafePublish() {       list.add(1);       list.add(2);       list.add(3);    }   public List getList() {      return list;   }   public static void main(String[] args) {      UnSafePublish unSafePublish = new UnSafePublish();      List&lt;Integer&gt; list = unSafePublish.getList();      System.out.println(list);      list.add(4);      System.out.println(list);      System.out.println(unSafePublish.getList());   }}</code></pre><p>将list发布出去后，外部线程就可以修改这个list，如果有多个线程同时修改就会出现不安全的情况，所以在发布这对象出去的时，就应该用线程安全的方式包装这个对象。</p><pre><code>/** * 安全的发布 */public class SafePublishToo {    private List&lt;Integer&gt; list            = Collections.synchronizedList(new ArrayList&lt;&gt;(3));    public SafePublishToo() {        list.add(1);        list.add(2);        list.add(3);    }    public List getList() {        return list;    }    public static void main(String[] args) {        SafePublishToo safePublishToo = new SafePublishToo();        List&lt;Integer&gt; list = safePublishToo.getList();        System.out.println(list);        list.add(4);        System.out.println(list);        System.out.println(safePublishToo.getList());    }}</code></pre><p>将list用Collections.synchronizedList()进行包装以后，无论多少线程使用这个list，就都是线程安全的了。</p><p>对于我们自己使用或者声明的类，JDK自然没有提供这种包装类的办法，但是我们可以仿造这种模式或者委托给线程安全的类。</p><pre><code>/** * 仿Collections对容器的包装，将内部成员对象进行线程安全包装 */public class SoftPublicUser {    private final UserVo user;    public UserVo getUser() {        return user;    }    public SoftPublicUser(UserVo user) {        this.user = new SynUser(user);    }    private static class SynUser extends UserVo{        private final UserVo userVo;        private final Object lock = new Object();        public SynUser(UserVo userVo) {            this.userVo = userVo;        }        @Override        public int getAge() {            synchronized (lock){                System.out.println(&quot;lock success&quot;);                return userVo.getAge();            }        }        @Override        public void setAge(int age) {            synchronized (lock){                userVo.setAge(age);            }        }    }}</code></pre><p>如果为final类，则可以采用委托的方式，将一些方法委托给一个线程安全的类。</p><pre><code>/** * 类说明：委托给线程安全的类来做 */public class SafePublicFinalUser {    private final SynFinalUser user;    public SynFinalUser getUser() {        return user;    }    public SafePublicFinalUser(FinalUserVo user) {        this.user = new SynFinalUser(user);    }    public static class SynFinalUser{        private final FinalUserVo userVo;        private final Object lock = new Object();        public SynFinalUser(FinalUserVo userVo) {            this.userVo = userVo;        }        public int getAge() {            synchronized (lock){                return userVo.getAge();            }        }        public void setAge(int age) {            synchronized (lock){                userVo.setAge(age);            }        }    }}</code></pre><p>对这种通过get等方法发布出去的对象，最根本的解决办法还是应该在实现上就考虑到线程安全问题。</p><h3 id="TheadLocal"><a href="#TheadLocal" class="headerlink" title="TheadLocal"></a>TheadLocal</h3><p>ThreadLocal是实现线程封闭的最好方法。ThreadLocal内部维护了一个Map，Map的key是每个线程的名称，而Map的值就是我们要封闭的对象。每个线程中的对象都对应着Map中一个值，也就是ThreadLocal利用Map实现了对象的线程封闭。</p><h3 id="Servlet辨析"><a href="#Servlet辨析" class="headerlink" title="Servlet辨析"></a>Servlet辨析</h3><p>Servlet其实不是线程安全的类，但一般不会出现问题的原因：</p><ol><li>在需求上，很少有共享的需求即对Servlet中成员变量的写操作，但是一旦有多线程下写Servlet中的成员变量，就很容易产生线程安全问题。</li><li>接收到了请求，返回应答的时候，一般都是由一个线程来负责的。</li><li>spring在bean初始化放入map容器时通过sync关键字保证安全性。因为spring只在初始化时放入一次之后的使用都是只读，相对于使用ConcurrentHashMap性能会更高。</li></ol><h2 id="线程不安全引发的问题"><a href="#线程不安全引发的问题" class="headerlink" title="线程不安全引发的问题"></a>线程不安全引发的问题</h2><h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><p>是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁。</p><p>举个例子：A和B去按摩洗脚，都想在洗脚的时候，顺便做个头部按摩，13技师擅长足底按摩，14擅长头部按摩。这个时候A先抢到14，B先抢到13，两个人都想同时洗脚和头部按摩，于是就互不相让，扬言我死也不让你，这样的话，A抢到14，想要13，B抢到13，想要14，此时，如果没有外力作用，A和B都会死在这，这就是死锁。</p><p>此时有两种解决方法：</p><p>第一种，假如这个时候，来了个15，刚好也是擅长头部按摩的，A又没有两个脑袋，自然就归了B，于是B就美滋滋的洗脚和做头部按摩，剩下A在旁边气鼓鼓的，这个时候死锁这种情况就被打破了，不存在了。</p><p>第二种，C出场了，用武力强迫A和B，必须先做洗脚，再头部按摩，这种情况下，A和B谁先抢到13，谁就可以进行下去，另外一个没抢到的，就等着，这种情况下，也不会产生死锁。</p><p>所以总结一下：</p><p>死锁是必然发生在多操作者（M&gt;=2个）情况下，争夺多个资源（N&gt;=2个，且N&lt;=M）才会发生这种情况。很明显，单线程自然不会有死锁，只有B一个去就不会产生竞争；单资源情况下，A和B也只会产生激烈竞争，谁抢到就是谁的，但不会产生死锁。同时，死锁还有一个重要的要求，争夺资源的顺序不同，如果争夺资源的顺序是一样的，也不会产生死锁。</p><h4 id="学术化的定义"><a href="#学术化的定义" class="headerlink" title="学术化的定义"></a>学术化的定义</h4><p>死锁的发生必须具备以下四个必要条件。 </p><ol><li><p>互斥条件：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。</p></li><li><p>请求和保持条件：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。</p></li><li><p>不剥夺条件：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。</p></li><li><p>环路等待条件：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源。</p></li></ol><p>理解了死锁的原因，尤其是产生死锁的四个必要条件，就可以最大可能地避免、预防和解除死锁。只要打破四个必要条件之一就能有效预防死锁的发生。</p><ul><li>打破互斥条件：改造独占性资源为虚拟资源，大部分资源已无法改造。</li><li>打破不可抢占条件：当一进程占有一独占性资源后又申请一独占性资源而无法满足，则退出原占有的资源。</li><li>打破占有且申请条件：采用资源预先分配策略，即进程运行前申请全部资源，满足则运行，不然就等待，这样就不会占有且申请。</li><li>打破循环等待条件：实现资源有序分配策略，对所有设备实现分类编号，所有进程只能采用按序号递增的形式申请资源。</li></ul><p>避免死锁常见的算法有有序资源分配法、银行家算法。</p><h4 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h4><p>数据库里多事务而且要同时操作多个表的情况下就可能产生死锁。所以数据库设计的时候就考虑到了检测死锁和从死锁中恢复的机制。比如oracle提供了检测和处理死锁的语句，而mysql也提供了“循环依赖检测的机制”</p><img src="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/pic6.png" srcset="/img/loading.gif" class=""><h5 id="简单顺序死锁"><a href="#简单顺序死锁" class="headerlink" title="简单顺序死锁"></a>简单顺序死锁</h5><pre><code>/** *类说明：演示普通账户的死锁和解决 */public class NormalDeadLock {    private static Object valueFirst = new Object();//第一个锁    private static Object valueSecond = new Object();//第二个锁    //先拿第一个锁，再拿第二个锁    private static void fisrtToSecond() throws InterruptedException {        String threadName = Thread.currentThread().getName();        synchronized (valueFirst){            System.out.println(threadName+&quot; get 1st&quot;);            Thread.sleep(100);            synchronized (valueSecond){                System.out.println(threadName+&quot; get 2nd&quot;);            }        }    }    //先拿第二个锁，再拿第一个锁    private static void SecondToFisrt() throws InterruptedException {        String threadName = Thread.currentThread().getName();        synchronized (valueFirst){            System.out.println(threadName+&quot; get 2nd&quot;);            Thread.sleep(100);            synchronized (valueSecond){                System.out.println(threadName+&quot; get 1st&quot;);            }        }    }    private static class TestThread extends Thread{        private String name;        public TestThread(String name) {            this.name = name;        }        public void run(){            Thread.currentThread().setName(name);            try {                SecondToFisrt();            } catch (InterruptedException e) {                e.printStackTrace();            }        }    }    public static void main(String[] args) {        Thread.currentThread().setName(&quot;TestDeadLock&quot;);        TestThread testThread = new TestThread(&quot;SubTestThread&quot;);        testThread.start();        try {            fisrtToSecond();        } catch (InterruptedException e) {            e.printStackTrace();        }    }}</code></pre><h5 id="动态顺序死锁"><a href="#动态顺序死锁" class="headerlink" title="动态顺序死锁"></a>动态顺序死锁</h5><p>顾名思义也是和获取锁的顺序有关，但是比较隐蔽，不像简单顺序死锁，往往从代码一眼就看出获取锁的顺序不对。</p><pre><code>/** *类说明：不安全的转账动作的实现 */public class TrasnferAccount implements ITransfer {    @Override    public void transfer(UserAccount from, UserAccount to, int amount)          throws InterruptedException {        synchronized (from){            System.out.println(Thread.currentThread().getName()                  +&quot; get&quot;+from.getName());            Thread.sleep(100);            synchronized (to){                System.out.println(Thread.currentThread().getName()                      +&quot; get&quot;+to.getName());                from.flyMoney(amount);                to.addMoney(amount);            }        }    }}</code></pre><pre><code>/** *@author Mark老师   享学课堂 https://enjoy.ke.qq.com  * *类说明：模拟支付公司转账的动作 */public class PayCompany {   /*执行转账动作的线程*/    private static class TransferThread extends Thread{        private String name;        private UserAccount from;        private UserAccount to;        private int amount;        private ITransfer transfer;        public TransferThread(String name, UserAccount from, UserAccount to,                              int amount, ITransfer transfer) {            this.name = name;            this.from = from;            this.to = to;            this.amount = amount;            this.transfer = transfer;        }        public void run(){            Thread.currentThread().setName(name);            try {                transfer.transfer(from,to,amount);            } catch (InterruptedException e) {                e.printStackTrace();            }        }    }    public static void main(String[] args) {        PayCompany payCompany = new PayCompany();        UserAccount zhangsan = new UserAccount(&quot;zhangsan&quot;,20000);        UserAccount lisi = new UserAccount(&quot;lisi&quot;,20000);        ITransfer transfer = new SafeOperateToo();        TransferThread zhangsanToLisi = new TransferThread(&quot;zhangsanToLisi&quot;                ,zhangsan,lisi,2000,transfer);        TransferThread lisiToZhangsan = new TransferThread(&quot;lisiToZhangsan&quot;                ,lisi,zhangsan,4000,transfer);        zhangsanToLisi.start();        lisiToZhangsan.start();    }}</code></pre><h4 id="危害"><a href="#危害" class="headerlink" title="危害"></a>危害</h4><p>时间不定，不是每次必现；一旦出现没有任何异常信息，只知道这个应用的所有业务越来越慢，最后停止服务，无法确定是哪个具体业务导致的问题；测试部门也无法复现，并发量不够。</p><ol><li>线程不工作了，但是整个程序还是活着的</li><li>没有任何的异常信息可以供我们检查。</li><li>一旦程序发生了发生了死锁，是没有任何的办法恢复的，只能重启程序，对生产平台的程序来说，这是个很严重的问题。</li></ol><h4 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h4><h5 id="定位"><a href="#定位" class="headerlink" title="定位"></a>定位</h5><p>通过<strong>jps</strong> 查询应用的id，再通过<strong>jstack[id]</strong> 查看应用的锁的持有情况</p><img src="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/pic1.png" srcset="/img/loading.gif" class=""><img src="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/pic2.png" srcset="/img/loading.gif" class=""><img src="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/pic3.png" srcset="/img/loading.gif" class=""><h5 id="修正"><a href="#修正" class="headerlink" title="修正"></a>修正</h5><p>关键是保证拿锁的顺序一致</p><p>两种解决方式：</p><ol><li>内部通过顺序比较，确定拿锁的顺序；</li></ol><pre><code>/** *@author Mark老师   享学课堂 https://enjoy.ke.qq.com  * *类说明：不会产生死锁的安全转账 */public class SafeOperate implements ITransfer {    private static Object tieLock = new Object();//第三把锁    @Override    public void transfer(UserAccount from, UserAccount to, int amount)            throws InterruptedException {        int fromHash = System.identityHashCode(from);        int toHash = System.identityHashCode(to);        if(fromHash&lt;toHash){            synchronized (from){                System.out.println(Thread.currentThread().getName()+&quot; get &quot;+from.getName());                Thread.sleep(100);                synchronized (to){                    System.out.println(Thread.currentThread().getName()+&quot; get &quot;+to.getName());                    from.flyMoney(amount);                    to.addMoney(amount);                    System.out.println(from);                    System.out.println(to);                }            }        }else if(toHash&lt;fromHash){            synchronized (to){                System.out.println(Thread.currentThread().getName()+&quot; get&quot;+to.getName());                Thread.sleep(100);                synchronized (from){                    System.out.println(Thread.currentThread().getName()+&quot; get&quot;+from.getName());                    from.flyMoney(amount);                    to.addMoney(amount);                    System.out.println(from);                    System.out.println(to);                }            }        }else{            synchronized (tieLock){                synchronized (from){                    synchronized (to){                        from.flyMoney(amount);                        to.addMoney(amount);                    }                }            }        }    }}</code></pre><ol start="2"><li>采用尝试拿锁的机制。</li></ol><pre><code>/** * @author Mark老师   享学课堂 https://enjoy.ke.qq.com * &lt;p&gt; * 类说明：不会产生死锁的安全转账第二种方法 */public class SafeOperateToo implements ITransfer {    @Override    public void transfer(UserAccount from, UserAccount to, int amount)            throws InterruptedException {        Random r = new Random();        while (true) {            if (from.getLock().tryLock()) {                try {                    System.out.println(Thread.currentThread().getName()                            + &quot; get&quot; + from.getName());                    if (to.getLock().tryLock()) {                        try {                            System.out.println(Thread.currentThread().getName()                                    + &quot; get&quot; + to.getName());                            from.flyMoney(amount);                            to.addMoney(amount);                            System.out.println(from);                            System.out.println(to);                            break;                        } finally {                            to.getLock().unlock();                        }                    }                } finally {                    from.getLock().unlock();                }            }            Thread.sleep(r.nextInt(2));        }    }}</code></pre><h3 id="活锁"><a href="#活锁" class="headerlink" title="活锁"></a>活锁</h3><p>两个线程在尝试拿锁的机制中，发生多个线程之间互相谦让，不断发生同一个线程总是拿到同一把锁，在尝试拿另一把锁时因为拿不到，而将本来已经持有的锁释放的过程。</p><p>解决办法：每个线程休眠随机数，错开拿锁的时间。</p><h3 id="线程饥饿"><a href="#线程饥饿" class="headerlink" title="线程饥饿"></a>线程饥饿</h3><p>低优先级的线程，总是拿不到执行时间</p><h3 id="性能和思考"><a href="#性能和思考" class="headerlink" title="性能和思考"></a>性能和思考</h3><p>使用并发的目标是为了提高性能，引入多线程后，其实会引入额外的开销，如线程之间的协调、增加的上下文切换，线程的创建和销毁，线程的调度等等。过度的使用和不恰当的使用，会导致多线程程序甚至比单线程还要低。</p><p>衡量应用的程序的性能：服务时间，延迟时间，吞吐量，可伸缩性等等，其中服务时间，延迟时间（多快），吞吐量（处理能力的指标，完成工作的多少）。多快和多少，完全独立，甚至是相互矛盾的。</p><p>对服务器应用来说：多少（可伸缩性，吞吐量）这个方面比多快更受重视。</p><p>我们做应用的时候：</p><ol><li><p>先保证程序正确，确实达不到要求的时候，再提高速度（黄金原则）。</p></li><li><p>一定要以测试为基准。</p></li></ol><h4 id="线程引入的开销"><a href="#线程引入的开销" class="headerlink" title="线程引入的开销"></a>线程引入的开销</h4><h5 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h5><p>如果主线程是唯一的线程，那么它基本上不会被调度出去。另一方面,如果可运行的线程数大于CPU的数量,那么操作系统最终会将某个正在运行的线程调度出来，从而使其他线程能够使用CPU。这将导致一次上下文切换，在这个过程中将保存当前运行线程的执行上下文，并将新调度进来的线程的执行上下文设置为当前上下文。上下文切换有点像我们同时阅读几本书，在来回切换书本的同时我们需要记住每本书当前读到的页码。</p><p>切换上下文需要一定的开销，而在线程调度过程中需要访问由操作系统和JVM共享的数据结构。由于应用程序、操作系统以及JVM都使用同一组CPU，所以在JVM和操作系统中消耗越多的CPU时钟周期，应用程序的可用CPU时钟周期就越少。而且上下文切换的开销并不只是包含JVM和操作系统的开销，由于当一个新的线程被切换进来时，它所需要的数据可能不在当前处理器的本地缓存，所以上下文切换也将导致一些缓存缺失，线程在首次调度运行时会更加缓慢。</p><p>当线程由于等待某个发生竞争的锁而被阻塞时，JVM通常会将这个线程挂起，并允许它被交换出去。如果线程频繁地发生阻塞，那么它们将无法使用完整的调度时间片。在程序中发生越多的阻塞（包括阻塞IO、等待获取发生竞争的锁或者在条件变量上等待）与CPU密集型的程序就会发生越多的上下文切换，从而增加调度开销，降低吞吐量。</p><p>上下文切换是计算密集型操作。也就是说，它需要相当可观的处理器时间。所以上下文切换对系统来说意味着消耗大量的 CPU 时间，而且可能是操作系统中时间消耗最大的操作。上下文切换的实际开销会随着平台的不同而变化，按照实际经验来看，在大多数通用的处理器中，上下文切换的开销相当于50~10000个时钟周期,也就是几微秒。</p><p>UNIX系统的vmstat命令能报告上下文切换次数以及在内核中执行时间所占比例等信息。如果内核占用率较高（超过10%），那么通常表示调度活动发生得很频繁，这很可能是由IO或竞争锁导致的阻塞引起的。</p><h5 id="内存同步"><a href="#内存同步" class="headerlink" title="内存同步"></a>内存同步</h5><p>同步操作的性能开销包括多个方面。在 synchronized和 volatile提供的可见性保证中可能会使用一些特殊指令，即内存栅栏( Memory Barrier)。</p><p>内存栅栏可以刷新缓存，使缓存无效从而刷新硬件的写缓冲，以及停止执行管道。</p><p>内存栅栏可能同样会对性能带来间接的影响，因为它们将抑制一些编译器优化操作。在内存栅栏中，大多数操作都是不能被重排序的。</p><h5 id="阻塞"><a href="#阻塞" class="headerlink" title="阻塞"></a>阻塞</h5><p>引起阻塞的原因：包括阻塞IO，等待获取发生竞争的锁或者在条件变量上的等待等等。</p><p>阻塞会导致线程挂起，挂起进程在操作系统中可以定义为暂时被淘汰出内存的进程，机器的资源是有限的，在资源不足的情况下，操作系统对在内存中的程序进行合理的安排，其中有的进程被暂时调离出内存，当条件允许的时候，会被操作系统再次调回内存，重新进入等待被执行的状态即就绪态。这个操作至少包括两次额外的上下文切换，还有相关的操作系统级的操作等等。</p><h4 id="如何减少锁的竞争"><a href="#如何减少锁的竞争" class="headerlink" title="如何减少锁的竞争"></a>如何减少锁的竞争</h4><h5 id="减少锁的粒度"><a href="#减少锁的粒度" class="headerlink" title="减少锁的粒度"></a>减少锁的粒度</h5><p>使用锁的时候，锁所保护的对象是多个，当这些多个对象其实是独立变化的时候，不如用多个锁来一一保护这些对象。但是如果有同时要持有多个锁的业务方法，要注意避免发生死锁。</p><h5 id="缩小锁的范围"><a href="#缩小锁的范围" class="headerlink" title="缩小锁的范围"></a>缩小锁的范围</h5><p>对锁的持有实现快进快出，尽量缩短持由锁的的时间。将一些与锁无关的代码移出锁的范围，特别是一些耗时，可能阻塞的操作</p><h5 id="避免多余的锁"><a href="#避免多余的锁" class="headerlink" title="避免多余的锁"></a>避免多余的锁</h5><p>两次加锁之间的语句非常简单，导致加锁的时间比执行这些语句还长，这个时候应该进行锁粗化即扩大锁的范围。</p><h5 id="锁分段"><a href="#锁分段" class="headerlink" title="锁分段"></a>锁分段</h5><p>ConcurrrentHashMap就是典型的锁分段。</p><h5 id="替换独占锁"><a href="#替换独占锁" class="headerlink" title="替换独占锁"></a>替换独占锁</h5><p>在业务允许的情况下：</p><ol><li>使用读写锁，</li><li>用自旋CAS</li><li>使用系统的并发容器</li></ol><h2 id="线程安全的单例模式"><a href="#线程安全的单例模式" class="headerlink" title="线程安全的单例模式"></a>线程安全的单例模式</h2><h3 id="双重检查锁定"><a href="#双重检查锁定" class="headerlink" title="双重检查锁定"></a>双重检查锁定</h3><pre><code>/** * 懒汉式-双重检查 */public class SingleDcl {    private volatile static SingleDcl singleDcl;    //私有化    private SingleDcl(){    }    public static SingleDcl getInstance(){        if (singleDcl == null){ //第一次检查，不加锁            System.out.println(Thread.currentThread()+&quot; is null&quot;);            synchronized(SingleDcl.class){ //加锁                if (singleDcl == null){ //第二次检查，加锁情况下                    System.out.println(Thread.currentThread()+&quot; is null&quot;);                    singleDcl = new SingleDcl();                }            }        }        return singleDcl;    }}</code></pre><p>仅仅是双重检查无法保证多线程下使用的安全性，因为在创建对象时为内存中分配空间、对象在内存空间的初始化、把这个内存空间的地址赋值给引用这三个步骤是可能被重新排序的，只要引用指向了内存空间的地址判断条件singleDc1==null就会不成立，而此时对象很可能还没有完成初始化，所以还需要加入volatile关键字保证指令不会被重排序。</p><h3 id="饿汉式"><a href="#饿汉式" class="headerlink" title="饿汉式"></a>饿汉式</h3><pre><code>/** * 饿汉式 */public class SingleEHan {    private SingleEHan(){}    private static SingleEHan singleDcl = new SingleEHan();}</code></pre><p>JVM对类的加载和类初始化，由虚拟机保证线程安全。多个线程同时加载一个类时会为其加锁保证只有一个类加载成功，所以饿汉式单例模式是线程安全的。</p><h3 id="延迟初始化占位类模式"><a href="#延迟初始化占位类模式" class="headerlink" title="延迟初始化占位类模式"></a>延迟初始化占位类模式</h3><pre><code>/** * 懒汉式-延迟初始化占位类模式 */public class SingleInit {    private SingleInit(){}    private static class InstanceHolder{        private static SingleInit instance = new SingleInit();    }    public static SingleInit getInstance(){        return InstanceHolder.instance;    }}</code></pre><p>延迟初始化占位类模式其实也是利用JVM类加载的线程安全，在子类中完成实例的初始化，如果在其他地方没有对子类的引用，子类的初始化将只在首次获取实例时完成，以此来解决饿汉式单例模式资源占用的问题。延迟占位模式也可以用在多线程下实例域的延迟赋值。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线程池</title>
    <link href="undefined2020/01/16/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"/>
    <url>2020/01/16/%E7%BA%BF%E7%A8%8B%E6%B1%A0/</url>
    
    <content type="html"><![CDATA[<h2 id="使用线程池的优势"><a href="#使用线程池的优势" class="headerlink" title="使用线程池的优势"></a>使用线程池的优势</h2><ol><li><p>降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。</p></li><li><p>提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。假设一个服务器完成一项任务所需时间为：T1 创建线程时间，T2 在线程中执行任务的时间，T3 销毁线程时间。  如果：T1 + T3 远大于 T2，则可以采用线程池，以提高服务器性能。线程池技术正是关注如何缩短或调整T1,T3时间的技术，从而提高服务器程序性能的。它把T1，T3分别安排在服务器程序的启动和结束的时间段或者一些空闲的时间段，这样在服务器程序处理客户请求时，不会有T1，T3的开销了。</p></li><li><p>提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。</p></li></ol><p>假设一个服务器一天要处理50000个请求，并且每个请求需要一个单独的线程完成。在线程池中，线程数一般是固定的，所以产生线程总数不会超过线程池中线程的数目，而如果服务器不利用线程池来处理这些请求则线程总数为50000。一般线程池大小是远小于50000，所以利用线程池的服务器程序不会为了创建50000而在处理请求时浪费时间，从而提高效率。</p><h2 id="自定义线程池的实现"><a href="#自定义线程池的实现" class="headerlink" title="自定义线程池的实现"></a>自定义线程池的实现</h2><pre><code>/** *类说明：自定义线程池实现 */public class MyThreadPool2 {    /*缺省线程数据量*/    private static int WORK_COUNT = 5;    /*存放任务*/    private final BlockingQueue&lt;Runnable&gt; taskQueue;    /*工作线程*/    private WorkThread[] workThreads;    private final int work_number;    public MyThreadPool2(){        this(100,WORK_COUNT);    }    /*任务数，线程的数量*/    public MyThreadPool2(int task_count,                         int work_number) {        if (work_number&lt;=0) work_number = WORK_COUNT;        if(task_count&lt;=0) task_count = 100;        this.taskQueue = new ArrayBlockingQueue&lt;&gt;(task_count);        this.work_number = work_number;        workThreads = new WorkThread[work_number];        /*工作线程准备好了*/        for(int i=0;i&lt;work_number;i++){            workThreads[i] = new WorkThread();            workThreads[i].start();        }    }    /*销毁线程池*/    public void destroy(){        System.out.println(&quot;ready close pool....&quot;);        for(int i=0;i&lt;work_number;i++){            workThreads[i].stopWorker();            workThreads[i] = null;//help gc        }        taskQueue.clear();    }    /*放入任务，但是只是加入队列*/    public void execute(Runnable task){        try {            taskQueue.put(task);        } catch (InterruptedException e) {            e.printStackTrace();        }    }    @Override    public String toString() {        return &quot;WorkThread number:&quot;+work_number                +&quot; wait task number:&quot;+taskQueue.size();    }    /*内部类，工作线程的实现*/    private class WorkThread extends Thread{        @Override        public void run() {            Runnable r = null;            try {                while(!isInterrupted()){                    r = taskQueue.take();                    if(r!=null){                        System.out.println(getId()+&quot; ready execute&quot;                                +((TestMyThreadPool.MyTask)r).getName());                        r.run();                    }                   r = null;                }            } catch (InterruptedException e) {                //e.printStackTrace();            }        }        /*停止工作*/        public void stopWorker() {            interrupt();        }    }}</code></pre><p>测试类</p><pre><code>/** *类说明：测试自定义线程池实现 */public class TestMyThreadPool {    public static void main(String[] args) throws InterruptedException {//         创建3个线程的线程池        MyThreadPool2 t = new MyThreadPool2(0,3);        t.execute(new MyTask(&quot;testA&quot;));        t.execute(new MyTask(&quot;testB&quot;));        t.execute(new MyTask(&quot;testC&quot;));        t.execute(new MyTask(&quot;testD&quot;));        t.execute(new MyTask(&quot;testE&quot;));        System.out.println(t);        Thread.sleep(10000);        t.destroy();// 所有线程都执行完成才destory        System.out.println(t);    }    // 任务类    static class MyTask implements Runnable {        private String name;        private Random r = new Random();        public MyTask(String name) {            this.name = name;        }        public String getName() {            return name;        }        @Override        public void run() {// 执行任务            try {                Thread.sleep(r.nextInt(1000)+2000);            } catch (InterruptedException e) {                System.out.println(Thread.currentThread().getId()+&quot; sleep InterruptedException:&quot;                        +Thread.currentThread().isInterrupted());            }            System.out.println(&quot;任务 &quot; + name + &quot; 完成&quot;);        }    }}</code></pre><h2 id="Executor框架"><a href="#Executor框架" class="headerlink" title="Executor框架"></a>Executor框架</h2><img src="/2020/01/16/%E7%BA%BF%E7%A8%8B%E6%B1%A0/pic1.png" srcset="/img/loading.gif" class=""><p>Executor是一个接口，它是Executor框架的基础，它将任务的提交与任务的执行分离开来；</p><p>ExecutorService接口继承了Executor，在其上做了一些shutdown()、submit()的扩展，可以说是真正的线程池接口；</p><p>AbstractExecutorService抽象类实现了ExecutorService接口中的大部分方法；</p><p>ThreadPoolExecutor是线程池的核心实现类，用来执行被提交的任务。</p><p>ScheduledExecutorService接口继承了ExecutorService接口，提供了带”周期执行”功能ExecutorService；</p><p>ScheduledThreadPoolExecutor是一个实现类，可以在给定的延迟后运行命令，或者定期执行命令。ScheduledThreadPoolExecutor比Timer更灵活，功能更强大。</p><h2 id="线程池的创建各个参数含义"><a href="#线程池的创建各个参数含义" class="headerlink" title="线程池的创建各个参数含义"></a>线程池的创建各个参数含义</h2><p>public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,BlockingQueue<Runnable> workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler)</p><ul><li><p><strong>corePoolSize</strong>：线程池中的核心线程数。当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize；如果当前线程数已经达到corePoolSize，继续提交的任务会被保存到阻塞队列中，等待被执行；如果执行了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有核心线程。</p></li><li><p><strong>maximumPoolSize</strong>：线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，前提是当前线程数小于maximumPoolSize</p></li><li><p><strong>keepAliveTime</strong>：线程空闲时的存活时间，即当线程没有任务执行时，继续存活的时间。默认情况下，该参数只在线程数大于corePoolSize时才有用</p></li><li><p><strong>unit</strong>：keepAliveTime的时间单位</p></li><li><p><strong>workQueue</strong>：workQueue必须是BlockingQueue阻塞队列，通过workQueue，线程池实现了阻塞功能。当线程池中的线程数超过它的corePoolSize的时候，线程会进入阻塞队列进行阻塞等待。一般来说，我们应该尽量使用有界队列，因为使用无界队列作为工作队列会对线程池带来如下影响：</p><ol><li>当线程池中的线程数达到corePoolSize后，新任务将在无界队列中等待，因此线程池中的线程数不会超过corePoolSize。</li><li>由于1，使用无界队列时maximumPoolSize将是一个无效参数。</li><li>由于1和2，使用无界队列时keepAliveTime将是一个无效参数。</li><li>更重要的，使用无界queue可能会耗尽系统资源，有界队列则有助于防止资源耗尽，同时即使使用有界队列，也要尽量控制队列的大小在一个合适的范围。</li></ol><p>所以我们一般会使用，ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue、PriorityBlockingQueue。</p></li><li><p><strong>threadFactory</strong>：创建线程的工厂，通过自定义的线程工厂可以给每个新建的线程设置一个具有识别度的线程名，当然还可以更加自由的对线程做更多的设置，比如设置所有的线程为守护线程。Executors静态工厂里默认的threadFactory，线程的命名规则是“pool-数字-thread-数字”。</p></li><li><p><strong>handler</strong>：线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，线程池提供了4种策略：</p><ol><li>AbortPolicy：直接抛出异常，默认策略；</li><li>CallerRunsPolicy：用调用者所在的线程来执行任务；</li><li>DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；</li><li>DiscardPolicy：直接丢弃任务；</li></ol><p>当然也可以根据应用场景实现RejectedExecutionHandler接口，自定义饱和策略，如记录日志或持久化存储不能处理的任务。</p></li></ul><h2 id="扩展线程池"><a href="#扩展线程池" class="headerlink" title="扩展线程池"></a>扩展线程池</h2><p>在JDK的线程池核心方法中预留出了三个空的方法，分别为任务执行前的方法、执行后的方法、线程池退出时执行的方法，我们可以通过这些方法执行我们自己的逻辑。如果要对Runnable任务做调整，如修改线程名字、设置线程为守护线程，则可以通过实现ThreadFactory接口，在newThread()方法中对runnable进行调整。</p><pre><code>/** * 类说明：扩展线程池的使用范例 */public class ThreadPoolExt {    static class Worker implements Runnable {        private String taskName;        private Random r = new Random();        public Worker(String taskName) {            this.taskName = taskName;        }        public String getName() {            return taskName;        }        @Override        public void run() {            System.out.println(Thread.currentThread().getName()                    + &quot; process the task : &quot; + taskName);            SleepTools.ms(r.nextInt(100) * 5);        }    }    public static void main(String[] args) throws InterruptedException, ExecutionException {        ExecutorService threadPool = new ThreadPoolExecutor(2, 4, 3,                TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(10),                new ThreadPoolExecutor.DiscardOldestPolicy()) {            @Override            protected void beforeExecute(Thread t, Runnable r) {                System.out.println(&quot;Ready Execute &quot; + ((Worker) r).getName());            }            @Override            protected void afterExecute(Runnable r, Throwable t) {                System.out.println(&quot;Complete Execute &quot; + ((Worker) r).getName());            }            @Override            protected void terminated() {                System.out.println(&quot;线程池退出&quot;);            }        };        for (int i = 0; i &lt;= 6; i++) {            Worker worker = new Worker(&quot;worker &quot; + i);            System.out.println(&quot;A new task has been added : &quot; + worker.getName());            threadPool.execute(worker);        }        threadPool.shutdown();    }}</code></pre><p>可以看到，每个任务执行前后都会调用 beforeExecute和 afterExecute方法。相当于执行了一个切面。而在调用shutdown 方法后则会调用 terminated 方法。</p><h2 id="线程池的工作机制"><a href="#线程池的工作机制" class="headerlink" title="线程池的工作机制"></a>线程池的工作机制</h2><ol><li>如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。</li><li>如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。</li><li>如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务。</li><li>如果继续添加任务导致当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。</li></ol><img src="/2020/01/16/%E7%BA%BF%E7%A8%8B%E6%B1%A0/pic2.png" srcset="/img/loading.gif" class=""><p>内存资源相比线程资源要廉价一下，所以jdk优先使用阻塞队列容纳多余线程数，在阻塞队列容纳不下的情况下才会创建新的线程（个人猜测）。</p><h2 id="提交任务"><a href="#提交任务" class="headerlink" title="提交任务"></a>提交任务</h2><p>execute()方法用于提交不需要返回值的任务（Runnable），所以无法判断任务是否被线程池执行成功。</p><p>submit()方法用于提交需要返回值的任务（Callable）。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用get(long timeout，TimeUnit unit)方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。</p><h2 id="关闭线程池"><a href="#关闭线程池" class="headerlink" title="关闭线程池"></a>关闭线程池</h2><p>可以通过调用线程池的shutdown()或shutdownNow()方法来关闭线程池。它们的原理是遍历线程池中的工作线程，然后逐个调用线程的interrupt()方法来中断线程，所以无法响应中断的任务可能永远无法终止。但是它们存在一定的区别，shutdownNow()首先将线程池的状态设置成STOP，然后尝试停止所有的正在执行或暂停任务的线程，并返回等待执行任务的列表，而shutdown()只是将线程池的状态设置成SHUTDOWN状态，然后中断所有<strong>没有正在执行任务的线程</strong>。</p><p>只要调用了这两个关闭方法中的任意一个，isShutdown方法就会返回true。当所有的任务都已关闭后，才表示线程池关闭成功，这时调用isTerminaed方法会返回true。至于应该调用哪一种方法来关闭线程池，应该由提交到线程池的任务特性决定，通常调用shutdown()方法来关闭线程池，如果任务不一定要执行完，则可以调用shutdownNow()方法。</p><h2 id="合理地配置线程池"><a href="#合理地配置线程池" class="headerlink" title="合理地配置线程池"></a>合理地配置线程池</h2><p>要想合理地配置线程池，就必须首先分析任务特性，可以从以下几个角度来分析：</p><ul><li><p>任务的性质：CPU密集型任务、IO密集型任务和混合型任务。</p></li><li><p>任务的优先级：高、中和低。</p></li><li><p>任务的执行时间：长、中和短。</p></li><li><p>任务的依赖性：是否依赖其他系统资源，如数据库连接。</p></li></ul><p>性质不同的任务可以用不同规模的线程池分开处理：</p><ul><li><p>CPU密集型任务（字符串的正则匹配、加密解密，数据的计算）应配置尽可能小的线程，如配置Ncpu+1个线程的线程池。</p></li><li><p>IO密集型任务（读写文件，数据库，http请求）线程并不是一直在执行任务，则应配置尽可能多的线程，如Ncpu*2，如果此时CPU占用率比较低的话可以尝试Ncpu*3。</p></li><li><p>混合型的任务（包括CPU密集及IO密集），如果将其拆分成一个CPU密集型任务和一个IO密集型任务，这两个任务执行的时间相差不是太大，那么分解后执行的吞吐量将高于串行执行的吞吐量，如果这两个任务执行时间相差太大，则没必要进行分解。</p></li></ul><p>可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数。</p><p>优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高的任务先执行。</p><p>执行时间不同的任务可以交给不同规模的线程池来处理，或者可以使用优先级队列，让执行时间短的任务先执行。</p><p>依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，等待的时间越长，则CPU空闲时间就越长，那么线程数应该设置得越大，这样才能更好地利用CPU。</p><p>在有界队列和无界队列的选择上，建议使用有界队列。有界队列能增加系统的稳定性和预警能力，队列的长度可以设置的大一些，比如几千。假设，我们现在有一个Web系统，里面使用了线程池来处理业务，在某些情况下，系统里后台任务线程池的队列和线程池全满了，不断抛出抛弃任务的异常，通过排查发现是数据库出现了问题，导致执行SQL变得非常缓慢，因为后台任务线程池里的任务全是需要向数据库查询和插入数据的，所以导致线程池里的工作线程全部阻塞，任务积压在线程池里。如果当时我们设置成无界队列，那么线程池的队列就会越来越多，有可能会撑满内存，导致整个系统不可用，而不只是后台任务出现问题。</p><h2 id="预定义线程池"><a href="#预定义线程池" class="headerlink" title="预定义线程池"></a>预定义线程池</h2><p>JDK在Executor中为我们提供了一些预定义的线程池，可以通过Executors.newFixedThreadPool()等方法来获取，但尽量还是自己通过构造方法根据当前场景创建。</p><h3 id="FixedThreadPool"><a href="#FixedThreadPool" class="headerlink" title="FixedThreadPool"></a>FixedThreadPool</h3><p>创建使用固定线程数的FixedThreadPool的API。适用于为了满足资源管理的需求，而需要限制当前线程数量的应用场景，它适用于负载比较重的服务器。FixedThreadPool的corePoolSize和maximumPoolSize都被设置为创建FixedThreadPool时指定的参数nThreads。</p><p>当线程池中的线程数大于corePoolSize时，keepAliveTime为多余的空闲线程等待新任务的最长时间，超过这个时间后多余的线程将被终止。这里把keepAliveTime设置为0L，意味着多余的空闲线程会被立即终止。</p><p>FixedThreadPool使用有界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为Integer.MAX_VALUE）。</p><h3 id="SingleThreadExecutor"><a href="#SingleThreadExecutor" class="headerlink" title="SingleThreadExecutor"></a>SingleThreadExecutor</h3><p>创建使用单个线程的SingleThread-Executor的API，于需要保证顺序地执行各个任务；并且在任意时间点，不会有多个线程是活动的应用场景。</p><p>corePoolSize和maximumPoolSize被设置为1。其他参数与FixedThreadPool相同。SingleThreadExecutor使用有界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为Integer.MAX_VALUE）。</p><h3 id="CachedThreadPool"><a href="#CachedThreadPool" class="headerlink" title="CachedThreadPool"></a>CachedThreadPool</h3><p>创建一个为所有任务创建新线程的CachedThreadPool的API。大小无界的线程池，适用于执行很多的短期异步任务的小程序，或者是负载较轻的服务器。</p><p>corePoolSize被设置为0，即corePool为空；maximumPoolSize被设置为Integer.MAX_VALUE。这里把keepAliveTime设置为60L，意味着CachedThreadPool中的空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被终止。</p><p>FixedThreadPool和SingleThreadExecutor使用有界队列LinkedBlockingQueue作为线程池的工作队列。CachedThreadPool使用没有容量的SynchronousQueue作为线程池的工作队列，但CachedThreadPool的maximumPool是无界的。这意味着，如果主线程提交任务的速度高于maximumPool中线程处理任务的速度时，CachedThreadPool会不断创建新线程。极端情况下，CachedThreadPool会因为创建过多线程而耗尽CPU和内存资源。</p><h3 id="WorkStealingPool"><a href="#WorkStealingPool" class="headerlink" title="WorkStealingPool"></a>WorkStealingPool</h3><p>利用所有运行的处理器数目来创建一个工作窃取的线程池，使用forkjoin实现</p><h3 id="ScheduledThreadPoolExecutor"><a href="#ScheduledThreadPoolExecutor" class="headerlink" title="ScheduledThreadPoolExecutor"></a>ScheduledThreadPoolExecutor</h3><p>使用工厂类Executors来创建。Executors可以创建2种类型的ScheduledThreadPoolExecutor，如下。</p><ul><li><p>ScheduledThreadPoolExecutor。包含若干个线程的ScheduledThreadPoolExecutor。</p></li><li><p>SingleThreadScheduledExecutor。只包含一个线程的ScheduledThreadPoolExecutor。</p></li></ul><p>ScheduledThreadPoolExecutor适用于需要多个后台线程执行周期任务，同时为了满足资源管理的需求而需要限制后台线程的数量的应用场景。</p><p>SingleThreadScheduledExecutor适用于需要单个后台线程执行周期任务，同时需要保证顺序地执行各个任务的应用场景。</p><p>提交定时任务：</p><ul><li><p>public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit)：向定时任务线程池提交一个延时Runnable任务（仅执行一次）</p></li><li><p>public <V> ScheduledFuture<V> schedule(Callable<V> callable, long delay, TimeUnit unit)：向定时任务线程池提交一个延时的Callable任务（仅执行一次）</p></li><li><p>public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay,   long period, TimeUnit unit)：向定时任务线程池提交一个固定时间间隔执行的任务</p></li><li><p>public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit)：向定时任务线程池提交一个固定延时间隔执行的任务</p></li></ul><p>固定延时间隔的任务是指每次执行完任务以后都延时一个固定的时间。由于操作系统调度以及每次任务执行的语句可能不同，所以每次任务执行所花费的时间是不确定的，也就导致了每次任务的执行周期存在一定的波动。</p><p>固定时间间隔的任务不论每次任务花费多少时间，下次任务开始执行时间从理论上讲是确定的，当然执行任务的时间不能超过执行周期。</p><p>定时任务异常问题：</p><p>如果任务在执行过程中出现了异常而且不进行捕捉的话，next周期将不会运行。</p><p>定时任务超时问题：</p><p>scheduleAtFixedRate中，若任务处理时长超出设置的定时频率时长，本次任务执行完才开始下次任务，下次任务已经处于超时状态，会马上开始执行。若任务处理时长小于定时频率时长，任务执行完后，定时器等待，下次任务会在定时器等待频率时长后执行。</p><p>如下例子：</p><p>设置定时任务每60s执行一次，那么从理论上应该第一次任务在第0s开始,第二次任务在第60s开始，第三次任务在120s开始，但实际运行时第一次任务时长80s，第二次任务时长30s，第三次任务时长50s，则实际运行结果为：</p><p>第一次任务第0s开始,第80s结束；</p><p>第二次任务第80s开始,第110s结束(上次任务已超时,本次不会再等待60s,会马上开始)；</p><p>第三次任务第120s开始,第170s结束.</p><p>第四次任务第180s开始…..</p><h2 id="Executor框架的基本使用流程"><a href="#Executor框架的基本使用流程" class="headerlink" title="Executor框架的基本使用流程"></a>Executor框架的基本使用流程</h2><img src="/2020/01/16/%E7%BA%BF%E7%A8%8B%E6%B1%A0/pic3.png" srcset="/img/loading.gif" class=""><h3 id="了解CompletionService"><a href="#了解CompletionService" class="headerlink" title="了解CompletionService"></a>了解CompletionService</h3><p>CompletionService实际上可以看做是Executor和BlockingQueue的结合体。CompletionService在接收到要执行的任务时，通过类似BlockingQueue的put()和take()获得任务执行的结果。</p><p>CompletionService的一个实现是ExecutorCompletionService，ExecutorCompletionService把具体的计算任务交给Executor完成。</p><p>在实现上，ExecutorCompletionService在构造函数中会创建一个BlockingQueue（使用的基于链表的LinkedBlockingQueue），该BlockingQueue的作用是保存Executor执行的结果。</p><p>当提交一个任务到ExecutorCompletionService时，首先将任务包装成QueueingFuture，它是FutureTask的一个子类，然后改写FutureTask的done方法，之后把Executor执行的计算结果放入BlockingQueue中。</p><p>与ExecutorService最主要的区别在于submit的task不一定是按照加入时的顺序完成的。CompletionService对ExecutorService进行了包装，内部维护一个保存Future对象的BlockingQueue。只有当这个Future对象状态是结束的时候，才会加入到这个Queue中，take()方法其实就是Producer-Consumer中的Consumer。它会从Queue中取出Future对象，如果Queue是空的，就会阻塞在那里，直到有完成的Future对象加入到Queue中。所以，先完成的必定先被取出。这样就减少了不必要的等待时间。</p><p>使用方法一，自己创建一个集合来保存Future存根并循环调用其返回结果的时候，主线程并不能保证首先获得的是最先完成任务的线程返回值。它只是按加入线程池的顺序返回。因为take方法是阻塞方法，后面的任务完成了，前面的任务却没有完成，主程序就那样等待在那儿，只到前面的完成了，它才知道原来后面的也完成了。</p><p>使用方法二，使用CompletionService来维护处理线程不的返回结果时，主线程总是能够拿到最先完成的任务的返回值，而不管它们加入线程池的顺序。</p><pre><code>/** *类说明： */public class CompletionCase {    private final int POOL_SIZE = Runtime.getRuntime().availableProcessors();    private final int TOTAL_TASK = Runtime.getRuntime().availableProcessors()*10;    // 方法一，自己写集合来实现获取线程池中任务的返回结果    public void testByQueue() throws Exception {       long start = System.currentTimeMillis();       AtomicInteger count = new AtomicInteger(0);        // 创建线程池        ExecutorService pool = Executors.newFixedThreadPool(POOL_SIZE);        // 拿任务的执行结果        BlockingQueue&lt;Future&lt;Integer&gt;&gt; queue =              new LinkedBlockingQueue&lt;Future&lt;Integer&gt;&gt;();        // 向里面扔任务        for (int i = 0; i &lt; TOTAL_TASK; i++) {            Future&lt;Integer&gt; future = pool.submit(new WorkTask(&quot;ExecTask&quot; + i));            queue.add(future);        }        // 检查线程池任务执行结果        for (int i = 0; i &lt; TOTAL_TASK; i++) {           int sleptTime = queue.take().get();           //System.out.println(&quot; slept &quot;+sleptTime+&quot; ms ...&quot;);           count.addAndGet(sleptTime);        }        // 关闭线程池        pool.shutdown();        System.out.println(&quot;-------------tasks sleep time &quot;+count.get()              +&quot;ms,and spend time &quot;              +(System.currentTimeMillis()-start)+&quot; ms&quot;);    }    public void testByCompletion() throws InterruptedException, ExecutionException {        long start = System.currentTimeMillis();        AtomicInteger count = new AtomicInteger(0);        // 创建线程池        ExecutorService pool = Executors.newFixedThreadPool(POOL_SIZE);        CompletionService&lt;Integer&gt; cService = new ExecutorCompletionService&lt;&gt;(pool);        // 向里面扔任务        for (int i = 0; i &lt; TOTAL_TASK; i++) {            cService.submit(new WorkTask(&quot;ExecTask&quot; + i));        }        // 检查线程池任务执行结果        for (int i = 0; i &lt; TOTAL_TASK; i++) {            int sleptTime = cService.take().get();            //System.out.println(&quot; slept &quot;+sleptTime+&quot; ms ...&quot;);            count.addAndGet(sleptTime);        }        // 关闭线程池        pool.shutdown();        System.out.println(&quot;-------------tasks sleep time &quot;+count.get()                +&quot;ms,and spend time &quot;                +(System.currentTimeMillis()-start)+&quot; ms&quot;);    }    public static void main(String[] args) throws Exception {        CompletionCase t = new CompletionCase();        t.testByQueue();        t.testByCompletion();    }}</code></pre><p>两种方法对比</p><pre><code>-------------tasks sleep time 38314ms,and spend time 5136 ms-------------tasks sleep time 40876ms,and spend time 5707 ms</code></pre>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Tomcat性能优化</title>
    <link href="undefined2020/01/10/tomcat%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    <url>2020/01/10/tomcat%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="Tomcat内存优化"><a href="#Tomcat内存优化" class="headerlink" title="Tomcat内存优化"></a>Tomcat内存优化</h2><p>tomcat默认参数是为开发环境制定，而非适合生产环境，尤其是内存和线程的配置，默认都很低，容易成为性能瓶颈。</p><p>TOMCAT_HOME/bin/catalina.sh，在前面加入</p><pre><code>JAVA_OPTS=&quot;-XX:PermSize=64M -XX:MaxPermSize=128m -Xms512m -Xmx1024m -Duser.timezone=Asia/Shanghai&quot;</code></pre><p>此设置将最大堆内存改为1024m，实际调整时还是按照服务器的具体配置优化。</p><ul><li>JVM初始化堆大小：Xms</li><li>JVM堆的最大值：Xmx</li><li>JVM初始分配的非堆内存：PermSize</li><li>JVM最大允许分配的非堆内存：MaxPermSize</li></ul><h2 id="Tomcat线程优化"><a href="#Tomcat线程优化" class="headerlink" title="Tomcat线程优化"></a>Tomcat线程优化</h2><p>在TOMCAT_HOME/conf/server.xml中设置</p><pre><code>&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; maxThreads=&quot;600&quot; minSpareThreads=&quot;100&quot; maxSpareThreads=&quot;500&quot; acceptCount=&quot;700&quot;connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt;</code></pre><ul><li>maxThreads：最大线程数</li><li>minSpareThreads：最小空闲线程数（tomcat初始化时创建的线程数）</li><li>maxSpareThreads：最大空闲线程数（超过这个值之后，tomcat会关闭多余的socket线程）</li><li>acceptCount：等待队列长度。超过这个数的请求将不予处理，http请求将返回502状态码</li></ul><p>如果使用apache和tomcat做集群的负载均衡，并且使用ajp协议做apache和tomcat的协议转发，那么还需要优化ajp connector。</p><pre><code>&lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; maxThreads=&quot;600&quot; minSpareThreads=&quot;100&quot; maxSpareThreads=&quot;500&quot; acceptCount=&quot;700&quot;connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt;</code></pre><p>由于tomcat有多个connector，所以tomcat线程的配置可以支持多个connector共享一个线程池。</p><pre><code>&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot; maxThreads=&quot;500&quot; minSpareThreads=&quot;20&quot; maxIdleTime=&quot;60000&quot; /&gt;</code></pre><p>修改Connector节点，增加executor属性设置为线程池的名字</p><pre><code>&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;80&quot; protocol=&quot;HTTP/1.1&quot;  connectionTimeout=&quot;60000&quot; keepAliveTimeout=&quot;15000&quot; maxKeepAliveRequests=&quot;1&quot;  redirectPort=&quot;443&quot; /&gt;</code></pre><p>可以多个connector公用1个线程池，所以ajp connector也同样可以设置使用tomcatThreadPool线程池。</p><h2 id="Tomcat的连接器优化"><a href="#Tomcat的连接器优化" class="headerlink" title="Tomcat的连接器优化"></a>Tomcat的连接器优化</h2><p>Tomcat Connector(Tomcat连接器)有bio、nio、apr三种运行模式</p><h3 id="BIO"><a href="#BIO" class="headerlink" title="BIO"></a>BIO</h3><p>bio（blocking I/O，阻塞式I/O操作），表示Tomcat使用的是传统的Java I/O操作(即java.io包及其子包)。<br><strong>默认的模式，性能最差，没有经过任何优化处理和支持。</strong></p><h3 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h3><p>nio(non-blocking I/O，非阻塞式I/O操作)，也被看成是<code>non-blocking I/O</code>的缩写，是Java SE 1.4及后续版本提供的一种新的I/O操作方式(即java.nio包及其子包)。Java nio是一个基于缓冲区、并能提供非阻塞I/O操作的Java API。拥有比传统I/O操作(bio)更好的并发运行性能。 tomcat在8.0之后已经将nio作为默认运行模式，在8.0之前要让tomcat以nio方式来运行也比较简单，只需要修改tomcat目录下的/conf/servcer.xml中的protocol设置为<code>org.apache.coyote.http11.Http11NioProtocol</code>即可</p><pre><code>&lt;Connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot;connectionTimeout=&quot;20000&quot;redirectPort=&quot;8443&quot; /&gt;</code></pre><p>点击tomcat管理页面的server status之后就可以看到当前的运行模式</p><img src="/2020/01/10/tomcat%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic1.png" srcset="/img/loading.gif" class=""><h3 id="APR"><a href="#APR" class="headerlink" title="APR"></a>APR</h3><p>apr(Apache Portable Runtime/Apache可移植运行时库)，Tomcat将以JNI(Java Native Interface)的形式调用Apache HTTP服务器的核心动态链接库来处理文件读取或网络传输操作，从而大大地提高Tomcat对静态文件的处理性能。使用操作系统的部分本地操作，解决异步的IO问题，大幅度的提高性能。 Tomcat apr也是在Tomcat上运行高并发应用的首选模式。</p><p>Tomcat apr运行模式的配置是三种运行模式之中相对比较麻烦的一种。据官方文档所述，Tomcat apr需要以下三个组件的支持：</p><ul><li>APR library[APR库]</li><li>JNI wrappers for APR used by Tomcat (libtcnative)[简单地说，如果是在Windows操作系统上，就是一个名为tcnative-1.dll的动态链接库文件]</li><li>OpenSSL libraries[OpenSSL库]</li></ul><h3 id="centos7下tomcat8开启APR步骤"><a href="#centos7下tomcat8开启APR步骤" class="headerlink" title="centos7下tomcat8开启APR步骤"></a>centos7下tomcat8开启APR步骤</h3><ol><li>下载APR组件依赖</li></ol><img src="/2020/01/10/tomcat%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic2.png" srcset="/img/loading.gif" class=""><ol start="2"><li>安装apr</li></ol><pre><code>tar zxvf apr-1.6.5.tar.gzcd apr-1.6.5./configure --prefix=/usr/local/aprmake &amp;&amp; make install</code></pre><ol start="3"><li>安装apr-iconv</li></ol><pre><code>tar zxvf apr-iconv.1.2.2.tar.gzcd apr-iconv-1.2.2./configure --prefix=/usr/local/apr-iconv --with-apr=/usr/local/aprmake &amp;&amp; make install</code></pre><ol start="4"><li>安装apr-util</li></ol><pre><code>tar zxvf apr-util.1.6.1.tar.gzcd apr-util-1.6.1./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr --with-apr-iconv=/usr/local/apr-iconv/bin/apriconvmake &amp;&amp; make install</code></pre><ol start="5"><li>安装tomcat的bin目录下的tomcat-native-1.2.21-src.tar.gz</li></ol><pre><code>tar zxf tomcat-native-1.2.21-src.tar.gzcd tomcat-native-1.2.21cd native./configure --with-apr=/usr/local/apr --with-java-home=/usr/java/jdk1.8.0_65make &amp;&amp; make install</code></pre><ol start="6"><li>在tomcat的bin目录下的catalina.sh的最后一行添加变量</li></ol><pre><code>JAVA_OPTS=”$JAVA_OPTS -Djava.library.path=/usr/local/apr/lib”</code></pre><ol start="7"><li>重启tomcat启动日志中出现以下内容证明APR模式启动</li></ol><pre><code>10-Jan-2020 17:23:29.744 信息 [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [&quot;http-apr-9080&quot;]</code></pre><p>同理，通过tomcat的启动日志也可以判断出其运行状态</p><ul><li>bio</li></ul><pre><code>INFO: Initializing ProtocolHandler [&quot;http-bio-8080&quot;]Aug 04, 2015 10:20:35 PM org.apache.coyote.AbstractProtocol init</code></pre><ul><li>nio</li></ul><pre><code>INFO: Initializing ProtocolHandler [&quot;http-nio-8080&quot;]Aug 04, 2015 10:27:58 PM org.apache.coyote.AbstractProtocol init</code></pre><ul><li>apr</li></ul><pre><code>INFO: Initializing ProtocolHandler [&quot;http-apr-8080&quot;]Aug 04, 2015 10:33:45 PM org.apache.coyote.AbstractProtocol init</code></pre><h2 id="禁用DNS查询"><a href="#禁用DNS查询" class="headerlink" title="禁用DNS查询"></a>禁用DNS查询</h2><p>当web应用程序向要记录客户端的信息时，它也会记录客户端的IP地址或者通过域名服务器查找机器名 转换为IP地址。</p><p>DNS查询需要占用网络，并且包括可能从很多很远的服务器或者不起作用的服务器上去获取对应的IP的过程，这样会消耗一定的时间。</p><p>修改server.xml文件中的Connector元素，修改属性enableLookups参数值: enableLookups=”false”</p><p>如果为true，则可以通过调用request.getRemoteHost()进行DNS查询来得到远程客户端的实际主机名，若为false则不进行DNS查询，而是返回其ip地址</p><h2 id="设置session过期时间"><a href="#设置session过期时间" class="headerlink" title="设置session过期时间"></a>设置session过期时间</h2><p>在tomcat目录下的conf\web.xml中通过参数指定，单位为分钟。</p><pre><code>&lt;session-config&gt;       &lt;session-timeout&gt;180&lt;/session-timeout&gt;     &lt;/session-config&gt;</code></pre><h2 id="Maven项目远程部署到Tomcat"><a href="#Maven项目远程部署到Tomcat" class="headerlink" title="Maven项目远程部署到Tomcat"></a>Maven项目远程部署到Tomcat</h2><p>其实本节内容并不属于tomcat性能调优，但内容较少不足以再开一篇文章，凑合凑合塞到这吧。</p><ol><li>在tomcat根目录下的/conf/tomcat-users.xml添加用户</li></ol><pre><code>&lt;tomcat-users version=&quot;1.0&quot; xmlns=&quot;http://tomcat.apache.org/xml&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://tomcat.apache.org/xml tomcat-users.xsd&quot;&gt;&lt;role rolename=&quot;manager-gui&quot; /&gt;&lt;role rolename=&quot;manager-script&quot; /&gt;&lt;role rolename=&quot;admin-gui&quot; /&gt;&lt;role rolename=&quot;admin-script&quot; /&gt;&lt;user username=&quot;admin&quot; password=&quot;tomcat&quot; roles=&quot;manager-gui,manager-script,admin-gui,admin-script&quot; /&gt;&lt;/tomcat-users&gt;</code></pre><ol start="2"><li>pom文件中加入maven插件</li></ol><pre><code>&lt;plugin&gt;    &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt;    &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt;    &lt;version&gt;2.2&lt;/version&gt;    &lt;configuration&gt;        &lt;charset&gt;utf-8&lt;/charset&gt;        &lt;update&gt;true&lt;/update&gt;        &lt;url&gt;http://{yourIP}:8080/manager/text&lt;/url&gt;        &lt;mode&gt;war&lt;/mode&gt;        &lt;username&gt;username&lt;/username&gt;        &lt;password&gt;password&lt;/password&gt;        &lt;path&gt;/${project.artifactId}&lt;/path&gt;    &lt;/configuration&gt;&lt;/plugin&gt;</code></pre><p>tomcat7-maven-plugin是很久以前的插件版本，默认支持到Tomcat7，但是对于目前最新的Tomcat9同样可以使用该插件</p><p>官方介绍文档为：<code>http://tomcat.apache.org/maven-plugin-2.1/index.html</code></p><p>参数说明：</p><p>以下参数必选，但是可以在pom中空缺，空缺时将采用默认值</p><table><thead><tr><th>名称</th><th>描述</th><th>默认值</th></tr></thead><tbody><tr><td>charset</td><td>在与Tomcat Manager通信是的URL编 码字符集</td><td>ISO-8859-1</td></tr><tr><td>mode</td><td>部署的模式，值可为：war,context,both</td><td>war</td></tr><tr><td>path</td><td>应用程序运行的上下文路径，必须以’/‘开始</td><td>/${project.artifactId}</td></tr><tr><td>update</td><td>当部署已存在的应用时，是否自动 undeploy该应用</td><td>false</td></tr><tr><td>url</td><td>Tomcat Manager实例使用的全路径</td><td>tomcat的根路径/manager/text</td></tr><tr><td>warFile</td><td>部署warFile的路径</td><td>${project.build.directory} ${project.build.finalName}.war</td></tr></tbody></table><p>对于个性化的需求，tomcat7插件提供了可配置的参数</p><table><thead><tr><th>名称</th><th>描述</th></tr></thead><tbody><tr><td>contextFile</td><td>Tomcat的context的XML路径，对于mode=war不适用，默认为 ${project.build.directory}/${project.build.finalName}/ META-INF/context.xml</td></tr><tr><td>ignorePackaging</td><td>如果设置为true，忽略类型不是war的项目</td></tr><tr><td>username</td><td>部署到Tomcat的username</td></tr><tr><td>password</td><td>部署到Tomcat的password</td></tr><tr><td>server</td><td>指定Maven的setting.xml中配置的server id用于Tomcat认证</td></tr><tr><td>tag</td><td>应用程序在Tomcat中使用的标签的名字</td></tr></tbody></table><p>还可以在maven目录中的conf/setting.xml中添加tomcat的用户名和密码</p><pre><code>&lt;servers&gt;    &lt;server&gt;        &lt;id&gt;tomcatServer&lt;/id&gt;        &lt;username&gt;username&lt;/username&gt;        &lt;password&gt;password&lt;/password&gt;    &lt;/server&gt;&lt;/servers&gt;</code></pre><p>之后在pom文件中指定server的id即可，不在需要用户名密码</p><pre><code>&lt;plugin&gt;    &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt;    &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt;    &lt;version&gt;2.2&lt;/version&gt;    &lt;configuration&gt;        &lt;url&gt;http://{yourIP}:8080/manager/text&lt;/url&gt;        &lt;server&gt;tomcatServer&lt;/server&gt;        &lt;update&gt;true&lt;/update&gt;        &lt;path&gt;/${project.artifactId}&lt;/path&gt;    &lt;/configuration&gt;        &lt;/plugin&gt;</code></pre><ol start="3"><li>idea部署项目</li></ol><p>idea可以直接在右侧边栏中的plugins中找到tomcat7，第一次部署时选择deploy之后选择redeploy就可以了</p><p>mvn命令</p><pre><code>mvn tomcat7:deploymvn tomcat7:redeploymvn tomcat7:undeploy</code></pre>]]></content>
    
    
    <categories>
      
      <category>性能优化</category>
      
    </categories>
    
    
    <tags>
      
      <tag>tomcat</tag>
      
      <tag>性能优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>并发容器</title>
    <link href="undefined2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/"/>
    <url>2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="Hash算法"><a href="#Hash算法" class="headerlink" title="Hash算法"></a>Hash算法</h2><p>Hash一般译做“散列”，就是把任意长度的输入（又叫做预映射， pre-image），通过散列算法，变换成固定长度的输出，该输出就是散列值。这种转换是一种压缩映射，也就是散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能从散列值来确定唯一的输入值（不可逆）。简单的说Hash算法就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。因为其不可逆的特性，Hash算法也可以用来作为加密算法。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic1.png" srcset="/img/loading.gif" class=""><p>处理冲突方法:</p><ol><li>开放寻址法：出现hash冲突时，从当前地址向后寻找</li><li>再散列法：出现hash冲突时，再次进行hash运算</li><li>链地址法(拉链法)：将有hash冲突的元素存储在链表或其他数据结构中</li></ol><p>常用hash算法的介绍：</p><ol><li>MD4 </li><li>MD5（常被用为加密算法）</li><li>SHA-1及其他。</li></ol><h2 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h2><h3 id="常用位运算"><a href="#常用位运算" class="headerlink" title="常用位运算"></a>常用位运算</h3><ul><li><p>位与 &amp; (1&amp;1=1 0&amp;0=0 1&amp;0=0)</p></li><li><p>位或 | (1|1=1 0|0=0 1|0=1)</p></li><li><p>位非 <del>(</del>1=0 ~0=1)</p></li><li><p>位异或 ^ (1^1=0 1^0=1 0^0=0)</p></li><li><p>有符号右移&gt;&gt;(若正数,高位补0,负数,高位补1)</p></li><li><p>有符号左移&lt;&lt;(低位补0)</p></li><li><p>无符号右移&gt;&gt;&gt;(不论正负,高位均补0)</p></li></ul><p>有趣的取模性质：取模a % (2^n) 等价于 a &amp; (2^n - 1)，所以在map里的数组个数一定是2的乘方数，计算key值在哪个元素中的时候，就用位运算来快速定位。</p><pre><code>public class IntToBinary {    public static void main(String[] args) throws UnsupportedEncodingException {        System.out.println(&quot;the 4 is : &quot; + Integer.toBinaryString(4));        System.out.println(&quot;the 6 is : &quot; + Integer.toBinaryString(6));        //位与&amp;(真真为真 真假为假 假假为假)        System.out.println(&quot;the 4&amp;6 is : &quot; + Integer.toBinaryString(6&amp;4));        //位或|(真真为真 真假为真 假假为假)        System.out.println(&quot;the 4|6 is : &quot; + Integer.toBinaryString(6|4));        //位非~        System.out.println(&quot;the ~4 is : &quot; + Integer.toBinaryString(~4));        //位异或^(真真为假 真假为真 假假为假)        System.out.println(&quot;the 4^6 is : &quot; + Integer.toBinaryString(6^4));        //有符号右移&gt;&gt;(若正数,高位补0,负数,高位补1)        System.out.println(&quot;the 4&gt;&gt;1 is : &quot; + Integer.toBinaryString(4&gt;&gt;1));        //有符号左移&lt;&lt;(若正数,高位补0,负数,高位补1)        System.out.println(&quot;the 4&lt;&lt;1 is : &quot; + Integer.toBinaryString(4&lt;&lt;1));        //无符号右移&gt;&gt;&gt;(不论正负,高位均补0)        System.out.println(&quot;the 234567 is : &quot; + Integer.toBinaryString(234567));        System.out.println(&quot;the 234567&gt;&gt;&gt;4 is : &quot; + Integer.toBinaryString(234567&gt;&gt;&gt;4));        //无符号右移&gt;&gt;&gt;(不论正负,高位均补0)        System.out.println(&quot;the -4 is : &quot; + Integer.toBinaryString(-4));        System.out.println(&quot;the -4&gt;&gt;&gt;4 is : &quot; + Integer.toBinaryString(-4&gt;&gt;&gt;4));        System.out.println(Integer.parseInt(Integer.toBinaryString(-4&gt;&gt;&gt;4), 2));        //取模a % (2^n) 等价于 a &amp; (2^n - 1)         System.out.println(&quot;the 345 % 16 is : &quot; + (345%16)+&quot; or &quot;+(345&amp;(16-1)));        System.out.println(&quot;Mark hashCode is : &quot;+&quot;Mark&quot;.hashCode()+&quot;=&quot;              +Integer.toBinaryString(&quot;Mark&quot;.hashCode()));        System.out.println(&quot;Bill hashCode is : &quot;+&quot;Bill&quot;.hashCode()+&quot;=&quot;              +Integer.toBinaryString(&quot;Bill&quot;.hashCode()));            } }</code></pre><h3 id="位运算运用场景"><a href="#位运算运用场景" class="headerlink" title="位运算运用场景"></a>位运算运用场景</h3><ul><li><p>Java中的类修饰符、成员变量修饰符、方法修饰符，比如Class类中</p></li><li><p>Java容器中的HashMap和ConcurrentHashMap的实现</p></li><li><p>权限控制或者商品属性</p></li><li><p>简单可逆加密，比如异或运算(1^1=0 ; 0^1=1 )</p></li></ul><p>实战：权限控制</p><pre><code>public class Permission {    private static final int ALLOW_SELECT = 1 &lt;&lt; 0;    private static final int ALLOW_INSERT = 1 &lt;&lt; 1;    private static final int ALLOW_UPDATE = 1 &lt;&lt; 2;    private static final int ALLOW_DELETE = 1 &lt;&lt; 3;    // 当前状态    private int flag;    public void setPermission(int permission) {        this.flag = permission;    }    // 增加权限，可以一项或者多项    public void addPermission(int permission) {        this.flag = flag | permission;    }    // 删除权限，可以一项或者多项    public void disablePermission(int permission) {        this.flag = flag &amp; ~permission;    }    // 是否拥有权限    public boolean isAllow(int permission) {        return (this.flag &amp; permission) == permission;    }    // 是否不拥有权限    public boolean isNotAllow(int permission) {        return (this.flag &amp; permission) == 0;    }    public static void main(String[] args) {      int flag = 15;      Permission permission = new Permission();      permission.setPermission(flag);      permission.disablePermission(ALLOW_DELETE|ALLOW_INSERT);      System.out.println(&quot;ALLOW_SELECT=&quot;+permission.isAllow(ALLOW_SELECT));      System.out.println(&quot;ALLOW_INSERT=&quot;+permission.isAllow(ALLOW_INSERT));      System.out.println(&quot;ALLOW_UPDATE=&quot;+permission.isAllow(ALLOW_UPDATE));      System.out.println(&quot;ALLOW_DELETE=&quot;+permission.isAllow(ALLOW_DELETE));    }</code></pre><p>使用位运算的优劣势：</p><p>节省很多代码量、效率高、属性变动影响小、不直观</p><h2 id="JDK1-7中HashMap死循环分析"><a href="#JDK1-7中HashMap死循环分析" class="headerlink" title="JDK1.7中HashMap死循环分析"></a>JDK1.7中HashMap死循环分析</h2><p>在多线程环境下，HashMap在并发执行put操作时会导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry，导致CPU利用率接近100%。</p><h3 id="HashMap扩容流程"><a href="#HashMap扩容流程" class="headerlink" title="HashMap扩容流程"></a>HashMap扩容流程</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>正常的扩容操作是这个流程。HashMap的扩容在put操作中会触发扩容，主要是三个方法：</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic2.png" srcset="/img/loading.gif" class=""><p>综合来说，HashMap一次扩容的过程：</p><ol><li><p>取当前table的2倍作为新table的大小</p></li><li><p>根据算出的新table的大小new出一个新的Entry数组来，名为newTable</p></li><li><p>轮询原table的每一个位置，将每个位置上连接的Entry，算出在新table上的位置，并以链表形式连接</p></li><li><p>原table上的所有Entry全部轮询完毕之后，意味着原table上面的所有Entry已经移到了新的table上，HashMap中的table指向newTable</p></li></ol><h4 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h4><p>现在hashmap中有三个元素，key分别为3、7、5，Hash表的size=2, 通过hash计算后这三个元素都将分配到table[1]。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic3.png" srcset="/img/loading.gif" class=""><p>按照方法中的代码</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic4.png" srcset="/img/loading.gif" class=""><p>对table[1]中的链表来说，进入while循环，此时e=key(3)，那么next=key(7)，经过计算重新定位e=key(3)在新表中的位置，并把e=key(3)分配newTable[3]的位置</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic5.png" srcset="/img/loading.gif" class=""><p>这样循环下去，将table[1]中的链表循环完成后，于是HashMap就完成了扩容</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic6.png" srcset="/img/loading.gif" class=""><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic7.png" srcset="/img/loading.gif" class=""><p>HashMap在hash冲突插入元素时采用的是头插法，先将新的元素的next指向当前table[i]，之后再将table[i]指向当前元素</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic8.png" srcset="/img/loading.gif" class=""><h3 id="并发下的扩容"><a href="#并发下的扩容" class="headerlink" title="并发下的扩容"></a>并发下的扩容</h3><p>初始的HashMap还是：</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic9.png" srcset="/img/loading.gif" class=""><p>现在假设有两个线程并发操作，都进入了扩容操作线程1执行到Entry&lt;K,V&gt; next = e.next;时被操作系统调度挂起了，而线程2执行完成了扩容操作:</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic10.png" srcset="/img/loading.gif" class=""><p>于是，在线程1,2看来，就应该是这个样子</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic11.png" srcset="/img/loading.gif" class=""><p>接下来，线程1被调度回来执行： </p><ol><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic12.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic13.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic14.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic15.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic16.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic17.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic18.png" srcset="/img/loading.gif" class=""></li></ol><p>循环列表产生后，一旦线程1调用get（11,15之类的元素）时，就会进入一个死循环的情况，将CPU的消耗到100%。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>HashMap之所以在并发下的扩容造成死循环，是因为多个线程并发进行时，一个线程先期完成了扩容，将原Map的链表重新散列到自己的表中，并将链表变成了倒序，后一个线程再扩容时，又进行自己的散列，再次将倒序链表变为正序链表，于是形成了一个环形链表，当get表中不存在的元素时，会去遍历链表造成死循环。</p><h2 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h2><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>除了Map系列应该有的线程安全的get，put等方法外，ConcurrentHashMap还提供了一个在并发下比较有用的方法 putIfAbsent，如果传入key对应的value已经存在，就返回存在的value，不进行替换。如果不存在，就添加key和value，返回null。在代码层面它的作用类似于：</p><pre><code>synchronized(map){    if (map.get(key) == null){         return map.put(key, value);    } else{         return map.get(key);    }}</code></pre><p>它让上述代码的整个操作是线程安全的。</p><h3 id="ConcurrentHashMap实现分析"><a href="#ConcurrentHashMap实现分析" class="headerlink" title="ConcurrentHashMap实现分析"></a>ConcurrentHashMap实现分析</h3><h4 id="在1-7下的实现"><a href="#在1-7下的实现" class="headerlink" title="在1.7下的实现"></a>在1.7下的实现</h4><h5 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic19.png" srcset="/img/loading.gif" class=""><p>ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁（ReentrantLock），在ConcurrentHashMap里扮演锁的角色；HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组。Segment的结构和HashMap类似，是一种数组和链表结构。一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素，每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得与它对应的Segment锁。Segment数组初始化之后大小不再改变，当需要扩容时Segment下的table数组进行扩容。</p><h5 id="初始化方法"><a href="#初始化方法" class="headerlink" title="初始化方法"></a>初始化方法</h5><p>ConcurrentHashMap初始化方法是通过initialCapacity（初始化容量）、loadFactor（负载因子）和concurrencyLevel（并发级别）来初始化segment数组、段偏移量segmentShift、段掩码segmentMask和每个segment里的HashEntry数组来实现的。</p><p>参数concurrencyLevel（并发度）可以理解为程序运行时能够同时更新ConccurentHashMap且不产生锁竞争的最大线程数，实际上就是ConcurrentHashMap中的分段锁个数，即Segment[]的数组长度。ConcurrentHashMap默认的并发度为16，用户也可以在构造函数中设置并发度，设置之后将不再改变。当用户设置并发度时，ConcurrentHashMap会使用大于等于该值的最小2幂指数作为实际并发度（假如用户设置并发度为17，实际并发度则为32）。如果设置的过小，会带来严重的锁竞争问题；如果设置的过大，原本位于同一个Segment内的访问会扩散到不同的Segment中，CPU cache命中率会下降，从而引起程序性能下降。大小可以通过cpu核心数或实际使用该Map的线程数量来确定。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic20.png" srcset="/img/loading.gif" class=""><p>参数initialCapacity是ConcurrentHashMap的初始化容量，loadfactor是每个Segment的负载因子，在构造方法里需要通过这两个参数来初始化数组中的每个Segment。上面代码中的变量cap就是Segment里HashEntry数组的长度，它等于initialCapacity除以ssize的倍数c，如果c大于1，就会取大于等于c的2的N次方值，所以segment里HashEntry数组的长度不是1，就是2的N次方。</p><p>在默认情况下， ssize = 16，initialCapacity = 16，loadFactor = 0.75f，那么cap = 1，threshold = (int) cap * loadFactor = 0。</p><p>在初始化时，默认只初始化Segment[0]中的table，其他Segment中的table在put时再进行初始化。</p><p>初始化segmentShift和segmentMask（了解即可，无需深究）这两个全局变量需要在定位segment时的散列算法里使用，shift等于size从1向左移位的次数，在默认情况下concurrencyLevel等于16，1需要向左移位移动4次，所以sshift等于4。segmentShift用于定位参与散列运算的位数，segmentShift等于32减sshift，所以等于28，这里之所以用<em>32</em>是因为ConcurrentHashMap里的hash()方法输出的最大数是<em>32</em>位的。segmentMask是散列运算的掩码，等于ssize减1，即15，掩码的二进制各个位的值都是<em>1</em>。因为ssize的最大长度是65536，所以segmentShift最大值是16，segmentMask最大值是65535，对应的二进制是16位，每个位都是1。</p><h5 id="get方法"><a href="#get方法" class="headerlink" title="get方法"></a>get方法</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic21.png" srcset="/img/loading.gif" class=""><p>既然ConcurrentHashMap使用分段锁Segment来保护不同段的数据，那么在插入和获取元素的时候，必须先通过散列算法定位到Segment。get操作先获取hash值，然后使用这个hash值通过hash运算定位到Segment(使用了hash值的高位部分)，再通过hash算法定位到table(使用了散列值的全部)。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic22.png" srcset="/img/loading.gif" class=""><p>整个get过程没有加锁，而是通过volatile保证get总是可以拿到最新值。</p><p>ConcurrentHashMap中使用的hash算法为Wang/Jenkins hash的变种算法，其产生的hash的值更加均匀，减少了hash冲突</p><h5 id="put方法"><a href="#put方法" class="headerlink" title="put方法"></a>put方法</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic24.png" srcset="/img/loading.gif" class=""><p>put方法首先会根据key计算出所在的Segment，然后调用ensureSegment()方法获取Segment。因为ConcurrentHashMap初始化时只会初始化第一个槽 segment[0]，所以其他槽在插入第一个值时会在ensureSegment()方法中进行初始化。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic25.png" srcset="/img/loading.gif" class=""><p>ensureSegment方法考虑了并发情况，当多个线程同时进入初始化同一个槽 segment[k]会进行循环CAS操作保证只有一个线程成功。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic26.png" srcset="/img/loading.gif" class=""><p>put方法在获取到Segment之后会调用Segment中的put方法，Segment中的put方法会通过tryLock()方法尝试获得锁，如果成功获得锁会将node置为null然后进入try语句块，如果没有获得锁会调用scanAndLockForPut()方法自旋等待获得锁。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic27.png" srcset="/img/loading.gif" class=""><p>scanAndLockForPut方法里在尝试获得锁的过程中会对对应HashEntity链表进行遍历，如果遍历完毕仍然找不到与key相同的HashEntry节点，则为后续的put操作提前创建一个HashEntry。当tryLock一定次数（当cpu可用核心数大于1时重试64次，否则只重试1次）后仍无法获得锁，则通过lock()阻塞式申请锁。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic28.png" srcset="/img/loading.gif" class=""><p>在获得锁之后，Segment对链表进行遍历，如果某个HashEntry节点具有相同的key，则更新该HashEntry的value值</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic29.png" srcset="/img/loading.gif" class=""><p>否则新建一个HashEntry节点，采用头插法，将它设置为链表的新head节点并将原头节点设为新head的下一个节点。新建过程中如果节点总数（含新建的HashEntry）超过threshold，则调用rehash()方法对Segment进行扩容，最后将新建HashEntry写入到数组中。</p><h5 id="rehash方法"><a href="#rehash方法" class="headerlink" title="rehash方法"></a>rehash方法</h5><p>rehash方法扩容时会先创建数组newTable，然后进行将table中的节点迁移至newTable，最后用newTable取代table。</p><p>由于扩容是基于2的幂指来操作，假设扩容前某HashEntry对应到Segment中数组的index为i，数组的容量为capacity，那么扩容后该HashEntry对应到新数组中的index只可能为i或者i+capacity，因此很多HashEntry节点在扩容前后index可以保持不变，避免让所有的节点都进行复制操作。</p><p>假设原来table长度为4，那么元素在table中的分布是这样的</p><table><thead><tr><th>Hash值</th><th>15</th><th>23</th><th>34</th><th>56</th><th>77</th></tr></thead><tbody><tr><td>在table中的下标</td><td>3 = 15%4</td><td>3=23%4</td><td>2 = 34%4</td><td>0= 56%4</td><td>1 =77 %4</td></tr></tbody></table><p>扩容后table长度变为8，那么元素在table中的分布变成：</p><table><thead><tr><th>Hash值</th><th>15</th><th>23</th><th>34</th><th>56</th><th>77</th></tr></thead><tbody><tr><td>在table中的下标</td><td>7</td><td>7</td><td>2</td><td>0</td><td>5</td></tr></tbody></table><p>可以看见 hash值为34和56的下标保持不变，而15,23,77的下标都是在原来下标的基础上+4即可，可以快速定位和减少重排次数。</p><p>该方法没有考虑并发，因为执行该方法之前已经获取了锁。</p><h5 id="remove方法"><a href="#remove方法" class="headerlink" title="remove方法"></a>remove方法</h5><p>与put方法类似，都是在操作前需要拿到锁，以保证操作的线程安全性。</p><h5 id="size、containsValue方法"><a href="#size、containsValue方法" class="headerlink" title="size、containsValue方法"></a>size、containsValue方法</h5><p>这些方法都是基于整个ConcurrentHashMap来进行操作的，他们的原理也基本类似：首先不加锁循环执行以下操作：循环所有的Segment，获得对应的值以及所有Segment的modcount之和。在 put、remove 和 clean 方法里操作元素前都会将变量 modCount 进行变动，如果连续两次所有Segment的modcount和相等，则过程中没有发生其他线程修改ConcurrentHashMap的情况，返回获得的值。</p><p>当循环次数超过预定义的值时，这时需要对所有的Segment依次进行加锁，获取返回值后再依次解锁。所以一般来说，应该避免在多线程环境下使用size和containsValue方法。</p><h5 id="ConcurrentHashMap的弱一致性"><a href="#ConcurrentHashMap的弱一致性" class="headerlink" title="ConcurrentHashMap的弱一致性"></a>ConcurrentHashMap的弱一致性</h5><p>ConcurrentHashMap的get()和containsKey()方法并没有加锁，在遍历链表节点判断key是否相同以及获得该节点的value时，其他线程对链表结构做的调整（put新的key或者remove操作）会由于HashEntity数组并不是volita修饰的导致返回的可能是过时的数据。如果要求强一致性，那么必须使用Collections.synchronizedMap()方法。</p><h4 id="在1-8下的实现"><a href="#在1-8下的实现" class="headerlink" title="在1.8下的实现"></a>在1.8下的实现</h4><h5 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h5><ol><li>取消segments字段，直接采用transient volatile HashEntry&lt;K,V&gt;[] table保存数据，使用table数组元素作为锁，由于table是可以扩容的，数据的增加时锁的粒度也会缩小以减少并发冲突的概率，同时大量使用了使用 CAS + synchronized 来保证并发安全性。</li><li>将原本的table数组＋单向链表的数据结构，变更为table数组＋单向链表＋红黑树的结构。hash表最核心的能力在于将key hash之后能均匀的分布在数组中，理想的情况下table数组中的每个队列长度主要为0或者1，但实际情况并非如此。在数据量过大的情况下，即使ConcurrentHashMap类会依据默认的加载因子0.75进行扩容、增加table数组长度，但是如果hash结果不均匀，也会使数据集中在某个队列导致队列过长。此时查询某个节点的时间复杂度为O(n)。所以对于个数超过8(默认值)的列表jdk1.8中采用了红黑树的结构，查询的时间复杂度可以降低到O(logN)，从而改进性能。</li><li>使用 Node（jdk1.7 为 HashEntry）作为链表的数据结点，仍然包含 key，value，hash 和 next 四个属性。 红黑树中使用的是 TreeNode（extends Node）。所以根据数组元素中第一个结点数据类型是 Node 还是 TreeNode 可以判断该位置下是链表还是红黑树。</li></ol><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic30.png" srcset="/img/loading.gif" class=""><p>当链表的长度大于8时会转为红黑树</p><p>当红黑树的大小小于6时会转为链表</p><h5 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h5><p>Node是最核心的内部类，它包装了key-value键值对。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic31.png" srcset="/img/loading.gif" class=""><p>定义基本和1.7中的HashEntry相同。Map本身所持有的也是一个Node型的数组</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic32.png" srcset="/img/loading.gif" class=""><p>增加了一个find方法来用以辅助map.get()方法。其实就是遍历链表，子类中会覆盖这个方法。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic35.png" srcset="/img/loading.gif" class=""><p>在map中还定义了Segment这个类，不过只是为了向前兼容而已，不做过多考虑。</p><h5 id="TreeNode"><a href="#TreeNode" class="headerlink" title="TreeNode"></a>TreeNode</h5><p>树节点类，另外一个核心的数据结构。当链表长度过长的时候，会转换为TreeNode。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic33.png" srcset="/img/loading.gif" class=""><p>与1.8中HashMap不同点：</p><ol><li><p>它并不是直接转换为红黑树，而是把这些结点放在TreeBin对象中，由TreeBin完成对红黑树的包装。</p></li><li><p>TreeNode在ConcurrentHashMap继承Node类，HashMap中的继承LinkedHashMap.Entry&lt;K,V&gt;类，ConcurrentHashMap中的TreeNode带有next指针。</p></li></ol><h5 id="TreeBin"><a href="#TreeBin" class="headerlink" title="TreeBin"></a>TreeBin</h5><p>负责TreeNode节点。它代替了TreeNode的根节点，也就是说在实际ConcurrentHashMap的table数组中存放的是TreeBin对象，而不是TreeNode对象。另外这个类还带有了读写锁机制。</p><h5 id="特殊的ForwardingNode"><a href="#特殊的ForwardingNode" class="headerlink" title="特殊的ForwardingNode"></a>特殊的ForwardingNode</h5><p>ForwardingNode是一个特殊的 Node 结点，hash 值为 -1，内部存储nextTable的引用。在table发生扩容的时作为一个占位符放在 table 中表示当前结点为 null 或者已经被移动。</p><h5 id="sizeCtl"><a href="#sizeCtl" class="headerlink" title="sizeCtl"></a>sizeCtl</h5><p>用来控制 table 的初始化和扩容操作。</p><p>负数代表正在进行初始化或扩容操作：-1代表正在初始化，-N 表示有N-1个线程正在进行扩容操作，0为默认值，代表当时的table还没有被初始化。</p><p>正数表示初始化大小或Map中的元素达到这个数量时，需要进行扩容了。</p><h5 id="核心方法"><a href="#核心方法" class="headerlink" title="核心方法"></a>核心方法</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic36.png" srcset="/img/loading.gif" class=""><h5 id="构造方法"><a href="#构造方法" class="headerlink" title="构造方法"></a>构造方法</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic37.png" srcset="/img/loading.gif" class=""><p>可以发现，在new出一个map的实例时，并不会创建其中的数组等等相关的部件，只是进行简单的属性设置而已。同样的，table的大小也被规定为必须是2的乘方数。</p><p>真正的初始化在放在了是在向ConcurrentHashMap中插入元素的时候发生的。如调用put()、computeIfAbsent()、compute()、merge()等方法的时候，调用时机是检查table==null。</p><h5 id="get操作"><a href="#get操作" class="headerlink" title="get操作"></a>get操作</h5><p>get方法比较简单，给定一个key来确定value的时候，必须满足两个条件 key相同 hash值相同，对于节点可能在链表或树上的情况，需要分别去查找。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic38.png" srcset="/img/loading.gif" class=""><h5 id="put操作"><a href="#put操作" class="headerlink" title="put操作"></a>put操作</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic40.png" srcset="/img/loading.gif" class=""><p>总结来说，put方法也继续沿用HashMap的put方法的思想，首先不允许key或value为null的情况放入，对于每一个放入的值，利用spread方法对key的hashcode进行一次hash计算，由此来确定这个值在table中的位置i，如果i位置是空的，直接放进去且不需要加锁操作，否则对i位置节点进行加锁，然后对节点进行判断，如果是树节点则按照树的方式插入新的节点，如果是链表节点，则得到的结点就是由hash值相同的节点组成的链表的头节点。此时需要向后遍历链表，如果遇到key值一致的情况，则需要更新其value值，否则依次向后遍历，到链表尾插入这个结点（尾插法）。如果加入这个节点以后链表长度大于8，就把这个链表转换成红黑树。</p><h5 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic39.png" srcset="/img/loading.gif" class=""><p>前面说过，构造方法中并没有真正初始化，真正的初始化在放在了是在向ConcurrentHashMap中插入元素的时候发生的。具体实现的方法就是initTable</p><h5 id="transfer"><a href="#transfer" class="headerlink" title="transfer"></a>transfer</h5><p>当ConcurrentHashMap容量不足的时需要对table进行扩容。这个方法的基本思想跟HashMap是很像的，但是由于它是支持并发扩容的，所以要复杂的多。我们不深入源码去讲述，只讲述其大概原理。</p><p>扩容的时总是会涉及到从一个“数组”到另一个“数组”拷贝的操作，并发扩容就是使这个操作能够并发进行，利用并发处理去减少扩容带来的时间影响。transfer中的并发扩容就是将数据迁移任务根据变量stride作为步长拆分成多个小迁移任务，每个线程每次负责迁移其中的一部分。</p><p>整个扩容操作分为两个部分：</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic41.png" srcset="/img/loading.gif" class=""><p>第一部分是构建一个nextTable,它的容量是原来的2倍。</p><p>第二个部分就是将原来table中的元素复制到nextTable中，这里允许多线程进行操作。</p><p>整个扩容流程就是遍历和复制：</p><p>为null或者已经处理过的节点，会被设置为forwardNode节点，当线程准备扩容时，发现节点是forwardNode节点，跳过这个节点，继续寻找未处理的节点，找到之后对节点上锁。</p><p>如果这个位置是Node节点（fh&gt;=0），说明它是一个链表，就构造一个反序链表，把他们分别放在nextTable的i和i+n的位置上</p><p>如果这个位置是TreeBin节点（fh&lt;0），也做一个反序处理，并且判断是否需要红黑树转链表，把处理的结果分别放在nextTable的i和i+n的位置上</p><p>遍历过所有的节点以后就完成了复制工作，这时让nextTable作为新的table，并且更新sizeCtl为新容量的0.75倍 ，完成扩容。</p><h5 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h5><p>移除方法的基本流程和put方法很类似，只不过操作由插入数据变为移除数据而已，而且如果存在红黑树的情况下，会检查是否需要将红黑树转为链表的步骤。不再重复讲述。</p><h5 id="treeifyBin"><a href="#treeifyBin" class="headerlink" title="treeifyBin"></a>treeifyBin</h5><p>用于将过长的链表转换为TreeBin对象。但是他并不是直接转换，而是进行一次容量判断，没有达到转换的要求，直接进行扩容操作并返回；如果满足条件才将链表的结构转换为TreeBin ，这与HashMap不同的是，它并没有把TreeNode直接放入红黑树，而是利用了TreeBin这个小容器来封装所有的TreeNode。</p><h5 id="size"><a href="#size" class="headerlink" title="size"></a>size</h5><p>JDK1.8中，调用put()方法时就会调用addCount()方法计算size的数量，扩容过程也会修改size的数量，因此在调用size()方法时可以直接返回，JDK1.7是调用size()方法时才会去计算。</p><p>调用addCount()方法时，会使用CAS更新baseCount，因为CAS只允许一个线程做修改，如果修改失败就会使用counterCells，大致的流程就是：</p><ol><li><p>对 baseCount 做 CAS 自增操作。</p></li><li><p>如果并发导致 baseCount CAS 失败了，则使用 counterCells。</p></li><li><p>如果counterCells CAS 失败了，在 fullAddCount 方法中，会继续死循环操作，直到成功。</p></li></ol><p>在具体实现上，计算大小的核心方法都是 sumCount()</p><p>JDK1.8中sumCount()会获取baseCount和CounterCell数组然后遍历CounterCell数组，将baseCount与CounterCell的值累加后返回。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic42.png" srcset="/img/loading.gif" class=""><p>其实去计算并发集合中实时在变的size是没有多大的意义的，但Doug Lea仍花费了很多心思去优化他的性能。</p><h2 id="HashTable"><a href="#HashTable" class="headerlink" title="HashTable"></a>HashTable</h2><p>HashTable容器使用synchronized来保证线程安全，这会导致在线程竞争激烈的情况下HashTable的效率非常低下。当一个线程访问HashTable的同步方法，其他线程也访问HashTable的同步方法时，会进入阻塞或轮询状态。如线程1使用put进行元素添加，线程2不但不能使用put方法添加元素，也不能使用get方法来获取元素，所以竞争越激烈效率越低。</p><h2 id="并发下的Map常见面试题汇总"><a href="#并发下的Map常见面试题汇总" class="headerlink" title="并发下的Map常见面试题汇总"></a>并发下的Map常见面试题汇总</h2><h3 id="HashMap-和-HashTable-有什么区别？"><a href="#HashMap-和-HashTable-有什么区别？" class="headerlink" title="HashMap 和 HashTable 有什么区别？"></a>HashMap 和 HashTable 有什么区别？</h3><ol><li><p>HashMap 是线程不安全的，HashTable 是线程安全的；</p></li><li><p>由于线程安全，所以 HashTable 的效率比不上 HashMap；</p></li><li><p>HashMap是允许key为value的，HashTable是不允许的，ConcurrentHashMap也是不允许的。</p></li><li><p>HashMap最多只允许一条记录的键为null，允许多条记录的值为null，而 HashTable 不允许；</p></li><li><p>HashMap 默认初始化数组的大小为16，HashTable 为 11，前者扩容时，扩大两倍，后者扩大两倍+1；</p></li><li><p>HashMap 需要重新计算 hash 值，而 HashTable 直接使用对象的 hashCode</p></li></ol><h3 id="Java-中的另一个线程安全的与-HashMap-极其类似的类是什么？同样是线程安全，它与-HashTable-在线程同步上有什么不同？"><a href="#Java-中的另一个线程安全的与-HashMap-极其类似的类是什么？同样是线程安全，它与-HashTable-在线程同步上有什么不同？" class="headerlink" title="Java 中的另一个线程安全的与 HashMap 极其类似的类是什么？同样是线程安全，它与 HashTable 在线程同步上有什么不同？"></a>Java 中的另一个线程安全的与 HashMap 极其类似的类是什么？同样是线程安全，它与 HashTable 在线程同步上有什么不同？</h3><p>ConcurrentHashMap 类（是 Java并发包 java.util.concurrent 中提供的一个线程安全且高效的 HashMap 实现）。</p><p>HashTable 是使用 synchronize 关键字加锁的原理（就是对对象加锁）；</p><p>而针对 ConcurrentHashMap，在 JDK 1.7 中采用Segment分段锁的方式；JDK 1.8 中直接采用了CAS（无锁算法）+ synchronized，也采用分段锁的方式但1.8中的分段锁是使用synchronized锁住table中的节点来实现的，缩小了锁的粒度。</p><h3 id="HashMap-amp-ConcurrentHashMap-的区别？"><a href="#HashMap-amp-ConcurrentHashMap-的区别？" class="headerlink" title="HashMap &amp; ConcurrentHashMap 的区别？"></a>HashMap &amp; ConcurrentHashMap 的区别？</h3><p>除了加锁，原理上无太大区别。</p><p>另外，HashMap 的键值对允许有null，但是ConCurrentHashMap 都不允许。</p><p>在数据结构上，红黑树相关的节点类不同继承的类不同</p><h3 id="为什么ConcurrentHashMap比HashTable效率要高？"><a href="#为什么ConcurrentHashMap比HashTable效率要高？" class="headerlink" title="为什么ConcurrentHashMap比HashTable效率要高？"></a>为什么ConcurrentHashMap比HashTable效率要高？</h3><p>HashTable 使用一把锁（锁住整个链表结构）处理并发问题，多个线程竞争一把锁，容易阻塞ConcurrentHashMap在JDK 1.7 中使用分段锁（ReentrantLock + Segment + HashEntry），相当于把一个 HashMap 分成多个段，每段分配一把锁，这样支持多线程访问。锁粒度基于 Segment，Segment中包含多个 HashEntry。JDK 1.8 中使用 CAS + synchronized + Node + 红黑树。锁粒度基于Node（首结点）（实现 Map.Entry&lt;K,V&gt;），锁粒度相对1.7降低了。</p><h3 id="针对ConcurrentHashMap-锁机制具体分析？"><a href="#针对ConcurrentHashMap-锁机制具体分析？" class="headerlink" title="针对ConcurrentHashMap 锁机制具体分析？"></a>针对ConcurrentHashMap 锁机制具体分析？</h3><p>JDK 1.7 中，采用分段锁的机制，实现并发的更新操作，底层采用数组+链表的存储结构，包括两个核心静态内部类 Segment 和 HashEntry。Segment 继承 ReentrantLock（重入锁） 用来充当锁的角色，每个 Segment 对象守护每个散列映射表的若干个桶；HashEntry 用来封装映射表的键-值对；每个桶是由若干个 HashEntry 对象链接起来的链表。</p><p>JDK 1.8 中，采用Node + CAS + Synchronized来保证并发安全。取消类 Segment，当需要锁时直接用synchronized锁住table数组中的对象，键值对直接存储在table中；当 Node 对象组成的链表长度超过 TREEIFY_THRESHOLD 时，链表转换为红黑树，Node对象被包装为TreeNode，以提升检索性能。此时底层变更为数组 + 链表 + 红黑树。</p><h3 id="ConcurrentHashMap在JDK-1-8中，为什么要使用内置锁-synchronized-来代替重入锁-ReentrantLock？"><a href="#ConcurrentHashMap在JDK-1-8中，为什么要使用内置锁-synchronized-来代替重入锁-ReentrantLock？" class="headerlink" title="ConcurrentHashMap在JDK 1.8中，为什么要使用内置锁 synchronized 来代替重入锁 ReentrantLock？"></a>ConcurrentHashMap在JDK 1.8中，为什么要使用内置锁 synchronized 来代替重入锁 ReentrantLock？</h3><ol><li><p>JVM 开发团队在1.8中对 synchronized做了大量性能上的优化，而且基于 JVM 的 synchronized 优化空间更大，更加自然。</p></li><li><p>在大量的数据操作下，对于 JVM 的内存压力，基于 API 的 ReentrantLock 会开销更多的内存。</p></li></ol><h3 id="ConcurrentHashMap简单介绍？"><a href="#ConcurrentHashMap简单介绍？" class="headerlink" title="ConcurrentHashMap简单介绍？"></a>ConcurrentHashMap简单介绍？</h3><ol><li><p>重要的常量：<strong>private transient volatile int sizeCtl</strong>，当为负数时，-1 表示正在初始化，-N 表示 N - 1 个线程正在进行扩容；当为 0 时，表示 table 还没有初始化；当为其他正数时，表示初始化或者下一次进行扩容的大小。</p></li><li><p>数据结构：<strong>Node 是存储结构的基本单元</strong>，继承 HashMap 中的 Entry，用于存储数据；TreeNode 继承 Node，但是数据结构换成了二叉树结构，是红黑树的存储结构，用于红黑树中存储数据；TreeBin 是封装 TreeNode 的容器，提供转换红黑树的一些条件和锁的控制。</p></li><li><p>put()方法：如果没有初始化，就调用 initTable() 方法来进行初始化；如果没有 hash 冲突就直接 CAS 无锁插入；如果需要扩容，就先进行扩容；如果存在 hash 冲突，就加锁来保证线程安全，两种情况：一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入；如果该链表的数量大于阀值 8，就要先转换成红黑树的结构，break 再一次进入循环如果添加成功就调用 addCount() 方法统计 size，并且检查是否需要扩容。</p></li><li><p>扩容方法 transfer()：默认容量为 16，扩容时，容量变为原来的两倍。helpTransfer()：调用多个工作线程一起帮助进行扩容，这样的效率就会更高。</p></li><li><p>get()方法：计算 hash 值，定位到该 table 索引位置，如果是首结点符合就返回；如果遇到扩容时，会调用标记正在扩容结点 ForwardingNode.find()方法，查找该结点，匹配就返回；以上都不符合的话，就往下遍历结点，匹配就返回，否则最后就返回 null。</p></li></ol><h3 id="ConcurrentHashMap的并发度是什么？"><a href="#ConcurrentHashMap的并发度是什么？" class="headerlink" title="ConcurrentHashMap的并发度是什么？"></a>ConcurrentHashMap的并发度是什么？</h3><p>1.7中程序运行时能够同时更新 ConccurentHashMap 且不产生锁竞争的最大线程数。默认为 16即Segment的数量，可以在构造函数中设置。当用户设置并发度时，ConcurrentHashMap 会使用大于等于该值的最小2幂指数作为实际并发度（假如用户设置并发度为17，实际并发度则为32）。1.8中由于直接使用table中的节点数量作为分段锁的数量，并发度已经没有太大的实际意义了，主要用处就是当设置的初始容量小于并发度，将初始容量提升至并发度大小。 </p><h2 id="ConcurrentSkipListMap和ConcurrentSkipListSet"><a href="#ConcurrentSkipListMap和ConcurrentSkipListSet" class="headerlink" title="ConcurrentSkipListMap和ConcurrentSkipListSet"></a>ConcurrentSkipListMap和ConcurrentSkipListSet</h2><p>TreeMap和TreeSet使用红黑树按照key的顺序（自然顺序、自定义顺序）来使得键值对有序存储，但是只能在单线程下安全使用；多线程下想要使键值对按照key的顺序来存储，则需要使用ConcurrentSkipListMap和ConcurrentSkipListSet，分别用以代替TreeMap和TreeSet，存入的数据按key排序。在实现上，ConcurrentSkipListSet 本质上就是ConcurrentSkipListMap，ConcurrentSkipListMap实际上就是一个跳表的实现。</p><p>ConcurrentSkipListMap和ConcurrentHashMap都是线程安全的Map实现，ConcurrentHashMap的性能和存储空间要优于ConcurrentSkipListMap，但是ConcurrentSkipListMap有一个功能： 它会按照键的顺序进行排序。</p><h3 id="二分查找和AVL树查找"><a href="#二分查找和AVL树查找" class="headerlink" title="二分查找和AVL树查找"></a>二分查找和AVL树查找</h3><p>二分查找要求元素可以随机访问，所以决定了需要把元素存储在连续内存。这样查找确实很快，但是插入和删除元素的时候，为了保证元素的有序性，就需要大量的移动元素了。</p><p>如果需要的是一个能够进行二分查找，又能快速添加和删除元素的数据结构，首先就是二叉查找树，二叉查找树在最坏情况下可能变成一个链表。</p><p>于是，就出现了平衡二叉树，根据平衡算法的不同有AVL树，B-Tree，B+Tree，红黑树等，但是AVL树实现起来比较复杂，平衡操作较难理解，这时候就可以用SkipList跳跃表结构。</p><h3 id="跳表（SkipList）"><a href="#跳表（SkipList）" class="headerlink" title="跳表（SkipList）"></a>跳表（SkipList）</h3><p>传统意义的单链表是一个线性结构，向有序的链表中插入一个节点需要O(n)的时间，查找操作需要O(n)的时间。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic43.png" srcset="/img/loading.gif" class=""><p>如果我们使用上图所示的跳跃表，就可以减少查找所需时间为O(n/2)，因为我们可以先通过每个节点的最上面的指针先进行查找，这样子就能跳过一半的节点。</p><p>比如我们想查找50，首先和20比较，大于20之后，在和40进行比较，然后在和70进行比较，发现70大于50，说明查找的点在40和50之间，从这个过程中，我们可以看出，查找的时候跳过了30。</p><p>跳跃表其实也是一种通过“空间来换取时间”的一个算法，令链表的每个结点不仅记录next结点位置，还可以按照level层级分别记录后继第level个结点。此法使用的就是“<strong>先大步查找确定范围，再逐渐缩小迫近</strong>”的思想进行的查找。跳跃表在算法效率上很接近红黑树。</p><p>跳跃表又被称为概率，或者说是随机化的数据结构，目前开源软件 Redis 和 lucence都有用到它。</p><h2 id="CopyOnWriteArrayList和CopyOnWriteArraySet"><a href="#CopyOnWriteArrayList和CopyOnWriteArraySet" class="headerlink" title="CopyOnWriteArrayList和CopyOnWriteArraySet"></a>CopyOnWriteArrayList和CopyOnWriteArraySet</h2><h3 id="什么是写时复制容器"><a href="#什么是写时复制容器" class="headerlink" title="什么是写时复制容器"></a>什么是写时复制容器</h3><p>CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。</p><p>这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。如果读的时候有多个线程正在向CopyOnWriteArrayList添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的CopyOnWriteArrayList。</p><p>CopyOnWrite容器用于对于绝大部分访问都是读，且只是偶尔写的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单当中，黑名单每天晚上更新一次。当用户搜索时，会检查当前关键字在不在黑名单当中，如果在，则提示不能搜索。</p><h3 id="使用CopyOnWriteMap需要注意两件事情："><a href="#使用CopyOnWriteMap需要注意两件事情：" class="headerlink" title="使用CopyOnWriteMap需要注意两件事情："></a>使用CopyOnWriteMap需要注意两件事情：</h3><ol><li><p>减少扩容开销。根据实际需要，初始化CopyOnWriteMap的大小，避免写时CopyOnWriteMap扩容的开销。</p></li><li><p>使用批量添加。因为每次添加，容器每次都会进行复制，所以减少添加次数，可以减少容器的复制次数。</p></li></ol><h3 id="写时复制容器的问题："><a href="#写时复制容器的问题：" class="headerlink" title="写时复制容器的问题："></a>写时复制容器的问题：</h3><ol><li><p>性能问题：每次修改都创建一个新数组，然后复制所有内容，如果数组比较大，修改操作又比较频繁，可以想象，性能是很低的，而且内存开销会很大。</p></li><li><p>数据一致性问题：CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，不要使用CopyOnWrite容器。</p></li></ol><h2 id="BlockingQueue"><a href="#BlockingQueue" class="headerlink" title="BlockingQueue"></a>BlockingQueue</h2><h3 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h3><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic44.png" srcset="/img/loading.gif" class=""><p>队列是一种特殊的线性表，特殊之处在于它只允许在表的前端（front）进行删除操作，而在表的后端（rear）进行插入操作，和栈一样，队列是一种操作受限制的线性表。进行插入操作的端称为队尾，进行删除操作的端称为队头。</p><p>在队列中插入一个队列元素称为入队，从队列中删除一个队列元素称为出队。因为队列只允许在一端插入，在另一端删除，所以只有最早进入队列的元素才能最先从队列中删除，故队列又称为先进先出（FIFO—first in first out）线性表。</p><h3 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h3><table><thead><tr><th>方法/处理方式</th><th>抛出异常</th><th>返回特殊值</th><th>一直阻塞</th><th>超时退出</th></tr></thead><tbody><tr><td><strong>插入方法</strong></td><td>add(e)</td><td>offer(e)</td><td>put(e)</td><td>offer(e,time,unit)</td></tr><tr><td><strong>移除方法</strong></td><td>remove()</td><td>poll()</td><td>take()</td><td>poll(time, unit)</td></tr><tr><td><strong>检查方法</strong></td><td>element()</td><td>peek()</td><td>不可用</td><td>不可用</td></tr></tbody></table><ul><li><p>支持阻塞的插入方法：当队列满时，队列会阻塞插入元素的线程直到队列不满。</p></li><li><p>支持阻塞的移除方法：在队列为空时，获取元素的线程会被阻塞直到队列变为非空。</p></li><li><p>抛出异常：当队列满时，如果再往队列里插入元素，会抛出IllegalStateException（”Queuefull”）异常。当队列空时，从队列里获取元素会抛出NoSuchElementException异常。</p></li><li><p>返回特殊值：当往队列插入元素时，会返回元素是否插入成功，成功返回true。如果是移除方法，则是从队列里取出一个元素，如果没有则返回null。</p></li><li><p>一直阻塞：当阻塞队列满时，如果线程往队列里put元素，队列会一直阻塞线程，直到队列可用或者响应中断退出。当队列空时，如果线程从队列里take元素，队列会阻塞住消费者线程，直到队列不为空。</p></li><li><p>超时退出：当阻塞队列满时，如果线程往队列里插入元素，队列会阻塞生产者线程一段时间，如果超过了指定的时间，线程就会退出。</p></li></ul><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序整体处理数据的速度。</p><p>在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。</p><p>为了解决这种生产消费能力不均衡的问题，便有了生产者和消费者模式。生产者和消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通信，而是通过阻塞队列来进行通信，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。</p><p>阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器。</p><h3 id="有界无界"><a href="#有界无界" class="headerlink" title="有界无界"></a>有界无界</h3><p>有限队列就是长度有限，满了以后生产者会阻塞，无界队列就是里面能放无数的东西而不会因为队列长度限制被阻塞，当然空间限制来源于系统资源的限制，如果处理不及时，导致队列越来越大越来越大，超出一定的限制致使内存超限，操作系统或者JVM帮你解决烦恼，直接把你 OOM kill 省事了。</p><h3 id="阻塞队列的实现原理"><a href="#阻塞队列的实现原理" class="headerlink" title="阻塞队列的实现原理"></a>阻塞队列的实现原理</h3><p>使用了等待通知模式实现。所谓通知模式，就是当生产者往满的队列里添加元素时会阻塞住生产者，当消费者消费了一个队列中的元素后，会通知生产者当前队列可用。通过查看JDK源码发现ArrayBlockingQueue使用了Condition来实现。其余队列的实现，大家可以自行查看，队列的实现的代码总体来说，并不复杂。</p><h3 id="常用阻塞队列"><a href="#常用阻塞队列" class="headerlink" title="常用阻塞队列"></a>常用阻塞队列</h3><ul><li><p>ArrayBlockingQueue：是一个用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下不保证线程公平的访问队列，所谓公平访问队列是指阻塞的线程，可以按照阻塞的先后顺序访问队列，即先阻塞线程先访问队列。非公平性是对先等待的线程是非公平的，当队列可用时，阻塞的线程都可以争夺访问队列的资格，有可能先阻塞的线程最后才访问队列。初始化时有参数可以设置</p></li><li><p>LinkedBlockingQueue：是一个用链表实现的有界阻塞队列。此队列的默认和最大长度为Integer.MAX_VALUE，按照先进先出的原则对元素进行排序。和ArrayBlockingQueue实现的区别：</p><ol><li><p>队列中锁的实现不同ArrayBlockingQueue实现的队列中的锁是没有分离的，即生产和消费用的是同一个锁；LinkedBlockingQueue实现的队列中的锁是分离的，即生产用的是putLock，消费是takeLock。</p></li><li><p>在生产或消费时操作不同：ArrayBlockingQueue实现的队列中在生产和消费的时候，是直接将枚举对象插入或移除的；LinkedBlockingQueue实现的队列中在生产和消费的时候，需要把枚举对象转换为Node<E>进行插入或移除，会影响性能。</p></li><li><p>队列大小初始化方式不同：ArrayBlockingQueue实现的队列中必须指定队列的大小LinkedBlockingQueue实现的队列中可以不指定队列的大小，但是默认是Integer.MAX_VALUE（20来个亿）一般的服务器是扛不住的，所以在使用LinkedBlockingQueue时还是尽量指定大小。</p></li></ol></li><li><p>PriorityBlockingQueue：是一个支持优先级的无界阻塞队列。默认情况下元素采取自然顺序升序排列。也可以自定义类实现compareTo()方法来指定元素排序规则，或者初始化PriorityBlockingQueue时，指定构造参数Comparator来对元素进行排序。需要注意的是不能保证同优先级元素的顺序。</p></li><li><p>DelayQueue：是一个支持延时获取元素的无界阻塞队列。队列使用PriorityQueue来实现。队列中的元素必须实现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。DelayQueue非常有用，可以将DelayQueue运用在以下应用场景。缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。还有订单到期，限时支付等等</p></li><li><p>SynchronousQueue：是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。SynchronousQueue可以看成是一个传球手，负责把生产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常适合传递性场景。SynchronousQueue的吞吐量高于LinkedBlockingQueue和ArrayBlockingQueue。</p></li><li><p>LinkedTransferQueue：一个由链表结构组成的无界阻塞队列，多了tryTransfer和transfer方法。如果当前有消费者正在等待接收元素（消费者使用take()方法或带时间限制的poll()方法时），transfer方法可以把生产者传入的元素立刻transfer（传输）给消费者。如果没有消费者在等待接收元素，transfer方法会将元素存放在队列的tail节点，并等到该元素被消费者消费了才返回。tryTransfer方法是用来试探生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回false。和transfer方法的区别是tryTransfer方法无论消费者是否接收，方法立即返回，而transfer方法是必须等到消费者消费了才返回。</p></li><li><p>LinkedBlockingDeque：是一个由链表结构组成的双向阻塞队列。所谓双向队列指的是可以从队列的两端插入和移出元素。双向队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。多了addFirst、addLast、offerFirst、offerLast、peekFirst和peekLast等方法，以First单词结尾的方法，表示插入、获取（peek）或移除双端队列的第一个元素。以Last单词结尾的方法，表示插入、获取或移除双端队列的最后一个元素。另外，插入方法add等同于addLast，移除方法remove等效于removeFirst。但是take方法却等同于takeFirst，不知道是不是JDK的bug，使用时还是用带有First和Last后缀的方法更清楚。在初始化LinkedBlockingDeque时可以设置容量防止其过度膨胀。另外，双向阻塞队列可以运用在“工作窃取”模式中。</p></li></ul><h2 id="ConcurrentLinkedQueue"><a href="#ConcurrentLinkedQueue" class="headerlink" title="ConcurrentLinkedQueue"></a>ConcurrentLinkedQueue</h2><p>ConcurrentLinkedQueue是一个无界非阻塞队列，它是基于链表的无界线程安全队列。该队列的元素遵循先进先出的原则。头是最先加入的，尾是最近加入的。插入元素是追加到尾上，提取一个元素是从头提取。</p><p>可以看成是LinkedList的并发版本，常用方法：</p><ul><li><p>add(e):插入指定元素</p></li><li><p>offer(e):将指定元素插入到此队列的尾部。  </p></li><li><p>peek():检索此队列的头但并不移除，如果此队列为空，则返回 null。  </p></li><li><p>poll(): 检索并移除此队列的头，如果此队列为空，则返回 null。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>显式锁和AQS</title>
    <link href="undefined2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/"/>
    <url>2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/</url>
    
    <content type="html"><![CDATA[<h2 id="显式锁"><a href="#显式锁" class="headerlink" title="显式锁"></a>显式锁</h2><p>Java程序是靠synchronized关键字实现锁功能的，synchronized关键字将会隐式地获取和释放锁，而且获取和释放锁的过程是固化的，也被称为内置锁。Lock是手动的获取和释放锁，这就是显式锁名称的由来。</p><h3 id="Lock接口和synchronized的比较"><a href="#Lock接口和synchronized的比较" class="headerlink" title="Lock接口和synchronized的比较"></a>Lock接口和synchronized的比较</h3><p>synchronized获取锁时会一直等待直到获取锁为止。Lock提供lockInterruptibly()方法可以在等待获取到锁的过程中能够响应中断，tryLock()方法尝试获取锁时如果失败会返回false，然后线程可以做其他的事，之后再进行tryLock()，tryLock()方法还可以接收long类型及TimeUnit类型的参数超时的获取锁。</p><p>如果尝试取锁及中断取锁尽量使用synchronized关键字，在目前的发展趋势jdk一直在对synchronized进行优化，synchronized的开销要比Lock接口更少。</p><h3 id="Lock的标准用法"><a href="#Lock的标准用法" class="headerlink" title="Lock的标准用法"></a>Lock的标准用法</h3><pre><code>lock.lock()try{    count++;}finally{    lock.unlock();}</code></pre><p>在finally块中释放锁，目的是保证在获取到锁之后，最终能够被释放。</p><p>不能将获取锁的过程写在try块中，如果在获取锁（自定义锁的实现）时发生了异常，异常抛出的同时会导致锁的无故释放。</p><h3 id="可重入锁ReentrantLock、锁的公平和非公平"><a href="#可重入锁ReentrantLock、锁的公平和非公平" class="headerlink" title="可重入锁ReentrantLock、锁的公平和非公平"></a>可重入锁ReentrantLock、锁的公平和非公平</h3><h4 id="可重入"><a href="#可重入" class="headerlink" title="可重入"></a>可重入</h4><p>同一个线程对于已经获得到的锁，可以多次继续申请到该锁的使用权。synchronized关键字也支持隐式的支持重进入，比如一个synchronized修饰的递归方法，在方法执行时，执行线程在获取了锁之后仍能连续多次地获得该锁。ReentrantLock在调用lock()方法时，如果当前线程已经获取到锁就能够再次调用lock()方法获取锁而不被阻塞。</p><h4 id="公平和非公平"><a href="#公平和非公平" class="headerlink" title="公平和非公平"></a>公平和非公平</h4><p>如果在时间上，先对锁进行获取的线程即等待时间最长的线程一定先获取到锁，那么这个锁是公平的，也可以说锁获取是顺序的，反之就是不公平的。 ReentrantLock提供了一个构造函数，能够控制锁是否是公平的，synchronized也是非公平锁。事实上，公平的锁机制往往没有非公平的效率高。  </p><p>线程被唤醒的上下文切换时间周期在5000-10000之间，在激烈竞争的情况下，非公平锁的性能高于公平锁的性能的一个原因是：在恢复一个被挂起的线程与该线程真正开始运行之间存在着严重的延迟。假设线程A持有一个锁，并且线程B请求这个锁。由于这个锁已被线程A持有，因此B将被挂起。当A释放锁时，B将被唤醒，B完全唤醒后会再次尝试获取锁。与此同时，如果C也请求这个锁，那么C很可能会在B被完全唤醒之前获得、使用以及释放这个锁。这样的情况是一种“双赢”的局面：B获得锁的时刻并没有推迟，C更早地获得了锁，并且吞吐量也获得了提高。</p><h3 id="读写锁ReentrantReadWriteLock"><a href="#读写锁ReentrantReadWriteLock" class="headerlink" title="读写锁ReentrantReadWriteLock"></a>读写锁ReentrantReadWriteLock</h3><p>之前提到锁（如synchronized和ReentrantLock）基本都是排他锁即独占锁，这些锁在同一时刻只允许一个线程进行访问，而读写锁在同一时刻可以允许多个读线程访问，但是在写线程访问时，所有的读线程和其他写线程均被阻塞。读写锁维护了一对锁，一个读锁和一个写锁，通过分离读锁和写锁，使得并发性相比一般的排他锁有了很大提升。写锁为独占锁，读锁为共享锁，但读写之前相互排斥。</p><p>除了保证写操作对读操作的可见性以及并发性的提升之外，读写锁能够简化读写交互场景的编程方式。假设在程序中定义一个共享的用作缓存数据结构，它大部分时间提供读服务（例如查询和搜索），而写操作占有的时间很少，但是写操作完成之后的更新需要对后续的读服务可见。</p><p>ReentrantReadWriteLock实现的为ReadAndWriteLock接口，ReadAndWriteLock接口提供了readLock()方法获取读锁，writeLock()方法获取写锁。在没有读写锁支持的（Java 5之前）时候，如果需要完成上述工作就要使用Java的等待通知机制，就是当写操作开始时，所有晚于写操作的读操作均会进入等待状态，只有写操作完成并进行通知之后，所有等待的读操作才能继续执行（写操作之间依靠synchronized关键进行同步），这样做的目的是使读操作能读取到正确的数据，不会出现脏读。改用读写锁实现上述功能，只需要在读操作时获取读锁，写操作时获取写锁即可。当写锁被获取到时，后续（非当前写操作线程）的读写操作都会被阻塞，写锁释放之后，所有操作继续执行，编程方式相对于使用等待通知机制的实现方式而言，变得简单明了。 </p><p>一般情况下，读写锁的性能都会比排它锁好，因为大多数场景读是多于写的，读写的比例约为10:1。在读多于写的情况下，读写锁能够提供比排它锁更好的并发性和吞吐量。</p><h3 id="Condition接口"><a href="#Condition接口" class="headerlink" title="Condition接口"></a>Condition接口</h3><p>任意一个Java对象，都拥有一组监视器方法（定义在java.lang.Object上），主要包括wait()、wait(long timeout)、notify()以及notifyAll()方法，这些方法与synchronized同步关键字配合，可以实现等待/通知模式。Condition接口也提供了类似Object的监视器方法await()，signal()，与Lock配合可以实现等待/通知模式。</p><h3 id="用Lock和Condition实现等待通知"><a href="#用Lock和Condition实现等待通知" class="headerlink" title="用Lock和Condition实现等待通知"></a>用Lock和Condition实现等待通知</h3><pre><code>/** * 类说明： */public class ExpressCond {    public final static String CITY = &quot;ShangHai&quot;;    /**     * 快递运输里程数     */    private int km;    /**     * 快递到达地点     */    private String site;    private Lock kmLock = new ReentrantLock();    private Lock siteLock = new ReentrantLock();    private Condition kmCondition = kmLock.newCondition();    private Condition siteCondition = siteLock.newCondition();    public ExpressCond(int km, String site) {        this.km = km;        this.site = site;    }    /**     * 变化公里数，然后通知处于wait状态并需要处理公里数的线程进行业务处理     */    public void changeKm() {        kmLock.lock();        try {            this.km = 101;            kmCondition.signal();        } finally {            kmLock.unlock();        }    }    /**     * 变化地点，然后通知处于wait状态并需要处理地点的线程进行业务处理     */    public void changeSite() {        siteLock.lock();        try {            this.site = &quot;BeiJing&quot;;            siteCondition.signal();        } finally {            siteLock.unlock();        }    }    /**     * 当快递的里程数大于100时更新数据库     */    public void waitKm() {        kmLock.lock();        try {            while (this.km &lt; 100) {                try {                    kmCondition.await();                    System.out.println(&quot;check Site thread[&quot; + Thread.currentThread().getId()                            + &quot;] is be notified&quot;);                } catch (InterruptedException e) {                    e.printStackTrace();                }            }        } finally {            kmLock.unlock();        }        System.out.println(&quot;the Km is &quot; + this.km + &quot;,I will change db&quot;);    }    /**     * 当快递到达目的地时通知用户     */    public void waitSite() {        siteLock.lock();        try {            while (this.site.equals(CITY)) {                try {                    siteCondition.await();//当前线程进行等待                    System.out.println(&quot;check Site thread[&quot; + Thread.currentThread().getName()                            + &quot;] is be notify&quot;);                } catch (InterruptedException e) {                    e.printStackTrace();                }            }        } finally {            siteLock.unlock();        }        System.out.println(&quot;the site is &quot; + this.site + &quot;,I will call user&quot;);    }    private static ExpressCond express = new ExpressCond(0, ExpressCond.CITY);    /**     * 检查里程数变化的线程,不满足条件，线程一直等待     */    private static class CheckKm extends Thread {        @Override        public void run() {            express.waitKm();        }    }    /**     * 检查地点变化的线程,不满足条件，线程一直等待     */    private static class CheckSite extends Thread {        @Override        public void run() {            express.waitSite();        }    }    public static void main(String[] args) throws InterruptedException {        for (int i = 0; i &lt; 3; i++) {            new ExpressCond.CheckSite().start();        }        for (int i = 0; i &lt; 3; i++) {            new ExpressCond.CheckKm().start();        }        Thread.sleep(1000);        express.changeKm();//快递里程变化    }}    </code></pre><h2 id="了解LockSupport工具"><a href="#了解LockSupport工具" class="headerlink" title="了解LockSupport工具"></a>了解LockSupport工具</h2><p>LockSupport定义了一组的公共静态方法，这些方法提供了最基本的线程阻塞和唤醒功能，而LockSupport也成为构建同步组件的基础工具。</p><p>LockSupport定义了一组以park开头的方法用来阻塞当前线程，以及unpark(Thread thread)方法来唤醒一个被阻塞的线程。在JDK1.6之后LockSupport增加了park(Object blocker)、parkNanos(Object blocker,long nanos)和parkUntil(Object blocker,long deadline)3个方法，便于问题排查和系统监控，其中参数blocker是用来标识当前线程在等待的对象即被阻塞对象。</p><h2 id="CLH队列锁"><a href="#CLH队列锁" class="headerlink" title="CLH队列锁"></a>CLH队列锁</h2><p>CLH队列锁即Craig, Landin, and Hagersten (CLH) locks。</p><p>CLH队列锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程仅仅在本地变量上自旋，它不断轮询前驱的状态，假设发现前驱释放了锁就结束自旋。</p><p>当一个线程需要获取锁时会创建一个的QNode，将其中的locked设置为true表示需要获取锁，myPred表示对其前驱结点的引用</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic1.png" srcset="/img/loading.gif" class=""><p>线程A对tail域调用getAndSet方法，使自己成为队列的尾部，同时获取一个指向其前驱结点的引用myPred</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic2.png" srcset="/img/loading.gif" class=""><p>线程B需要获得锁，同样的流程再来一遍</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic3.png" srcset="/img/loading.gif" class=""><p>线程就在前驱结点的locked字段上旋转，直到前驱结点释放锁(前驱节点的锁值 locked == false)</p><p>当一个线程需要释放锁时，将当前结点的locked域设置为false，同时回收前驱结点</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic4.png" srcset="/img/loading.gif" class=""><p>如上图所示，前驱结点释放锁，线程A的myPred所指向的前驱结点的locked字段变为false，线程A就可以获取到锁。</p><p>CLH队列锁的优点是空间复杂度低（如果有n个线程，L个锁，每个线程每次只获取一个锁，那么需要的存储空间是O（L+n），n个线程有n个myNode，L个锁有L个tail）。CLH队列锁常用在SMP体系结构下。</p><p>Java中的AQS是CLH队列锁的一种变体实现。</p><p><strong>扩展知识点</strong></p><p>SMP(Symmetric Multi-Processor)。即对称多处理器结构，指server中多个CPU对称工作，每一个CPU访问内存地址所需时间同样。其主要特征是共享，包括对CPU，内存，I/O等进行共享。SMP的长处是可以保证内存一致性。缺点是这些共享的资源非常可能成为性能瓶颈。随着CPU数量的添加，每一个CPU都要访问同样的内存资源，可能导致内存访问冲突，可能会导致CPU资源的浪费。经常使用的PC机就属于这样的。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic5.png" srcset="/img/loading.gif" class=""><p>非一致存储访问，将CPU分为CPU模块，每个CPU模块由多个<em>CPU*组成，并且具有独立的本地内存、I/O槽口等，模块之间可以通过互联模块相互访问，访问本地内存（本CPU模块的内存）的速度将远远高于访问远地内存</em>(<em>其他CPU模块的内存</em>)*的速度，这也是非一致存储访问的由来。NUMA较好地解决SMP的扩展问题，当CPU数量增加时，因为访问远地内存的延时远远超过本地内存，系统性能无法线性增加。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic6.png" srcset="/img/loading.gif" class=""><p>CLH唯一的缺点是在NUMA系统结构下性能很差，但是在SMP系统结构下该法还是非常有效的。解决NUMA系统结构的思路是MCS队列锁。</p><h2 id="AbstractQueuedSynchronizer深入分析"><a href="#AbstractQueuedSynchronizer深入分析" class="headerlink" title="AbstractQueuedSynchronizer深入分析"></a>AbstractQueuedSynchronizer深入分析</h2><h3 id="学习AQS的必要性"><a href="#学习AQS的必要性" class="headerlink" title="学习AQS的必要性"></a>学习AQS的必要性</h3><p>队列同步器AbstractQueuedSynchronizer（以下简称同步器或AQS），是用来构建锁或者其他同步组件的基础框架，它使用了一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作。并发包的大师（Doug Lea）期望它能够成为实现大部分同步需求的基础。</p><h3 id="AQS使用方式和其中的设计模式"><a href="#AQS使用方式和其中的设计模式" class="headerlink" title="AQS使用方式和其中的设计模式"></a>AQS使用方式和其中的设计模式</h3><p>AQS的主要使用方式是继承，子类通过继承AQS并实现它的抽象方法来管理同步状态，在AQS里由一个int型的state来代表这个状态，在抽象方法的实现过程中免不了要对同步状态进行更改，这时就需要使用同步器提供的3个方法（getState()、setState(int newState)和compareAndSetState(int expect,int update)）来进行操作，因为它们能够保证状态的改变是安全的。</p><p>AQS自身没有实现任何同步接口，它仅仅是定义了若干同步状态获取和释放的方法来供自定义同步组件使用，同步器既可以支持独占式地获取同步状态，也可以支持共享式地获取同步状态，这样就可以方便实现不同类型的同步组件（ReentrantLock、ReentrantReadWriteLock和CountDownLatch等）。</p><p>同步器是实现锁（也可以是任意同步组件）的关键，在锁的实现中聚合同步器。可以这样理解二者之间的关系：锁是面向使用者的，它定义了使用者与锁交互的接口（比如可以允许两个线程并行访问），隐藏了实现细节；同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作。锁和同步器很好地隔离了使用者和实现者所需关注的领域。</p><p>实现者需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法。</p><h3 id="模板方法模式"><a href="#模板方法模式" class="headerlink" title="模板方法模式"></a>模板方法模式</h3><p>同步器的设计基于模板方法模式。模板方法模式的意图是，定义一个操作中的算法的骨架，而将一些步骤的实现延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。我们最常见的就是Spring框架里的各种Template。</p><p>实际例子</p><p>假设蛋糕店中奶油蛋糕，芝士蛋糕和慕斯蛋糕。这三种蛋糕在制作方式上一样，都包括造型，烘焙和涂抹蛋糕上的东西。所以可以定义一个抽象蛋糕模型</p><pre><code>/** * 类说明：抽象蛋糕模型 */public abstract class AbstractCake {    protected abstract void shape();    protected abstract void apply();    protected abstract void brake();    /*模板方法*/    public final void run(){        this.shape();        this.apply();        this.brake();    }    protected boolean shouldApply(){        return true;    }}</code></pre><p>然后就可以批量生产三种蛋糕</p><pre><code>/** * 类说明：芝士蛋糕 */public class CheeseCake  extends AbstractCake {    @Override    protected void shape() {        System.out.println(&quot;芝士蛋糕造型&quot;);    }    @Override    protected void apply() {        System.out.println(&quot;芝士蛋糕涂抹&quot;);    }    @Override    protected void brake() {        System.out.println(&quot;芝士蛋糕烘焙&quot;);    }}</code></pre><p>这样一来，不但可以批量生产三种蛋糕，而且如果日后有扩展，只需要继承抽象蛋糕方法就可以了，突然有一天，我们发现市面有一种最简单的小蛋糕销量很好，这种蛋糕就是简单烘烤成型就可以卖，并不需要涂抹什么食材，于是我们也想要生产这种蛋糕。但是我们发现了一个问题，抽象蛋糕是定义了抽象的涂抹方法的，也就是说扩展的这种蛋糕是必须要实现涂抹方法，这时可以将原来的模板修改为带钩子的模板。</p><pre><code>/** * 类说明：抽象蛋糕模型 */public abstract class AbstractCake {    protected abstract void shape();    protected abstract void apply();    protected abstract void brake();    /*模板方法*/    public final void run() {        this.shape();        if (shouldApply()) {            this.apply();        }        this.brake();    }    protected boolean shouldApply(){        return true;    }}</code></pre><p>做小蛋糕的时候通过flag来控制是否涂抹，其余已有的蛋糕制作不需要任何修改可以照常进行。</p><pre><code>/** * 类说明：小蛋糕 */public class SmallCake extends AbstractCake {    private boolean flag = false;    public void setFlag(boolean shouldApply){        flag = shouldApply;    }    @Override    protected boolean shouldApply() {        return this.flag;    }    @Override    protected void shape() {        System.out.println(&quot;小蛋糕造型&quot;);    }    @Override    protected void apply() {        System.out.println(&quot;小蛋糕涂抹&quot;);    }    @Override    protected void brake() {        System.out.println(&quot;小蛋糕烘焙&quot;);    }}</code></pre><h3 id="AQS中的方法"><a href="#AQS中的方法" class="headerlink" title="AQS中的方法"></a>AQS中的方法</h3><h4 id="模板方法"><a href="#模板方法" class="headerlink" title="模板方法"></a>模板方法</h4><p>实现自定义同步组件时，将会调用同步器提供的模板方法，</p><table><thead><tr><th align="center">方法名称</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">void acquire(int arg)</td><td align="center">独占式获取同步状态，如果当前线程获取同步状态成功，则由该方法返回，否则，将会进人同步队列等待，该方法将会调用重写的tryAcquire(int  arg)方法</td></tr><tr><td align="center">void acquireInterruptibly(int arg)</td><td align="center">与acquire(int arg)相同，但是该方法响应中断，当前线程未获取到同步状态而进入同步队列中，如果当前线程被中断，则该方法会抛出InterruptedException并返回</td></tr><tr><td align="center">boolean tryAcquireNanos(int arg,long nanos)</td><td align="center">在acquireInterruptibly(int arg)基础上增加了超时限制，如果当前线程在超时时间内没有获取到同步状态，那么将会返回false.如果获取到了返回true</td></tr><tr><td align="center">void acquireShared(int arg)</td><td align="center">共享式的获取同步状态，如果当前线程未获取到同步状态,将会进人同步队列等待，与独占式获取的主要区别是在同一时刻可以有多个线程获取到同步状态</td></tr><tr><td align="center">void acquireSharedInteruptibly(int arg)</td><td align="center">与acquireShared(int arg)相同，该方法响应中断</td></tr><tr><td align="center">boolean tryAcquireSharedNanos(int arg, long nanos)</td><td align="center">在acquireSharedInterruptibly(int arg)基础上增加了超时限制</td></tr><tr><td align="center">boolean release(int arg)</td><td align="center">独占式的释放同步状态，该方法会在释放同步状态之后，将同步队列中第一个节点包含的线程唤醒</td></tr><tr><td align="center">boolean releaseShared(int arg)</td><td align="center">共享式的释放同步状态</td></tr><tr><td align="center">Collection&lt; Thread&gt; getQueuedThreads()</td><td align="center">获取等待在同步队列上的线程集合</td></tr></tbody></table><p>这些模板方法同步器提供的模板方法基本上分为3类：独占式获取与释放同步状态、共享式获取与释放、同步状态和查询同步队列中的等待线程情况。</p><h4 id="可重写的方法"><a href="#可重写的方法" class="headerlink" title="可重写的方法"></a>可重写的方法</h4><table><thead><tr><th align="center">方法名称</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">protected boolean tryAcquire(int arg)</td><td align="center">独占式获取同步状态，实现该方法需要查询当前状态并判断同步状态是否符合预期，然后再进行CAS设置同步状态</td></tr><tr><td align="center">protected boolean tryRelease(int arg)</td><td align="center">独占式释放同步状态，等待获取同步状态的线程将有机会获取同步状态</td></tr><tr><td align="center">protected int tryAcquireShared(int arg)</td><td align="center">共享式获取同步状态，返回大于等于0的值，表示获取成功，反之，获取失败</td></tr><tr><td align="center">protected boolean tryReleaseShared(int arg)</td><td align="center">共享式释放同步状态</td></tr><tr><td align="center">protected boolean isHeldExclusively()</td><td align="center">当前同步器是否在独占模式下被线程占用，一般该方法表示是否被当前线程所独占</td></tr></tbody></table><h4 id="访问或修改同步状态的方法"><a href="#访问或修改同步状态的方法" class="headerlink" title="访问或修改同步状态的方法"></a>访问或修改同步状态的方法</h4><p>重写同步器指定的方法时，需要使用同步器提供的如下3个方法来访问或修改同步状态。</p><ul><li><p>getState()：获取当前同步状态。</p></li><li><p>setState(int newState)：设置当前同步状态。</p></li><li><p>compareAndSetState(int expect,int update)：使用CAS设置当前状态，该方法能够保证状态设置的原子性。 </p></li></ul><h3 id="实现一个自己的独占锁"><a href="#实现一个自己的独占锁" class="headerlink" title="实现一个自己的独占锁"></a>实现一个自己的独占锁</h3><pre><code>public class SelfLock implements Lock {    /**     * 静态内部类，自定义同步器     */    private static class Sync extends AbstractQueuedSynchronizer {        //private static final long serialVersionUID = -4387327721959839431L;        /**         * 是否处于占用状态         */        @Override        protected boolean isHeldExclusively() {            return getState() == 1;        }        /**         * 获得锁         */        @Override        protected boolean tryAcquire(int arg) {            if (compareAndSetState(0, 1)) {                setExclusiveOwnerThread(Thread.currentThread());                return true;            }            return false;        }        /**         * 释放锁         */        @Override        protected boolean tryRelease(int arg) {            if (getState() == 0) {                throw new IllegalMonitorStateException();            }            setExclusiveOwnerThread(null);            setState(0);            return true;        }        /**         * 返回一个Condition，每个condition都包含了一个condition队列         */        Condition newCondition() {            return new ConditionObject();        }    }    /**     * 仅需要将操作代理到Sync上即可     */    private final Sync sync = new Sync();    @Override    public void lock() {        System.out.println(Thread.currentThread().getName() + &quot; ready get lock&quot;);        sync.acquire(1);        System.out.println(Thread.currentThread().getName() + &quot; already got lock&quot;);    }    @Override    public boolean tryLock() {        return sync.tryAcquire(1);    }    @Override    public void unlock() {        System.out.println(Thread.currentThread().getName() + &quot; ready release lock&quot;);        sync.release(1);        System.out.println(Thread.currentThread().getName() + &quot; already released lock&quot;);    }    @Override    public Condition newCondition() {        return sync.newCondition();    }    public boolean isLocked() {        return sync.isHeldExclusively();    }    public boolean hasQueuedThreads() {        return sync.hasQueuedThreads();    }    @Override    public void lockInterruptibly() throws InterruptedException {        sync.acquireInterruptibly(1);    }    @Override    public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {        return sync.tryAcquireNanos(1, unit.toNanos(timeout));    }}</code></pre><p><strong>测试类</strong></p><pre><code>public class TestMyLock {    public void test() {        final Lock lock = new SelfLock();        class Worker extends Thread {         @Override            public void run() {                lock.lock();                System.out.println(Thread.currentThread().getName());                try {                    SleepTools.second(1);                } finally {                    lock.unlock();                }            }        }        // 启动4个子线程        for (int i = 0; i &lt; 4; i++) {            Worker w = new Worker();            //w.setDaemon(true);            w.start();        }        // 主线程每隔1秒换行        for (int i = 0; i &lt; 10; i++) {           SleepTools.second(1);            //System.out.println();        }    }    public static void main(String[] args) {        TestMyLock testMyLock = new TestMyLock();        testMyLock.test();    }}</code></pre><h3 id="AQS中的数据结构节点和同步队列"><a href="#AQS中的数据结构节点和同步队列" class="headerlink" title="AQS中的数据结构节点和同步队列"></a>AQS中的数据结构节点和同步队列</h3><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic8.png" srcset="/img/loading.gif" class=""><h4 id="节点Node"><a href="#节点Node" class="headerlink" title="节点Node"></a>节点Node</h4><p>既然说Java中的AQS是CLH队列锁的一种变体实现，毫无疑问，作为队列来说，必然要有一个节点的数据结构来保存我们前面所说的各种域，比如前驱节点，节点的状态等，这个数据结构就是AQS中的内部类Node。作为这个数据结构应该保存的信息：</p><ol><li>前驱和后继线程，因为是一个等待队列，那么也就需要知道当前线程前面的是哪个线程，当前线程后面的是哪个线程（因为当前线程释放锁以后，理当立马通知后继线程去获取锁）。</li><li>线程信息</li><li>队列中线程状态，是取消了“获锁”请求，还是在“”等待中”，或者说“即将得到锁”</li></ol><h4 id="Node类的设计"><a href="#Node类的设计" class="headerlink" title="Node类的设计"></a>Node类的设计</h4><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic7.png" srcset="/img/loading.gif" class=""><p>线程的2种等待模式：</p><ul><li><p>SHARED：表示线程以共享的模式等待锁（如ReadLock）</p></li><li><p>EXCLUSIVE：表示线程以互斥的模式等待锁（如ReetrantLock）</p></li></ul><p>线程在队列中的状态枚举：</p><ul><li><p>CANCELLED：值为1，表示线程已经取消获取锁的请求</p></li><li><p>SIGNAL：值为-1，表示该线程已经准备就绪，等待获取锁</p></li><li><p>CONDITION：值为-2，表示线程等待某一个条件（Condition）被满足</p></li><li><p>PROPAGATE：值为-3，表示下一个的acquireShared值应该被无条件的传播下去，在线程处于SHARED模式时才会被用到。</p></li></ul><p>成员变量：</p><ul><li><p>waitStatus：该int变量表示线程在队列中的状态，其值就是上述提到的CANCELLED、SIGNAL、CONDITION、PROPAGATE</p></li><li><p>prev：该变量类型为Node对象，表示该节点的前一个Node节点（前驱）</p></li><li><p>next：该变量类型为Node对象，表示该节点的后一个Node节点（后继）</p></li><li><p>thread：该变量类型为Thread对象，表示该节点的代表的线程</p></li><li><p>nextWaiter：该变量类型为Node对象，表示等待condition条件的Node节点</p></li></ul><p>当前线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成为一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒，使其再次尝试获取同步状态。同步队列中的节点（Node）用来保存获取同步状态失败的线程引用、等待状态以及前驱和后继节点。</p><h4 id="head和tail"><a href="#head和tail" class="headerlink" title="head和tail"></a>head和tail</h4><p>AQS还拥有首节点（head）和尾节点（tail）两个引用，一个指向队列头节点，而另一个指向队列尾节点。</p><p>注意 ：因为首节点<em>head</em>是不保存线程信息的节点，仅仅是因为数据结构设计上的需要，在数据结构上，这种做法往往叫做“空头节点链表”，对应的就有“非空头结点链表”。</p><h4 id="节点在同步队列中的增加和移出"><a href="#节点在同步队列中的增加和移出" class="headerlink" title="节点在同步队列中的增加和移出"></a>节点在同步队列中的增加和移出</h4><h5 id="节点加入到同步队列"><a href="#节点加入到同步队列" class="headerlink" title="节点加入到同步队列"></a>节点加入到同步队列</h5><p>当一个线程成功地获取了同步状态（或者锁），其他线程将无法获取到同步状态，也就是获取同步状态失败，AQS会通过addWaiter()方法将这个线程以及等待状态等信息构造成为一个节点（Node）并将其加入同步队列的尾部。而这个加入队列的过程必须要保证线程安全，因此同步器提供了一个基于CAS的设置尾节点的方法：compareAndSetTail(Node expect,Nodeupdate)，AQS它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic9.png" srcset="/img/loading.gif" class=""><h5 id="首节点的变化"><a href="#首节点的变化" class="headerlink" title="首节点的变化"></a>首节点的变化</h5><p>首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点。设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节点的方法并不需要使用CAS来保证，它只需要将首节点设置成为原首节点的后继节点并断开原首节点的next引用即可。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic10.png" srcset="/img/loading.gif" class=""><h5 id="独占式同步状态获取与释放"><a href="#独占式同步状态获取与释放" class="headerlink" title="独占式同步状态获取与释放"></a>独占式同步状态获取与释放</h5><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic11.png" srcset="/img/loading.gif" class=""><h6 id="获取"><a href="#获取" class="headerlink" title="获取"></a>获取</h6><p>通过调用同步器的acquire(int arg)方法可以获取同步状态，主要完成了同步状态获取、节点构造、加入同步队列以及在同步队列中自旋等待的相关工作，其主要逻辑是：</p><p>首先调用自定义同步器实现的tryAcquire(int arg)方法，该方法需要保证线程安全的获取同步状态。</p><p>如果同步状态获取失败（tryAcquire返回false），则构造同步节点（独占式Node.EXCLUSIVE，同一时刻只能有一个线程成功获取同步状态）并通过addWaiter(Node node)方法将该节点加入到同步队列的尾部，在addWaiter()方法中会尝试通过compareAndSetTail()方法设置首尾节点关系，如果设置不成功才会进入enq()方法循环尝试设置节点关系。</p><p>最后调用acquireQueued(Node node,int arg)方法，使得该节点以“死循环”的方式获取同步状态。如果获取不到则阻塞节点中的线程，而被阻塞线程的唤醒主要依靠前驱节点的出队或阻塞线程被中断来实现。</p><p>addWaiter(Node node)方法中</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic12.png" srcset="/img/loading.gif" class=""><p>将当前线程包装成Node后，队列不为空的情况下，先尝试把当前节点加入队列并成为尾节点，如果不成功或者队列为空进入enq(final Node node)方法。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic13.png" srcset="/img/loading.gif" class=""><p>在enq(final Node node)方法中，同步器通过“死循环”来保证节点的正确添加，这个死循环中，做了两件事，第一件，如果队列为空，初始化队列，new出一个空节点，并让<strong>首节点</strong>（head）和<strong>尾节点</strong>（tail）两个引用都指向这个空节点；第二件事，把当前节点加入队列。</p><p>在“死循环”中只有通过CAS将节点设置成为尾节点之后，当前线程才能从该方法返回，否则，当前线程不断地尝试设置。</p><p>节点进入同步队列之后，观察acquireQueued(Node node,int arg)方法</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic14.png" srcset="/img/loading.gif" class=""><p>其实就是一个自旋的过程，每个节点（或者说每个线程）都在自省地观察，当条件满足，获取到了同步状态，就可以从这个自旋过程中退出，否则依旧留在这个自旋过程中（并会阻塞节点的线程）。</p><p>在acquireQueued(final Node node,int arg)方法中，当前线程在“死循环”中尝试获取同步状态，而只有前驱节点是头节点才能够尝试获取同步状态，这是为什么？原因有两个。</p><p>第一，头节点是成功获取到同步状态的节点，而头节点的线程释放了同步状态之后，将会唤醒其后继节点，后继节点的线程被唤醒后需要检查自己的前驱节点是否是头节点。</p><p>第二，维护同步队列的FIFO原则。</p><p>当前线程获取到同步状态后，让<strong>首节点</strong>（head）这个引用指向自己所在节点。当同步状态获取成功后，当前线程就从acquire方法返回了。如果同步器实现的是锁，那就代表当前线程获得了锁。</p><h6 id="释放"><a href="#释放" class="headerlink" title="释放"></a>释放</h6><p>当前线程获取同步状态并执行了相应逻辑之后，就需要释放同步状态，使得后续节点能够继续获取同步状态。通过调用同步器的release(int arg)方法可以释放同步状态，该方法在释放了同步状态之后，会唤醒其后继节点（进而使后继节点重新尝试获取同步状态）。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic15.png" srcset="/img/loading.gif" class=""><p>该方法执行时，会唤醒<strong>首节点</strong>（head）所指向节点的后继节点线程，unparkSuccessor(Node node)方法使用LockSupport来唤醒处于等待状态的线程。</p><p>而在unparkSuccessor中， </p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic16.png" srcset="/img/loading.gif" class=""><p>这段代码的意思，一般情况下，被唤醒的是head指向节点的后继节点线程，如果这个后继节点处于被cancel状态，（我推测开发者的思路这样的：后继节点处于被cancel状态，意味着当锁竞争激烈时，队列的第一个节点等了很久（一直被还未加入队列的节点抢走锁），包括后续的节点cancel的几率都比较大，所以）先从尾开始遍历，找到最前面且没有被cancel的节点。</p><h6 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h6><p>在获取同步状态时，同步器维护一个同步队列，获取状态失败的线程都会被加入到队列中并在队列中进行自旋；移出队列（或停止自旋）的条件是前驱节点为头节点且成功获取了同步状态。在释放同步状态时，同步器调用tryRelease(int arg)方法释放同步状态，然后唤醒head指向节点的后继节点。</p><h5 id="共享式同步状态获取与释放"><a href="#共享式同步状态获取与释放" class="headerlink" title="共享式同步状态获取与释放"></a>共享式同步状态获取与释放</h5><p>共享式获取与独占式获取最主要的区别在于同一时刻能否有多个线程同时获取到同步状态。以读写为例，如果一个程序在进行读操作，那么这一时刻写操作均被阻塞，而读操作能够同时进行。写操作要求对资源的独占式访问，而读操作可以是共享式访问。</p><p>在acquireShared(int arg)方法中，同步器调用tryAcquireShared(int arg)方法尝试获取同步状态，tryAcquireShared(int arg)方法返回值为int类型，当返回值大于等于0时，表示能够获取到同步状态。因此，在共享式获取的自旋过程中，成功获取到同步状态并退出自旋的条件就是tryAcquireShared(int arg)方法返回值大于等于0。可以看到，在doAcquireShared(int arg)方法的自旋过程中，如果当前节点的前驱为头节点时，尝试获取同步状态，如果返回值大于等于0，表示该次获取同步状态成功并从自旋过程中退出。</p><p>该方法在释放同步状态之后，将会唤醒后续处于等待状态的节点。对于能够支持多个线程同时访问的并发组件（比如Semaphore），它和独占式主要区别在于tryReleaseShared(int arg)方法必须确保同步状态（或者资源数）线程安全释放，一般是通过循环和CAS来保证的，因为释放同步状态的操作会同时来自多个线程。</p><h5 id="共享式的同步工具类"><a href="#共享式的同步工具类" class="headerlink" title="共享式的同步工具类"></a>共享式的同步工具类</h5><p>设计一个同步工具：该工具在同一时刻，只允许至多3个线程同时访问，超过3个线程的访问将被阻塞。</p><p>首先，确定访问模式。TrinityLock能够在同一时刻支持多个线程的访问，这显然是共享式访问，因此，需要使用同步器提供的acquireShared(int args)方法等和Shared相关的方法，这就要求TwinsLock必须重写tryAcquireShared(int args)方法和tryReleaseShared(int args)方法，这样才能保证同步器的共享式同步状态的获取与释放方法得以执行。</p><p>其次，定义资源数。TrinityLock在同一时刻允许至多三个线程的同时访问，表明同步资源数为3，这样可以设置初始状态status为3，当一个线程进行获取，status减1，该线程释放，则status加1，状态的合法范围为0、1和2,3，其中0表示当前已经有3个线程获取了同步资源，此时再有其他线程对同步状态进行获取，该线程只能被阻塞。在同步状态变更时，需要使用compareAndSet(int expect,int update)方法做原子性保障。</p><p>最后，组合自定义同步器。前面的章节提到，自定义同步组件通过组合自定义同步器来完成同步功能，一般情况下自定义同步器会被定义为自定义同步组件的内部类。</p><pre><code>/** *类说明：共享同步工具类 */public class TrinityLock  implements Lock {    //为n表示允许n个线程同时获得锁    private final Sync sync = new Sync(4);    private static final class Sync extends AbstractQueuedSynchronizer {        //private static final long serialVersionUID = -7889272986162341211L;        Sync(int count) {            if (count &lt;= 0) {                throw new IllegalArgumentException(&quot;count must large than zero.&quot;);            }            setState(count);        }        /**         *         * @param reduceCount  扣减个数         * @return  返回小于0，表示当前线程获得同步状态失败         * 大于0，表示当前线程获得同步状态成功         */        public int tryAcquireShared(int reduceCount) {            for (;;) {                int current = getState();                int newCount = current - reduceCount;                if (newCount &lt; 0 || compareAndSetState(current, newCount)) {                    return newCount;                }            }        }        /**         *         * @param returnCount 归还个数         * @return         */        public boolean tryReleaseShared(int returnCount) {            for (;;) {                int current = getState();                int newCount = current + returnCount;                if (compareAndSetState(current, newCount)) {                    return true;                }            }        }        final ConditionObject newCondition() {            return new ConditionObject();        }    }    public void lock() {        sync.acquireShared(1);    }    public void unlock() {        sync.releaseShared(1);    }    public void lockInterruptibly() throws InterruptedException {        sync.acquireSharedInterruptibly(1);    }    public boolean tryLock() {        return sync.tryAcquireShared(1) &gt;= 0;    }    public boolean tryLock(long time, TimeUnit unit) throws InterruptedException {        return sync.tryAcquireSharedNanos(1, unit.toNanos(time));    }    @Override    public Condition newCondition() {        return sync.newCondition();    }}</code></pre><h3 id="Condition分析"><a href="#Condition分析" class="headerlink" title="Condition分析"></a>Condition分析</h3><h4 id="Condition的数据结构"><a href="#Condition的数据结构" class="headerlink" title="Condition的数据结构"></a>Condition的数据结构</h4><p>等待队列是一个FIFO的队列，在队列中的每个节点都包含了一个线程引用，该线程就是在Condition对象上等待的线程，如果一个线程调用了Condition.await()方法，那么该线程将会释放锁、构造成节点加入等待队列并进入等待状态。事实上，节点的定义复用了同步器中节点的定义，也就是说，同步队列和等待队列中节点类型都是同步器的静态内部类。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic17.png" srcset="/img/loading.gif" class=""><p>一个Condition包含一个等待队列，Condition拥有首节点（firstWaiter）和尾节点（lastWaiter）。当前线程调用Condition.await()方法，将会以当前线程构造节点，并将节点从尾部加入等待队列。Condition拥有首尾节点的引用，而新增节点只需要将原有的尾节点nextWaiter指向它，并且更新尾节点即可。上述节点引用更新的过程并没有使用CAS保证，原因在于调用await()方法的线程必定是获取了锁的线程，也就是说该过程是由锁来保证线程安全的。</p><p>Lock（更确切地说是同步器）拥有一个同步队列和多个等待队列。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic18.png" srcset="/img/loading.gif" class=""><p>调用Condition的await()方法（或者以await开头的方法），会使当前线程进入等待队列并释放锁，同时线程状态变为等待状态。当从await()方法返回时，当前线程一定获取了Condition相关联的锁。</p><p>如果从队列（同步队列和等待队列）的角度看await()方法，当调用await()方法时，相当于同步队列的首节点（获取了锁的节点）移动到Condition的等待队列中。调用该方法的线程成功获取了锁的线程，也就是同步队列中的首节点，该方法会将当前线程构造成节点并加入等待队列中，然后释放同步状态，唤醒同步队列中的后继节点，然后当前线程会进入等待状态。当等待队列中的节点被唤醒，则唤醒节点的线程开始尝试获取同步状态。如果不是通过其他线程调用Condition.signal()方法唤醒，而是对等待线程进行中断，则会抛出InterruptedException。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic19.png" srcset="/img/loading.gif" class=""><p>如图所示，同步队列的首节点并不会直接加入等待队列，而是通过addConditionWaiter()方法把当前线程构造成一个新的节点并将其加入等待队列中。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic20.png" srcset="/img/loading.gif" class=""><p>调用Condition的signal()方法，将会唤醒在等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节点移到同步队列中。</p><p>调用该方法的前置条件是当前线程必须获取了锁，可以看到signal()方法进行了isHeldExclusively()检查，也就是当前线程必须是获取了锁的线程。接着获取等待队列的首节点，将其移动到同步队列并使用LockSupport唤醒节点中的线程。</p><p>通过调用同步器的enq(Node node)方法，等待队列中的头节点线程安全地移动到同步队列。当节点移动到同步队列后，当前线程再使用LockSupport唤醒该节点的线程。</p><p>被唤醒后的线程，将从await()方法中的while循环中退出（isOnSyncQueue(Node node)方法返回true，节点已经在同步队列中），进而调用同步器的acquireQueued()方法加入到获取同步状态的竞争中。</p><p>成功获取同步状态（或者说锁）之后，被唤醒的线程将从先前调用的await()方法返回，此时该线程已经成功地获取了锁。</p><p>Condition的signalAll()方法，相当于对等待队列中的每个节点均执行一次signal()方法，效果就是将等待队列中所有节点全部移动到同步队列中，并唤醒每个节点的线程。</p><h2 id="Lock的实现"><a href="#Lock的实现" class="headerlink" title="Lock的实现"></a>Lock的实现</h2><h3 id="ReentrantLock的实现"><a href="#ReentrantLock的实现" class="headerlink" title="ReentrantLock的实现"></a>ReentrantLock的实现</h3><h4 id="锁的可重入"><a href="#锁的可重入" class="headerlink" title="锁的可重入"></a>锁的可重入</h4><p>重进入是指任意线程在获取到锁之后能够再次获取该锁而不会被锁所阻塞，该特性的实现需要解决以下两个问题。</p><ol><li><p>线程再次获取锁。锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取。</p></li><li><p>锁的最终释放。线程重复n次获取了锁，随后在第n次释放该锁后，其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增，计数表示当前锁被重复获取的次数，而锁被释放时，计数自减，当计数等于0时表示锁已经成功释放。</p></li></ol><p>nonfairTryAcquire方法增加了再次获取同步状态的处理逻辑：通过判断当前线程是否为获取锁的线程来决定获取操作是否成功，如果是获取锁的线程再次请求，则将同步状态值进行增加并返回true，表示获取同步状态成功。同步状态表示锁被一个线程重复获取的次数。</p><p>如果该锁被获取了n次，那么前(n-1)次tryRelease(int releases)方法必须返回false，而只有同步状态完全释放了，才能返回true。可以看到，该方法将同步状态是否为0作为最终释放的条件，当同步状态为0时，将占有线程设置为null，并返回true，表示释放成功。</p><h4 id="公平和非公平锁"><a href="#公平和非公平锁" class="headerlink" title="公平和非公平锁"></a>公平和非公平锁</h4><p>ReentrantLock的构造函数中，默认的无参构造函数将会把Sync对象创建为NonfairSync对象，这是一个“非公平锁”；而另一个构造函数ReentrantLock(boolean fair)传入参数为true时将会把Sync对象创建为“公平锁”FairSync。公平锁的tryAcquire()方法与非公平锁的nonfairTryAcquire(int acquires)相比，唯一不同的位置为判断条件多了hasQueuedPredecessors()方法，即加入了同步队列中当前节点是否有前驱节点的判断，如果该方法返回true，则表示有线程比当前线程更早地请求获取锁，因此需要等待前驱线程获取并释放锁之后才能继续获取锁，而非公平锁只要CAS设置同步状态成功，则表示当前线程获取了锁。</p><h4 id="改造之前的独占锁为可重入"><a href="#改造之前的独占锁为可重入" class="headerlink" title="改造之前的独占锁为可重入"></a>改造之前的独占锁为可重入</h4><pre><code>/** *类说明：实现我们自己独占锁,可重入 */public class ReenterSelfLock implements Lock {    // 静态内部类，自定义同步器    private static class Sync extends AbstractQueuedSynchronizer {        // 是否处于占用状态        protected boolean isHeldExclusively() {            return getState() &gt; 0;        }        // 当状态为0的时候获取锁        public boolean tryAcquire(int acquires) {            if (compareAndSetState(0, 1)) {                setExclusiveOwnerThread(Thread.currentThread());                return true;            }else if(getExclusiveOwnerThread()==Thread.currentThread()){                setState(getState()+1);                return  true;            }            return false;        }        // 释放锁，将状态设置为0        protected boolean tryRelease(int releases) {            if(getExclusiveOwnerThread()!=Thread.currentThread()){                throw new IllegalMonitorStateException();            }            if (getState() == 0)                throw new IllegalMonitorStateException();            setState(getState()-1);            if(getState()==0){                setExclusiveOwnerThread(null);            }            return true;        }        // 返回一个Condition，每个condition都包含了一个condition队列        Condition newCondition() {            return new ConditionObject();        }    }    // 仅需要将操作代理到Sync上即可    private final Sync sync = new Sync();    public void lock() {       System.out.println(Thread.currentThread().getName()+&quot; ready get lock&quot;);        sync.acquire(1);        System.out.println(Thread.currentThread().getName()+&quot; already got lock&quot;);    }    public boolean tryLock() {        return sync.tryAcquire(1);    }    public void unlock() {       System.out.println(Thread.currentThread().getName()+&quot; ready release lock&quot;);        sync.release(1);        System.out.println(Thread.currentThread().getName()+&quot; already released lock&quot;);    }    public Condition newCondition() {        return sync.newCondition();    }    public boolean isLocked() {        return sync.isHeldExclusively();    }    public boolean hasQueuedThreads() {        return sync.hasQueuedThreads();    }    public void lockInterruptibly() throws InterruptedException {        sync.acquireInterruptibly(1);    }    public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {        return sync.tryAcquireNanos(1, unit.toNanos(timeout));    }}</code></pre><p>测试类</p><pre><code>/** *类说明： */public class TestReenterSelfLock {    static final Lock lock = new ReenterSelfLock();    public void reenter(int x){        lock.lock();        try {            System.out.println(Thread.currentThread().getName()+&quot;:递归层级:&quot;+x);            int y = x - 1;            if (y==0) return;            else{                reenter(y);            }        } finally {            lock.unlock();        }    }    public void test() {        class Worker extends Thread {            public void run() {                System.out.println(Thread.currentThread().getName());                SleepTools.second(1);                reenter(3);            }        }        // 启动3个子线程        for (int i = 0; i &lt; 3; i++) {            Worker w = new Worker();            w.start();        }        // 主线程每隔1秒换行        for (int i = 0; i &lt; 100; i++) {            SleepTools.second(1);        }    }    public static void main(String[] args) {        TestReenterSelfLock testMyLock = new TestReenterSelfLock();        testMyLock.test();    }}</code></pre><h3 id="ReentrantReadWriteLock的实现"><a href="#ReentrantReadWriteLock的实现" class="headerlink" title="ReentrantReadWriteLock的实现"></a>ReentrantReadWriteLock的实现</h3><h4 id="读写状态的设计"><a href="#读写状态的设计" class="headerlink" title="读写状态的设计"></a>读写状态的设计</h4><p>读写锁同样依赖自定义同步器来实现同步功能，而读写状态就是其同步器的同步状态。</p><p>回想ReentrantLock中自定义同步器的实现，同步状态表示锁被一个线程重复获取的次数，而读写锁的自定义同步器需要在同步状态（一个整型变量）上维护多个读线程和一个写线程的状态，使得该状态的设计成为读写锁实现的关键。</p><p>如果在一个整型变量上维护多种状态，就一定需要“按位切割使用”这个变量，读写锁将变量切分成了两个部分，高16位表示读，低16位表示写，读写锁通过位运算来维护各自的运算。假设当前同步状态值为S，写状态等于S&amp;0x0000FFFF（将高16位全部抹去），读状态等于S&gt;&gt;&gt;16（无符号补0右移16位）。当写状态增加1时，等于S+1，当读状态增加1时，等于S+(1&lt;&lt;16)，也就是S+0x00010000。根据状态的划分能得出一个推论：S不等于0时，当写状态（S&amp;0x0000FFFF）等于0时，则读状态（S&gt;&gt;&gt;16）大于0，即读锁已被获取。</p><h4 id="写锁的获取与释放"><a href="#写锁的获取与释放" class="headerlink" title="写锁的获取与释放"></a>写锁的获取与释放</h4><p>写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。读写锁在内部有一个ThreadLocal记录写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态。</p><p>该方法除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。如果存在读锁，则写锁不能被获取，原因在于：读写锁要确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。</p><p>写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，从而等待的读写线程能够继续访问读写锁，同时前次写线程的修改对后续读写线程可见。</p><h4 id="读锁的获取与释放"><a href="#读锁的获取与释放" class="headerlink" title="读锁的获取与释放"></a>读锁的获取与释放</h4><p>读锁是一个支持重进入的共享锁，它能够被多个线程同时获取，在没有其他写线程访问（或者写状态为0）时，读锁总会被成功地获取，而所做的也只是（线程安全的）增加读状态。如果当前线程已经获取了读锁，则增加读状态。</p><p>如果当前线程在获取读锁时，写锁已被其他线程获取，则进入等待状态。读状态是所有线程获取读锁次数的总和，而每个线程各自获取读锁的次数只能选择保存在ThreadLocal中，由线程自身维护。在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态。</p><h4 id="锁的升降级"><a href="#锁的升降级" class="headerlink" title="锁的升降级"></a>锁的升降级</h4><p>锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。</p><p>锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。</p><p>RentrantReadWriteLock不支持锁升级（把持读锁、获取写锁，最后释放读锁的过程）。目的是保证数据可见性，如果读锁已被多个线程获取，其中任意线程成功获取了写锁并更新了数据，则其更新对其他获取到读锁的线程是不可见的。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>原子操作CAS(Compare And Swap)</title>
    <link href="undefined2019/12/24/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9CCAS/"/>
    <url>2019/12/24/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9CCAS/</url>
    
    <content type="html"><![CDATA[<h2 id="什么是原子操作，如何实现？"><a href="#什么是原子操作，如何实现？" class="headerlink" title="什么是原子操作，如何实现？"></a>什么是原子操作，如何实现？</h2><p>假定有两个操作A和B，如果从执行A的线程来看，当另一个线程执行B时，要么将B全部执行完，要么完全不执行B，那么A和B对彼此来说是原子的。</p><p>实现原子操作可以使用锁机制即synchronized关键字来实现，但synchronized关键字是基于阻塞的锁机制，也就是说当一个线程拥有锁的时候，访问同一资源的其它线程需要等待该线程执行完毕释放锁。显然，这种机制不是很灵活。比如被阻塞的线程优先级比较高，或者获得锁的线程一直不释放锁，还有大量的线程来竞争资源CPU将会花费更多的时间和资源来处理这些竞争，还可能出现一些例如死锁之类的情况，这些都会严重影响程序的性能。其实锁机制是一种比较粗糙，粒度比较大的机制，相对于像计数器这样的需求过于笨重。</p><p>CAS是利用CPU的多处理能力，实现硬件层面的阻塞，再加上volatile变量的特性即可实现基于原子操作的线程安全。当前的处理器基本都支持CAS指令，只不过每个厂家所实现的算法并不一样，每一个CAS操作过程都包含三个运算符：一个内存地址V，一个期望的值A和一个新值B，操作的时候如果这个地址上存放的值等于这个期望的值A，则将地址上的值赋为新值B，否则将循环这个指令直到成功为止。</p><img src="/2019/12/24/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9CCAS/pic1.png" srcset="/img/loading.gif" class=""><h2 id="CAS实现原子操作的三大问题"><a href="#CAS实现原子操作的三大问题" class="headerlink" title="CAS实现原子操作的三大问题"></a>CAS实现原子操作的三大问题</h2><h3 id="ABA问题"><a href="#ABA问题" class="headerlink" title="ABA问题"></a>ABA问题</h3><p>因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。</p><p>ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A→B→A就会变成1A→2B→3A。</p><h3 id="循环时间长开销大"><a href="#循环时间长开销大" class="headerlink" title="循环时间长开销大"></a>循环时间长开销大</h3><p>多个线程争夺同一个资源时，如果自旋一直不成功，将会一直占用CPU。</p><p>解决方法：破坏掉for死循环，当超过一定时间或者一定次数时，return退出。JDK8新增的LongAddr,和ConcurrentHashMap类似的方法。当多个线程竞争时，将粒度变小，将一个变量拆分为多个变量，达到多个线程访问多个资源的效果，最后再调用sum把它合起来。</p><h3 id="只能保证一个共享变量的原子操作"><a href="#只能保证一个共享变量的原子操作" class="headerlink" title="只能保证一个共享变量的原子操作"></a>只能保证一个共享变量的原子操作</h3><p>CAS指令同时刻只能保证对一个地址是原子的，当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。还有一个取巧的办法，就是把多个共享变量合并成一个共享变量或者封装为对象来操作。比如，有两个共享变量i＝2，j=a，合并一下ij=2a，然后用CAS来操作ij。从Java 1.5开始，JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。</p><h2 id="Jdk中相关原子操作类的使用"><a href="#Jdk中相关原子操作类的使用" class="headerlink" title="Jdk中相关原子操作类的使用"></a>Jdk中相关原子操作类的使用</h2><h3 id="jdk中提供的原子操作类"><a href="#jdk中提供的原子操作类" class="headerlink" title="jdk中提供的原子操作类"></a>jdk中提供的原子操作类</h3><ul><li>更新基本类型：AtomicBoolean,AtomicInteger,AtomicLong</li><li>更新数组类型：AtomicIntegerArray,AtomicLongArray,AtomicReferenceArray</li><li>更新基本引用类型：AtomicReference,AtomicMarkableReference,AtomicStampedReference</li><li>更新字段类型：AtomicReferenceFieldUpdater,AtomicIntegerFieldUpdater,AtomicLongFieldUpdater</li></ul><h3 id="更新基本类型"><a href="#更新基本类型" class="headerlink" title="更新基本类型"></a>更新基本类型</h3><p><strong>AtomicInteger</strong></p><ul><li><p>int addAndGet(int delta)：以原子方式将输入的数值与实例中的值相加，并返回结果。</p></li><li><p>Int  (int delta)：返回实例中的值之后，以原子操作与输入的值相加。</p></li><li><p>int getAndIncrement()：返回实例中的值之后以原子方式加1</p></li><li><p>int incrementAndGet()：以原子操作将实例中的值加1之后返回</p></li><li><p>int getAndDecrement()：返回实例中的值之后以原子方式减1</p></li><li><p>int decrementAndGet()：以原子操作将实例中的值减1之后返回</p></li><li><p>int getAndSet(int newValue)：返回实例中的值之后以原子方式设置为newValue的值。</p></li><li><p>boolean compareAndSet(int expect，int update)：如果实例中的值等于expect值，则以原子方式设置为update的值。</p></li></ul><h3 id="更新数组类型"><a href="#更新数组类型" class="headerlink" title="更新数组类型"></a>更新数组类型</h3><p><strong>AtomicIntegerArray</strong></p><p>主要是提供原子的方式更新数组里的整型，其常用方法如下。</p><ul><li><p>int addAndGet(int i，int delta)：以原子方式将输入值与实例中索引i的元素相加后返回。</p></li><li><p>boolean compareAndSet(int i，int expect，int update)：如果实例中索引i的元素等于预期值，则以原子方式将实例中索引i的元素设置成update值。</p></li><li><p>int getAndAccumulate(int i, int x,IntBinaryOperator accumulatorFunction)：将实例中索引i的元素返回之后以原子方式设置为accumulatorFunction中的操作返回的值，accumulatorFunction的left为原始值，left为传入的值。</p></li></ul><p>需要注意的是，AtomicIntegerArray中存储的数组是复制之后的原数组，当使用AtomicIntegerArray对内部的数组元素进行修改时，不会影响原数组。</p><h3 id="更新引用类型"><a href="#更新引用类型" class="headerlink" title="更新引用类型"></a>更新引用类型</h3><p>原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包提供了以下3个类。</p><p><strong>AtomicReference</strong></p><p>原子更新引用类型（不能解决ABA问题）。</p><ul><li>boolean compareAndSet(V expect，V update)：如果实例中对象等于预期值，则以原子方式将实例中对象替换为输入的对象</li></ul><p><strong>AtomicMarkableReference</strong></p><p>可以解决ABA问题，  可以记录更新过程中有没有变化</p><ul><li>AtomicMarkableReference(V initialRef, boolean initialMark)：initialRef（要关联的对象），initialMark（版本戳）</li></ul><p>AtomicStampedReference利用版本戳的形式记录了每次改变以后的版本号，版本戳为boolean类型，可以记录值是否被修改过。</p><p><strong>AtomicStampedReference</strong></p><p>能够解决ABA问题，并且可以记录变化次数</p><ul><li>AtpmicStampedReference(V initialRef,int initialStamp)：构造函数，initialRef（要关联的对象），initialStamp（版本戳）</li><li>V getStamp()：获取当前版本号</li><li>V getReference()：获取当前对象</li><li>boolean compareAndSet(V   expectedReference,V   newReference,int expectedStamp,int newStamp) ：更新当前对象及版本号</li></ul><p>AtomicStampedReference跟AtomicMarkableReference差不多， AtomicStampedReference是使用int类型的值作为版本戳，AtomicMarkableReference使用boolean mark作为版本戳。 </p><h3 id="原子更新字段类"><a href="#原子更新字段类" class="headerlink" title="原子更新字段类"></a>原子更新字段类</h3><p>如果需原子地更新某个类里的某个字段时，就需要使用原子更新字段类，Atomic包提供了以下3个类进行原子字段更新。</p><ul><li><p>AtomicIntegerFieldUpdater：原子更新整型的字段的更新器。</p></li><li><p>AtomicLongFieldUpdater：原子更新长整型字段的更新器。</p></li><li><p>AtomicReferenceFieldUpdater：原子更新引用类型里的字段。</p></li></ul><p>要想原子地更新字段类需要两步。第一步，因为原子更新字段类都是抽象类，每次使用的时候必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。第二步，更新类的字段（属性）必须使用public volatile修饰符。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线程的并发工具类</title>
    <link href="undefined2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/"/>
    <url>2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<h1 id="Fork-Join"><a href="#Fork-Join" class="headerlink" title="Fork-Join"></a>Fork-Join</h1><p>forkjoin体现了分而治之的策略，java下多线程的开发可以我们自己启用多线程，线程池，还可以使用forkjoin，forkjoin可以让我们不去了解诸如Thread，Runnable等相关的知识，只要遵循forkjoin的开发模式，就可以写出很好的多线程并发程序。</p><h3 id="分而治之"><a href="#分而治之" class="headerlink" title="分而治之"></a>分而治之</h3><p>分治策略是：对于一个规模为n的问题，若该问题可以容易地解决（比如说规模n较小）则直接解决，否则将其分解为k个规模较小的子问题，这些子问题互相独立且与原问题形式相同（子问题相互之间有联系就会变为动态规范算法），递归地解这些子问题，然后将各子问题的解合并得到原问题的解，这种算法设计策略叫做分治法。</p><p>归并排序，快速排序，二分查找及大数据中M/R都体现了分而治之的策略。</p><h3 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h3><p>若将两个有序表合并成一个有序表，称为2-路归并，与之对应的还有多路归并。</p><p>对于给定的一组数据，利用递归与分治技术将数据序列划分成为越来越小的半子表，在对半子表排序后，再用递归方法将排好序的半子表合并成为越来越大的有序序列。</p><p>为了提升性能，有时我们在半子表的个数小于某个数（比如15）的情况下，对半子表的排序采用其他排序算法，比如插入排序。</p><h3 id="归并排序（降序）示例"><a href="#归并排序（降序）示例" class="headerlink" title="归并排序（降序）示例"></a>归并排序（降序）示例</h3><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic1.png" srcset="/img/loading.gif" class=""><p>先讲数组划分为左右两个子表：</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic2.png" srcset="/img/loading.gif" class=""> <img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic3.png" srcset="/img/loading.gif" class=""><p>然后继续左右两个子表拆分：</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic4.png" srcset="/img/loading.gif" class=""><p>对最后的拆分的子表，两两进行排序</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic5.png" srcset="/img/loading.gif" class=""><p>对有序的子表进行排序和比较合并</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic6.png" srcset="/img/loading.gif" class=""><p>对合并后的子表继续比较合并</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic7.png" srcset="/img/loading.gif" class=""><h2 id="Fork-Join原理"><a href="#Fork-Join原理" class="headerlink" title="Fork-Join原理"></a>Fork-Join原理</h2><p>Fork/Join框架：就是在必要的情况下，讲一个大任务，进行拆分（fork）成若干个小任务（拆到不可在拆时），再将一个个小任务进行join汇总。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic8.png" srcset="/img/loading.gif" class=""><h3 id="工作密取"><a href="#工作密取" class="headerlink" title="工作密取"></a>工作密取</h3><p>即当前线程的Task已经全被执行完毕，则自动取到其他线程的Task池中取出Task继续执行。</p><p>ForkJoinPool中维护着多个线程（一般为CPU核数）在不断地执行Task，每个线程除了执行自己职务内的Task之外，还会根据自己工作线程的闲置情况去获取其他繁忙的工作线程的Task，如此一来就能能够减少线程阻塞或是闲置的时间，提高CPU利用率。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic9.png" srcset="/img/loading.gif" class=""><h2 id="Fork-Join实战"><a href="#Fork-Join实战" class="headerlink" title="Fork-Join实战"></a>Fork-Join实战</h2><h3 id="Fork-Join使用的标准范式"><a href="#Fork-Join使用的标准范式" class="headerlink" title="Fork/Join使用的标准范式"></a>Fork/Join使用的标准范式</h3><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic10.png" srcset="/img/loading.gif" class=""><p>要使用ForkJoin框架，必须首先创建一个ForkJoin任务，创建方式为继承ForkJoin的子类：RecursiveAction或RecursiveTask，然后实现其中的compute方法。ForkJoin框架将compute()中的逻辑来进行fork或join操作。</p><ol><li><p><strong>RecursiveAction：</strong>没有返回结果的任务</p></li><li><p><strong>RecursiveTask：</strong>有返回值的任务</p></li></ol><p>在compute方法里，首先需要判断任务是否足够小，如果足够小就直接执行任务。如果不足够小，就必须分割成两个并创建子任务，然后调用invokeAll()方法将创建的子任务提交，如果子任务有返回值，则调用join()方法获取子任务的执行结果之后需要将执行结果合并并返回，提交之后的子任务会再次进入compute，判断子任务是否需要继续拆分，如果不需要继续分割，则执行当前子任务并返回结果。</p><p> 继承之后的子类要提交到ForkJoinPool中执行，可以使用invoke()，submit()，execture()提交，区别是：invoke()是同步执行，调用之后当前线程阻塞，等待任务完成；submit()和execture()是异步执行不会阻塞当前线程，submit()可以返回结果值，execute()不会返回结果值。之后可以通过join()或get()方法获取执行结果，如果是异步执行，join()和get()方法会阻塞当前线程直到所有任务执行完毕。</p><h3 id="实现数组排序"><a href="#实现数组排序" class="headerlink" title="实现数组排序"></a>实现数组排序</h3><pre><code>public class MergeSort {    //数组长度    public static final int ARRAY_LENGTH  = 40000000;    public final static int THRESHOLD = 47;    public static int[] makeArray() {        //new一个随机数发生器        Random r = new Random();        int[] result = new int[ARRAY_LENGTH];        for(int i=0;i&lt;ARRAY_LENGTH;i++){            //用随机数填充数组            result[i] =  r.nextInt(ARRAY_LENGTH*3);        }        return result;    }    /**     * 归并排序——将两段排序好的数组结合成一个排序数组     *     * @param left     * @param right     * @return     */    public static int[] merge(int[] left, int[] right) {        int[] result = new int[left.length + right.length];        for (int index = 0, i = 0, j = 0; index &lt; result.length; index++) {            if (i &gt;= left.length)/*左边数组已经取完，完全取右边数组的值即可*/                result[index] = right[j++];            else if (j &gt;= right.length)/*右边数组已经取完，完全取左边数组的值即可*/                result[index] = left[i++];            else if (left[i] &gt; right[j])/*左边数组的元素值大于右边数组，取右边数组的值*/                result[index] = right[j++];            else/*右边数组的元素值大于左边数组，取左边数组的值*/                result[index] = left[i++];        }        return result;    }     /**     * 插入排序     *     * @param array     * @return     */    public static int[] sort(int[] array) {        if (array.length == 0)            return array;        int currentValue;/*当前待排序数据，该元素之前的元素均已被排序过*/        for (int i = 0; i &lt; array.length - 1; i++) {            int preIndex = i;/*已被排序数据的索引*/            currentValue = array[preIndex + 1];            /*在已被排序过数据中倒序寻找合适的位置，如果当前待排序数据比比较的元素要小，            将比较的元素元素后移一位*/            while (preIndex &gt;= 0 &amp;&amp; currentValue &lt; array[preIndex]) {                //将当前元素后移一位                array[preIndex + 1] = array[preIndex];                preIndex--;            }            /*while循环结束时，说明已经找到了当前待排序数据的合适位置，插入*/            array[preIndex + 1] = currentValue;        }        return array;    }    public static void main(String[] args) {        System.out.println(&quot;============================================&quot;);        long start = System.currentTimeMillis();        ForkJoinPool forkJoinPool = new ForkJoinPool();        MergeSortTask sortTask = new MergeSortTask(MakeArray.makeArray());        forkJoinPool.invoke(sortTask);        //forkJoinPool.submit(sortTask);        //int[] array = sortTask.join();        System.out.println(&quot; spend time:&quot;+(System.currentTimeMillis()-start)+&quot;ms&quot;);        System.out.println(&quot;============================================&quot;);    }    private static class MergeSortTask extends RecursiveTask&lt;int[]&gt;{        private int[] array;        public MergeSortTask(int[] array){            this.array = array;        }        @Override        protected int[] compute() {            if (array.length&lt;= THRESHOLD) {                return sort(array);            }else{                int mid = array.length / 2;                int[] leftArray = Arrays.copyOfRange(array, 0, mid);                int[] rightArray = Arrays.copyOfRange(array, mid, array.length);                MergeSortTask leftTask = new MergeSortTask(leftArray);                MergeSortTask rightTask = new MergeSortTask(rightArray);                invokeAll(leftTask, rightTask);                return merge(leftTask.join(), rightTask.join());            }        }    }}</code></pre><h3 id="异步寻找目录下的文件"><a href="#异步寻找目录下的文件" class="headerlink" title="异步寻找目录下的文件"></a>异步寻找目录下的文件</h3><pre><code>public class FindDirsFiles extends RecursiveAction {    private File path;    public FindDirsFiles(File path) {        this.path = path;    }    @Override    protected void compute() {        List&lt;FindDirsFiles&gt; subTasks = new ArrayList&lt;&gt;();        File[] files = path.listFiles();        if (files!=null){            for (File file : files) {                if (file.isDirectory()) {                    // 对每个子目录都新建一个子任务。                    subTasks.add(new FindDirsFiles(file));                } else {                    // 遇到文件，检查。                    if (file.getAbsolutePath().endsWith(&quot;txt&quot;)){                        System.out.println(&quot;文件:&quot; + file.getAbsolutePath());                    }                }            }            if (!subTasks.isEmpty()) {                // 在当前的 ForkJoinPool 上调度所有的子任务。                for (FindDirsFiles subTask : invokeAll(subTasks)) {                    subTask.join();                }            }        }    }    public static void main(String [] args){        try {            // 用一个 ForkJoinPool 实例调度总任务            ForkJoinPool pool = new ForkJoinPool();            FindDirsFiles task = new FindDirsFiles(new File(&quot;./&quot;));            /*异步提交*/            pool.execute(task);            /*主线程做自己的业务工作*/            System.out.println(&quot;Task is Running......&quot;);            Thread.sleep(1);            int otherWork = 0;            for(int i=0;i&lt;100;i++){                otherWork = otherWork+i;            }            System.out.println(&quot;Main Thread done sth......,otherWork=&quot;                    +otherWork);            task.join();//阻塞方法            System.out.println(&quot;Task end&quot;);        } catch (Exception e) {            // TODO Auto-generated catch block            e.printStackTrace();        }    }}</code></pre><h1 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h1><p>闭锁，CountDownLatch这个类能够使一个线程或多个线程等待其他线程完成后再执行。例如，应用程序的主线程希望在负责启动框架服务的线程已经完成之后再执行。</p><p>CountDownLatch是通过一个计数器来实现的，计数器的初始值为初始任务的数量（也可以大于线程数即线程中可以多次执行countDown()，线程执行countDown()之后也可以继续执行）。每当完成了一个任务后，计数器的值就会减1（CountDownLatch.countDown()方法）。当计数器值到达0时，它表示所有的已经完成了任务，然后在闭锁上等待CountDownLatch.await()方法的线程就可以继续执行。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic11.png" srcset="/img/loading.gif" class=""><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>实现最大的并行性：有时我们想同时启动多个线程，实现最大程度的并行性。例如，我们想测试一个单例类。如果我们创建一个初始计数为1的CountDownLatch，并让所有线程都在这个锁上等待，那么我们可以很轻松地完成测试。我们只需调用 一次countDown()方法就可以让所有的等待线程同时恢复执行。</p><p>开始执行前等待n个线程完成各自任务：例如应用程序启动类要确保在处理用户请求前，所有N个外部系统已经启动和运行了，例如处理excel中多个表单。</p><h3 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h3><pre><code>/** *类说明：演示CountDownLatch用法， * 共5个初始化子线程，6个闭锁扣除点，扣除完毕后，主线程和业务线程才能继续执行 */public class UseCountDownLatch {    static CountDownLatch latch = new CountDownLatch(6);    /*初始化线程*/    private static class InitThread implements Runnable{        public void run() {            System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                    +&quot; ready init work......&quot;);            latch.countDown();            for(int i =0;i&lt;2;i++) {                System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                        +&quot; ........continue do its work&quot;);            }        }    }    /*业务线程等待latch的计数器为0完成*/    private static class BusiThread implements Runnable{        public void run() {            try {                latch.await();            } catch (InterruptedException e) {                e.printStackTrace();            }            for(int i =0;i&lt;3;i++) {                System.out.println(&quot;BusiThread_&quot;+Thread.currentThread().getId()                        +&quot; do business-----&quot;);            }        }    }    public static void main(String[] args) throws InterruptedException {        new Thread(new Runnable() {            public void run() {                SleepTools.ms(1);                System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                        +&quot; ready init work step 1st......&quot;);                latch.countDown();                System.out.println(&quot;begin step 2nd.......&quot;);                SleepTools.ms(1);                System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                        +&quot; ready init work step 2nd......&quot;);                latch.countDown();            }        }).start();        new Thread(new BusiThread()).start();        for(int i=0;i&lt;=3;i++){            Thread thread = new Thread(new InitThread());            thread.start();        }        latch.await();        System.out.println(&quot;Main do ites work........&quot;);    }}</code></pre><h1 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h1><p>CyclicBarrier的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到所有线程到达屏障时，解除屏障，所有被屏障拦截的线程才会继续运行。CyclicBarrier默认的构造方法是CyclicBarrier（int parties），其参数表示屏障拦截的线程数量，每个线程调用await()方法告诉CyclicBarrier当前线程已经到达了屏障，然后这个线程被阻塞。</p><p>CyclicBarrier还提供一个更高级的构造函数CyclicBarrier（int parties，Runnable barrierAction），用于在线程到达屏障时，执行barrierAction，方便处理更复杂的业务场景。</p><p>await()方法可以执行多次，当满足条件屏障解除之后，CyclicBarrier就会被复位。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic12.png" srcset="/img/loading.gif" class=""><h3 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h3><p>CyclicBarrier可以用于多线程计算数据，最后合并计算结果的场景。</p><h3 id="用法-1"><a href="#用法-1" class="headerlink" title="用法"></a>用法</h3><pre><code>/** * 类说明：演示CyclicBarrier用法,共4个子线程，他们全部完成工作后，交出自己结果， * 再被统一释放去做自己的事情，而交出的结果被另外的线程拿来拼接字符串 */public class UseCyclicBarrier {    private static CyclicBarrier barrier = new CyclicBarrier(4, new CollectThread());    //存放子线程工作结果的容器    private static ConcurrentHashMap&lt;String, Long&gt; resultMap            = new ConcurrentHashMap&lt;&gt;();    public static void main(String[] args) {        for (int i = 0; i &lt; 4; i++) {            Thread thread = new Thread(new SubThread());            thread.start();        }    }    /*汇总的任务*/    private static class CollectThread implements Runnable {        @Override        public void run() {            StringBuilder result = new StringBuilder();            for (Map.Entry&lt;String, Long&gt; workResult : resultMap.entrySet()) {                result.append(&quot;[&quot; + workResult.getValue() + &quot;]&quot;);            }            System.out.println(&quot; the result = &quot; + result);            System.out.println(&quot;do other business........&quot;);        }    }    /*相互等待的子线程*/    private static class SubThread implements Runnable {        @Override        public void run() {            long id = Thread.currentThread().getId();            resultMap.put(Thread.currentThread().getId() + &quot;&quot;, id);            try {                Thread.sleep(1000 + id);                System.out.println(&quot;Thread_&quot; + id + &quot; ....do something &quot;);                barrier.await();                Thread.sleep(1000 + id);                System.out.println(&quot;Thread_&quot; + id + &quot; ....do its business &quot;);            } catch (Exception e) {                e.printStackTrace();            }        }    }}</code></pre><h3 id="CountDownLatch和CyclicBarrier辨析"><a href="#CountDownLatch和CyclicBarrier辨析" class="headerlink" title="CountDownLatch和CyclicBarrier辨析"></a>CountDownLatch和CyclicBarrier辨析</h3><ul><li><p>CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以反复使用。</p></li><li><p>CountDownLatch.await()会阻塞当前线程，等待所有工作线程执行countDown()之后继续执行，而CyclicBarrier通过线程调用await()阻塞工作线程，直到所有工作线程达到指定屏障，所有工作线程再继续执行。</p></li><li><p>在控制多个线程同时运行上，CountDownLatch可以不限线程数量，而CyclicBarrier是固定线程数。</p></li><li><p>CyclicBarrier还可以提供一个barrierAction，用于进行到达屏障后的工作，如：合并多线程计算结果。</p></li></ul><h1 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h1><p>Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。应用场景Semaphore可以用于做流量控制，特别是公用资源有限的应用场景，比如数据库连接。假如有一个需求，要读取几万个文件的数据，因为都是IO密集型任务，我们可以启动几十个线程并发地读取，但是如果读到内存后，还需要存储到数据库中，而数据库的连接数只有10个，这时我们必须控制只有10个线程同时获取数据库连接保存数据，否则会报错无法获取数据库连接。这个时候，就可以使用Semaphore来做流量控制。Semaphore的构造方法Semaphore（int permits）接受一个整型的数字，表示可用的许可证数量。Semaphore的用法也很简单，首先线程使用Semaphore的acquire()方法获取一个许可证 ，使用完之后调用release()方法归还许可证。还可以用tryAcquire()方法尝试获取许可证。</p><p>Semaphore还提供一些其他方法，具体如下。</p><ul><li><p><strong>int availablePermits()：</strong>返回此信号量中当前可用的许可证数。</p></li><li><p><strong>int getQueueLength()：</strong>返回正在等待获取许可证的线程数。</p></li><li><p><strong>boolean hasQueuedThreads()：</strong>是否有线程正在等待获取许可证。</p></li><li><p><strong>void reducePermits(int reduction)：</strong>减少reduction个许可证，是个protected方法。</p></li><li><p><strong>Collection getQueuedThreads()</strong>：返回所有等待获取许可证的线程集合，是个protected方法。</p></li></ul><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic13.png" srcset="/img/loading.gif" class=""><h3 id="用Semaphore实现数据库连接池"><a href="#用Semaphore实现数据库连接池" class="headerlink" title="用Semaphore实现数据库连接池"></a>用Semaphore实现数据库连接池</h3><pre><code>/** *类说明：演示Semaphore用法，一个数据库连接池的实现 */public class DBPoolSemaphore {    private final static int POOL_SIZE = 10;    //两个指示器，分别表示池子还有可用连接和已用连接    private final Semaphore useful, useless;    //存放数据库连接的容器    private static LinkedList&lt;Connection&gt; pool = new LinkedList&lt;Connection&gt;();    //初始化池    static {        for (int i = 0; i &lt; POOL_SIZE; i++) {            pool.addLast(SqlConnectImpl.fetchConnection());        }    }    public DBPoolSemaphore() {        this.useful = new Semaphore(10);        this.useless = new Semaphore(10);    }    /*归还连接*/    public void returnConnect(Connection connection) throws InterruptedException {        if(connection!=null) {            System.out.println(&quot;当前有&quot;+useful.getQueueLength()+&quot;个线程等待数据库连接!!&quot;                    +&quot;可用连接数：&quot;+useful.availablePermits());            useless.acquire();            synchronized (pool) {                pool.addLast(connection);            }            useful.release();        }    }    /*从池子拿连接*/    public Connection takeConnect() throws InterruptedException {        useful.acquire();        Connection connection;        synchronized (pool) {            connection = pool.removeFirst();        }        useless.release();        return connection;    }    private static DBPoolSemaphore dbPool = new DBPoolSemaphore();    private static class BusiThread extends Thread{        @Override        public void run() {            Random r = new Random();//让每个线程持有连接的时间不一样            long start = System.currentTimeMillis();            try {                Connection connect = dbPool.takeConnect();                System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                        +&quot;_获取数据库连接共耗时【&quot;+(System.currentTimeMillis()-start)+&quot;】ms.&quot;);                SleepTools.ms(100+r.nextInt(100));//模拟业务操作，线程持有连接查询数据                System.out.println(&quot;查询数据完成，归还连接！&quot;);                dbPool.returnConnect(connect);            } catch (InterruptedException e) {            }        }    }    public static void main(String[] args) {        for (int i = 0; i &lt; 50; i++) {            Thread thread = new BusiThread();            thread.start();        }    }}</code></pre><h3 id="Semaphore注意事项"><a href="#Semaphore注意事项" class="headerlink" title="Semaphore注意事项"></a>Semaphore注意事项</h3><p>当只有不使用userless控制可归还链接数，在归还链接时，Semaphore允许归还并不是通过线程池获取而是通过其他方式创建的链接，这就会导致Semaphore的数量增加。</p><pre><code>/** *类说明：演示Semaphore用法，一个数据库连接池的实现 */public class DBPoolNoUseless {    private final static int POOL_SIZE = 10;    private final Semaphore useful;    //存放数据库连接的容器    private static LinkedList&lt;Connection&gt; pool = new LinkedList&lt;Connection&gt;();    //初始化池    static {        for (int i = 0; i &lt; POOL_SIZE; i++) {            pool.addLast(SqlConnectImpl.fetchConnection());        }    }    public DBPoolNoUseless() {        this.useful = new Semaphore(10);    }    /*归还连接*/    public void returnConnect(Connection connection) throws InterruptedException {        if(connection!=null) {            System.out.println(&quot;当前有&quot;+useful.getQueueLength()+&quot;个线程等待数据库连接!!&quot;                    +&quot;可用连接数：&quot;+useful.availablePermits());            synchronized (pool) {                pool.addLast(connection);            }            useful.release();        }    }    /*从池子拿连接*/    public Connection takeConnect() throws InterruptedException {        useful.acquire();        Connection connection;        synchronized (pool) {            connection = pool.removeFirst();        }        return connection;    }    private static DBPoolNoUseless dbPoolNoUseless = new DBPoolNoUseless();    private static class BusiThread extends Thread{        @Override        public void run() {            Random r = new Random();//让每个线程持有连接的时间不一样            long start = System.currentTimeMillis();            try {                System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                        +&quot;_获取数据库连接共耗时【&quot;+(System.currentTimeMillis()-start)+&quot;】ms.&quot;);                SleepTools.ms(100+r.nextInt(100));//模拟业务操作，线程持有连接查询数据                System.out.println(&quot;查询数据完成，归还连接！&quot;);                dbPoolNoUseless.returnConnect(new SqlConnectImpl());            } catch (InterruptedException e) {            }        }    }    public static void main(String[] args) {        for (int i = 0; i &lt; 50; i++) {            Thread thread = new BusiThread();            thread.start();        }    }}</code></pre><h1 id="Exchange"><a href="#Exchange" class="headerlink" title="Exchange"></a>Exchange</h1><p>Exchanger（交换者）是一个用于线程间协作的工具类。Exchanger用于进行线程间的数据交换。它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过exchange方法交换数据，如果第一个线程先执行exchange()方法，它会一直等待第二个线程也执行exchange()方法，当两个线程都到达同步点时，这两个线程就可以交换数据，将本线程生产出来的数据传递给对方。交换过程由jdk保证线程安全。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic14.png" srcset="/img/loading.gif" class=""><h3 id="用法-2"><a href="#用法-2" class="headerlink" title="用法"></a>用法</h3><pre><code>/** * 类说明：演示CyclicExchange用法 */public class UseExchange {    private static final Exchanger&lt;Set&lt;String&gt;&gt; exchange = new Exchanger&lt;Set&lt;String&gt;&gt;();    public static void main(String[] args) {        new Thread(new Runnable() {            @Override            public void run() {                Set&lt;String&gt; setA = new HashSet&lt;String&gt;();//存放数据的容器                try {                    setA.add(&quot;A&quot;);                    setA = exchange.exchange(setA);//交换set                    System.out.println(&quot;A:&quot; + setA);                    /*处理交换后的数据*/                } catch (InterruptedException e) {                }            }        }).start();        new Thread(new Runnable() {            @Override            public void run() {                Set&lt;String&gt; setB = new HashSet&lt;String&gt;();//存放数据的容器                try {                    setB.add(&quot;B&quot;);                    setB = exchange.exchange(setB);//交换set                    System.out.println(&quot;B:&quot; + setB);                    /*处理交换后的数据*/                } catch (InterruptedException e) {                }            }        }).start();    }}</code></pre><h1 id="Callable、Future和FutureTask"><a href="#Callable、Future和FutureTask" class="headerlink" title="Callable、Future和FutureTask"></a>Callable、Future和FutureTask</h1><p>Runnable是一个接口，在它里面只声明了一个run()方法，由于run()方法返回值为void类型，所以在执行完任务之后无法返回任何结果。</p><p>Callable位于java.util.concurrent包下，它也是一个接口，在它里面也只声明了一个call()方法，这是一个泛型接口，call()函数返回的类型就是传递进来的V类型。 但Callable无法直接交给Thread执行，这时就需要一个类来包装Callable使其能够被Thread类执行。</p><p>RunnableFuture继承了Runnable接口和Future接口所以RunnableFuture接口可以被Thread执行，FutureTask类实现了RunnableFuture接口，所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。</p><p>Future就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。但Future只是一个接口，所以是无法直接用来创建对象使用的，就有了上面的FutureTask。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic15.png" srcset="/img/loading.gif" class=""><p>因此我们通过一个线程运行Callable，但是Thread不支持构造方法中传递Callable的实例，所以我们需要通过FutureTask把一个Callable包装成Runnable，然后再通过这个FutureTask拿到Callable运行后的返回值。</p><h3 id="用法-3"><a href="#用法-3" class="headerlink" title="用法"></a>用法</h3><pre><code>/** * 类说明：演示Future等的使用 */public class UseFuture {    /*实现Callable接口，允许有返回值*/    private static class UseCallable implements Callable&lt;Integer&gt; {        private int sum;        @Override        public Integer call() throws Exception {            System.out.println(&quot;Callable子线程开始计算！&quot;);            for (int i = 0; i &lt; 500; i++) {                if (Thread.currentThread().isInterrupted()) {                    System.out.println(&quot;Callable子线程计算任务中断！&quot;);                    return null;                }                sum = sum + i;            }            System.out.println(&quot;Callable子线程计算结束！结果为: &quot; + sum);            return sum;        }    }    public static void main(String[] args) throws InterruptedException, ExecutionException {        UseCallable useCallable = new UseCallable();        FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(useCallable);        new Thread(futureTask).start();        Random r = new Random();        if (r.nextInt(100) &gt; 50) {            System.out.println(&quot;result = &quot; + futureTask.get());        } else {            System.out.println(&quot;cancel&quot;);            futureTask.cancel(true);        }    }}</code></pre>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线程基础、线程之间的共享和合作</title>
    <link href="undefined2019/12/17/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B1%E4%BA%AB%E5%92%8C%E5%90%88%E4%BD%9C/"/>
    <url>2019/12/17/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B1%E4%BA%AB%E5%92%8C%E5%90%88%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><ul><li><strong>CPU核心和线程数的关系</strong>：核心数比线程数一般为1:1，超线程技术1:2</li><li><strong>CPU时间片轮转机制(RR调度)</strong>：古老、简单、公平、应用最广泛的算法。在时间片用完，或线程阻塞，完成式会剥夺线程cpu占用，进行上下文切换，切换时需要保存装入寄存器的值，同时载入下一个线程的值，线程切换大约需要5000-20000个cpu时钟周期。当线程切换需要大量时间时，多线程的效率可能不如单线程。</li><li><strong>进程和线程</strong>：进程是程序进行资源分配的最小单位，一个进程可能会有多个线程会共享这个进程的资源。线程是cpu资源调度的最小单位。</li><li><strong>并行和并发</strong>：并行是指同一时刻的处理能力、并发和事件相关呢，在单位时间内处理事情的能力。</li><li><strong>高并发编程的意义、好处和注意事项</strong>：提高资源利用效率，但由于共享资源，可能存在冲突、死锁，过多的线程还会造成服务器崩溃。</li></ul><h2 id="java中的线程"><a href="#java中的线程" class="headerlink" title="java中的线程"></a>java中的线程</h2><p>java中的程序天生就是多线程的，且线程之间的关系与windwos中不同，windows系统之线程之间是抢占式的，java中是协作式，可以通过虚拟机的线程管理接口查看当前进行的线程。</p><pre><code>public static void main(String[] args) {    ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();    ThreadInfo[] threadInfos=threadMXBean.dumpAllThreads(false, false);    for(ThreadInfo threadInfo:threadInfos){        System.out.println(&quot;[&quot;+threadInfo.getThreadId()+&quot;]&quot;+&quot; &quot;+threadInfo.getThreadName());    }}</code></pre><h3 id="启动线程的方式"><a href="#启动线程的方式" class="headerlink" title="启动线程的方式"></a>启动线程的方式</h3><ol><li>继承Thread类后通过start()方法启动。</li><li>实现Runable接口后通过new Thread(runable).start()启动。</li><li>实现Callable接口之后使用new FutureTask&lt;&gt;(callable)创建task后通过new Thread(runable).start()启动，可以通过futureTask的get方法获取线程返回值，获取返回值时当前线程会阻塞。</li><li>start方法会判断线程时候被启动，如果已经被启动会抛出异常</li><li>Thread是线程的抽象，Runnable是任务的抽象。</li></ol><h3 id="停止线程的方式"><a href="#停止线程的方式" class="headerlink" title="停止线程的方式"></a>停止线程的方式</h3><ol><li>thread中的stop(),resume(),suspend()方法，这三个方法过于强势，stop停止方法无法保证线程资源释放可能导致不可知的错误，suspend挂起线程时不会释放资源可能导致死锁问题。</li><li>interrupt()可以中断一个线程，并不是强行关闭这个线程，调用interrupt()方法后，讲线程的中断标识为置为true，线程是否停止由线程决定，以此确保每个线程有充足的时间做好后续工作。</li><li>isInterrupted()、静态方法interrupted()都是判断当前线程是否处于中断状态，isInterrupted()为判断为判断中断标识为是否为true，interrupted()调用之后将中断标识为改为flase。</li><li>使用自定义标志位在线程被挂起时不会去判断标志位的变化，但调用interrupt()方法会使中断方法抛出InterruptException，抛出异常后interrupt标志位重新设置为false，此时开发者可以释放线程资源，之后再决定线程是否需要终止线程。</li></ol><h3 id="interrupt-的使用示例"><a href="#interrupt-的使用示例" class="headerlink" title="interrupt()的使用示例"></a>interrupt()的使用示例</h3><pre><code>public class Main {    private static class UserThread extends Thread{        public UserThread(String name){            super(name);        }        @Override        public void run() {            String threadName=Thread.currentThread().getName();            while(!isInterrupted()){                System.out.println(threadName);            }            System.out.println(threadName+&quot; interrput flag is &quot;+isInterrupted());        }    }    // 实现Runnable中断的方法    private static class UserThread implements Runnable{        @Override        public void run() {            String threadName=Thread.currentThread().getName();            while(!Thread.currentThread().isInterrupted()){                System.out.println(threadName);            }            System.out.println(threadName+&quot; interrput flag is &quot;+Thread.currentThread().isInterrupted());        }    }    public static void main(String[] args) throws InterruptedException {        Thread endThread=new UserThread(&quot;endThread&quot;);        endThread.start();        Thread.sleep(20L);        endThread.interrupt();    }}</code></pre><p>当线程处于阻塞状态时调用interrupted方法时会抛出InterruptedExcetion异常时，抛出异常后，线程的中断标识为会被复位为false。</p><pre><code>public class Main {    private static class UserThread extends Thread {        public UserThread(String name) {            super(name);        }        @Override        public void run() {            String threadName = Thread.currentThread().getName();            while (!isInterrupted()) {                try {                    Thread.sleep(100);                } catch (InterruptedException e) {                    System.out.println(threadName+&quot; interrput flag is &quot;+isInterrupted());                    interrupt();                    e.printStackTrace();                }                System.out.println(threadName);            }            System.out.println(threadName+&quot; interrput flag is &quot;+isInterrupted());        }    }    public static void main(String[] args) throws InterruptedException {        Thread endThread=new UserThread(&quot;endThread&quot;);        endThread.start();        Thread.sleep(500);        endThread.interrupt();    }}</code></pre><h3 id="线程常用方法和线程的状态"><a href="#线程常用方法和线程的状态" class="headerlink" title="线程常用方法和线程的状态"></a>线程常用方法和线程的状态</h3><img src="/2019/12/17/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B1%E4%BA%AB%E5%92%8C%E5%90%88%E4%BD%9C/pic1.png" srcset="/img/loading.gif" class=""><ol><li>线程处于阻塞态时，系统不会进行资源分配。</li><li>当前线程变为守护线程后，所有非守护线程结束后，守护线程会死亡。</li><li>阻塞态唤醒时，进入就绪态，等待cpu调度。</li><li>interrupt()是改变线程标识位，如果线程不判断interrupt()线程不会死亡。</li><li>yield()方法是让出cpu调度权进入就绪态，所占有的资源不会释放，cpu时间片分配可能会再次分配到yield()方法。 </li><li>join()方法会让出当前线程资源及cpu执行权后进入挂起态，调用join的线程执行完之后继续执行当前线程。</li><li>setPriority()可以设置线程的优先级但不一定会起作用，范围为1-10有些系统范围为1-3，优先级是否发挥作用完全由操作系统决定。 需要休眠或者io操作的优先级高，计算的优先级低，确保处理器时间不会被计算型的线程占据。</li><li><strong>yield()方法和sleep()方法的区别</strong>：yield()方法是让出cpu调度权，重新进入就绪态，sleep()是阻塞线程，sleep()执行之后线程不会获取cpu调度权，yield()执行之后会再去抢夺cpu调度权。</li><li><strong>run()方法和start()方法</strong>：run()方法归属于调用方法所在线程的运行栈，如在main()方法中调用run()方法，此时run()方法会被打包为栈帧在main()方法的运行栈中运行，此时若在run()方法中打印线程名则线程名为main。调用start()方法后，虚拟机会将run()方法与线程映射为run()方法开启单独线程。</li><li>守护线程大多用来支持程序，可以用线程的setDaemon()方法设置，当用户线程停止后，所有的守护线程也将停止，守护线程中的finally不一定会执行。守护线程大多用于资源管理，当用户线程结束后，作为资源管理的守护线程也就没有必要释放资源。操作系统在判定当前线程被结束时就不会分配资源，但也有可能在终止进程关闭时有一段很短的时间使守护线程执行finally中的方法。 用户线程中的finally一定会执行。</li></ol><h2 id="线程间的共享"><a href="#线程间的共享" class="headerlink" title="线程间的共享"></a>线程间的共享</h2><h3 id="synchronized内置锁"><a href="#synchronized内置锁" class="headerlink" title="synchronized内置锁"></a>synchronized内置锁</h3><p>synchronized可以修饰方法或者以同步块的形式来进行使用，它主要确保多个线程在同一个时刻，只能有一个线程处于方法或者同步块中，它保证了线程对变量访问的可见性和排他性，又称为内置锁机制。</p><h5 id="对象锁和类锁"><a href="#对象锁和类锁" class="headerlink" title="对象锁和类锁"></a>对象锁和类锁</h5><p>对象锁时用于对象实例，类锁用于类的静态方法或者一个类的class对象上，不同对象实例的对象锁互不干扰。每个类在虚拟机加载时会生成class对象，类锁是将锁加到class类上。类锁与对象锁互不干扰。</p><h5 id="错误的加锁和原因分析"><a href="#错误的加锁和原因分析" class="headerlink" title="错误的加锁和原因分析"></a>错误的加锁和原因分析</h5><p>通常是在线程执行过程中改变了锁住的对象导致加锁的对象并不是同一个。</p><h4 id="volatile关键字"><a href="#volatile关键字" class="headerlink" title="volatile关键字"></a>volatile关键字</h4><p>volatile是<strong>最轻量的同步机制</strong>，volatile保证了不同线程对这个变量进行操作时的可见性，但是volatile不能保证数据在多个线程下同时写时的线程安全，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的，但多个线程同时写时volatile不能保证线程安全。所以volatile最适用的场景为一写多读。</p><h2 id="ThreadLocal辨析"><a href="#ThreadLocal辨析" class="headerlink" title="ThreadLocal辨析"></a>ThreadLocal辨析</h2><h3 id="与Synchronized的比较"><a href="#与Synchronized的比较" class="headerlink" title="与Synchronized的比较"></a>与Synchronized的比较</h3><p>ThreadLocal和Synchonized都用于解决多线程并发访问。可是ThreadLocal与synchronized有本质的差别。synchronized是利用锁的机制，使变量或代码块在某一时该仅仅能被一个线程访问。ThreadLocal为每个线程都提供了变量的副本，使得每个线程在某一时间访问到的并非同一个对象，这样就隔离了多个线程对数据的数据共享。</p><p>jdbc事务是以一个connection的操作为整体，Web容器中，每一个完整的请求周期都会由一个线程处理，spring事务则借助了ThreadLocal类，将connection与当前线程绑定，对数据库所有的操作在一个connection中进行，从而保证事务的边界。</p><h3 id="ThreadLocal的使用"><a href="#ThreadLocal的使用" class="headerlink" title="ThreadLocal的使用"></a>ThreadLocal的使用</h3><p>ThreadLocal类接口很简单，只有4个方法</p><ul><li><p><strong>void set(Object value)</strong> 设置当前线程的线程局部变量的值。</p></li><li><p><strong>public Object get()</strong> 该方法返回当前线程所对应的线程局部变量。</p></li><li><p><strong>public void remove()</strong> 将当前线程局部变量的值删除，目的是为了减少内存的占用，该方法是JDK 5.0新增的方法。需要指出的是，当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显式调用该方法清除线程的局部变量并不是必须的操作，但它可以加快内存回收的速度。</p></li><li><p><strong>protected Object initialValue()</strong> 返回该线程局部变量的初始值，该方法是一个protected的方法，显然是为了让子类覆盖而设计的。这个方法是一个延迟调用方法，在线程第1次调用get()或set(Object)时才执行，并且仅执行1次。ThreadLocal中的缺省实现直接返回一个null。</p></li><li><p><strong>public final static ThreadLocal<String> RESOURCE = new ThreadLocal<String>();</strong>RESOURCE代表一个能够存放String类型的ThreadLocal对象。此时不论什么一个线程能够并发访问这个变量，对它进行写入、读取操作，都是线程安全的。</p></li></ul><h3 id="实现解析"><a href="#实现解析" class="headerlink" title="实现解析"></a>实现解析</h3><img src="/2019/12/17/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B1%E4%BA%AB%E5%92%8C%E5%90%88%E4%BD%9C/pic2.png" srcset="/img/loading.gif" class=""><p>Thread中有一个ThreadLocalMap对象，ThreadLocalMap是ThreadLocal的静态内部类，存储的对象为Model类型的数组，Model类型的键为ThreadLocal对象，值为ThreadLocal对象的值，ThreadLocal的get方法会获取当前Thread，然后调用getMap()获取当前Thread的ThreadLocalMap，再从ThreadLocalMap中通过ThreadLocal找到对应的值。</p><h3 id="引发的内存泄露分析"><a href="#引发的内存泄露分析" class="headerlink" title="引发的内存泄露分析"></a>引发的内存泄露分析</h3><h4 id="jvm中的引用类型"><a href="#jvm中的引用类型" class="headerlink" title="jvm中的引用类型"></a>jvm中的引用类型</h4><p><strong>强引用：</strong>常用的Object o = new Object()就是强引用，在线程中执行方法时， 方法会被打包为栈帧在栈上运行，方法中创建的对象实例存储在在堆上，而方法中对象的命名指向堆上的实例，这就是引用（类似于c++的指针）。当强引用存在时即栈上有一个引用指向堆中的对象实例，gc就不会回收该对象实例。</p><p><strong>软引用：</strong>用来描述一些还有用但并非必需的对象。将要发生内存溢出时，会把软引用对象实例列入回收范围，进入第二次回收。如果回收之后还是没有足够的内存才会抛出内存溢出异常。在JDK 1.2之后，提供了SoftReference类来实现软引用。</p><p><strong>弱饮用</strong>：用来描述非必需对象的，强度低于软引用，只要发生垃圾回收，弱引用指向的对象实例就一定会被回收掉，不管是否将要发生内存溢出。在JDK 1.2之后，提供了WeakReference类来实现弱引用。</p><p><strong>虚引用</strong>：也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象实例是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象实例被收集器回收时收到一个系统通知。在JDK 1.2之后，提供了PhantomReference类来实现虚引用。</p><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><img src="/2019/12/17/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B1%E4%BA%AB%E5%92%8C%E5%90%88%E4%BD%9C/pic3.png" srcset="/img/loading.gif" class=""><p>Thread维护的ThreadLocalMap中的Model的key使用的是ThreadLocal的的弱引用 ，方法执行完出栈后，threadLocal变量会被置为null，此时强引用消失，没有强引用指向ThreadLocal实例，ThreadLocal会被gc回收即model中的key被回收，但Thread对ThreadLocalMap的应用是强引用，所以model中的value会依然存在，这就有可能造成内存泄漏。只有当前thread结束以后，thread就不会存在栈中，强引用断开，thread、threadLocalMap将全部被GC回收。最好的做法是不在需要使用threadLocal变量后，都调用它的remove()方法，清除数据。</p><p>jdk提供了相应的补偿机制，ThreadLocal的get()，set()有可能会去调用expungeStaleEntry()，replaceStaleEntry()方法去清除key为null即ThreadLocal为null的value值。</p><p>如果对key的引用为强引用的话，set()，get()方法中对Model的释放就一定不会触发，必然会造成内存泄漏。</p><h3 id="ThreadLocal线程不安全"><a href="#ThreadLocal线程不安全" class="headerlink" title="ThreadLocal线程不安全"></a>ThreadLocal线程不安全</h3><p> 当多个线程的ThreadLocalMap的value保存的是同一个对象实例的引用时，线程通过这个引用对对象实例做修改，也同样会影响了其他线程中引用的这个对象实例。显然要避免ThreadLocal线程不安全就应该让每个线程中的ThreadLocal都应该持有一个新的对象。</p><h2 id="线程间的协作"><a href="#线程间的协作" class="headerlink" title="线程间的协作"></a>线程间的协作</h2><p>线程之间相互配合，完成某项工作，如一个线程对对象做了初步处理，另一个线程感知到初步处理完成，然后进行之后的再处理，整个过程开始于一个线程，而继续执行又是另一个线程。相对而言，前者是生产者，后者就是消费者，简单的办法是让消费者线程轮训检查变量是否符合预期，如果条件满足则退出循环，从而完成消费者的工作。却存在以下问题：</p><ol><li>及时性。</li><li>开销。</li></ol><p>如果要确保及时性就要缩短轮询的间隔就会不可避免的消耗更多资源。</p><h3 id="等待和通知"><a href="#等待和通知" class="headerlink" title="等待和通知"></a>等待和通知</h3><p> 是指一个线程调用Object的wait()方法后，释放占有的资源进入阻塞态，另一个线程调用Object的notify()或者notifyAll()之后阻塞的线程被唤醒，但notify()和notifyAll()不会立即释放锁，而是等待之后的业务代码执行完之后才会释放锁，阻塞的线程被唤醒之后继续执行后续操作。上述两个线程必须通过一个Object进行操作完成交互，而wait()和notify()用来构建等待方和通知方的通信。</p><ul><li><p>notify()：随机通知一个在对象上等待的线程，使其从wait()中返回，而返回的前提是该线程获取到了对象的锁，没有获得锁的线程重新进入阻塞态。</p></li><li><p>notifyAll()：通知所有等待在该对象上的线程</p></li><li><p>wait()：调用该方法的线程进入阻塞态，只有线程调用notify()或被中断才会返回。调用wait()方法后,会释放对象的锁</p></li><li><p>wait(long)：超时等待一段时间,这里的参数时间是毫秒,也就是等待长达n毫秒,如果没有通知就超时返回</p></li><li><p>wait (long,int)：对于超时时间更细粒度的控制,可以达到纳秒</p></li></ul><h4 id="等待标准范式"><a href="#等待标准范式" class="headerlink" title="等待标准范式"></a>等待标准范式</h4><pre><code>synchronized(对象){    while(预期不满足){        对象.wait();    }}</code></pre><h4 id="通知标准范式"><a href="#通知标准范式" class="headerlink" title="通知标准范式"></a>通知标准范式</h4><pre><code>synchronized(对象){    //业务逻辑，改变条件    对象.notify()/notifyAll();}</code></pre><p>在调用wait()、notify()系列方法之前，线程必须要获得该对象的对象级别锁，即只能在同步方法或同步块中调用wait()、notify()。进入wait()方法后，当前线程释放锁，在从wait()返回前，线程与其他线程竞争重新获得锁。执行notify()系列方法的线程退出后，释放对象锁，其他线程就回去竞争对象锁。如果其中一个线程获得了该对象锁，它就会继续往下执行，在它退出synchronized代码块，释放锁后，其他的已经被唤醒的线程将会继续竞争获取该锁，一直进行下去，直到所有被唤醒的线程都执行完毕。</p><h4 id="notify和notifyAll应该用谁"><a href="#notify和notifyAll应该用谁" class="headerlink" title="notify和notifyAll应该用谁"></a>notify和notifyAll应该用谁</h4><p>尽可能用notifyall()，谨慎使用notify()，因为notify()只会唤醒一个线程，我们无法确保被唤醒的这个线程一定就是需要唤醒的线程</p><h4 id="等待超时模式实现-一个连接池"><a href="#等待超时模式实现-一个连接池" class="headerlink" title="等待超时模式实现 一个连接池"></a>等待超时模式实现 一个连接池</h4><p>DBPool.java</p><pre><code>package cn.enjoyedu.ch1.pool;import java.sql.Connection;import java.util.LinkedList;/** *类说明：连接池的实现 */public class DBPool {    /*容器，存放连接*/    private static LinkedList&lt;Connection&gt; pool = new LinkedList&lt;Connection&gt;();    /*限制了池的大小=20*/    public DBPool(int initialSize) {        if (initialSize &gt; 0) {            for (int i = 0; i &lt; initialSize; i++) {                pool.addLast(SqlConnectImpl.fetchConnection());            }        }    }    /*释放连接,通知其他的等待连接的线程*/    public void releaseConnection(Connection connection) {        if (connection != null) {            synchronized (pool){                pool.addLast(connection);                //通知其他等待连接的线程                pool.notifyAll();            }        }    }    /*获取*/    // 在mills内无法获取到连接，将会返回null 1S    public Connection fetchConnection(long mills)            throws InterruptedException {        synchronized (pool){            //永不超时            if(mills&lt;=0){                while(pool.isEmpty()){                    pool.wait();                }                return pool.removeFirst();            }else{                /*超时时刻*/                long future = System.currentTimeMillis()+mills;                /*等待时长*/                long remaining = mills;                while(pool.isEmpty()&amp;&amp;remaining&gt;0){                    pool.wait(remaining);                    /*唤醒一次，重新计算等待时长*/                    remaining = future-System.currentTimeMillis();                }                Connection connection = null;                if(!pool.isEmpty()){                    connection = pool.removeFirst();                }                return connection;            }        }    }}</code></pre><p>DBPoolTest.java</p><pre><code>package cn.enjoyedu.ch1.pool;import java.sql.Connection;import java.util.concurrent.CountDownLatch;import java.util.concurrent.atomic.AtomicInteger;/** *类说明： */public class DBPoolTest {    static DBPool pool  = new DBPool(10);    // 控制器:控制main线程将会等待所有Woker结束后才能继续执行    static CountDownLatch end;    public static void main(String[] args) throws Exception {        // 线程数量        int threadCount = 50;        end = new CountDownLatch(threadCount);        int count = 20;//每个线程的操作次数        AtomicInteger got = new AtomicInteger();//计数器：统计可以拿到连接的线程        AtomicInteger notGot = new AtomicInteger();//计数器：统计没有拿到连接的线程        for (int i = 0; i &lt; threadCount; i++) {            Thread thread = new Thread(new Worker(count, got, notGot),                     &quot;worker_&quot;+i);            thread.start();        }        end.await();// main线程在此处等待        System.out.println(&quot;总共尝试了: &quot; + (threadCount * count));        System.out.println(&quot;拿到连接的次数：  &quot; + got);        System.out.println(&quot;没能连接的次数： &quot; + notGot);    }    static class Worker implements Runnable {        int           count;        AtomicInteger got;        AtomicInteger notGot;        public Worker(int count, AtomicInteger got,                               AtomicInteger notGot) {            this.count = count;            this.got = got;            this.notGot = notGot;        }        public void run() {            while (count &gt; 0) {                try {                    // 从线程池中获取连接，如果1000ms内无法获取到，将会返回null                    // 分别统计连接获取的数量got和未获取到的数量notGot                    Connection connection = pool.fetchConnection(1000);                    if (connection != null) {                        try {                            connection.createStatement();//                            PreparedStatement preparedStatement//                                    = connection.prepareStatement(&quot;&quot;);//                            preparedStatement.execute();                            connection.commit();                        } finally {                            pool.releaseConnection(connection);                            got.incrementAndGet();                        }                    } else {                        notGot.incrementAndGet();                        System.out.println(Thread.currentThread().getName()                                +&quot;等待超时!&quot;);                    }                } catch (Exception ex) {                } finally {                    count--;                }            }            end.countDown();        }    }}</code></pre><h4 id="调用yield-，sleep-，wait-，notify-notifyAll-方法对锁的影响"><a href="#调用yield-，sleep-，wait-，notify-notifyAll-方法对锁的影响" class="headerlink" title="调用yield()，sleep()，wait()，notify()/notifyAll()方法对锁的影响"></a>调用yield()，sleep()，wait()，notify()/notifyAll()方法对锁的影响</h4><p>yield()调用之后会让出cpu执行权参入下次RR调度，sleep()在休眠结束之后需要继续执行之后的代码，所以yield()跟notify()都不会释放资源即不会释放锁，wait()方法被调用之后会释放当前线程所持有的锁进入阻塞态，等待唤醒，当线程被唤醒之后会去竞争锁，竞争到锁之后才会去继续执行。notify()也不会释放锁，而是等notify()/notifyAll()所在的同步代码块执行完之后才会释放锁，所以notify()/notifyAll()通常在同步代码块的最后一行。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>springboot2+shiro+token认证</title>
    <link href="undefined2019/12/13/springboot2-shiro-token%E8%AE%A4%E8%AF%81/"/>
    <url>2019/12/13/springboot2-shiro-token%E8%AE%A4%E8%AF%81/</url>
    
    <content type="html"><![CDATA[<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>从shiro过滤器的源码中可以看到，shiro过滤器拦截请求之后会调用isAccessAllowed()和onAccessDenied()方法，只要其中一个方法返回true，这次请求就会被放行。本文的实现方法是在onAccessDenied()中的执行登录验证即执行executeLogin()方法，这个方法会去执行AuthorizingRealm中的doGetAuthenticationInfo()方法，所以我们只需要在doGetAuthenticationInfo()里实现token的合法性检查，而doGetAuthenticationInfo()中需要AuthenticationToken类，这个类一般是存用户的用户名和密码，所以要重写这个类，把等待验证的token放入这个类，在executeLogin()方法会调用shiro过滤器中的createToken()方法创建AuthenticationToken实例，所以我们只需要重写createToken()方法创建带有token的重写之后的AuthenticationToken类即可。如果验证失败，因为我们是在executeLogin()方法中执行的登录，所以登录失败后会进入shiro过滤器中的onLoginFailure()方法，我们再重写这个方法，将验证失败的结果写入response就可以实现返回json而不是shiro默认的重定向到登录页。</p><p>多点登录限制是借助于redis实现，在用户登录时会将用户id作为键，当前token作为值存入redis中，在验证时获取token中的用户id，然后根据用户id去取redis中的token后对比，如果不同则当前token已经失效，提醒用户重新登录。</p><h2 id="pom文件"><a href="#pom文件" class="headerlink" title="pom文件"></a>pom文件</h2><pre><code>        &lt;!--shiro--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt;            &lt;artifactId&gt;shiro-core&lt;/artifactId&gt;            &lt;version&gt;1.4.0&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt;            &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt;            &lt;version&gt;1.4.0&lt;/version&gt;        &lt;/dependency&gt;        &lt;!--jwt--&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.auth0&lt;/groupId&gt;            &lt;artifactId&gt;java-jwt&lt;/artifactId&gt;            &lt;version&gt;3.3.0&lt;/version&gt;        &lt;/dependency&gt;        &lt;!--redis--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre><h2 id="重写shiro过滤器"><a href="#重写shiro过滤器" class="headerlink" title="重写shiro过滤器"></a>重写shiro过滤器</h2><pre><code>import com.alibaba.fastjson.JSON;import com.minte.english.security.common.utils.JwtUtil;import com.minte.english.security.common.utils.R;import org.apache.commons.lang3.StringUtils;import org.apache.shiro.authc.AuthenticationException;import org.apache.shiro.authc.AuthenticationToken;import org.apache.shiro.web.filter.authc.AuthenticatingFilter;import org.springframework.web.bind.annotation.RequestMethod;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;public class OAuth2Filter extends AuthenticatingFilter {    @Override    protected AuthenticationToken createToken(ServletRequest request, ServletResponse response) throws Exception {        //获取请求token        String token = JwtUtil.getRequestToken((HttpServletRequest) request);        if(StringUtils.isBlank(token)){            return null;        }        return new OAuth2Token(token);    }    @Override    protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) {        if(((HttpServletRequest) request).getMethod().equals(RequestMethod.OPTIONS.name())){            return true;        }        return false;    }    @Override    protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception {        //获取请求token，如果token不存在，直接返回401        String token = JwtUtil.getRequestToken((HttpServletRequest) request);        if(StringUtils.isBlank(token)){            HttpServletResponse httpResponse = (HttpServletResponse) response;            httpResponse.setHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;);            String json = JSON.toJSONString(R.failed(&quot;false&quot;, &quot;获取token信息失败&quot;));            httpResponse.getWriter().print(json);            return false;        }        return executeLogin(request, response);    }    @Override    protected boolean onLoginFailure(AuthenticationToken token, AuthenticationException e, ServletRequest request, ServletResponse response) {        HttpServletResponse httpResponse = (HttpServletResponse) response;        httpResponse.setContentType(&quot;application/json;charset=utf-8&quot;);        try {            //处理登录失败的异常            Throwable throwable = e.getCause() == null ? e : e.getCause();            R r = R.reLogin(throwable.getMessage());            String json = JSON.toJSONString(r);            httpResponse.getWriter().print(json);        } catch (IOException e1) {        }        return false;    }}</code></pre><h2 id="重写AuthorizingRealm"><a href="#重写AuthorizingRealm" class="headerlink" title="重写AuthorizingRealm"></a>重写AuthorizingRealm</h2><pre><code>import com.auth0.jwt.exceptions.TokenExpiredException;import com.minte.english.security.common.utils.JwtUtil;import com.minte.english.security.module.sys.redis.UserRedis;import com.minte.english.security.module.user.pojo.Role;import com.minte.english.security.module.user.pojo.User;import com.minte.english.security.module.user.service.IRoleService;import com.minte.english.security.module.user.service.IUserRoleService;import org.apache.shiro.authc.*;import org.apache.shiro.authc.pam.UnsupportedTokenException;import org.apache.shiro.authz.AuthorizationInfo;import org.apache.shiro.authz.SimpleAuthorizationInfo;import org.apache.shiro.authz.UnauthenticatedException;import org.apache.shiro.realm.AuthorizingRealm;import org.apache.shiro.subject.PrincipalCollection;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import java.io.UnsupportedEncodingException;import java.util.Arrays;import java.util.HashSet;import java.util.Set;@Componentpublic class OAuth2Realm extends AuthorizingRealm {    @Autowired    private IUserRoleService userRoleService;    @Autowired    private IRoleService roleService;    @Autowired    private UserRedis userRedis;    @Override    public boolean supports(AuthenticationToken token) {        return token instanceof OAuth2Token;    }    /**     * 授权(验证权限时调用)     */    @Override    protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) {        User user = (User) principals.getPrimaryPrincipal();        Long userId = user.getId();        Integer roleId = userRoleService.getRoleIdByUserId(userId);        Role role = roleService.getById(roleId);        //用户权限列表        Set&lt;String&gt; permsSet = new HashSet&lt;&gt;(Arrays.asList(role.getPermissions().split(&quot;,&quot;)));        SimpleAuthorizationInfo info = new SimpleAuthorizationInfo();        info.setStringPermissions(permsSet);        return info;    }    /**     * 认证(登录时调用)     */    @Override    protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException {        String accessToken = (String) token.getPrincipal();        // 验证token信息        try {            JwtUtil.verify(accessToken);        } catch (TokenExpiredException e) {            throw new ExpiredCredentialsException();        } catch (UnsupportedEncodingException e) {            throw new UnsupportedTokenException(&quot;token已失效&quot;);        }        // 检测是否在其他设备登录        Long userId = JwtUtil.getUserId(accessToken);        String onlineToken = userRedis.getOnlineUserToken(userId);        if (!onlineToken.equals(accessToken)) {            throw new ConcurrentAccessException(&quot;该账号已在其他设备登录&quot;);        }        // 检查用户授权天数，是否被冻结        User user = userRedis.get(accessToken);        if (user.getValidityDays() &lt;= 0) {            throw new UnauthenticatedException(&quot;授权天数不足&quot;);        }        //账号锁定        if (!user.getEnabled()) {            throw new DisabledAccountException(&quot;该账号已被禁用&quot;);        }        SimpleAuthenticationInfo info = new SimpleAuthenticationInfo(user, accessToken, getName());        return info;    }}</code></pre><h2 id="Config类"><a href="#Config类" class="headerlink" title="Config类"></a>Config类</h2><pre><code>@Configurationpublic class ShiroConfig {    @Bean(&quot;securityManager&quot;)    public SecurityManager securityManager(OAuth2Realm oAuth2Realm) {        DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager();        securityManager.setRealm(oAuth2Realm);        securityManager.setRememberMeManager(null);        return securityManager;    }    /**     * setUsePrefix(false)用于解决一个奇怪的bug。在引入spring aop的情况下。     * 在@Controller注解的类的方法中加入@RequiresRole注解，会导致该方法无法映射请求，导致返回404。 加入这项配置能解决这个bug     * 在使用@Transaction注解时出现无法注入bug解决     *     * @return     */    @Bean    public static DefaultAdvisorAutoProxyCreator getDefaultAdvisorAutoProxyCreator() {        DefaultAdvisorAutoProxyCreator creator = new DefaultAdvisorAutoProxyCreator();        creator.setProxyTargetClass(true);        creator.setUsePrefix(false);        return creator;    }    @Bean(&quot;shiroFilter&quot;)    public ShiroFilterFactoryBean shirFilter(SecurityManager manager) {        ShiroFilterFactoryBean shiroFilterFactory = new ShiroFilterFactoryBean();        shiroFilterFactory.setSecurityManager(manager);        Map&lt;String, Filter&gt; filterMap = shiroFilterFactory.getFilters();        filterMap.put(&quot;oauth2&quot;, new OAuth2Filter());        shiroFilterFactory.setFilters(filterMap);        Map&lt;String, String&gt; filterChainDefinitionMap = new LinkedHashMap&lt;&gt;();        filterChainDefinitionMap.put(&quot;/login&quot;, &quot;anon&quot;);        filterChainDefinitionMap.put(&quot;/actuator&quot;, &quot;anon&quot;);        filterChainDefinitionMap.put(&quot;/actuator/**&quot;, &quot;anon&quot;);        filterChainDefinitionMap.put(&quot;/validate/**&quot;, &quot;anon&quot;);        filterChainDefinitionMap.put(&quot;/user/getByUsername&quot;, &quot;anon&quot;);        filterChainDefinitionMap.put(&quot;/**&quot;, &quot;oauth2&quot;);        shiroFilterFactory.setFilterChainDefinitionMap(filterChainDefinitionMap);        return shiroFilterFactory;    }    @Bean(&quot;lifecycleBeanPostProcessor&quot;)    public LifecycleBeanPostProcessor lifecycleBeanPostProcessor() {        return new LifecycleBeanPostProcessor();    }    @Bean    public AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor(SecurityManager securityManager) {        AuthorizationAttributeSourceAdvisor advisor = new AuthorizationAttributeSourceAdvisor();        advisor.setSecurityManager(securityManager);        return advisor;    }}</code></pre><h2 id="重写AuthenticationToken类"><a href="#重写AuthenticationToken类" class="headerlink" title="重写AuthenticationToken类"></a>重写AuthenticationToken类</h2><pre><code>import org.apache.shiro.authc.AuthenticationToken;/** * token * * @author Mark sunlightcs@gmail.com */public class OAuth2Token implements AuthenticationToken {    private String token;    public OAuth2Token(String token){        this.token = token;    }    @Override    public String getPrincipal() {        return token;    }    @Override    public Object getCredentials() {        return token;    }}</code></pre><h2 id="userRedis的配置"><a href="#userRedis的配置" class="headerlink" title="userRedis的配置"></a>userRedis的配置</h2><pre><code>import com.minte.english.security.common.utils.JwtUtil;import com.minte.english.security.common.utils.RedisKeys;import com.minte.english.security.common.utils.RedisUtil;import com.minte.english.security.module.sys.service.ISysConfigService;import com.minte.english.security.module.user.pojo.User;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;/** * @author zgc * @since 2019/12/5 */@Componentpublic class UserRedis {    @Autowired    private RedisUtil redisUtil;    @Autowired    private ISysConfigService sysConfigService;    public void saveOrUpdate(User user, String token) {        String imgPath = sysConfigService.getValue(&quot;ICON_PATH&quot;) + user.getImagePath();        user.setImagePath(imgPath);        redisUtil.set(RedisKeys.getUserKey(token), user, JwtUtil.getExpiresTime(token));    }    public void delete(String token) {        redisUtil.delete(RedisKeys.getUserKey(token));    }    public User get(String token) {        return redisUtil.get(RedisKeys.getUserKey(token), User.class);    }    public void saveOrUpdateOnlineUser(Long userId, String token) {        redisUtil.set(RedisKeys.getOnlineUserKey(userId), token, JwtUtil.getExpiresTime(token));    }    public String getOnlineUserToken(Long userId) {        return redisUtil.get(RedisKeys.getOnlineUserKey(userId), String.class);    }    public void deleteOnlineUser(Long userId, String token) {        if (getOnlineUserToken(userId).equals(token)) {            redisUtil.delete(RedisKeys.getOnlineUserKey(userId));        }    }    public boolean isOnline(Long userId) {        return userId == null ? false : redisUtil.containsKey(RedisKeys.getOnlineUserKey(userId));    }    public void update(User user) {        Long userId = user.getId();        if (isOnline(userId)) {            String token = getOnlineUserToken(userId);            saveOrUpdate(user, token);        }    }}</code></pre><h2 id="Shiro的异常"><a href="#Shiro的异常" class="headerlink" title="Shiro的异常"></a>Shiro的异常</h2><ul><li>AuthenticationException:身份验证异常<ul><li>CredentitalsException:凭证异常<ul><li>IncorrectCredentialsException:不支持的凭证</li><li>ExpiredCredentialsException:凭证过期</li></ul></li><li>AccountException:账号异常<ul><li>ConcurrentAccessException:并发访问异常</li><li>UnknownAccountException:未知的账号</li><li>ExcessiveAttemptsException:认证次数超限</li><li>DisabledAccountException:账号被禁用</li><li>LockedAccountException:账号被锁定</li></ul></li><li>UnsupportedTokenException:Token异常</li></ul></li><li>AuthorizationException:授权异常<ul><li>UnauthorizedException:抛出以指示请求的操作或对请求的资源的访问是不允许的</li><li>UnanthenticatedException:当尚未完成成功认证时，尝试执行授权操作时引发异常</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>shiro</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>shiro</tag>
      
      <tag>token</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ajax跨域访问shiro问题</title>
    <link href="undefined2019/12/06/ajax%E8%B7%A8%E5%9F%9F%E8%AE%BF%E9%97%AEshiro%E9%97%AE%E9%A2%98/"/>
    <url>2019/12/06/ajax%E8%B7%A8%E5%9F%9F%E8%AE%BF%E9%97%AEshiro%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1 id="ajax跨域访问shiro问题"><a href="#ajax跨域访问shiro问题" class="headerlink" title="ajax跨域访问shiro问题"></a>ajax跨域访问shiro问题</h1><p>因为之前的ssm项目要做一次迭代，将前后端不分离改为前后端分离，但是做了跨域设置之后登录可以成功，但其他接口仍然访问不到，前端控制台报错为跨域错误：预请求被重定向。既然登录访问可以成功，说明跨域已经成功，但依然访问不到登录其他接口应该是shiro的问题。查看代码后发现，之前的shiro并没有对预请求进行处理，而且也没有做cookie的跨域，因为shiro所需要的sessionId依赖于cookie或url中的sessionId，但前端没有对sessionId进行处理，cookie也不允许跨域，shiro依然会对登录成功之后的请求进行拦截。所以这次要解决两个问题</p><ol><li>shiro过滤器中放行预请求</li><li>做关于cookie跨域的设置</li></ol><h2 id="ajax参考"><a href="#ajax参考" class="headerlink" title="ajax参考"></a>ajax参考</h2><pre><code>$.ajax({    url:url,    data:{        unitId:&quot;801&quot;    },    // 允许携带cookie跨域    crossDomain: true,     xhrFields:{              withCredentials:true          },    type:&quot;GET&quot;,    success:function(data){        console.log(data);    }})</code></pre><h2 id="后端跨域处理"><a href="#后端跨域处理" class="headerlink" title="后端跨域处理"></a>后端跨域处理</h2><p>因为项目为ssm项目，所以跨域的处理使用filter实现</p><ol><li>添加跨域cookie后，Allow-Origin不能设置为*</li><li>Allow-Method根据情况而定</li></ol><pre><code>@WebFilter(&quot;/*&quot;)public class CORSFilter implements Filter {    public CORSFilter() {    }    public void destroy() {    }    public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException {        //设置跨域请求        response.setHeader(&quot;Access-Control-Allow-Headers&quot;, &quot;x-requested-with&quot;);        response.setHeader(&quot;Access-Control-Allow-Method&quot;, &quot;POST, GET, OPTIONS&quot;);        response.setHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;http://localhost:8090&quot;);        response.setHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;);        filterChain.doFilter(request, response);        chain.doFilter(req, response);    }    public void init(FilterConfig fConfig) throws ServletException {    }}</code></pre><h2 id="重写shiro过滤器"><a href="#重写shiro过滤器" class="headerlink" title="重写shiro过滤器"></a>重写shiro过滤器</h2><p>配置中没有定义自己的shiro过滤器，所以都是默认过滤器</p><table><thead><tr><th>Filter Name</th><th>Class</th></tr></thead><tbody><tr><td>anon</td><td>org.apache.shiro.web.filter.authc.AnonymousFilter</td></tr><tr><td>authc</td><td>org.apache.shiro.web.filter.authc.FormAuthenticationFilter</td></tr><tr><td>authcBasic</td><td>org.apache.shiro.web.filter.authc.BasicHttpAuthenticationFilter</td></tr><tr><td>perms</td><td>org.apache.shiro.web.filter.authz.PermissionsAuthorizationFilter</td></tr><tr><td>port</td><td>org.apache.shiro.web.filter.authz.PortFilter</td></tr><tr><td>rest</td><td>org.apache.shiro.web.filter.authz.HttpMethodPermissionFilter</td></tr><tr><td>roles</td><td>org.apache.shiro.web.filter.authz.RolesAuthorizationFilter</td></tr><tr><td>ssl</td><td>org.apache.shiro.web.filter.authz.SslFilter</td></tr><tr><td>user</td><td>org.apache.shiro.web.filter.authc.UserFilter</td></tr></tbody></table><p>根据以上表格，我们需要重写FormAuthenticationFilter及RolesAuthorizationFilter</p><p>FormAuthenticationFilter</p><pre><code>package com.yaoxx.base.shiro;import java.io.PrintWriter;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.apache.commons.lang3.StringUtils;import org.apache.shiro.web.filter.authc.FormAuthenticationFilter;import org.apache.shiro.web.util.WebUtils;import org.springframework.http.HttpStatus;public class MyAuthenticationFilter extends FormAuthenticationFilter {   @Override   protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) {       boolean allowed = super.isAccessAllowed(request, response, mappedValue);       if (!allowed) {           // 判断请求是否是options请求           String method = WebUtils.toHttp(request).getMethod();           if (StringUtils.equalsIgnoreCase(&quot;OPTIONS&quot;, method)) {               return true;           }       }       return allowed;   }   @Override   protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception {   // 判断是否登录       if (isLoginRequest(request, response)) {          // 判断是否为post访问           if (isLoginSubmission(request, response)) {                return executeLogin(request, response);           } else {               // sessionID已经注册,但是并没有使用post方式提交               return true;           }       } else {           HttpServletRequest req = (HttpServletRequest) request;           HttpServletResponse resp = (HttpServletResponse) response;           String ajaxHeader = req.getHeader(CustomSessionManager.AUTHORIZATION);           if (StringUtils.isNotBlank(ajaxHeader)) {               // 前端Ajax请求，则不会重定向               resp.setHeader(&quot;Access-Control-Allow-Origin&quot;, req.getHeader(&quot;Origin&quot;));               resp.setHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;);               resp.setContentType(&quot;application/json; charset=utf-8&quot;);               resp.setCharacterEncoding(&quot;UTF-8&quot;);               //设置未登录状态码               resp.setStatus(HttpStatus.UNAUTHORIZED.value());               PrintWriter out = resp.getWriter();               String result = &quot;{\&quot;MESSAGE\&quot;:\&quot;未登录用户\&quot;}&quot;;               out.println(result);               out.flush();               out.close();           } else {               // == 如果是普通访问重定向至shiro配置的登录页面 == //               saveRequestAndRedirectToLogin(request, response);           }       }       return false;   }}</code></pre><p>RolesAuthorizationFilter</p><pre><code>package com.yaoxx.base.shiro;import java.io.IOException;import java.io.PrintWriter;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.apache.commons.lang3.StringUtils;import org.apache.shiro.web.filter.authz.RolesAuthorizationFilter;import org.apache.shiro.web.util.WebUtils;import org.springframework.http.HttpStatus;import org.springframework.web.bind.annotation.RequestMethod;public class MyAuthorizationFilter extends RolesAuthorizationFilter {   @Override   public boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue)throws IOException {       boolean allowed =super.isAccessAllowed(request, response, mappedValue);       if (!allowed) {           String method = WebUtils.toHttp(request).getMethod();           if (StringUtils.equalsIgnoreCase(&quot;OPTIONS&quot;, method)) {               return true;           }       }       return allowed;   }   @Override   protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws IOException {       HttpServletRequest req = (HttpServletRequest) request;       HttpServletResponse resp = (HttpServletResponse) response;       // 前端Ajax请求时requestHeader里面带一些参数，用于判断是否是前端的请求       String ajaxHeader = req.getHeader(CustomSessionManager.AUTHORIZATION);       if (StringUtils.isNotBlank(ajaxHeader)) {           // 前端Ajax请求，则不会重定向           resp.setHeader(&quot;Access-Control-Allow-Origin&quot;, req.getHeader(&quot;Origin&quot;));           resp.setHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;);           resp.setContentType(&quot;application/json; charset=utf-8&quot;);           resp.setCharacterEncoding(&quot;UTF-8&quot;);           PrintWriter out = resp.getWriter();           String result = &quot;{\&quot;MESSAGE\&quot;:\&quot;角色，权限不足\&quot;}&quot;;           out.println(result);           out.flush();           out.close();           return false;       }       return super.onAccessDenied(request, response);   }}</code></pre>]]></content>
    
    
    <categories>
      
      <category>shiro</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>shiro</tag>
      
      <tag>bug</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>summernote文本编辑器的使用</title>
    <link href="undefined2019/08/26/summernote%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>2019/08/26/summernote%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>summernote是一款Jquery文本编辑器的插件，本文只是简单的实现文本编辑及图片上传下载功能，更多api请参考<a href="https://summernote.org/getting-started/" target="_blank" rel="noopener">summernote官方文档</a></p><h2 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h2><p>summernote依赖于bootstrap和jquery所以也需要引入bootstrap和jquery</p><pre><code>&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;/assets/css/lib/bootstrap.min.css&quot; &gt;&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;/css/summernote.css&quot;&gt;&lt;script src=&quot;/assets/js/lib/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;/assets/js/lib/bootstrap.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;/js/summernote.js&quot;&gt;&lt;/script&gt;</code></pre><h2 id="html"><a href="#html" class="headerlink" title="html"></a>html</h2><pre><code>&lt;div id=&quot;summernote&quot;&gt;&lt;/div&gt;</code></pre><h2 id="js"><a href="#js" class="headerlink" title="js"></a>js</h2><pre><code>// summernote的初始化方法$(&quot;#summernote&quot;).summernote({    placeholder: &quot;输入内容&quot;,    tabsize: 2,    height: 300,    lang: &#39;zh-CN&#39;,    focus: true,    callbacks: {        onImageUpload: function (files) {                // 上传图片            uploadFile(files[0]);        },        onMediaDelete: function (target){                // 删除图片            deleteFile(target);        }    }});// 上传文件function uploadFile(file){    var imgPath = sendFile(file);    $(&#39;#summernote&#39;).summernote(&#39;insertImage&#39;, imgPath);}// 用于summernote内容回显function getContent(){    var content = $(&#39;#summernote&#39;).summernote(&#39;code&#39;);    if (content==&quot;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&quot;){        return &#39;&#39;;    }    return content;}// 获取summernote的内容function addContent(content){    $(&#39;#summernote&#39;).summernote(&#39;code&#39;, content);}// 上传图片至服务器function sendFile(file) {    if (file == null||file==undefined) {        return null;    }    var formData = new FormData();    formData.append(&quot;file&quot;, file);    console.log(formData);    var filePath = &quot;&quot;;    $.ajax({        url: &quot;/file/upload&quot;,        type: &quot;POST&quot;,        data: formData,        async: false,        contentType: false,        processData: false,        success: function (result) {            filePath = result.data.filePath;        }    });    return filePath;}// 删除服务器图片function deleteFile(filePath) {    $.ajax({        url: &quot;/file/delete&quot;,        type: &quot;POST&quot;,        data: {            &quot;filePath&quot;: filePath        },        success: function (result) {            console.log(result);        }    })}</code></pre><h2 id="java接口"><a href="#java接口" class="headerlink" title="java接口"></a>java接口</h2><pre><code>    @RequestMapping(&quot;/addImg&quot;)    public Map addImg(@RequestParam(&quot;file&quot;) MultipartFile file, HttpServletRequest request) throws IOException {        String fileName = file.getOriginalFilename();        fileName.split(&quot;.&quot;);        System.out.println(&quot;接收到文件:&quot; + fileName);        String fileType = fileName.substring(fileName.lastIndexOf(&quot;.&quot;));        String filePath = new File(&quot;&quot;).getCanonicalFile().getPath() + &quot;/static/images/&quot;;        filePath = filePath + UUID.randomUUID().toString() + fileType;        File dest = new File(filePath);        if (dest.getParentFile() != null) {            dest.getParentFile().mkdirs();        }        try {            file.transferTo(dest);        } catch (IOException e) {            log.warning(&quot;文件上传失败:&quot; + e);            return ResultMap.failed(&quot;文件上传失败&quot;);        }        String path = request.getScheme() + &quot;://&quot; + request.getServerName() + &quot;:&quot;                + request.getServerPort() + request.getContextPath() + &quot;/images/&quot; + dest.getName();        return ResultMap.success(path);    }    @RequestMapping(&quot;deleteImg&quot;)    public Map deleteImg(String imgSrc) {        String fileName = imgSrc.substring(imgSrc.lastIndexOf(&quot;/&quot;) + 1);        System.out.println(fileName);        String filePath = Thread.currentThread().getContextClassLoader().getResource(&quot;&quot;).getPath() + &quot;static/images/&quot;;        filePath = filePath + fileName;        File dest = new File(filePath);        return dest.delete() ? ResultMap.success() : ResultMap.failed();    }</code></pre>]]></content>
    
    
    <categories>
      
      <category>html插件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>html</tag>
      
      <tag>富文本编辑器</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>vim的使用</title>
    <link href="undefined2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="vim介绍"><a href="#vim介绍" class="headerlink" title="vim介绍"></a>vim介绍</h2><p>Vim是从 vi 发展出来的一个文本编辑器。代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。 </p><p>简单的来说， vi 是老式的字处理器，不过功能已经很齐全了，但是还是有可以进步的地方。 vim 则可以说是程序开发者的一项很好用的工具。 </p><p>连 vim 的官方网站 (<a href="http://www.vim.org/" target="_blank" rel="noopener">http://www.vim.org</a>) 自己也说 vim 是一个程序开发工具而不是文字处理软件。（这段是复制来的，不说点啥的话不好看）</p><h2 id="1-vim模式"><a href="#1-vim模式" class="headerlink" title="1. vim模式"></a>1. vim模式</h2><pre><code class="text">正常模式（按Esc或Ctrl+[进入） 左下角显示文件名或为空插入模式（按i进入） 左下角显示--INSERT--可视模式（按v进入） 左下角显示--VISUAL--替换模式（按r或R开始） 左下角显示 --REPLACE--命令行模式（按:或者/或者?开始）ex模式 没用过，有兴趣的同学可以自行了解</code></pre><h2 id="2-打开文件"><a href="#2-打开文件" class="headerlink" title="2. 打开文件"></a>2. 打开文件</h2><pre><code class="text"># 打开单个文件vim file    # 同时打开多个文件vim file1 file2..  # 在vim窗口中打开一个新文件:open [file]       【举个例子】# 当前打开1.txt，做了一些编辑没保存:open!         放弃这些修改，并重新打开未修改的文件# 当前打开1.txt，做了一些编辑并保存:open 2.txt    直接退出对1.txt的编辑，直接打开2.txt编辑，省了退出:wq再重新vim 2.txt的步骤# 打开远程文件，比如ftp或者share folder:e ftp://192.168.10.76/abc.txt:e \qadrive\test\1.txt# 以只读形式打开文件，但是仍然可以使用 :wq! 写入vim -R file # 强制性关闭修改功能，无法使用 :wq! 写入vim -M file</code></pre><h2 id="3-插入命令"><a href="#3-插入命令" class="headerlink" title="3. 插入命令"></a>3. 插入命令</h2><pre><code class="text">i 在当前位置生前插入I 在当前行首插入a 在当前位置后插入A 在当前行尾插入o 在当前行之后插入一行O 在当前行之前插入一行</code></pre><h2 id="4-查找命令"><a href="#4-查找命令" class="headerlink" title="4. 查找命令"></a>4. 查找命令</h2><p>最简单的查找</p><pre><code class="text">/text　　查找text，按n健查找下一个，按N健查找前一个。?text　　查找text，反向查找，按n健查找下一个，按N健查找前一个。vim中有一些特殊字符在查找时需要转义　　.*[]^%/?~$:set ignorecase　　忽略大小写的查找:set noignorecase　　不忽略大小写的查找</code></pre><p>快速查找，不需要手打字符即可查找</p><pre><code class="text">*        向后（下）寻找游标所在处的单词#        向前（上）寻找游标所在处的单词以上两种查找，n,N 的继续查找命令依然可以适用</code></pre><p>精准查找：匹配单词查找</p><p>如果文本中有 <code>hello</code>，<code>helloworld</code>，<code>hellopython</code></p><p>那我使用 /hello ，这三个词都会匹配到。</p><p>有没有办法实现精准查找呢？可以使用</p><pre><code class="text">/hello\&gt;</code></pre><p>精准查找：匹配行首、行末</p><pre><code class="text"># hello位于行首/^hello# world位于行末/world$</code></pre><h2 id="5-替换命令"><a href="#5-替换命令" class="headerlink" title="5. 替换命令"></a>5. 替换命令</h2><pre><code class="text">~  反转游标字母大小写r&lt;字母&gt;           将当前字符替换为所写字母R&lt;字母&gt;&lt;字母&gt;...  连续替换字母cc    替换整行（就是删除当前行，并在下一行插入）cw    替换一个单词（就是删除一个单词，就进入插入模式），前提是游标处于单词第一个字母（可用b定位）C     (大写C)替换至行尾（和D有所区别，D是删除（剪切）至行尾，C是删除至行位并进入插入模式）:s/old/new/    用old替换new，替换当前行的第一个匹配:s/old/new/g   用old替换new，替换当前行的所有匹配:%s/old/new/   用old替换new，替换所有行的第一个匹配:%s/old/new/g  用old替换new，替换整个文件的所有匹配:10,20 s/^/ /g 在第10行至第20行每行前面加四个空格，用于缩进。ddp    交换光标所在行和其下紧邻的一行。</code></pre><h2 id="6-撤销与重做"><a href="#6-撤销与重做" class="headerlink" title="6. 撤销与重做"></a>6. 撤销与重做</h2><pre><code class="text">u 撤销（Undo）U 撤销对整行的操作Ctrl + r 重做（Redo），即撤销的撤销。</code></pre><h2 id="7-删除命令"><a href="#7-删除命令" class="headerlink" title="7. 删除命令"></a>7. 删除命令</h2><p>需要说明的是，vim 其实并没有单纯的删除命令，下面你或许理解为剪切更加准确。</p><p>以字符为单位删除</p><pre><code class="text">x   删除当前字符3x  删除当前字符3次X   删除当前字符的前一个字符。3X  删除当前光标向前三个字符dl  删除当前字符， dl=xdh  删除前一个字符，X=dhD   删除当前字符至行尾。D=d$d$  删除当前字符至行尾d^  删除当前字符之前至行首</code></pre><p>以单词为单位删除</p><pre><code class="text">dw  删除当前字符到单词尾daw 删除当前字符所在单词</code></pre><p>以行为单位删除</p><pre><code class="text">dd  删除当前行dj  删除下一行dk  删除上一行dgg  删除当前行至文档首部d1G  删除当前行至文档首部dG   删除当前行至文档尾部kdgg  删除当前行之前所有行（不包括当前行）jdG   删除当前行之后所有行（不包括当前行）10d     删除当前行开始的10行。:1,10d  删除1-10行:11,$d  删除11行及以后所有的行:1,$d   删除所有行J　　   删除两行之间的空行，实际上是合并两行。</code></pre><h2 id="8-复制粘贴"><a href="#8-复制粘贴" class="headerlink" title="8. 复制粘贴"></a>8. 复制粘贴</h2><p>普通模式中使用y复制</p><pre><code class="text">yy   复制游标所在的整行（3yy表示复制3行）y^   复制至行首，或y0。不含光标所在处字符。y$   复制至行尾。含光标所在处字符。yw   复制一个单词。y2w  复制两个单词。yG   复制至文本末。y1G  复制至文本开头。</code></pre><p>普通模式中使用p粘贴</p><pre><code class="text">p(小写)：代表粘贴至光标后（下边，右边）P(大写)：代表粘贴至光标前（上边，左边）</code></pre><h2 id="9-剪切粘贴"><a href="#9-剪切粘贴" class="headerlink" title="9. 剪切粘贴"></a>9. 剪切粘贴</h2><pre><code class="text">dd    其实就是剪切命令，剪切当前行ddp   剪切当前行并粘贴，可实现当前行和下一行调换位置正常模式下按v（逐字）或V（逐行）进入可视模式然后用jklh命令移动即可选择某些行或字符，再按d即可剪切ndd 剪切当前行之后的n行。利用p命令可以对剪切的内容进行粘贴:1,10d 将1-10行剪切。利用p命令可将剪切后的内容进行粘贴。:1, 10 m 20 将第1-10行移动到第20行之后。</code></pre><h2 id="10-退出保存"><a href="#10-退出保存" class="headerlink" title="10. 退出保存"></a>10. 退出保存</h2><pre><code class="text">:wq 保存并退出ZZ 保存并退出:q! 强制退出并忽略所有更改:e! 放弃所有修改，并打开原来文件。ZZ 保存并退出:sav(eas) new.txt  另存为一个新文件，退出原文件的编辑且不会保存:f(ile) new.txt    新开一个文件，并不保存，退出原文件的编辑且不会保存</code></pre><h2 id="11-移动命令"><a href="#11-移动命令" class="headerlink" title="11. 移动命令"></a>11. 移动命令</h2><p>以字符为单位移动</p><pre><code class="text">h   左移一个字符l   右移一个字符k   上移一个字符j   下移一个字符# 【定位字符】f和Ffx    找到光标后第一个为x的字符3fd   找到光标后第三个为d的字符F   同f，反向查找。</code></pre><p>以行为单位移动</p><pre><code class="text"># 10指代所有数字，可任意指定10h  左移10个字符10l  右移10个字符10k  上移10行10j  下移10行$   移动到行尾 3$  移动到下面3行的行尾</code></pre><p>以单词为单位移动</p><pre><code class="text">w  向前移动一个单词（光标停在单词首部）b  向后移动一个单词e，同w，只不过是光标停在单词尾部ge 同b，光标停在单词尾部。</code></pre><p>以句为单位移动</p><pre><code class="text">(   移动到句首)   移动到句尾</code></pre><p>跳转到文件的首尾</p><pre><code class="text">gg  移动到文件头。 = [[  == ``G   移动到文件尾。 = ]]</code></pre><p>其他移动方法</p><pre><code class="text">^   移动到本行第一个非空白字符上。0   移动到本行第一个字符上(可以是空格)</code></pre><p>使用 <code>具名标记</code> 跳转，个人感觉这个很好用，因为可以跨文件。</p><pre><code class="text">使用 ma ，可以将此处标记为 a，使用 &#39;a 进行跳转使用 :marks 可以查看所有的标记使用 :delm！可以删除所有的标记</code></pre><p>当在查看错误日志时，正常的步骤是，vim打开文件，然后使用 <code>shift+g</code> 再跳转到最后一行，这里有个更简单的操作可以在打开文件时立即跳到最后一行。只要在 vim 和 文件 中间加个 <code>+</code>即可。</p><pre><code class="text">vim + you.log</code></pre><p>举一反三，当你想打开文件立即跳转到指定行时，可以这样</p><pre><code class="text"># 打开文件并跳转到 20 行vim you.log +20</code></pre><p>当你使用 <code>/</code> 搜索定位跳转或者使用 <code>:行号</code> 进行精准跳转时，有时我们想返回到上一次的位置，如何实现？</p><p>只要使用 Ctrl+o 即可返回上一次的位置。</p><h2 id="12-排版功能"><a href="#12-排版功能" class="headerlink" title="12. 排版功能"></a>12. 排版功能</h2><p><strong>缩进</strong></p><pre><code class="text">:set shiftwidth?   查看缩进值:set shiftwidth=4  设置缩进值为4# 缩进相关 最好写到配置文件中  ~/.vimrc:set tabstop=4:set softtabstop=4:set shiftwidth=4:set expandtab&gt;&gt;   向右缩进&lt;&lt;   取消缩进</code></pre><p>如何你要对代码进行缩进，还可以用 <code>==</code> 对当前行缩进，如果要对多行对待缩进，则使用 n<code>==</code>，这种方式要求你所编辑的文件的扩展名是被vim所识别的，比如<code>.py</code>文件。</p><p><strong>排版</strong></p><pre><code class="text">:ce   居中:le   靠左:ri   靠右</code></pre><h2 id="13-注释命令"><a href="#13-注释命令" class="headerlink" title="13. 注释命令"></a>13. 注释命令</h2><p><strong>多行注释</strong></p><pre><code class="text">进入命令行模式，按ctrl + v进入 visual block模式，然后按j, 或者k选中多行，把需要注释的行标记起来按大写字母I，再插入注释符，例如//按esc键就会全部注释了</code></pre><p><strong>取消多行注释</strong></p><pre><code class="text">进入命令行模式，按ctrl + v进入 visual block模式，按字母l横向选中列的个数，例如 // 需要选中2列按字母j，或者k选中注释符号按d键就可全部取消注释</code></pre><p><strong>复杂注释</strong></p><pre><code class="text">:3,5 s/^/#/g 注释第3-5行:3,5 s/^#//g 解除3-5行的注释:1,$ s/^/#/g 注释整个文档:1,$ s/^#//g 取消注释整个文档:%s/^/#/g 注释整个文档，此法更快:%s/^#//g 取消注释整个文档</code></pre><h2 id="14-调整视野"><a href="#14-调整视野" class="headerlink" title="14. 调整视野"></a>14. 调整视野</h2><pre><code class="text">&quot;zz&quot;：命令会把当前行置为屏幕正中央，&quot;zt&quot;：命令会把当前行置于屏幕顶端&quot;zb&quot;：则把当前行置于屏幕底端.Ctrl + e 向下滚动一行Ctrl + y 向上滚动一行Ctrl + d 向下滚动半屏Ctrl + u 向上滚动半屏Ctrl + f 向下滚动一屏Ctrl + b 向上滚动一屏【跳到指定行】：两种方法可以先把行号打开:set nu  打开行号:20    跳到第20行20G    跳到第20行</code></pre><h2 id="15-区域选择"><a href="#15-区域选择" class="headerlink" title="15. 区域选择"></a>15. 区域选择</h2><pre><code class="text">要进行区域选择，要先进入可视模式v   以字符为单位，上下左右选择V   以行为单位，上下选择选择后可进行操作d   剪切/删除y   复制Ctrl+v   如果当前是V(大写)模式，就变成v(小写)         如果当前是v(小写)模式，就变成普通模式。         如果当前是普通模式，就进入v(小写)模式利用这个，可以进行多行缩进。ggVG   选择全文</code></pre><h2 id="16-窗口控制"><a href="#16-窗口控制" class="headerlink" title="16. 窗口控制"></a>16. 窗口控制</h2><p><strong>新建窗口</strong></p><pre><code class="text"># 打开两个文件分属两个窗口vim -o 1.txt 2.txt# 假设现在已经打开了1.txt:sp 2.txt   开启一个横向的窗口，编辑2.txt:vsp 2.txt  开启一个竖向的窗口，编辑2.txt:split        将当前窗口再复制一个窗口出来，内容同步，游标可以不同:split 2.txt  在新窗口打开2.txt的横向窗口# 需要注意：内容同步，但是游标位置是独立的Ctrl-w s    将当前窗口分成水平窗口Ctrl-w v    将当前窗口分成竖直窗口Ctrl-w q    等同:q 结束分割出来的视窗。Ctrl-w q!   等同:q! 结束分割出来的视窗。Ctrl-w o    打开一个视窗并且隐藏之前的所有视窗</code></pre><p><strong>窗口切换</strong></p><pre><code class="text"># 特别说明：Ctrl w &lt;字母&gt; 不需要同时按Ctrl-w h    切换到左边窗口Ctrl-w l    切换到右边窗口Ctrl-w j    切换到下边窗口Ctrl-w k    切换到上边窗口# 特别说明：全屏模式下:n    切换下一个窗口:N    切换上一个窗口:bp   切换上一个窗口# 特别说明：非全屏模式:bn    切换下一个窗口，就当前位置的窗口的内容变了，其他窗口不变:bN    切换上一个窗口，就当前位置的窗口的内容变了，其他窗口不变</code></pre><p><strong>窗口移动</strong></p><pre><code class="text"># 特别说明：Ctrl w &lt;字母&gt; 不需要同时按Ctrl-w J   将当前视窗移至最下面Ctrl-w K   将当前视窗移最上面Ctrl-w H   将当前视窗移至最左边Ctrl-w L   将当前视窗移至最右边Ctrl-ww    按顺序切换窗口</code></pre><p><strong>调整尺寸</strong></p><pre><code class="text"># 友情提示：键盘切记不要处于中文状态Ctrl-w +   增加窗口高度Ctrl-w -   减少窗口高度</code></pre><p><strong>退出窗口</strong></p><pre><code class="text">:close    关闭当前窗口:close!   强制关闭当前窗口:q       退出，不保存:q!      强制退出，不保存:x       保存退出:wq      保存退出:wq!     强制保存退出:w &lt;[路径/]文件名&gt;        另存为:savesa &lt;[路径/]文件名&gt;   另存为ZZ 保存并退出。:only    关闭所有窗口，只保留当前窗口(前提：其他窗口内容有改变的话都要先保存):only!   关闭所有窗口，只保留当前窗口:qall 放弃所有操作并退出:wall 保存所有，:wqall 保存所有并退出。</code></pre><h2 id="17-文档加密"><a href="#17-文档加密" class="headerlink" title="17. 文档加密"></a>17. 文档加密</h2><pre><code class="text">vim -x file_name然后输入密码：确认密码：如果不修改内容也要保存。:wq，不然密码设定不会生效。</code></pre><h2 id="18-录制宏"><a href="#18-录制宏" class="headerlink" title="18. 录制宏"></a>18. 录制宏</h2><p>按q键加任意字母开始录制，再按q键结束录制（这意味着vim中的宏不可嵌套），使用的时候@加宏名，比如qa。。。q录制名为a的宏，@a使用这个宏。</p><h2 id="19-执行命令"><a href="#19-执行命令" class="headerlink" title="19. 执行命令"></a>19. 执行命令</h2><pre><code class="text"># 重复前一次命令. # 执行shell命令:!command# 比如列出当前目录下文件:!ls # 执行脚本:!perl -c script.pl 检查perl脚本语法，可以不用退出vim，非常方便。:!perl script.pl 执行perl脚本，可以不用退出vim，非常方便。:suspend或Ctrl - Z 挂起vim，回到shell，按fg可以返回vim。</code></pre><h2 id="20-帮助命令"><a href="#20-帮助命令" class="headerlink" title="20. 帮助命令"></a>20. 帮助命令</h2><pre><code class="text">在Unix/Linux系统上$ vimtutor# 普通模式下键盘输入vim或F1# 命令行模式下:help     显示整个帮助:help xxx 显示xxx的帮助，比如 :help i, :help CTRL-[（即Ctrl+[的帮助）。:help &#39;number&#39; Vim选项的帮助用单引号括起在Windows系统上:help tutor</code></pre><h2 id="21-配置命令"><a href="#21-配置命令" class="headerlink" title="21. 配置命令"></a>21. 配置命令</h2><p>显示当前设定</p><pre><code class="text">:set或者:se显示所有修改过的配置:set all 显示所有的设定值:set option? 显示option的设定值:set nooption 取消当期设定值:ver   显示vim的所有信息（包括版本和参数等）# 需要注意：全屏模式下:args   查看当前打开的文件列表，当前正在编辑的文件会用[]括起来</code></pre><p>更改设定</p><pre><code class="text">:set nu   显示行号set autoindent(ai)   设置自动缩进set autowrite(aw)    设置自动存档，默认未打开set backup(bk) 设置自动备份，默认未打开set background=dark或light，设置背景风格set cindent(cin) 设置C语言风格缩进:set ts=4   设置tab键转换为4个空格:set ff=unix   # 修改文件dos文件为unix:set shiftwidth?   查看缩进值:set shiftwidth=4  设置缩进值为4:set ignorecase　　忽略大小写的查找:set noignorecase　　不忽略大小写的查找:set paste  # insert模式下，粘贴格式不会乱掉:set ruler?　　查看是否设置了ruler，在.vimrc中，使用set命令设制的选项都可以通过这个命令查看:scriptnames　　查看vim脚本文件的位置，比如.vimrc文件，语法文件及plugin等。:set list 显示非打印字符，如tab，空格，行尾等。如果tab无法显示，请确定用set lcs=tab:&gt;-命令设置了.vimrc文件，并确保你的文件中的确有tab，如果开启了expendtab，那么tab将被扩展为空格。:syntax        列出已经定义的语法项:syntax clear  清除已定义的语法规则:syntax case match    大小写敏感，int和Int将视为不同的语法元素:syntax case ignore   大小写无关，int和Int将视为相同的语法元素，并使用同样的配色方案</code></pre><img src="/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/pic1.png" srcset="/img/loading.gif" class=""><img src="/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/pic2.png" srcset="/img/loading.gif" class=""><img src="/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/pic3.png" srcset="/img/loading.gif" class=""><img src="/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/pic4.png" srcset="/img/loading.gif" class="">]]></content>
    
    
    <categories>
      
      <category>快速开发</category>
      
    </categories>
    
    
    <tags>
      
      <tag>开发技巧</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>