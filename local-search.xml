<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>RabbitMQ与spring的集成</title>
    <link href="/2020/05/10/RabbitMQ%E4%B8%8Espring%E7%9A%84%E9%9B%86%E6%88%90/"/>
    <url>/2020/05/10/RabbitMQ%E4%B8%8Espring%E7%9A%84%E9%9B%86%E6%88%90/</url>
    
    <content type="html"><![CDATA[<h2 id="与spring的集成"><a href="#与spring的集成" class="headerlink" title="与spring的集成"></a>与spring的集成</h2><h3 id="pom文件"><a href="#pom文件" class="headerlink" title="pom文件"></a>pom文件</h3><p>项目中使用的spring版本为4.3.11，所以引入的是2.0.0，兼容性可以在spring官网中查到。</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt;    &lt;artifactId&gt;spring-rabbit&lt;/artifactId&gt;    &lt;version&gt;2.0.0.RELEASE&lt;/version&gt;&lt;/dependency&gt;</code></pre><h3 id="消息的发送"><a href="#消息的发送" class="headerlink" title="消息的发送"></a>消息的发送</h3><h4 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h4><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!-- 查找最新的schemaLocation 访问 http://www.springframework.org/schema/ --&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;      xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;      xmlns:rabbit=&quot;http://www.springframework.org/schema/rabbit&quot;      xmlns:context=&quot;http://www.springframework.org/schema/context&quot;      xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans          http://www.springframework.org/schema/beans/spring-beans-4.0.xsd      http://www.springframework.org/schema/rabbit      http://www.springframework.org/schema/rabbit/spring-rabbit-2.0.xsd      http://www.springframework.org/schema/context      http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;     &lt;!-- 配置扫描路径 --&gt;     &lt;context:component-scan base-package=&quot;cn.enjoyedu&quot;&gt;       &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt;     &lt;/context:component-scan&gt;   &lt;!-- rabbitMQ配置 --&gt;   &lt;bean id=&quot;rabbitConnectionFactory&quot;        class=&quot;org.springframework.amqp.rabbit.connection.CachingConnectionFactory&quot;&gt;      &lt;constructor-arg value=&quot;127.0.0.1&quot;/&gt;      &lt;property name=&quot;username&quot; value=&quot;guest&quot;/&gt;      &lt;property name=&quot;password&quot; value=&quot;guest&quot;/&gt;      &lt;property name=&quot;channelCacheSize&quot; value=&quot;8&quot;/&gt;      &lt;property name=&quot;port&quot; value=&quot;5672&quot;&gt;&lt;/property&gt;   &lt;/bean&gt;   &lt;!--Spring的rabbitmq admin--&gt;   &lt;rabbit:admin connection-factory=&quot;rabbitConnectionFactory&quot;/&gt;    &lt;!-- 创建rabbitTemplate 消息模板类 --&gt;      &lt;rabbit:template id=&quot;rabbitTemplate&quot; connection-factory=&quot;rabbitConnectionFactory&quot;/&gt;    &lt;!--生产者创建队列--&gt;    &lt;rabbit:queue name=&quot;h4_queue&quot; durable=&quot;false&quot;&gt;    &lt;/rabbit:queue&gt;   &lt;!--fanout交换器--&gt;    &lt;rabbit:fanout-exchange name=&quot;fanout-exchange&quot;          xmlns=&quot;http://www.springframework.org/schema/rabbit&quot; durable=&quot;false&quot;&gt;        &lt;bindings&gt;            &lt;binding queue=&quot;h4_queue&quot;&gt;&lt;/binding&gt;        &lt;/bindings&gt;    &lt;/rabbit:fanout-exchange&gt;&lt;/beans&gt;</code></pre><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><p>注意：生产者和消费者中都可以完成交换器、队列的申明，以及绑定关系的建立，但建议在生产者和消费者中都进行设置，这样可以保证在其中一方没有启动的情况下，另一方可以完成自己的功能，不会受影响。</p><pre><code class="java">@Controller@RequestMapping(&quot;/rabbitmq&quot;)public class RabbitMqController {    private Logger logger = LoggerFactory.getLogger(RabbitMqController.class);    @Autowired    RabbitTemplate rabbitTemplate;    @ResponseBody    @RequestMapping(&quot;/fanoutSender&quot;)    public String fanoutSender(@RequestParam(&quot;message&quot;)String message){        String opt=&quot;&quot;;        try {            for(int i=0;i&lt;3;i++){                String str = &quot;Fanout,the message_&quot;+i+&quot; is : &quot;+message;                logger.info(&quot;**************************Send Message:[&quot;+str+&quot;]&quot;);                rabbitTemplate.send(&quot;fanout-exchange&quot;,&quot;&quot;,                        new Message(str.getBytes(),new MessageProperties()));            }            opt = &quot;suc&quot;;        } catch (Exception e) {            opt = e.getCause().toString();        }        return opt;    }    @ResponseBody    @RequestMapping(&quot;/topicSender&quot;)    public String topicSender(@RequestParam(&quot;message&quot;)String message){        String opt=&quot;&quot;;        try {            String[] routekeys={&quot;king&quot;,&quot;mark&quot;,&quot;james&quot;};            String[] modules={&quot;kafka&quot;,&quot;jvm&quot;,&quot;redis&quot;};            for(int i=0;i&lt;routekeys.length;i++){                for(int j=0;j&lt;modules.length;j++){                    String routeKey = routekeys[i]+&quot;.&quot;+modules[j];                    String str = &quot;Topic,the message_[&quot;+i+&quot;,&quot;+j+&quot;] is [rk:&quot;+routeKey+&quot;][msg:&quot;+message+&quot;]&quot;;                    logger.info(&quot;**************************Send Message:[&quot;+str+&quot;]&quot;);                    MessageProperties messageProperties = new MessageProperties();                    rabbitTemplate.send(&quot;topic-exchange&quot;,                            routeKey,                            new Message(str.getBytes(), messageProperties));                }            }            opt = &quot;suc&quot;;        } catch (Exception e) {            opt = e.getCause().toString();        }        return opt;    }}</code></pre><h3 id="消息的接收"><a href="#消息的接收" class="headerlink" title="消息的接收"></a>消息的接收</h3><h4 id="配置文件-1"><a href="#配置文件-1" class="headerlink" title="配置文件"></a>配置文件</h4><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!-- 查找最新的schemaLocation 访问 http://www.springframework.org/schema/ --&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;      xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;      xmlns:context=&quot;http://www.springframework.org/schema/context&quot;      xmlns:rabbit=&quot;http://www.springframework.org/schema/rabbit&quot;      xsi:schemaLocation=&quot;           http://www.springframework.org/schema/beans           http://www.springframework.org/schema/beans/spring-beans-4.0.xsd           http://www.springframework.org/schema/context           http://www.springframework.org/schema/context/spring-context-4.0.xsd           http://www.springframework.org/schema/rabbit           http://www.springframework.org/schema/rabbit/spring-rabbit-2.0.xsd&quot;&gt;     &lt;!-- 配置扫描路径 --&gt;    &lt;context:component-scan base-package=&quot;cn.enjoyedu&quot;&gt;       &lt;!-- 只扫描Service，也可以添加Repostory，但是要把Controller排除在外，Controller由spring-mvc.xml去加载 --&gt;       &lt;!-- &lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Service&quot; /&gt; --&gt;       &lt;!-- &lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Repository&quot; /&gt; --&gt;        &lt;!--&lt;context:include-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Component&quot; /&gt;--&gt;         &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt;    &lt;/context:component-scan&gt;&lt;!-- rabbitMQ配置 --&gt;   &lt;bean id=&quot;rabbitConnectionFactory&quot;        class=&quot;org.springframework.amqp.rabbit.connection.CachingConnectionFactory&quot;&gt;      &lt;constructor-arg value=&quot;127.0.0.1&quot;/&gt;      &lt;property name=&quot;username&quot; value=&quot;guest&quot;/&gt;      &lt;property name=&quot;password&quot; value=&quot;guest&quot;/&gt;      &lt;property name=&quot;channelCacheSize&quot; value=&quot;8&quot;/&gt;      &lt;property name=&quot;port&quot; value=&quot;5672&quot;&gt;&lt;/property&gt;   &lt;/bean&gt;   &lt;rabbit:admin connection-factory=&quot;rabbitConnectionFactory&quot;/&gt;    &lt;!-- fanout交换器 begin--&gt;    &lt;!-- 定义队列 --&gt;    &lt;rabbit:queue name=&quot;h1_queue&quot; durable=&quot;false&quot;/&gt;    &lt;rabbit:queue name=&quot;h2_queue&quot; durable=&quot;false&quot;/&gt;    &lt;rabbit:queue name=&quot;h3_queue&quot; durable=&quot;false&quot;/&gt;    &lt;!-- 把需要数据的队列与交换器绑定一起 --&gt;    &lt;rabbit:fanout-exchange name=&quot;fanout-exchange&quot;        xmlns=&quot;http://www.springframework.org/schema/rabbit&quot; durable=&quot;false&quot;&gt;        &lt;rabbit:bindings&gt;            &lt;rabbit:binding queue=&quot;h1_queue&quot;&gt;&lt;/rabbit:binding&gt;            &lt;rabbit:binding queue=&quot;h2_queue&quot;&gt;&lt;/rabbit:binding&gt;            &lt;rabbit:binding queue=&quot;h3_queue&quot;&gt;&lt;/rabbit:binding&gt;        &lt;/rabbit:bindings&gt;    &lt;/rabbit:fanout-exchange&gt;    &lt;!-- fanout交换器 end--&gt;    &lt;!-- topic交换器 begin--&gt;    &lt;!-- 定义队列 --&gt;    &lt;rabbit:queue name=&quot;all_queue&quot; durable=&quot;false&quot;/&gt;    &lt;rabbit:queue name=&quot;all_kafka_queue&quot; durable=&quot;false&quot;/&gt;    &lt;rabbit:queue name=&quot;king_kafka_queue&quot; durable=&quot;false&quot;/&gt;    &lt;rabbit:queue name=&quot;king_all_queue&quot; durable=&quot;false&quot;/&gt;    &lt;!-- 把需要数据的队列通过路由键与topic交换器绑定一起 --&gt;    &lt;rabbit:topic-exchange name=&quot;topic-exchange&quot;           xmlns=&quot;http://www.springframework.org/schema/rabbit&quot; durable=&quot;false&quot;&gt;        &lt;rabbit:bindings&gt;            &lt;binding pattern=&quot;#&quot; queue=&quot;all_queue&quot;&gt;&lt;/binding&gt;            &lt;binding pattern=&quot;*.kafka&quot; queue=&quot;all_kafka_queue&quot;&gt;&lt;/binding&gt;            &lt;binding pattern=&quot;king.kafka&quot; queue=&quot;king_kafka_queue&quot;&gt;&lt;/binding&gt;            &lt;binding pattern=&quot;king.*&quot; queue=&quot;king_all_queue&quot;&gt;&lt;/binding&gt;        &lt;/rabbit:bindings&gt;    &lt;/rabbit:topic-exchange&gt;    &lt;!-- topic交换器 end--&gt;    &lt;!--消费者定义--&gt;    &lt;bean id=&quot;h1_Service&quot; class=&quot;cn.enjoyedu.service.fanout.H1_Service&quot;&gt;    &lt;/bean&gt;    &lt;bean id=&quot;h2_Service&quot; class=&quot;cn.enjoyedu.service.fanout.H2_Service&quot;&gt;    &lt;/bean&gt;    &lt;bean id=&quot;h3_Service&quot; class=&quot;cn.enjoyedu.service.fanout.H3_Service&quot;&gt;    &lt;/bean&gt;    &lt;!--监听容器--&gt;    &lt;rabbit:listener-container connection-factory=&quot;rabbitConnectionFactory&quot;&gt;        &lt;rabbit:listener ref=&quot;h1_Service&quot; queues=&quot;h1_queue&quot;                         method=&quot;onMessage&quot;/&gt;        &lt;rabbit:listener ref=&quot;h2_Service&quot; queues=&quot;h2_queue&quot;                         method=&quot;onMessage&quot;/&gt;        &lt;rabbit:listener ref=&quot;h3_Service&quot; queues=&quot;h3_queue&quot;                         method=&quot;onMessage&quot;/&gt;        &lt;rabbit:listener ref=&quot;allTopicService&quot; queues=&quot;all_queue&quot;                         method=&quot;onMessage&quot;/&gt;        &lt;rabbit:listener ref=&quot;allKafkaTopicService&quot; queues=&quot;all_kafka_queue&quot;                         method=&quot;onMessage&quot;/&gt;        &lt;rabbit:listener ref=&quot;kingKafkaTopicService&quot; queues=&quot;king_kafka_queue&quot;                         method=&quot;onMessage&quot;/&gt;        &lt;rabbit:listener ref=&quot;kingAllTopicService&quot; queues=&quot;king_all_queue&quot;                         method=&quot;onMessage&quot;/&gt;    &lt;/rabbit:listener-container&gt;&lt;/beans&gt;</code></pre><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><p>其他消费者代码与此相同，不再赘述。</p><pre><code class="java">public class H2_Service implements MessageListener{    private Logger logger = LoggerFactory.getLogger(H2_Service.class);    public void onMessage(Message message) {        logger.info(&quot;Get message: &quot;+new String( message.getBody()));    }}</code></pre><h3 id="高级特性"><a href="#高级特性" class="headerlink" title="高级特性"></a>高级特性</h3><h4 id="生产者的失败通知及发送者确认"><a href="#生产者的失败通知及发送者确认" class="headerlink" title="生产者的失败通知及发送者确认"></a>生产者的失败通知及发送者确认</h4><p>配置文件</p><pre><code class="xml">&lt;rabbit:template id=&quot;rabbitTemplate&quot;    connection-factory=&quot;rabbitConnectionFactory&quot;   mandatory=&quot;true&quot;   return-callback=&quot;sendReturnCallback&quot;   confirm-callback=&quot;confirmCallback&quot;&gt;&lt;/rabbit:template&gt;</code></pre><p>失败通知的回调</p><pre><code class="java">@Componentpublic class SendReturnCallback implements RabbitTemplate.ReturnCallback {    public void returnedMessage(Message message, int replyCode,                                String replyText, String exchange,                                String routingKey) {        String msg = new String(message.getBody());        System.out.println(&quot;返回的replyText ：&quot;+replyText);        System.out.println(&quot;返回的exchange ：&quot;+exchange);        System.out.println(&quot;返回的routingKey ：&quot;+routingKey);        System.out.println(&quot;返回的message ：&quot;+message);    }}</code></pre><p>发送者确认的回调</p><pre><code class="java">@Componentpublic class ConfirmCallback implements RabbitTemplate.ConfirmCallback {    public void confirm(CorrelationData correlationData,                        boolean ack, String cause) {        if(ack){            System.out.println(&quot;消息发送给mq成功&quot;);        }else{            System.out.println(&quot;消息发送给mq失败，原因：&quot;+cause);        }    }}</code></pre><h4 id="消费者手动确认"><a href="#消费者手动确认" class="headerlink" title="消费者手动确认"></a>消费者手动确认</h4><p>配置文件</p><pre><code class="xml">&lt;!-- 设置acknowledge属性 --&gt;&lt;rabbit:listener-container connection-factory=&quot;rabbitConnectionFactory&quot;        acknowledge=&quot;manual&quot;&gt;    &lt;rabbit:listener queues=&quot;depot_queue&quot;            ref=&quot;processDepot&quot;            method=&quot;onMessage&quot;/&gt;&lt;/rabbit:listener-container&gt;</code></pre><p>代码，注意此时的接口为ChannelAwareMessageListener</p><pre><code class="java">@Servicepublic class ProcessDepot implements ChannelAwareMessageListener {    private static Logger logger = LoggerFactory.getLogger(ProcessDepot.class);    @Autowired    private DepotManager depotManager;    private static Gson gson = new Gson();    @Override    public void onMessage(Message message, Channel channel) throws Exception {        try {            String msg = new String(message.getBody());            logger.info(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;接收到消息:&quot;+msg);            GoodTransferVo goodTransferVo = gson.fromJson(msg,GoodTransferVo.class);            try {                depotManager.operDepot(goodTransferVo);                channel.basicAck(message.getMessageProperties().getDeliveryTag(),                        false);                logger.info(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;库存处理完成，应答Mq服务&quot;);            } catch (Exception e) {                logger.error(e.getMessage());                channel.basicNack(message.getMessageProperties().getDeliveryTag(),                        false,true);                logger.info(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;库存处理失败，拒绝消息，要求Mq重新派发&quot;);                throw e;            }        } catch (Exception e) {            logger.error(e.getMessage());        }    }}</code></pre><h4 id="消费者预取模式"><a href="#消费者预取模式" class="headerlink" title="消费者预取模式"></a>消费者预取模式</h4><pre><code class="xml">&lt;!-- prefetch表示预取的数量 --&gt;&lt;rabbit:listener-container connection-factory=&quot;rabbitConnectionFactory&quot;        acknowledge=&quot;manual&quot; prefetch=&quot;150&quot;&gt;    &lt;rabbit:listener queues=&quot;depot_queue&quot;            ref=&quot;processDepot&quot;            method=&quot;onMessage&quot;/&gt;&lt;/rabbit:listener-container&gt;</code></pre>]]></content>
    
    
    <categories>
      
      <category>消息中间件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>消息中间件</tag>
      
      <tag>RabbitMQ</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RabbitMQ的高级特性</title>
    <link href="/2020/05/09/RabbitMQ%E7%9A%84%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/"/>
    <url>/2020/05/09/RabbitMQ%E7%9A%84%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/</url>
    
    <content type="html"><![CDATA[<h2 id="消息的拒绝"><a href="#消息的拒绝" class="headerlink" title="消息的拒绝"></a>消息的拒绝</h2><h3 id="Reject和Nack"><a href="#Reject和Nack" class="headerlink" title="Reject和Nack"></a>Reject和Nack</h3><img src="/2020/05/09/RabbitMQ%E7%9A%84%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/pic1.png" srcset="/img/loading.gif" class=""><p>RabbitMQ也提供了消息拒绝的机制，用于当本消费者无法进行消息的处理时，丢弃消息或让其他的消费者进行处理。消息的拒绝共有两种机制：</p><ul><li>Reject：Reject一次只能拒绝一条消息，在拒绝消息时可以使用requeue标识告诉RabbitMQ是否需要重新发送给别的消费者。如果是false则不重新发送，这个消息就会被RabbitMQ丢弃，如果是true则进行重新投递。</li><li>Nack：跟Reject类似，但可以一次性拒绝多个消息。也可以使用requeue标识，这是RabbitMQ对AMQP规范的一个扩展。</li></ul><h3 id="具体使用"><a href="#具体使用" class="headerlink" title="具体使用"></a>具体使用</h3><pre><code class="java">public class RejectRequeuConsumer {    public static void main(String[] argv)            throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        final Channel channel = connection.createChannel();        channel.exchangeDeclare(DirectProducer.EXCHANGE_NAME,                &quot;direct&quot;);        String queueName = &quot;rejectrequeue&quot;;        channel.queueDeclare(queueName, false, false,                false, null);        String routekey = &quot;error&quot;;        channel.queueBind(queueName, DirectProducer.EXCHANGE_NAME, routekey);        System.out.println(&quot;waiting for message........&quot;);        final Consumer consumer = new DefaultConsumer(channel) {            @Override            public void handleDelivery(String consumerTag,                                       Envelope envelope,                                       AMQP.BasicProperties properties,                                       byte[] body) throws IOException {                try {                    String message = new String(body, &quot;UTF-8&quot;);                    System.out.println(&quot;Received[&quot;                            + envelope.getRoutingKey()                            + &quot;]&quot; + message);                    throw new RuntimeException(&quot;处理异常&quot; + message);                } catch (Exception e) {                    e.printStackTrace();                    //Reject方式拒绝(第2个参数决定是否重新投递)                    channel.basicReject(envelope.getDeliveryTag(),true);                    //Nack方式的拒绝（第2个参数决定是否批量，第3个参数决定是否重新投递）                    //channel.basicNack(envelope.getDeliveryTag(), false, false);                }            }        };        channel.basicConsume(queueName, false, consumer);    }}</code></pre><h2 id="死信交换器DLX"><a href="#死信交换器DLX" class="headerlink" title="死信交换器DLX"></a>死信交换器DLX</h2><p>前面我们看到，如果使用消息拒绝机制，同时requeue参数设置为false时，消息就会丢失。RabbitMQ作为一个高级消息中间件，提出了死信交换器的概念来应对这种情况，这种交换器专门处理被丢弃的信息（被拒绝后进行重新投递的信息不属于私信）。死信交换器是RabbitMQ对AMQP规范的一个扩展，通常用在对问题消息的诊断上（主要针对消费者），还有延时队列的功能。消息变成死信一般是以下三种情况:</p><ul><li>消息被拒绝，并且设置requeue参数为false</li><li>消息过期（默认情况下Rabbit中的消息不过期，但是可以设置队列的过期时间和消息的过期时间以达到消息过期的效果）</li><li>队列达到最大长度（一般当设置了最大队列长度或大小并达到最大值时）</li></ul><p>死信交换器仍然只是一个普通的交换器，创建时并没有特别要求和操作。在创建队列的时候，声明该交换器将用作保存被拒绝的消息即可，相关的参数是x-dead-letter-exchange。</p><img src="/2020/05/09/RabbitMQ%E7%9A%84%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/pic2.png" srcset="/img/loading.gif" class=""><h3 id="和备用交换器的区别"><a href="#和备用交换器的区别" class="headerlink" title="和备用交换器的区别"></a>和备用交换器的区别</h3><ol><li><p>备用交换器是主交换器无法路由消息，那么消息将被路由到这个新的备用交换器，而死信交换器则是接收过期或者被拒绝的消息。</p></li><li><p>备用交换器是在声明主交换器时绑定至交换器，而死信交换器则声明队列时绑定至队列。</p></li></ol><p>场景分析：备用交换器一般是用于生产者生产消息时，确保消息可以尽量进入RabbitMQ，而死信交换器主要是用于消费消息时确保消息尽量被消费（比如消息过期，队列满了，消息拒绝且不重新投递）。</p><h3 id="具体使用-1"><a href="#具体使用-1" class="headerlink" title="具体使用"></a>具体使用</h3><p>普通消费者</p><pre><code class="java">public class WillMakeDlxConsumer {    public static void main(String[] argv)            throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        final Channel channel = connection.createChannel();        channel.exchangeDeclare(DlxProducer.EXCHANGE_NAME,                BuiltinExchangeType.TOPIC);        //将队列绑定死信交换器        String queueName = &quot;dlx_make&quot;;        Map&lt;String,Object&gt; args = new HashMap&lt;String,Object&gt;();        args.put(&quot;x-dead-letter-exchange&quot;, DlxProcessConsumer.DLX_EXCHANGE_NAME);        channel.queueDeclare(queueName,false,true,                false,                args);        channel.queueBind(queueName,                DlxProducer.EXCHANGE_NAME,&quot;#&quot;);        System.out.println(&quot;waiting for message........&quot;);        final Consumer consumer = new DefaultConsumer(channel){            @Override            public void handleDelivery(String consumerTag,                                       Envelope envelope,                                       AMQP.BasicProperties properties,                                       byte[] body) throws IOException {                String message = new String(body, &quot;UTF-8&quot;);                //TODO                //如果是test1的消息确认                if(envelope.getRoutingKey().equals(&quot;test1&quot;)){                    System.out.println(&quot;Received[&quot;                            +envelope.getRoutingKey()                            +&quot;]&quot;+message);                    channel.basicAck(envelope.getDeliveryTag(),                            false);                }else{                    //如果是其他的消息拒绝（queue=false），成为死信消息                    System.out.println(&quot;Will reject[&quot;                            +envelope.getRoutingKey()                            +&quot;]&quot;+message);                    channel.basicReject(envelope.getDeliveryTag(),                            false);                }            }        };        channel.basicConsume(queueName,false,consumer);    }}</code></pre><p>死信消费者</p><pre><code class="java">public class DlxProcessConsumer {    public final static String DLX_EXCHANGE_NAME = &quot;dlx_accept&quot;;    public static void main(String[] argv)            throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        final Channel channel = connection.createChannel();        //声明死信交换器        channel.exchangeDeclare(DLX_EXCHANGE_NAME,                BuiltinExchangeType.TOPIC);        String queueName = &quot;dlx_accept&quot;;        channel.queueDeclare(queueName,false,false,                false,null);        channel.queueBind(queueName,                DLX_EXCHANGE_NAME,&quot;#&quot;);        System.out.println(&quot;waiting for message........&quot;);        final Consumer consumer = new DefaultConsumer(channel){            @Override            public void handleDelivery(String consumerTag,                                       Envelope envelope,                                       AMQP.BasicProperties properties,                                       byte[] body) throws IOException {                String message = new String(body, &quot;UTF-8&quot;);                System.out.println(&quot;Received dead letter[&quot;                        +envelope.getRoutingKey()                        +&quot;]&quot;+message);            }        };        channel.basicConsume(queueName,true,consumer);    }}</code></pre><h2 id="队列的类型"><a href="#队列的类型" class="headerlink" title="队列的类型"></a>队列的类型</h2><p>在使用queueDeclare()方法声明队列时，可以通过设置相应的参数，来控制声明的队列类型。</p><pre><code class="java">Queue.DeclareOk queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete,Map&lt;String, Object&gt; arguments);</code></pre><ul><li>queue：队列名</li><li>durable：是否为持久化队列</li><li>exclusive：是否为单消费者队列</li><li>autoDelete：是否为自动删除队列</li></ul><h3 id="持久化队列"><a href="#持久化队列" class="headerlink" title="持久化队列"></a>持久化队列</h3><p>持久化队列和非持久化队列的区别是，持久化队列会被保存在磁盘中，固定并持久的存储，当Rabbit服务重启后，该队列会保持原来的状态在RabbitMQ中被管理，而非持久化队列不会被保存在磁盘中，Rabbit服务重启后队列就会消失。</p><p>由于非持久化不需要保存在磁盘中，所以使用速度就比持久化队列快。而持久化的优点就是会一直存在，不会随服务的重启或服务器的宕机而消失。</p><p>在声明队列时，将属性durable设置为“false”，则该队列为非持久化队列，设置成“true”时，该队列就为持久化队列</p><h3 id="自动删除队列"><a href="#自动删除队列" class="headerlink" title="自动删除队列"></a>自动删除队列</h3><p>自动删除队列和普通队列在使用上没有什么区别，唯一的区别是当消费者断开连接时队列将会被删除。自动删除队列允许的消费者没有限制， 也就是说当这个队列上最后一个消费者断开连接才会执行删除。</p><p>自动删除队列只需要在声明队列时，设置属性auto-delete标识为true即可。系统声明的随机队列，就是自动删除队列。</p><h3 id="单消费者队列"><a href="#单消费者队列" class="headerlink" title="单消费者队列"></a>单消费者队列</h3><p>普通队列允许的消费者没有限制，当队列绑定多个消费者时，RabbitMQ会采用轮询的方式进行投递。如果需要消费者独占队列，可以在队列创建的时候设定属性exclusive为true。</p><h3 id="队列的保留参数"><a href="#队列的保留参数" class="headerlink" title="队列的保留参数"></a>队列的保留参数</h3><table><thead><tr><th>参数名</th><th>作用</th></tr></thead><tbody><tr><td>x-dead-letter-exchange</td><td>死信交换器</td></tr><tr><td>x-dead-letter-routing-key</td><td>死信消息的可选路由键</td></tr><tr><td>x-expires</td><td>队列在指定毫秒数后被删除</td></tr><tr><td>x-ha-policy</td><td>创建HA队列</td></tr><tr><td>x-ha-nodes</td><td>HA队列的分布节点</td></tr><tr><td>x-max-length</td><td>队列的最大消息数</td></tr><tr><td>x-message-ttl</td><td>毫秒为单位的消息过期时间，队列级别</td></tr><tr><td>x-max-priority</td><td>最大优先值为255的队列优先排序功能</td></tr></tbody></table><h2 id="消息的属性"><a href="#消息的属性" class="headerlink" title="消息的属性"></a>消息的属性</h2><p>消息的构成：</p>{% asset_img pic6.png %}<p>消息头中的属性：</p><table><thead><tr><th><strong>属性名</strong></th><th><strong>用处</strong></th></tr></thead><tbody><tr><td>content-type</td><td>消息体的MIME类型，如application/json</td></tr><tr><td>content-encoding</td><td>消息的编码类型，如是否压缩</td></tr><tr><td>message-id</td><td>消息的唯一性标识，由应用进行设置</td></tr><tr><td>correlation-id</td><td>一般用做关联消息的message-id，常用于消息的响应</td></tr><tr><td>timestamp</td><td>消息的创建时刻，整形，精确到秒</td></tr><tr><td>expiration</td><td>消息的过期时刻， 字符串，但是呈现格式为整型，精确到秒</td></tr><tr><td>delivery-mode</td><td>消息的持久化类型，1为非持久化，2为持久化，性能影响巨大</td></tr><tr><td>app-id</td><td>应用程序的类型和版本号</td></tr><tr><td>user-id</td><td>标识已登录用户，极少使用</td></tr><tr><td>type</td><td>消息类型名称，完全由应用决定如何使用该字段</td></tr><tr><td>reply-to</td><td>构建回复消息的私有响应队列</td></tr><tr><td>headers</td><td>键/值对表，用户自定义任意的键和值</td></tr><tr><td>priority</td><td>指定队列中消息的优先级</td></tr></tbody></table><p>在发送消息时，我们还可以对消息的属性做更细微的控制，比如构建 Request-Response 模式，</p><p>使用方式</p><pre><code class="java">public class ReplyToProducer {    public final static String EXCHANGE_NAME = &quot;replyto&quot;;    public static void main(String[] args)            throws IOException, TimeoutException {        ConnectionFactory connectionFactory = new ConnectionFactory();        connectionFactory.setHost(&quot;127.0.0.1&quot;);        Connection connection = connectionFactory.newConnection();        Channel channel = connection.createChannel();        channel.exchangeDeclare(EXCHANGE_NAME,&quot;direct&quot;,false);        String msgId = UUID.randomUUID().toString();        AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder()                .messageId(msgId)                .build();        final Consumer consumer = new DefaultConsumer(channel){            @Override            public void handleDelivery(String consumerTag,                                       Envelope envelope,                                       AMQP.BasicProperties properties,                                       byte[] body) throws IOException {                String message = new String(body, &quot;UTF-8&quot;);                System.out.println(&quot;Received[&quot;+envelope.getRoutingKey()                        +&quot;]&quot;+message);            }        };        channel.basicConsume(responseQueue,true,consumer);        String msg = &quot;Hellol,RabbitMq&quot;;        //添加创建的properties        channel.basicPublish(EXCHANGE_NAME,&quot;error&quot;,                properties,                msg.getBytes());        System.out.println(&quot;Sent error:&quot;+msg);    }}</code></pre><h3 id="消息存活时间"><a href="#消息存活时间" class="headerlink" title="消息存活时间"></a>消息存活时间</h3><p>当队列消息的TTL和消息TTL都被设置，时间短的TTL设置生效。如果将一个过期消息发送给 RabbitMQ，该消息不会路由到任何队列，而是直接丢弃。</p><p>RabbitMQ只判断处于队头的消息是否过期，不会扫描队列，所以很可能队列中已存在过期消息，但是队列并不知情。这会影响队列统计数据的正确性，妨碍队列及时释放资源。</p><h3 id="消息的持久化"><a href="#消息的持久化" class="headerlink" title="消息的持久化"></a>消息的持久化</h3><p>默认情况下，队列和交换器在服务器重启后都会消失，消息当然也是。如果要使消息持久化，需要将将队列和交换器的durable属性设为true，还需要在消息发布前，将投递模式设置为2。</p><h3 id="应用程序的类型和版本号"><a href="#应用程序的类型和版本号" class="headerlink" title="应用程序的类型和版本号"></a>应用程序的类型和版本号</h3><img src="/2020/05/09/RabbitMQ%E7%9A%84%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/pic4.png" srcset="/img/loading.gif" class=""><p>如果生产者进行了迭代，消息内容、处理方式都发生了变化，而且之前的生产者跟消费者的处理逻辑还要继续使用，这时就可以通过设置消息的版本号来区分这两种消息。</p><h3 id="Request-Response模式"><a href="#Request-Response模式" class="headerlink" title="Request-Response模式"></a>Request-Response模式</h3><p>前面的例子中都是一方负责发送消息而另外一方负责处理，实际应用中上也需要请求-应答的这种通信方式，即双方都能给对方发送消息，也能接收到对方的消息。</p><img src="/2020/05/09/RabbitMQ%E7%9A%84%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/pic5.png" srcset="/img/loading.gif" class=""><p>生产者</p><pre><code class="java">public class ReplyToProducer {    public final static String EXCHANGE_NAME = &quot;replyto&quot;;    public static void main(String[] args)            throws IOException, TimeoutException {        ConnectionFactory connectionFactory = new ConnectionFactory();        connectionFactory.setHost(&quot;127.0.0.1&quot;);        Connection connection = connectionFactory.newConnection();        Channel channel = connection.createChannel();        channel.exchangeDeclare(EXCHANGE_NAME,&quot;direct&quot;,false);        //声明响应队列，消费者将会把要返回的信息发送到该队列        String responseQueue = channel.queueDeclare().getQueue();        //设置消息的唯一id        String msgId = UUID.randomUUID().toString();        //设置消息的响应队列        AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder()                .replyTo(responseQueue)                .messageId(msgId)                .build();        //绑定响应队列消费者        final Consumer consumer = new DefaultConsumer(channel){            @Override            public void handleDelivery(String consumerTag,                                       Envelope envelope,                                       AMQP.BasicProperties properties,                                       byte[] body) throws IOException {                String message = new String(body, &quot;UTF-8&quot;);                System.out.println(&quot;Received[&quot;+envelope.getRoutingKey()                        +&quot;]&quot;+message);            }        };        channel.basicConsume(responseQueue,true,consumer);        String msg = &quot;Hellol,RabbitMq&quot;;        channel.basicPublish(EXCHANGE_NAME,&quot;test&quot;,                properties,                msg.getBytes());        System.out.println(&quot;Sent error:&quot;+msg);    }}</code></pre><p>消费者</p><pre><code class="java">public class ReplyToConsumer {    public static void main(String[] argv)            throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        final Channel channel = connection.createChannel();        channel.exchangeDeclare(ReplyToProducer.EXCHANGE_NAME,                &quot;direct&quot;, false);        String queueName = &quot;queue&quot;;        channel.queueDeclare(queueName, false, false,                false, null);        String routekey = &quot;test&quot;;        channel.queueBind(queueName, ReplyToProducer.EXCHANGE_NAME, routekey);        System.out.println(&quot;waiting for message........&quot;);        final Consumer consumer = new DefaultConsumer(channel) {            @Override            public void handleDelivery(String consumerTag,                                       Envelope envelope,                                       AMQP.BasicProperties properties,                                       byte[] body) throws IOException {                String message = new String(body, &quot;UTF-8&quot;);                System.out.println(&quot;Received[&quot; + envelope.getRoutingKey()                        + &quot;]&quot; + message);                //设置响应队列及绑定的messageId                AMQP.BasicProperties respProp                        = new AMQP.BasicProperties.Builder()                        .replyTo(properties.getReplyTo())                        .correlationId(properties.getMessageId())                        .build();                System.out.println(&quot;Sent[&quot; + properties.getReplyTo() + &quot;]&quot;);                channel.basicPublish(&quot;&quot;, respProp.getReplyTo(),                        respProp,                        (&quot;Hi,&quot; + message).getBytes(&quot;UTF-8&quot;));            }        };        channel.basicConsume(queueName, true, consumer);    }}</code></pre>]]></content>
    
    
    <categories>
      
      <category>消息中间件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>消息中间件</tag>
      
      <tag>RabbitMQ</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RabbitMQ中消息发布与权衡</title>
    <link href="/2020/05/08/RabbitMQ%E4%B8%AD%E6%B6%88%E6%81%AF%E5%8F%91%E5%B8%83%E4%B8%8E%E6%9D%83%E8%A1%A1/"/>
    <url>/2020/05/08/RabbitMQ%E4%B8%AD%E6%B6%88%E6%81%AF%E5%8F%91%E5%B8%83%E4%B8%8E%E6%9D%83%E8%A1%A1/</url>
    
    <content type="html"><![CDATA[<h2 id="使用Java客户端进行消息通信"><a href="#使用Java客户端进行消息通信" class="headerlink" title="使用Java客户端进行消息通信"></a>使用Java客户端进行消息通信</h2><p>客户端需要amqp-client-5.0.0.jar和slf4j-api-1.6.1.jar</p><p>建议使用Maven：</p><pre><code class="xml">&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.0.0&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>注意：5系列的版本最好使用JDK8及以上， 低于JDK8可以使用4.x(具体的版本号到Maven的中央仓库查)的版本。</p><h3 id="Direct交换器"><a href="#Direct交换器" class="headerlink" title="Direct交换器"></a>Direct交换器</h3><img src="/2020/05/08/RabbitMQ%E4%B8%AD%E6%B6%88%E6%81%AF%E5%8F%91%E5%B8%83%E4%B8%8E%E6%9D%83%E8%A1%A1/pic3.png" srcset="/img/loading.gif" class=""><h4 id="生产者和消费者的一般用法"><a href="#生产者和消费者的一般用法" class="headerlink" title="生产者和消费者的一般用法"></a>生产者和消费者的一般用法</h4><p>创建消息生产者</p><pre><code class="java">public class DirectProducer {    /**     * 交换器名称     */    public final static String EXCHANGE_NAME = &quot;direct_logs&quot;;    /**     * 路由键     */    public final static String[] ROUTE_KEYS ={&quot;route_key_1&quot;,&quot;route_key_2&quot;,&quot;route_key_3&quot;};    public static void main(String[] args)            throws IOException, TimeoutException {        //创建连接、连接到RabbitMQ        ConnectionFactory connectionFactory= new ConnectionFactory();        //设置下连接工厂的连接地址(使用默认端口5672)        connectionFactory.setHost(&quot;localhost&quot;);        //创建连接        Connection connection =connectionFactory.newConnection();        //创建信道        Channel channel =connection.createChannel();        //在信道中设置交换器        channel.exchangeDeclare(EXCHANGE_NAME,BuiltinExchangeType.DIRECT);        for (int i=0;i&lt;6;i++){            String routeKey = ROUTE_KEYS[i%3];            String msg = &quot;Hello,RabbitMQ&quot;+(i+1);            //发布消息            channel.basicPublish(EXCHANGE_NAME,routeKey,null,msg.getBytes());            System.out.println(&quot;Sent:&quot;+routeKey+&quot;:&quot;+msg);        }        channel.close();        connection.close();    }}</code></pre><p>创建消费者</p><pre><code class="java">public class NormalConsumer {    public static void main(String[] argv) throws IOException, TimeoutException {        //创建连接、连接到RabbitMQ        ConnectionFactory connectionFactory = new ConnectionFactory();        //设置下连接工厂的连接地址(使用默认端口5672)        connectionFactory.setHost(&quot;localhost&quot;);        //创建连接        Connection connection = connectionFactory.newConnection();        //创建信道        Channel channel = connection.createChannel();        //在信道中设置交换器        channel.exchangeDeclare(DirectProducer.EXCHANGE_NAME, BuiltinExchangeType.DIRECT);        //申明队列        String queueName = &quot;queue_1&quot;;        channel.queueDeclare(queueName, false, false, false, null);        //绑定：将队列与交换器通过路由键绑定        String routeKey = DirectProducer.ROUTE_KEYS[0];        channel.queueBind(queueName, DirectProducer.EXCHANGE_NAME, routeKey);        System.out.println(&quot;waiting for message ......&quot;);        //申明一个消费者        final Consumer consumer = new DefaultConsumer(channel) {            @Override            public void handleDelivery(String s, Envelope envelope, AMQP.BasicProperties basicProperties, byte[] bytes) throws IOException {                String message = new String(bytes, &quot;UTF-8&quot;);                System.out.println(&quot;Received[&quot; + envelope.getRoutingKey() + &quot;]&quot; + message);            }        };        //消息者正式开始在指定队列上消费。        //第二个参数是自动确认参数，如果是true则是自动确认        channel.basicConsume(queueName, true, consumer);    }}</code></pre><p>通过测试发现，使用DirectProducer作为生产者，NormalConsumer作为消费者，消费者绑定一个队列，时只接收该队列绑定的路由键的消息。</p><h4 id="队列和交换器的多重绑定"><a href="#队列和交换器的多重绑定" class="headerlink" title="队列和交换器的多重绑定"></a>队列和交换器的多重绑定</h4><h5 id="一个队列绑定多个路由键"><a href="#一个队列绑定多个路由键" class="headerlink" title="一个队列绑定多个路由键"></a>一个队列绑定多个路由键</h5><p>这时队列可以接收到绑定的所有路由键的消息。</p><pre><code class="java">public class MultiBindConsumer {    public static void main(String[] argv) throws IOException,            InterruptedException, TimeoutException {        //连接工厂        ConnectionFactory factory = new ConnectionFactory();        //连接rabbitMq的地址        factory.setHost(&quot;127.0.0.1&quot;);        // 打开连接和创建频道，与发送端一样        Connection connection = factory.newConnection();        //创建一个信道        final Channel channel = connection.createChannel();        //在信道中设置交换器        channel.exchangeDeclare(DirectProducer.EXCHANGE_NAME, BuiltinExchangeType.DIRECT);        //声明一个随机队列        String queueName = channel.queueDeclare().getQueue();        //队列绑定到交换器上时，是允许绑定多个路由键的，也就是多重绑定        for (String routekey : DirectProducer.ROUTE_KEYS) {            channel.queueBind(queueName, DirectProducer.EXCHANGE_NAME, routekey);        }        System.out.println(&quot; [*] Waiting for messages:&quot;);        // 创建队列消费者        final Consumer consumerA = new DefaultConsumer(channel) {            @Override            public void handleDelivery(String consumerTag,                                       Envelope envelope,                                       AMQP.BasicProperties                                               properties,                                       byte[] body)                    throws IOException {                String message = new String(body, &quot;UTF-8&quot;);                System.out.println(&quot; Received &quot;                        + envelope.getRoutingKey() + &quot;:&#39;&quot; + message                        + &quot;&#39;&quot;);            }        };        channel.basicConsume(queueName, true, consumerA);    }}</code></pre><h5 id="一个连接多个信道"><a href="#一个连接多个信道" class="headerlink" title="一个连接多个信道"></a>一个连接多个信道</h5><p>实现方法为使用多线程创建信道，然后生成随机的队列并绑定到信道。这时所有队列都可以接收到全部的消息。</p><pre><code class="java">public class MultiChannelConsumer {    private static class ConsumerWorker implements Runnable {        final Connection connection;        public ConsumerWorker(Connection connection) {            this.connection = connection;        }        public void run() {            try {                //创建一个信道，意味着每个线程单独一个信道                Channel channel = connection.createChannel();                channel.exchangeDeclare(DirectProducer.EXCHANGE_NAME, BuiltinExchangeType.DIRECT);                // 声明一个随机队列                String queueName = channel.queueDeclare().getQueue();                //消费者名字，打印输出用                final String consumerName = Thread.currentThread().getName() + &quot;-all&quot;;                for (String routekey : DirectProducer.ROUTE_KEYS) {                    channel.queueBind(queueName, DirectProducer.EXCHANGE_NAME,                            routekey);                }                System.out.println(&quot;[&quot; + consumerName + &quot;] Waiting for messages:&quot;);                final Consumer consumerA = new DefaultConsumer(channel) {                    @Override                    public void handleDelivery(String consumerTag,                                               Envelope envelope,                                               AMQP.BasicProperties                                                       properties,                                               byte[] body)                            throws IOException {                        String message =                                new String(body, &quot;UTF-8&quot;);                        System.out.println(consumerName                                + &quot; Received &quot; + envelope.getRoutingKey()                                + &quot;:&#39;&quot; + message + &quot;&#39;&quot;);                    }                };                channel.basicConsume(queueName, true, consumerA);            } catch (Exception e) {                e.printStackTrace();            }        }    }    public static void main(String[] argv) throws TimeoutException, IOException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;localhost&quot;);        Connection connection = factory.newConnection();        for (int i = 0; i &lt; 2; i++) {            //将连接作为参数，传递给每个线程            Thread worker = new Thread(new ConsumerWorker(connection));            worker.start();        }    }}</code></pre><h5 id="一个队列多个消费者"><a href="#一个队列多个消费者" class="headerlink" title="一个队列多个消费者"></a>一个队列多个消费者</h5><p>也是利用多线程，只不过这是创建指定名称的队列，如果队列已存在不会重复绑定。这时会轮询将队列中的消息分发给消费者，所有消费者共享这个队列中的消息。</p><pre><code class="java">public class MultiConsumerOneQueue {    private static class ConsumerWorker implements Runnable {        final Connection connection;        final String queueName;        public ConsumerWorker(Connection connection, String queueName) {            this.connection = connection;            this.queueName = queueName;        }        public void run() {            try {                final Channel channel = connection.createChannel();                channel.exchangeDeclare(DirectProducer.EXCHANGE_NAME, BuiltinExchangeType.DIRECT);                //声明一个队列,rabbitmq，如果队列已存在，不会重复创建                channel.queueDeclare(queueName, false, false, false, null);                final String consumerName = Thread.currentThread().getName();                for (String routekey : DirectProducer.ROUTE_KEYS) {                    channel.queueBind(queueName, DirectProducer.EXCHANGE_NAME,                            routekey);                }                System.out.println(&quot; [&quot; + consumerName + &quot;] Waiting for messages:&quot;);                final Consumer consumerA = new DefaultConsumer(channel) {                    @Override                    public void handleDelivery(String consumerTag,                                               Envelope envelope,                                               AMQP.BasicProperties                                                       properties,                                               byte[] body)                            throws IOException {                        String message =                                new String(body, &quot;UTF-8&quot;);                        System.out.println(consumerName                                + &quot; Received &quot; + envelope.getRoutingKey()                                + &quot;:&#39;&quot; + message + &quot;&#39;&quot;);                    }                };                channel.basicConsume(queueName, true, consumerA);            } catch (Exception e) {                e.printStackTrace();            }        }    }    public static void main(String[] argv) throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        String queueName = &quot;focusAll&quot;;        for (int i = 0; i &lt; 3; i++) {            //将连接及队列名作为参数，传递给每个线程            Thread worker = new Thread(new ConsumerWorker(connection, queueName));            worker.start();        }    }}</code></pre><h3 id="Fanout交换器"><a href="#Fanout交换器" class="headerlink" title="Fanout交换器"></a>Fanout交换器</h3><img src="/2020/05/08/RabbitMQ%E4%B8%AD%E6%B6%88%E6%81%AF%E5%8F%91%E5%B8%83%E4%B8%8E%E6%9D%83%E8%A1%A1/pic2.png" srcset="/img/loading.gif" class=""><p>创建生产者</p><pre><code class="java">public class FanoutProducer {    public final static String EXCHANGE_NAME = &quot;fanout_logs&quot;;    public final static String[] ROUTE_KEYS = {&quot;route_key_1&quot;, &quot;route_key_2&quot;, &quot;route_key_3&quot;};    public static void main(String[] args) throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        Channel channel = connection.createChannel();        channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT);        for (int i = 0; i &lt; 3; i++) {            String routekey = ROUTE_KEYS[i % 3];            String message = &quot;Hello World_&quot; + (i + 1);            channel.basicPublish(EXCHANGE_NAME, routekey,                    null, message.getBytes());            System.out.println(&quot; [x] Sent &#39;&quot; + routekey + &quot;&#39;:&#39;&quot;                    + message + &quot;&#39;&quot;);        }        channel.close();        connection.close();    }}</code></pre><p>创建消费者1，注意，此时消费者不受路由键的影响，就算不绑定生产者的路由键仍然可以接收到消息。</p><pre><code class="java">public class Consumer1 {    public static void main(String[] argv) throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        final Channel channel = connection.createChannel();        channel.exchangeDeclare(FanoutProducer.EXCHANGE_NAME,                BuiltinExchangeType.FANOUT);        String queueName = channel.queueDeclare().getQueue();        for (String routekey : FanoutProducer.ROUTE_KEYS) {            channel.queueBind(queueName, FanoutProducer.EXCHANGE_NAME,                    routekey);        }        System.out.println(&quot; [&quot; + queueName + &quot;] Waiting for messages:&quot;);        final Consumer consumerA = new DefaultConsumer(channel) {            @Override            public void handleDelivery(String consumerTag, Envelope envelope,                                       AMQP.BasicProperties properties, byte[] body)                    throws IOException {                String message = new String(body, &quot;UTF-8&quot;);                System.out.println(&quot;Received &quot; + envelope.getRoutingKey() + &quot;&#39;:&#39;&quot; + message + &quot;&#39;&quot;);            }        };        channel.basicConsume(queueName, true, consumerA);    }}</code></pre><p>消费者2，注意这时绑定的是一个不存在的路由键，广播交换器不会受路由键影响，此时消费者2仍然可以接收到所有消息。</p><pre><code class="java">public class Consumer2 {    public static void main(String[] argv) throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        final Channel channel = connection.createChannel();        channel.exchangeDeclare(FanoutProducer.EXCHANGE_NAME,                BuiltinExchangeType.FANOUT);        String queueName = channel.queueDeclare().getQueue();        //设置一个不存在的路由键        String routekey=&quot;xxx&quot;;        channel.queueBind(queueName, FanoutProducer.EXCHANGE_NAME, routekey);        System.out.println(&quot; [*] Waiting for messages......&quot;);        final Consumer consumerB = new DefaultConsumer(channel) {            @Override            public void handleDelivery(String consumerTag,                                       Envelope envelope,                                       AMQP.BasicProperties properties,                                       byte[] body)                    throws IOException {                String message = new String(body, &quot;UTF-8&quot;);                System.out.println( &quot;Received [&quot;+ envelope.getRoutingKey()                        + &quot;] &quot;+message);            }        };        channel.basicConsume(queueName, true, consumerB);    }}</code></pre><h3 id="Topic交换器"><a href="#Topic交换器" class="headerlink" title="Topic交换器"></a>Topic交换器</h3><img src="/2020/05/08/RabbitMQ%E4%B8%AD%E6%B6%88%E6%81%AF%E5%8F%91%E5%B8%83%E4%B8%8E%E6%9D%83%E8%A1%A1/pic4.png" srcset="/img/loading.gif" class=""><p>创建生产者</p><pre><code class="java">public class TopicProducer {    public final static String EXCHANGE_NAME = &quot;topic_course&quot;;    public static void main(String[] args)            throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        Channel channel = connection.createChannel();        //创建主题        channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC);        String[] types = {&quot;TYPE_A&quot;, &quot;TYPE_B&quot;, &quot;TYPE_C&quot;};        for (int i = 0; i &lt; 3; i++) {            String[] modules = {&quot;moduleA&quot;, &quot;moduleB&quot;, &quot;moduleC&quot;};            for (int j = 0; j &lt; 3; j++) {                String[] status = {&quot;0&quot;, &quot;1&quot;, &quot;2&quot;};                for (int k = 0; k &lt; 3; k++) {                    // 发送的消息                    String message = &quot;Hello Topic_[&quot; + i + &quot;,&quot; + j + &quot;,&quot; + k + &quot;]&quot;;                    String routeKey = types[i % 3] + &quot;.&quot; + modules[j % 3]                            + &quot;.&quot; + status[k % 3];                    channel.basicPublish(EXCHANGE_NAME, routeKey,                            null, message.getBytes());                    System.out.println(&quot; [x] Sent &#39;&quot; + routeKey + &quot;:&#39;&quot;                            + message + &quot;&#39;&quot;);                }            }        }        channel.close();        connection.close();    }}</code></pre><p>创建<code>#</code>类型的消费者，该消费者将订阅所有消息</p><pre><code class="java">public class AllConsumer {    public static void main(String[] argv) throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        final Channel channel = connection.createChannel();        channel.exchangeDeclare(TopicProducer.EXCHANGE_NAME,                BuiltinExchangeType.TOPIC);        String queueName = channel.queueDeclare().getQueue();        //绑定        channel.queueBind(queueName,TopicProducer.EXCHANGE_NAME, &quot;#&quot;);        System.out.println(&quot; [*] Waiting for messages:&quot;);        final Consumer consumerA = new DefaultConsumer(channel) {            @Override            public void handleDelivery(String consumerTag,                                       Envelope envelope,                                       AMQP.BasicProperties properties,                                       byte[] body)                    throws IOException {                String message = new String(body, &quot;UTF-8&quot;);                System.out.println(&quot; AllConsumer Received &quot;                        + envelope.getRoutingKey()                        + &quot;&#39;:&#39;&quot; + message + &quot;&#39;&quot;);            }        };        channel.basicConsume(queueName, true, consumerA);    }}</code></pre><p>创建<code>TYPE_A.#</code>类型的消费者，该消费者将接收所有第一位为<code>TYPE_A</code>的消息。</p><pre><code class="java">public class TypeConsumer {    public static void main(String[] argv) throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        final Channel channel = connection.createChannel();        channel.exchangeDeclare(TopicProducer.EXCHANGE_NAME,                BuiltinExchangeType.TOPIC);        String queueName = channel.queueDeclare().getQueue();        channel.queueBind(queueName, TopicProducer.EXCHANGE_NAME,                &quot;TYPE_A.#&quot;);        System.out.println(&quot; [*] Waiting for messages:&quot;);        final Consumer consumerA = new DefaultConsumer(channel) {            @Override            public void handleDelivery(String consumerTag,                                       Envelope envelope,                                       AMQP.BasicProperties properties,                                       byte[] body)                    throws IOException {                String message = new String(body, &quot;UTF-8&quot;);                System.out.println(&quot; AllConsumer Received &quot;                        + envelope.getRoutingKey()                        + &quot;&#39;:&#39;&quot; + message + &quot;&#39;&quot;);            }        };        channel.basicConsume(queueName, true, consumerA);    }}</code></pre><p>创建<code>*.moduleA.*</code>类型的消费者，该消费者将接收所有第二位为<code>moduleA</code>的消息</p><pre><code class="java">public class ModuleConsumer {    public static void main(String[] argv) throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        final Channel channel = connection.createChannel();        channel.exchangeDeclare(TopicProducer.EXCHANGE_NAME,                BuiltinExchangeType.TOPIC);        String queueName = channel.queueDeclare().getQueue();        channel.queueBind(queueName, TopicProducer.EXCHANGE_NAME, &quot;*.moduleA.*&quot;);        System.out.println(&quot; [*] Waiting for messages:&quot;);        final Consumer consumerA = new DefaultConsumer(channel) {            @Override            public void handleDelivery(String consumerTag,                                       Envelope envelope,                                       AMQP.BasicProperties properties,                                       byte[] body)                    throws IOException {                String message = new String(body, &quot;UTF-8&quot;);                System.out.println(&quot; AllConsumer Received &quot;                        + envelope.getRoutingKey()                        + &quot;&#39;:&#39;&quot; + message + &quot;&#39;&quot;);            }        };        channel.basicConsume(queueName, true, consumerA);    }}</code></pre><p>同样，还可以创建<code>#.0</code>、<code>*.moduleA.1</code>、<code>TYPE_B.moduleC.2</code>等类型的消费者，来匹配对应的消息。</p><h2 id="消息发布时的权衡"><a href="#消息发布时的权衡" class="headerlink" title="消息发布时的权衡"></a>消息发布时的权衡</h2><p>不做任何配置的情况下，生产者是不知道消息是否真正到达了RabbitMQ，也就是说消息发布操作不返回任何信息给生产者，通常有以下几种方式来保证消息的可靠性。</p><img src="/2020/05/08/RabbitMQ%E4%B8%AD%E6%B6%88%E6%81%AF%E5%8F%91%E5%B8%83%E4%B8%8E%E6%9D%83%E8%A1%A1/pic1.png" srcset="/img/loading.gif" class=""><p>在RabbitMQ中，有不同的投递机制（生产者），但是每一种机制都对性能有一定的影响。一般来讲速度快的可靠性低，可靠性好的性能差，具体怎么使用需要根据应用程序来定，所以说没有最好的方式，只有最合适的方式。</p><p>在RabbitMQ中实际项目中，生产者和消费者都是客户端，它们都可以完成交换器、队列和绑定关系的申明，但是在使用过程中，通常在生产者代码中申明交换器，在消费者代码中申明队列和绑定关系。但生产者发布消息时不一定非得需要消费者，对于RabbitMQ来说，如果是单纯的生产者就只需要生产者客户端申明交换器、队列、确定绑定关系，就可以将消息发送至RabbitMQ。</p><h3 id="无保障"><a href="#无保障" class="headerlink" title="无保障"></a>无保障</h3><p>在演示各种交换器中使用的就是无保障的方式，通过basicPublish发布你的消息并使用正确的交换器和路由信息，你的消息会被接收并发送到合适的队列中。但是如果有网络问题，或者消息不可路由，或者RabbitMQ自身有问题的话，这种方式就有风险。所以无保证的消息发送一般情况下不推荐。</p><h3 id="失败确认"><a href="#失败确认" class="headerlink" title="失败确认"></a>失败确认</h3><p>在发送消息时设置mandatory标志，告诉RabbitMQ，如果消息不可路由，应该将消息返回给发送者，并通知失败。可以这样认为，开启mandatory是开启故障检测模式。<br>但是它只会让RabbitMQ向你通知失败，而不会通知成功。如果消息正确路由到队列，则发布者不会收到任何通知。带来的问题是无法确保发布消息一定是成功的，因为通知失败的消息可能会丢失。</p><p>具体使用：</p><pre><code class="java">public class DirectProducer {    public final static String EXCHANGE_NAME = &quot;direct_logs&quot;;    public final static String[] ROUTE_KEYS = {&quot;route_key_1&quot;, &quot;route_key_2&quot;, &quot;route_key_3&quot;};    public static void main(String[] args)            throws IOException, TimeoutException, InterruptedException {        ConnectionFactory connectionFactory = new ConnectionFactory();        connectionFactory.setHost(&quot;localhost&quot;);        Connection connection = connectionFactory.newConnection();        Channel channel = connection.createChannel();        channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT);        //消息发送失败时回调        channel.addReturnListener(new ReturnListener() {            public void handleReturn(int replyCode, String replyText, String exchange, String routeKey, AMQP.BasicProperties basicProperties, byte[] bytes) throws IOException {                String string = new String(bytes);                System.out.println(&quot;回调内容：replyCode：&quot; + replyCode);                System.out.println(&quot;回调内容：replyText：&quot; + replyText);                System.out.println(&quot;回调内容：exchange：&quot; + exchange);                System.out.println(&quot;回调内容：routeKey：&quot; + routeKey);                System.out.println(&quot;回调内容：content：&quot; + string);            }        });        //连接关闭时的回调        connection.addShutdownListener(new ShutdownListener() {            public void shutdownCompleted(ShutdownSignalException e) {            }        });        //信道关闭时的回掉        channel.addShutdownListener(new ShutdownListener() {            public void shutdownCompleted(ShutdownSignalException e) {            }        });        for (int i = 0; i &lt; 6; i++) {            String routeKey = ROUTE_KEYS[i % 3];            String msg = &quot;Hello,RabbitMQ&quot; + (i + 1);            //发布消息 第三个参数为true表示开启失败通知            channel.basicPublish(EXCHANGE_NAME, routeKey, true, null, msg.getBytes());            System.out.println(&quot;Sent:&quot; + routeKey + &quot;:&quot; + msg);            TimeUnit.MICROSECONDS.sleep(200);        }        channel.close();        connection.close();    }}</code></pre><h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>事务的实现主要是对信道（Channel）的设置，主要的方法有三个:</p><ol><li>channel.txSelect()声明启动事务模式;</li><li>channel.txComment()提交事务;</li><li>channel.txRollback()回滚事务;</li></ol><p>在发送消息之前，需要声明channel为事务模式，提交或者回滚事务即可。 开启事务后，客户端和RabbitMQ之间的通讯交互流程:</p><ul><li>客户端发送给服务器 Tx.Select(开启事务模式)</li><li>服务器端返回 Tx.Select-Ok(开启事务模式 ok)  推送消息</li><li>客户端发送给事务提交 Tx.Commit</li></ul><p>服务器端返回 Tx.Commit-Ok<br>以上就完成了事务的交互流程，如果其中任意一个环节出现问题，就会抛出 IoException，这样用户就可以拦截异常进行事务回滚，或决定要不要重复消息。</p><p>但是事务机制本身也会带来问题：</p><ol><li><p>严重的性能问题，加入事务后将会导致2-10倍的性能下降。</p></li><li><p>使应用程序产生同步。</p></li></ol><p>具体使用：</p><pre><code class="java">public class ProducerTransaction {    public final static String EXCHANGE_NAME = &quot;producer_transaction&quot;;    public static void main(String[] args)            throws IOException, TimeoutException, InterruptedException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        Channel channel = connection.createChannel();        channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT);        String[] routekeys={&quot;keys1&quot;,&quot;keys2&quot;,&quot;keys3&quot;};        //开启事务        channel.txSelect();        try {            for(int i=0;i&lt;3;i++){                String routekey = routekeys[i%3];                String message = &quot;Hello World_&quot;+(i+1)                        +(&quot;_&quot;+System.currentTimeMillis());                channel.basicPublish(EXCHANGE_NAME, routekey, true,                        null, message.getBytes());                System.out.println(&quot;----------------------------------&quot;);                System.out.println(&quot; Sent Message: [&quot; + routekey +&quot;]:&#39;&quot;                        + message + &quot;&#39;&quot;);                Thread.sleep(200);            }            //事务提交            channel.txCommit();        } catch (IOException e) {            e.printStackTrace();            //事务回滚            channel.txRollback();        } catch (InterruptedException e) {            e.printStackTrace();        }        channel.close();        connection.close();    }}</code></pre><h3 id="发布者确认"><a href="#发布者确认" class="headerlink" title="发布者确认"></a>发布者确认</h3><p>基于事务的性能问题，RabbitMQ团队为我们拿出了更好的方案，即采用发送方确认模式，该模式比事务更轻量，性能影响几乎可以忽略不计。</p><p>原理：生产者将信道设置成confirm模式，一旦信道进入confirm模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID（从1开始），由这个id在生产者和RabbitMQ之间进行消息的确认。</p><p>不可路由的消息，当交换器发现消息不能路由到任何队列，会进行失败确认操作，表示收到了消息。如果发送方设置了mandatory模式，则会调用addReturnListener()方法设置的监听器。</p><p>可路由的消息，要等到消息被投递到所有匹配的队列之后，broker会发送一个确认给生产者（包含消息的唯一ID），如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出，broker回传给生产者的确认消息中的delivery-tag域包含了确认消息的序列号。</p><img src="/2020/05/08/RabbitMQ%E4%B8%AD%E6%B6%88%E6%81%AF%E5%8F%91%E5%B8%83%E4%B8%8E%E6%9D%83%E8%A1%A1/pic5.png" srcset="/img/loading.gif" class=""><p>confirm模式最大的好处在于他可以是异步的，消息发送完成后生产者可以在等信道返回时，继续发送下一条消息，当消息最终得到确认之后，生产者可以通过回调方法来处理该确认消息，如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消息，生产者应用程序同样可以在回调方法中处理该nack消息决定下一步的操作。 </p><p>Confirm的三种实现方式：</p><ul><li><p>channel.waitForConfirms()普通发送方确认模式，消息到达交换器就会返回true。</p><pre><code class="java">public class ProducerConfirm {    public final static String EXCHANGE_NAME = &quot;producer_confirm&quot;;    private final static String ROUTE_KEY = &quot;test&quot;;    public static void main(String[] args) throws IOException, TimeoutException, InterruptedException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        Channel channel = connection.createChannel();        channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT);        channel.addReturnListener(new ReturnListener() {            public void handleReturn(int replyCode, String replyText,                                     String exchange, String routingKey,                                     AMQP.BasicProperties properties,                                     byte[] body)                    throws IOException {                String message = new String(body);                System.out.println(&quot;RabbitMq返回的replyCode:  &quot; + replyCode);                System.out.println(&quot;RabbitMq返回的replyText:  &quot; + replyText);                System.out.println(&quot;RabbitMq返回的exchange:  &quot; + exchange);                System.out.println(&quot;RabbitMq返回的routingKey:  &quot; + routingKey);                System.out.println(&quot;RabbitMq返回的message:  &quot; + message);            }        });        // 启用发送者确认模式        channel.confirmSelect();        for (int i = 0; i &lt; 2; i++) {            String message = &quot;Hello World_&quot; + (i + 1);            channel.basicPublish(EXCHANGE_NAME, ROUTE_KEY, true, null, message.getBytes());            System.out.println(&quot; Sent Message: [&quot; + ROUTE_KEY + &quot;]:&#39;&quot; + message + &quot;&#39;&quot;);            //确认是否成功(true成功)            if (channel.waitForConfirms()) {                System.out.println(&quot;send success&quot;);            } else {                System.out.println(&quot;send failure&quot;);            }        }        channel.close();        connection.close();    }}</code></pre></li><li><p>channel.waitForConfirmsOrDie()批量确认模式，使用同步方式等所有的消息发送之后才会执行后面代码，只要有一个消息未到达交换器就会 抛出IOException异常。</p><pre><code class="java">public class ProducerBatchConfirm {    public final static String EXCHANGE_NAME = &quot;producer_wait_confirm&quot;;    private final static String ROUTE_KEY = &quot;test&quot;;    public static void main(String[] args) throws IOException, TimeoutException, InterruptedException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        Channel channel = connection.createChannel();        channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT);        channel.addReturnListener(new ReturnListener() {            public void handleReturn(int replyCode, String replyText,                                     String exchange, String routingKey,                                     AMQP.BasicProperties properties,                                     byte[] body)                    throws IOException {                String message = new String(body);                System.out.println(&quot;RabbitMq返回的replyCode:  &quot; + replyCode);                System.out.println(&quot;RabbitMq返回的replyText:  &quot; + replyText);                System.out.println(&quot;RabbitMq返回的exchange:  &quot; + exchange);                System.out.println(&quot;RabbitMq返回的routingKey:  &quot; + routingKey);                System.out.println(&quot;RabbitMq返回的message:  &quot; + message);            }        });        // 启用发送者确认模式        channel.confirmSelect();        for (int i = 0; i &lt; 10; i++) {            String message = &quot;Hello World_&quot; + (i + 1);            channel.basicPublish(EXCHANGE_NAME, ROUTE_KEY, true, null, message.getBytes());            System.out.println(&quot; Sent Message: [&quot; + ROUTE_KEY + &quot;]:&#39;&quot; + message + &quot;&#39;&quot;);        }        // 批量确认，如果失败会抛出异常        channel.waitForConfirmsOrDie();        channel.close();        connection.close();    }}</code></pre></li><li><p>channel.addConfirmListener()异步监听发送方确认模式。</p><pre><code class="java">public class ProducerConfirmAsync {    public final static String EXCHANGE_NAME = &quot;producer_async_confirm&quot;;    public static void main(String[] args) throws IOException, TimeoutException, InterruptedException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        Channel channel = connection.createChannel();        channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT);        // 启用发送者确认模式        channel.confirmSelect();        // 添加发送者确认监听器        channel.addConfirmListener(new ConfirmListener() {            public void handleAck(long deliveryTag, boolean multiple)                    throws IOException {                System.out.println(&quot;send_ACK:&quot;+deliveryTag+&quot;,multiple:&quot;+multiple);            }            public void handleNack(long deliveryTag, boolean multiple)                    throws IOException {                System.out.println(&quot;Error----send_NACK:&quot;+deliveryTag+&quot;,multiple:&quot;+multiple);            }        });        channel.addReturnListener(new ReturnListener() {            public void handleReturn(int replyCode, String replyText,                                     String exchange, String routingKey,                                     AMQP.BasicProperties properties,                                     byte[] body)                    throws IOException {                String message = new String(body);                System.out.println(&quot;RabbitMQ路由失败:  &quot;+routingKey+&quot;.&quot;+message);            }        });        String[] routekeys={&quot;test&quot;,&quot;test2&quot;};        for(int i=0;i&lt;20;i++){            String routekey = routekeys[i%2];            String message = &quot;Hello World_&quot;+(i+1)+(&quot;_&quot;+System.currentTimeMillis());            channel.basicPublish(EXCHANGE_NAME, routekey, true,                    MessageProperties.PERSISTENT_BASIC, message.getBytes());        }    }}</code></pre></li></ul><h3 id="备用交换器"><a href="#备用交换器" class="headerlink" title="备用交换器"></a>备用交换器</h3><p>在第一次声明交换器时被指定，用来提供一种预先存在的交换器，如果主交换器无法路由消息，那么消息将被路由到这个新的备用交换器。这时RabbitMQ也不会向发布者发送失败通知，因为消息已经发送至备用交换器，表示消息已经被路由了。注意，备用交换器就是普通的交换器，没有任何特殊的地方。</p><p>使用备用交换器，向往常一样，声明Queue和备用交换器，把Queue绑定到备用交换器上。然后在声明主交换器时，通过交换器的参数，alternate-exchange，将备用交换器设置给主交换器。建议备用交换器设置为faout类型，Queue绑定时的路由键设置为“#”。</p><img src="/2020/05/08/RabbitMQ%E4%B8%AD%E6%B6%88%E6%81%AF%E5%8F%91%E5%B8%83%E4%B8%8E%E6%9D%83%E8%A1%A1/pic6.png" srcset="/img/loading.gif" class=""><pre><code class="java">public class BackupExProducer {    public final static String EXCHANGE_NAME = &quot;main-exchange&quot;;    public final static String BAK_EXCHANGE_NAME = &quot;ae&quot;;    public static void main(String[] args)            throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        Channel channel = connection.createChannel();        Map&lt;String,Object&gt; argsMap = new HashMap&lt;String,Object&gt;();        argsMap.put(&quot;alternate-exchange&quot;,BAK_EXCHANGE_NAME);        //主交换器        channel.exchangeDeclare(EXCHANGE_NAME,&quot;direct&quot;,                false,false,argsMap);        //备用交换器        channel.exchangeDeclare(BAK_EXCHANGE_NAME,BuiltinExchangeType.FANOUT,                true,false,null);        String[] routekeys={&quot;test1&quot;,&quot;test2&quot;,&quot;test3&quot;};        for(int i=0;i&lt;3;i++){            String routekey = routekeys[i%3];            String message = &quot;Hello World_&quot;+(i+1);            channel.basicPublish(EXCHANGE_NAME, routekey,                    null, message.getBytes());            System.out.println(&quot; [x] Sent &#39;&quot; + routekey +&quot;&#39;:&#39;&quot;                    + message + &quot;&#39;&quot;);        }        channel.close();        connection.close();    }}</code></pre><p>主交换器绑定消费者</p><pre><code class="java">public class MainConsumer {    public static void main(String[] argv)            throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        final Channel channel = connection.createChannel();        String queueName = &quot;backupexchange&quot;;        channel.queueDeclare(queueName,                false,false,                false,null);        //只绑定test1路由键        String routekey=&quot;test1&quot;;        channel.queueBind(queueName,                BackupExProducer.EXCHANGE_NAME, routekey);        System.out.println(&quot; [*] Waiting for messages......&quot;);        final Consumer consumerB = new DefaultConsumer(channel) {            @Override            public void handleDelivery(String consumerTag,                                       Envelope envelope,                                       AMQP.BasicProperties properties,                                       byte[] body)                    throws IOException {                String message = new String(body, &quot;UTF-8&quot;);                System.out.println( &quot;Received [&quot;                        + envelope.getRoutingKey() + &quot;] &quot;+message);            }        };        channel.basicConsume(queueName, true, consumerB);    }}</code></pre><p>副交换器绑定消费者</p><pre><code class="java">public class BackupExConsumer {    public static void main(String[] argv)            throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        final Channel channel = connection.createChannel();        channel.exchangeDeclare(BackupExProducer.BAK_EXCHANGE_NAME,                BuiltinExchangeType.FANOUT,                true, false, null);        String queueName = &quot;fetchother&quot;;        channel.queueDeclare(queueName,                false,false,                false,null);        channel.queueBind(queueName,                BackupExProducer.BAK_EXCHANGE_NAME, &quot;#&quot;);        System.out.println(&quot; [*] Waiting for messages......&quot;);        final Consumer consumerB = new DefaultConsumer(channel) {            @Override            public void handleDelivery(String consumerTag,                                       Envelope envelope,                                       AMQP.BasicProperties properties,                                       byte[] body)                    throws IOException {                String message = new String(body, &quot;UTF-8&quot;);                System.out.println( &quot;Received [&quot;                        + envelope.getRoutingKey() + &quot;] &quot;+message);            }        };        channel.basicConsume(queueName, true, consumerB);    }}</code></pre><h2 id="消息消费时的权衡"><a href="#消息消费时的权衡" class="headerlink" title="消息消费时的权衡"></a>消息消费时的权衡</h2><h3 id="消费的获取方式"><a href="#消费的获取方式" class="headerlink" title="消费的获取方式"></a>消费的获取方式</h3><ul><li><p>拉取Get，消费者主动从队列中拉取消息。</p><img src="/2020/05/08/RabbitMQ%E4%B8%AD%E6%B6%88%E6%81%AF%E5%8F%91%E5%B8%83%E4%B8%8E%E6%9D%83%E8%A1%A1/pic7.png" srcset="/img/loading.gif" class=""><pre><code class="java">public class GetMessageConsumer {    public static void main(String[] argv)            throws IOException, TimeoutException, InterruptedException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        final Channel channel = connection.createChannel();        channel.exchangeDeclare(GetMessageProducer.EXCHANGE_NAME,                &quot;direct&quot;);        String queueName = &quot;focuserror&quot;;        channel.queueDeclare(queueName,                false,false,                false,null);        String routekey=&quot;test&quot;;        channel.queueBind(queueName,                GetMessageProducer.EXCHANGE_NAME, routekey);        System.out.println(&quot; [*] Waiting for messages......&quot;);        //无限循环拉取        while(true){            //从指定队列中拉取一条消息，第二个参数为是否自动确认            GetResponse getResponse = channel.basicGet(queueName, false);            if(null!=getResponse){                System.out.println(&quot;received[&quot;                        +getResponse.getEnvelope().getRoutingKey()+&quot;]&quot;                        +new String(getResponse.getBody()));            }            //消息手动确认，确认后消息会从队列中移除            channel.basicAck(0,true);            Thread.sleep(1000);        }    }}</code></pre></li><li><p>推送Consume，rabbitMQ将队列中的消息主动推送给消费者，之前的消费者示例都是使用这种方式。</p><img src="/2020/05/08/RabbitMQ%E4%B8%AD%E6%B6%88%E6%81%AF%E5%8F%91%E5%B8%83%E4%B8%8E%E6%9D%83%E8%A1%A1/pic7.png" srcset="/img/loading.gif" class=""></li></ul><h3 id="消息的确认"><a href="#消息的确认" class="headerlink" title="消息的确认"></a>消息的确认</h3><ul><li><p>自动确认：在使用<code>channel.basicConsume(queueName,false,consumer);</code>声明队列时，第二个参数为autoAck，当autoAck=true时，一旦消费者接收到了消息，就视为自动确认了消息。如果之后的处理过程中出现错误，也不会影响消息的确认。所以很多时候，需要在消息处理成功后再确认消息，这时就需要手动确认。</p></li><li><p>手动确认：当autoAck=false时，RabbitMQ会等待消费者显式发回ack信号后才从内存和磁盘中（如果是持久化消息的话，消息会被保存到磁盘中）中移去消息。采用消息确认机制后，只要令autoAck=false，消费者就有足够的时间处理消息，不用担心处理消息过程中消费者进程挂掉后消息丢失的问题，因为RabbitMQ会一直持有消息直到消费者显式调用basicAck为止。</p><p>当autoAck=false时，对于RabbitMQ服务器端而言，队列中的消息分成了两部分：一部分是等待投递给消费者的消息，一部分是已经投递给消费者但是还没有收到消费者ack信号的消息。如果服务器端一直没有收到消费者的ack信号，并且消费此消息的消费者已经断开连接，则服务器端会安排该消息重新进入队列，等待投递给下一个消费者（也可能还是原来的那个消费者）。</p></li></ul><h3 id="Qos预取模式"><a href="#Qos预取模式" class="headerlink" title="Qos预取模式"></a>Qos预取模式</h3><p>在确认消息被接收之前，消费者可以预先要求接收一定数量的消息，在处理完一定数量的消息后，可以进行批量确认。如果消费者应用程序在确认消息之前崩溃，则所有未确认的消息将被重新发送给其他消费者。这种机制一方面可以实现限速（将消息暂存到RabbitMQ内存中）的作用，一方面可以保证消息确认质量。</p><p>注意：消费确认模式必须是非自动确认机制，这个是使用baseQos的前提条件，否则会Qos不生效，然后设置basicQos的值。另外，还可以基于consume和channel的粒度进行设置（global）。</p><h4 id="批量确认"><a href="#批量确认" class="headerlink" title="批量确认"></a>批量确认</h4><pre><code class="java">public class BatchQosConsumer {    public static void main(String[] argv)            throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        final Channel channel = connection.createChannel();        channel.exchangeDeclare(DirectProducer.EXCHANGE_NAME,                &quot;direct&quot;);        String queueName = &quot;focuserror&quot;;        channel.queueDeclare(queueName, false, false,                false, null);        String routekey = &quot;error&quot;;        channel.queueBind(queueName, DirectProducer.EXCHANGE_NAME, routekey);        System.out.println(&quot;waiting for message........&quot;);        final Consumer consumer = new DefaultConsumer(channel) {            private int meesageCount = 0;            @Override            public void handleDelivery(String consumerTag,                                       Envelope envelope,                                       AMQP.BasicProperties properties,                                       byte[] body) throws IOException {                String message = new String(body, &quot;UTF-8&quot;);                System.out.println(&quot;批量消费者---Received[&quot; + envelope.getRoutingKey()                        + &quot;]&quot; + message);                meesageCount++;                //批量确认50一批                if (meesageCount % 50 == 0) {                    this.getChannel().basicAck(envelope.getDeliveryTag(), true);                    System.out.println(&quot;批量消息费进行消息的确认------------&quot;);                }                //如果是最后一条消息，则把剩余的消息都进行确认                if (message.equals(&quot;stop&quot;)) {                     this.getChannel().basicAck(envelope.getDeliveryTag(), true);                    System.out.println(&quot;批量消费者进行最后业务消息的确认---------&quot;);                }            }        };        //150条预取        channel.basicQos(500, true);        channel.basicConsume(queueName, false, consumer);    }}</code></pre><h4 id="单条确认"><a href="#单条确认" class="headerlink" title="单条确认"></a>单条确认</h4><pre><code class="java">public class QosConsumerMain {    public static void main(String[] argv)            throws IOException, TimeoutException {        ConnectionFactory factory = new ConnectionFactory();        factory.setHost(&quot;127.0.0.1&quot;);        Connection connection = factory.newConnection();        final Channel channel = connection.createChannel();        channel.exchangeDeclare(DirectProducer.EXCHANGE_NAME,                &quot;direct&quot;);        String queueName = &quot;focuserror&quot;;        channel.queueDeclare(queueName,false,false,                false,null);        String routekey = &quot;test&quot;;        channel.queueBind(queueName,DirectProducer.EXCHANGE_NAME,routekey);        System.out.println(&quot;waiting for message........&quot;);        final Consumer consumer = new DefaultConsumer(channel){            @Override            public void handleDelivery(String consumerTag,                                       Envelope envelope,                                       AMQP.BasicProperties properties,                                       byte[] body) throws IOException {                String message = new String(body, &quot;UTF-8&quot;);                System.out.println(&quot;Received[&quot;+envelope.getRoutingKey()                        +&quot;]&quot;+message);                //TODO 单条确认                channel.basicAck(envelope.getDeliveryTag(),false);            }        };        //150条预取        channel.basicQos(500,true);        channel.basicConsume(queueName,false,consumer);    }}</code></pre><h4 id="basicQos-方法参数详细解释"><a href="#basicQos-方法参数详细解释" class="headerlink" title="basicQos()方法参数详细解释"></a>basicQos()方法参数详细解释</h4><ul><li>prefetchSize：最多传输内容的大小限制，0为不限制，但据说prefetchSize参数，rabbitmq没有实现。</li><li>prefetchCount：表示不要同时给一个消费者推送多于N个消息，即一旦有N个消息还没有ack，则该consumer将阻塞掉，直到有消息ack。</li><li>global：boolean类型表示是否将上面设置应用于channel，即上面的限制是channel级别的还是consumer级别。</li></ul><p>如果同时对channel和消费者进行设置，如</p><pre><code class="java">channel.basicQos(10,false);channel.basicQos(15,true);</code></pre><p>AMQP规范中没有解释如果使用不同的全局值，多次调用basic.qos会发生什么。RabbitMQ认为两个预取限制应该彼此独立地强制执行。也就是说，整个通道加起来最多允许15条未确认的消息，每个消费者则最多有10条消息。消费者只有在未达到未确认消息限制时才会收到新消息。</p><h3 id="消费者中的事务"><a href="#消费者中的事务" class="headerlink" title="消费者中的事务"></a>消费者中的事务</h3><p>使用方法和生产者一致。假设消费者模式中使用了事务，并且在消息确认之后进行了事务回滚，结果会分为两种情况：</p><ol><li><p>autoAck=false手动应对的时候是支持事务的，也就是说即使你已经手动确认了消息已经收到了，但 RabbitMQ对消息的确认会等事务的返回结果，最终决定是移除消息还是重新放回队列。如果你手动确认之后又回滚了事务，那么此条消息会重新放回队列。</p></li><li><p>autoAck=true如果自动确认为true的情况是不支持事务的，也就是说你即使在收到消息之后在回滚事务也是于事无补的，队列已经把消息移除了。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>消息中间件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>消息中间件</tag>
      
      <tag>RabbitMQ</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RabbitMQ与AMQP</title>
    <link href="/2020/05/07/RabbitMQ%E4%B8%8EAMQP%E5%8D%8F%E8%AE%AE/"/>
    <url>/2020/05/07/RabbitMQ%E4%B8%8EAMQP%E5%8D%8F%E8%AE%AE/</url>
    
    <content type="html"><![CDATA[<h2 id="AMQP"><a href="#AMQP" class="headerlink" title="AMQP"></a>AMQP</h2><p>AMQP是应用层协议的一个开放标准,为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。目标是实现一种在全行业广泛使用的标准消息中间件技术，以便降低企业和系统集成的开销，并且向大众提供工业级的集成服务，主要实现有 RabbitMQ。</p><h3 id="客户端与RabbitMQ的通信"><a href="#客户端与RabbitMQ的通信" class="headerlink" title="客户端与RabbitMQ的通信"></a>客户端与RabbitMQ的通信</h3><p><strong>连接</strong></p><p>首先作为客户端(无论是生产者还是消费者)，如果要与RabbitMQ通讯的话，必须创建一条TCP连接，创建连接后还需要确认机制来验证双方都是AMQP规范的，确认之后就可以创建一条AMQP的信道。</p><p>连接在RabbitMQ原生客户端(5.0.0)版本中默认使用java的原生socket，但是也支持NIO，需要手动设置修改。</p><p><strong>信道</strong></p><p>道是生产者/消费者与RabbitMQ通信的渠道。信道是建立在TCP连接上的虚拟连接，RabbitMQ在一条TCP上可能会建立成百上千个信道来进行多个线程处理，这个TCP被多个线程共享，每个线程对应一个信道，信道在RabbitMQ都有唯一的ID，保证了信道私有性，及被唯一的线程使用。</p><p>系统为每个线程开辟一个TCP是非常消耗性能，每秒成百上千的建立销毁TCP会严重消耗系统。所以RabbitMQ选择建立多个信道（建立在tcp的虚拟连接）来连接。从技术上讲，这被称之为“多路复用”，对于执行多个任务的多线程或者异步应用程序来说，它非常有用。</p><h3 id="AMQP在RabbitMQ中的实现"><a href="#AMQP在RabbitMQ中的实现" class="headerlink" title="AMQP在RabbitMQ中的实现"></a>AMQP在RabbitMQ中的实现</h3><img src="/2020/05/07/RabbitMQ%E4%B8%8EAMQP%E5%8D%8F%E8%AE%AE/pic1.png" srcset="/img/loading.gif" class=""><p>包括的要素：</p><ul><li><p>生产者：消息的创建者，发送消息到RabbitMQ；</p></li><li><p>消费者：连接到RabbitMQ，订阅并消费队列上的消息，订阅分为持续订阅（basicConsumer）和单条订阅（basicGet）；</p></li><li><p>消息：包含有效载荷和标签，有效载荷指要传输的数据，标签描述了有效载荷，并且RabbitMQ用它来决定谁获得消息，消费者只能拿到有效载荷，并不知道生产者是谁；</p></li></ul><p>队列通过路由键（routing key，某种确定的规则）绑定到交换器，生产者将消息发布到交换器，交换器根据绑定的路由键将消息路由到特定队列， 然后由订阅这个队列的消费者进行接收。(路由键routing key和绑定键binding key的最大长度是 255 个字节)。</p><h3 id="消息的确认"><a href="#消息的确认" class="headerlink" title="消息的确认"></a>消息的确认</h3><p>消费者收到的每一条消息都必须进行确认(自动确认和自行确认)。</p><p>消费者在声明队列时，可以指定autoAck参数，当autoAck=false时，RabbitMQ会等待消费者显式发回ack信号后才从内存（磁盘，如果是持久化消息的话）中移去消息。否则，RabbitMQ会在队列中消息被消费后立即删除它。<br>采用消息确认机制后，只要令autoAck=false，消费者就有足够的时间处理消息（任务），不用担心处理消息过程中消费者进程挂掉后消息丢失的问题，因为RabbitMQ会一直持有消息直到消费者显式调用basicAck为止。</p><p>当autoAck=false时，对于RabbitMQ服务器端而言，队列中的消息分成了两部分：一部分是等待投递给消费者的消息，一部分是已经投递给消费者，但是还没有收到消费者ack信号的消息。如果服务器端一直没有收到消费者的ack信号，并且消费此消息的消费者已经断开连接，则服务器端会安排该消息重新进入队列，等待投递给下一个消费者（也可能还是原来的那个消费者）。RabbitMQ不会为未ack的消息设置超时时间，它判断此消息是否需要重新投递给消费者的唯一依据是消费该消息的消费者连接是否已经断开。这么设计的原因是RabbitMQ允许消费者消费一条消息的时间可以很久很久。</p><p><strong>常见问题</strong></p><ul><li><p>如果消息达到无人订阅的队列会怎么办?</p><p>消息会一直在队列中等待，RabbitMq 默认队列是无限长度的。 </p></li><li><p>多个消费者订阅到同一队列怎么办?</p><p>消息以轮询的方式发送给消费者，每个消息只会发送给一个消费者。 </p></li><li><p>消息路由到了不存在的队列怎么办?</p><p>一般情况下，RabbitMq会忽略，当这个消息不存在，也就是丢弃掉这条消息。</p></li></ul><h2 id="RabbitMQ中的概念"><a href="#RabbitMQ中的概念" class="headerlink" title="RabbitMQ中的概念"></a>RabbitMQ中的概念</h2><h3 id="虚拟主机"><a href="#虚拟主机" class="headerlink" title="虚拟主机"></a>虚拟主机</h3><p>虚拟消息服务器（vhost）本质上就是一个mini版的mq服务器，有自己的队列、交换器和绑定以及自己的权限机制。Vhost提供了逻辑上的分离，可以将众多客户端进行区分，避免队列和交换器的命名冲突。Vhost必须在连接时指定，rabbitmq包含缺省vhost：“/”，通过缺省用户和口令guest进行访问。</p><img src="/2020/05/07/RabbitMQ%E4%B8%8EAMQP%E5%8D%8F%E8%AE%AE/pic2.png" srcset="/img/loading.gif" class=""><p>如上图中的others交换器，连接时的地址为：<code>localhost:8888/other</code></p><p>rabbitmq里创建用户，必须要被指派给至少一个vhost，并且只能访问被指派内的队列、交换器和绑定。Vhost必须通过rabbitmq的管理控制工具创建。</p><h4 id="交换器类型"><a href="#交换器类型" class="headerlink" title="交换器类型"></a>交换器类型</h4><p>共有四种： <strong>direct</strong>、<strong>fanout</strong>、<strong>topic</strong>、<strong>headers</strong>，其中<strong>headers</strong>（几乎和 <strong>direct</strong> 一样）不实用，可以忽略。</p><h4 id="Direct"><a href="#Direct" class="headerlink" title="Direct"></a>Direct</h4><p>路由键完全匹配消息被投递到的队列，direct交换器是默认交换器。声明一个队列时，会自动绑定到默认交换器，并且以队列名称作为路由键。</p><img src="/2020/05/07/RabbitMQ%E4%B8%8EAMQP%E5%8D%8F%E8%AE%AE/pic3.png" srcset="/img/loading.gif" class=""><h4 id="Fanout"><a href="#Fanout" class="headerlink" title="Fanout"></a>Fanout</h4><p>消息广播到绑定的队列，不管队列绑定了什么路由键，消息经过交换器时会投递到每个队列。</p><img src="/2020/05/07/RabbitMQ%E4%B8%8EAMQP%E5%8D%8F%E8%AE%AE/pic4.png" srcset="/img/loading.gif" class=""><h4 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h4><p>通过使用“*”和“#”通配符进行处理，使来自不同源头的消息到达同一个队列，”.”将路由键分为了几个标识符，“*”匹配1个，“#”匹配一个或多个。</p><img src="/2020/05/07/RabbitMQ%E4%B8%8EAMQP%E5%8D%8F%E8%AE%AE/pic5.png" srcset="/img/loading.gif" class="">]]></content>
    
    
    <categories>
      
      <category>消息中间件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>消息中间件</tag>
      
      <tag>RabbitMQ</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>消息中间件</title>
    <link href="/2020/05/07/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    <url>/2020/05/07/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/</url>
    
    <content type="html"><![CDATA[<h2 id="消息中间件"><a href="#消息中间件" class="headerlink" title="消息中间件"></a>消息中间件</h2><h3 id="消息中间件（MQ）的定义"><a href="#消息中间件（MQ）的定义" class="headerlink" title="消息中间件（MQ）的定义"></a>消息中间件（MQ）的定义</h3><img src="/2020/05/07/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/pic1.png" srcset="/img/loading.gif" class=""><p>没有标准定义。一般认为，消息中间件属于分布式系统中一个子系统，关注于数据的发送和接收，利用高效可靠的异步消息传递机制对分布式系统中的其余各个子系统进行集成。</p><ul><li>高效：对于消息的处理处理速度快。 </li><li>可靠：一般消息中间件都会有消息持久化机制和其他的机制确保消息不丢失。 </li><li>异步：指发送完一个请求，不需要等待返回，随时可以再发送下一个请求，既不需要等待。 </li></ul><p>消息中间件和RPC都是分布式的通信机制，与RPC场景的差异很大程度上在于“依赖性”和“同步性”。</p><ul><li><p>依赖性：比如短信通知服务并不是事交易环节必须的，并不影响下单流程，不是强依赖，所以交易系统不应该依赖短信服务。如果是RPC调用，短信通知服务挂了，整个业务就挂了，这个就是依赖性导致的，而消息中间件则没有这个依赖性。</p><p>消息中间件出现以后对于交易场景可能是调用库存中心等强依赖系统执行业务，之后发布一条消息(这条消息存储于消息中间件中)。像是短信通 知服务、数据统计服务等等都是依赖于消息中间件去消费这条消息来完成自己的业务逻辑。</p></li><li><p>同步性：RPC 方式是典型的同步方式，让远程调用像本地调用。消息中间件方式属于异步方式。</p></li></ul><h3 id="为什么要用消息中间件"><a href="#为什么要用消息中间件" class="headerlink" title="为什么要用消息中间件"></a>为什么要用消息中间件</h3><p>假设一个电商交易的场景，用户下单之后调用库存系统减库存，然后需要调用物流系统进行发货，如果交易、库存、物流是属于一个系统的，就必须通过接口调用。但是随着系统的发展，各个模块越来越庞大、业务逻辑越来越复杂，必然是要做服务化和业务拆分的。这个时候就需要考虑这些系统之间如何交互，一般的处理方式就是RPC（Remote Procedure Call 具体实现 dubbo,SpringCloud）。系统继续发展，可能一笔交易后续需要调用 几十个接口来执行业务，比如还有风控系统、短信服务等等。这时候就需要消息中间件来解决问题了。</p><p>所以消息中间件主要解决分布式系统之间消息的传递，同时为分布式系统中其他子系统提供了松耦合的架构，同时还有以下好处:</p><ul><li><p><strong>低耦合</strong>：不管是程序还是模块之间，使用消息中间件进行间接通信。</p></li><li><p><strong>异步通信能力</strong>：使得子系统之间得以充分执行自己的逻辑而无需等待。</p></li><li><p><strong>缓冲能力</strong>：消息中间件像是一个巨大的蓄水池，将高峰期大量的请求存储下来慢慢交给后台进行处理，对于秒杀业务来说尤为重要。</p></li><li><p><strong>伸缩性</strong>：是指通过不断向集群中加入服务器的手段来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。衡量架构是否高伸缩性的主要标准就是是否可以使用多台服务器构建集群、是否容易向集群中添加新的服务器、加入新的服务器后是否可以提供和原来服务器无差别的服务、集群中可容纳的总的服务器数量是否有限制。</p></li><li><p><strong>扩展性</strong>：主要标准就是在网站增加新的业务产品时，是否可以实现对现有产品透明无影响，不需要任何改动或者很少改动既有业务功能就可以上线新产品。比如用户购买电影票的应用，现在我们要增加一个功能，用户买票后，随机抽取用户送限量周边。这时可以扩展消息的处理逻辑，这样也符合设计模式中的开闭原则（对扩展开放，对修改关闭）。</p></li></ul><h3 id="消息中间件使用的场景"><a href="#消息中间件使用的场景" class="headerlink" title="消息中间件使用的场景"></a>消息中间件使用的场景</h3><h4 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h4><p>场景说明:用户注册后，需要发注册邮件和注册短信。传统的做法有两种 1.串行的方式;2.并行方式。</p><ul><li><p>串行方式：将注册信息写入数据库成功后，发送注册邮件，再发送注册短信。以上三个任务全部完成后，返回给客户端。</p><img src="/2020/05/07/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/pic2.png" srcset="/img/loading.gif" class=""></li><li><p>并行方式：将注册信息写入数据库成功后，发送注册邮件的同时，发送注册短信。以上三个任务完成后，返回给客户端。与串行的差别是，并 行的方式可以提高处理的时间。</p><p>假设三个业务节点每个使用 50 毫秒钟，不考虑网络等其他开销，则串行方式的时间是 150 毫秒，并行的时间可能是 100 毫秒。</p><img src="/2020/05/07/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/pic3.png" srcset="/img/loading.gif" class=""></li><li><p>引入消息中间件：按照以上约定，用户的响应时间相当于是注册信息写入数据库的时间，也就是 50 毫秒。注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是 50 毫秒。因此架构改变后，系统的吞吐量提高到每秒 20 QPS。比串行提高了 3 倍， 比并行提高了两倍。</p><img src="/2020/05/07/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/pic4.png" srcset="/img/loading.gif" class=""></li></ul><h4 id="应用解耦"><a href="#应用解耦" class="headerlink" title="应用解耦"></a>应用解耦</h4><p>场景说明:用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。 传统模式的缺点：</p><ol><li>假如库存系统无法访问，则订单减库存将失败，从而导致订单失败。</li><li>订单系统与库存系统耦合。</li></ol><p>这时可以使用消息中间件用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。 库存系统:订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。这时在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦。</p><h4 id="流量削峰"><a href="#流量削峰" class="headerlink" title="流量削峰"></a>流量削峰</h4><p>流量削峰也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。</p><p>秒杀活动中一般会因为流量过大，导致流量暴增压垮应用。为解决这个问题，一般需要在应用前端加入消息队列控制活动的人数，缓解短时间内高流量防止应用被压垮。</p><img src="/2020/05/07/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/pic6.png" srcset="/img/loading.gif" class=""><h3 id="消息中间件编年史"><a href="#消息中间件编年史" class="headerlink" title="消息中间件编年史"></a>消息中间件编年史</h3><img src="/2020/05/07/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/pic7.png" srcset="/img/loading.gif" class=""><h3 id="消息中间件的选择"><a href="#消息中间件的选择" class="headerlink" title="消息中间件的选择"></a>消息中间件的选择</h3><table><thead><tr><th></th><th><strong>ActiveMQ</strong></th><th><strong>RabbitMQ</strong></th><th><strong>RocketMQ</strong></th><th><strong>Kafka</strong></th></tr></thead><tbody><tr><td>性能（单台）</td><td>6000+</td><td>万级(12000+)</td><td>十万级</td><td>百万级</td></tr><tr><td>消息持久化</td><td>支持</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td>多语言支持</td><td>支持</td><td>支持</td><td>很少</td><td>支持</td></tr><tr><td>社区活跃度</td><td>高</td><td>高</td><td>中</td><td>高</td></tr><tr><td>支持协议</td><td>多（JMS，AMQP….. ）</td><td>多（AMQP，STOMP，MQTT….. ）</td><td>自定义协议</td><td>自定义协议</td></tr><tr><td>综合评价</td><td>优点： 成熟，已经在很多公司得到应用。较多的文档。各种协议支持较好，有多个语言的成熟客户端。 缺点： 性能较弱。缺乏大规模吞吐的场景的应用，有江河日下之感。</td><td>优点：性能较好，管理界面较丰富，在互联网公司也有较大规模的应用，有多个语言的成熟客户端。 缺点： 内部机制很难了解，也意味很难定制和掌控。集群不支持动态扩展。</td><td>优点：模型简单，接口易用。在阿里有大规模应用。分布式系统，性能很好，版本更新很快。 缺点：文档少，支持的语言较少。</td><td>优点：天生分布式，性能最好，所以常见用于大数据领域。 缺点：运维难度大，偶尔有数据混乱的情况，对ZooKeeeper强依赖。多副本机制下对带宽有一定的要求。</td></tr></tbody></table><p>如果用户访问量在ActiveMQ的可承受范围内，而且确实主要是基于解耦和异步来用的，可以考虑ActiveMQ，也比较贴近Java工程师的使用习惯，但是 ActiveMQ 现在停止维护了，同时ActiveMQ并发不高，所以业务量一定的情况下可以考虑使用。RabbitMQ作为一个纯正血统的消息中间件，有着高级消息协议 AMQP 的完美结合，在消息中间件中地位无可取代，但是 erlang 语言阻止了我们去深入研究和掌控，对公司而言，底层技术无法控制，但是确实是开源的，有比较稳定的支持，活跃度也高。对自己公司技术实力有绝对自信的，可以用RocketMQ，但是RocketMQ诞生比较晚，并且更新迭代很快，这个意味着在使用过程中有可能会遇到 很多坑，所以如果你们公司Java技术不是很强，不推荐使用 。所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 ActiveMQ、RabbitMQ是不错的选择;大型公司，基础架构研发实力较强，用RocketMQ是很好的选择。如果是大数据领域的实时计算、日志采集等场景，用Kafka是业内标准的，绝对没问题，社区活跃度很高。从性能上来看，使用文件系统的消息中间件（kafka、rokcetMq）性能是最好的，所以基于文件系统存储的消息中间件是发展趋势。(从存储方式和效率来看 文件系统&gt;KV 存储&gt;关系型数据库)</p>]]></content>
    
    
    <categories>
      
      <category>消息中间件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>消息中间件</tag>
      
      <tag>mq</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>tomcat的简单实现</title>
    <link href="/2020/05/06/tomcat%E7%9A%84%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0/"/>
    <url>/2020/05/06/tomcat%E7%9A%84%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="tomcat本质"><a href="#tomcat本质" class="headerlink" title="tomcat本质"></a>tomcat本质</h2><p>Tomcat本质上是一款开源轻量级Web应用服务器,是一款优秀的Servlet容器实现。</p><img src="/2020/05/06/tomcat%E7%9A%84%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0/pic3.png" srcset="/img/loading.gif" class=""><p>阿里中间件团队：<a href="http://jm.taobao.org/about/" target="_blank" rel="noopener">http://jm.taobao.org/about/</a></p><p>很多公司都实现过自己的tomcat如aliTomcat :  <a href="https://help.aliyun.com/document_detail/90754.html" target="_blank" rel="noopener">https://help.aliyun.com/document_detail/90754.html</a></p><h3 id="网络基础知识"><a href="#网络基础知识" class="headerlink" title="网络基础知识"></a>网络基础知识</h3><img src="/2020/05/06/tomcat%E7%9A%84%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0/pic1.png" srcset="/img/loading.gif" class=""><p>客户端的上层应用会通过Socket发送请求。Socket是应用层与TCP/IP协议族通信的中间软件抽象层，是一组接口。Socket会根据TCP/IP协议将数据发送到服务器，服务器再通过协议将内容封装，传递给上层应用处理。</p><h3 id="tomcat的基础结构"><a href="#tomcat的基础结构" class="headerlink" title="tomcat的基础结构"></a>tomcat的基础结构</h3><img src="/2020/05/06/tomcat%E7%9A%84%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0/pic2.png" srcset="/img/loading.gif" class=""><p><strong>所需要的技术点</strong></p><ul><li>BIO模型</li><li>HTTP协议</li><li>Servlet</li><li>类加载</li></ul><h2 id="tomcat的简单实现"><a href="#tomcat的简单实现" class="headerlink" title="tomcat的简单实现"></a>tomcat的简单实现</h2><h3 id="建立连接池并获取请求内容"><a href="#建立连接池并获取请求内容" class="headerlink" title="建立连接池并获取请求内容"></a>建立连接池并获取请求内容</h3><pre><code class="java">public class MyServer {    private static ExecutorService executorService = Executors.newCachedThreadPool();    public static void main(String[] args) throws Exception{        ServerSocket serverSocket = new ServerSocket(8081);        System.out.println(&quot;socket服务器已启动&quot;);        while(!serverSocket.isClosed()){            Socket socket = serverSocket.accept();            executorService.execute(()-&gt;{                try {                    InputStream inputStream = socket.getInputStream();                    System.out.println(&quot;接收到请求&quot;);                    BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream, &quot;utf-8&quot;));                    String msg = null;                    StringBuffer requestInfo = new StringBuffer();                    while ((msg = reader.readLine()) != null&amp;&amp;msg.length()!=0) {                        requestInfo.append(msg).append(&quot;\r\n&quot;);                    }                    System.out.println(requestInfo);                } catch (IOException e) {                    e.printStackTrace();                }            });        }    }}</code></pre><p>使用浏览器请求接口，接收到的请求内容为</p><pre><code>GET /SerAreaSys HTTP/1.1Host: localhost:8081Connection: keep-aliveUpgrade-Insecure-Requests: 1User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9Sec-Fetch-Site: noneSec-Fetch-Mode: navigateSec-Fetch-User: ?1Sec-Fetch-Dest: documentAccept-Encoding: gzip, deflate, brAccept-Language: zh-CN,zh;q=0.9</code></pre><h3 id="解析请求内容"><a href="#解析请求内容" class="headerlink" title="解析请求内容"></a>解析请求内容</h3><img src="/2020/05/06/tomcat%E7%9A%84%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0/pic3.png" srcset="/img/loading.gif" class=""><p><strong>请求</strong>：第一行一般包含请求方式、请求路径、协议类型中间以空格分隔，第二行为cookie信息，这些都属于请求头，如果为post请求，请求头隔一行后为requestBody请求体的内容。</p><p><strong>响应</strong>：第一行为协议版本、响应码、状态中间也是以空格分隔，第二行为响应内容的类型及字符编码，第三行为响应内容的长度这些内容为响应头，第四行为responseBody响应体。</p><h3 id="构造响应内容"><a href="#构造响应内容" class="headerlink" title="构造响应内容"></a>构造响应内容</h3><pre><code class="java">public class MyServer {    private static ExecutorService executorService = Executors.newFixedThreadPool(10);    public static void main(String[] args) throws Exception {        ServerSocket serverSocket = new ServerSocket(8081);        System.out.println(&quot;socket服务器已启动&quot;);        while (!serverSocket.isClosed()) {            Socket socket = serverSocket.accept();            executorService.execute(() -&gt; {                try {                    InputStream inputStream = socket.getInputStream();                    System.out.println(&quot;接收到请求&quot;);                    BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream, StandardCharsets.UTF_8));                    String msg = null;                    StringBuffer requestInfo = new StringBuffer();                    while ((msg = reader.readLine()) != null&amp;&amp;msg.length()!=0) {                        requestInfo.append(msg).append(&quot;\r\n&quot;);                    }                    System.out.println(requestInfo);                    String responseMsg = &quot;处理成功&quot;;                    OutputStream outputStream = socket.getOutputStream();                    String responseInfo = &quot;HTTP/1.1 200 OK&quot; +                            &quot;\r\n&quot; +                            &quot;Content-Type:text/html;charset=utf-8&quot; +                            &quot;\r\n&quot; +                            &quot;Content-Length:&quot; + responseMsg.length() +                            &quot;\r\n&quot; +                            &quot;\r\n&quot; +                            responseMsg;                    outputStream.write(responseInfo.getBytes(StandardCharsets.UTF_8));                    outputStream.flush();                } catch (IOException e) {                    e.printStackTrace();                }            });        }    }}</code></pre><h3 id="部署项目"><a href="#部署项目" class="headerlink" title="部署项目"></a>部署项目</h3><p>servlet加载类</p><pre><code class="java">public class ProjectLoader {    public static Map load() throws Exception{        //定义一个Map,存储项目信息        Map&lt;String,Object&gt; webapp = new HashMap&lt;&gt;();        //servlet        Map&lt;String, Servlet&gt; servletInstances = new HashMap&lt;&gt;();        //servlet-mapping        Map&lt;String, String&gt; servletMapping = new HashMap&lt;&gt;();        //项目路径        String webappPath =&quot;D:\\work_public\\servletdemo\\out\\artifacts\\servletdemo_war_exploded\\WEB-INF&quot;;        //JDK提供类加载器 URL        URL classFile = new URL(&quot;file:&quot;+webappPath+&quot;\\classes\\&quot;);        URLClassLoader urlClassLoader = new URLClassLoader(new URL[]{classFile});        //解析xml文件        //1.获取解析器        SAXReader reader = new SAXReader();        //2.获取文档对象(xml)        Document document = reader.read(new File(webappPath+&quot;\\web.xml&quot;));        //3.获取根元素        Element root = document.getRootElement();        //4.获取根元素下的子元素        List&lt;Element&gt; childElements = root.elements();        //5.遍历子元素        for (Element element:childElements) {            //6.判断元素名称为servlet的元素            if (&quot;servlet&quot;.equals(element.getName())) {                //获取servlet-name元素                Element servletName = element.element(&quot;servlet-name&quot;);                //获取servlet-class元素                Element servletClass = element.element(&quot;servlet-class&quot;);                String strServletName = servletName.getText();                String strServletClass = servletClass.getText();                System.out.println(&quot;servlet:&quot;+strServletName+&quot;=&quot;+strServletClass);                //1.加载到JVM                Class&lt;?&gt; classzz= urlClassLoader.loadClass(strServletClass);                //2 创建对象实例(反射) -servlet;                Servlet servlet  = (Servlet)classzz.newInstance();                //web.xml的servlet实例化放入hashmap                servletInstances.put(strServletName, servlet);            }            //7.判断元素名称为servlet-mapping的元素            if (&quot;servlet-mapping&quot;.equals(element.getName())) {                //获取servlet-name元素                Element servletName = element.element(&quot;servlet-name&quot;);                //获取url-pattern元素                Element urlPattern = element.element(&quot;url-pattern&quot;);                String strServletName = servletName.getText();                String strUrlPattern = urlPattern.getText();                //web.xml的servlet的Mapping放入hashmap                System.out.println(&quot;servlet-mapping:&quot;+strUrlPattern+&quot;=&quot;+strServletName);                servletMapping.put(strUrlPattern,strServletName);            }        }        webapp.put(&quot;servlet&quot;,servletInstances);        webapp.put(&quot;servlet-mapping&quot;,servletMapping);        return  webapp;    }}</code></pre><p>创建request对象</p><pre><code class="java">private static HttpServletRequest createRequest() {    return new HttpServletRequest() {        @Override        public String getAuthType() {            return null;        }        @Override        public Cookie[] getCookies() {            return new Cookie[0];        }        @Override        public long getDateHeader(String s) {            return 0;        }        @Override        public String getHeader(String s) {            return null;        }        @Override        public Enumeration&lt;String&gt; getHeaders(String s) {            return null;        }        @Override        public Enumeration&lt;String&gt; getHeaderNames() {            return null;        }        @Override        public int getIntHeader(String s) {            return 0;        }        @Override        public String getMethod() {            return &quot;GET&quot;;        }        @Override        public String getPathInfo() {            return null;        }        @Override        public String getPathTranslated() {            return null;        }        @Override        public String getContextPath() {            return null;        }        @Override        public String getQueryString() {            return null;        }        @Override        public String getRemoteUser() {            return null;        }        @Override        public boolean isUserInRole(String s) {            return false;        }        @Override        public Principal getUserPrincipal() {            return null;        }        @Override        public String getRequestedSessionId() {            return null;        }        @Override        public String getRequestURI() {            return null;        }        @Override        public StringBuffer getRequestURL() {            return null;        }        @Override        public String getServletPath() {            return null;        }        @Override        public HttpSession getSession(boolean b) {            return null;        }        @Override        public HttpSession getSession() {            return null;        }        @Override        public String changeSessionId() {            return null;        }        @Override        public boolean isRequestedSessionIdValid() {            return false;        }        @Override        public boolean isRequestedSessionIdFromCookie() {            return false;        }        @Override        public boolean isRequestedSessionIdFromURL() {            return false;        }        @Override        public boolean isRequestedSessionIdFromUrl() {            return false;        }        @Override        public boolean authenticate(HttpServletResponse httpServletResponse) throws IOException, ServletException {            return false;        }        @Override        public void login(String s, String s1) throws ServletException {        }        @Override        public void logout() throws ServletException {        }        @Override        public Collection&lt;Part&gt; getParts() throws IOException, ServletException {            return null;        }        @Override        public Part getPart(String s) throws IOException, ServletException {            return null;        }        @Override        public &lt;T extends HttpUpgradeHandler&gt; T upgrade(Class&lt;T&gt; aClass) throws IOException, ServletException {            return null;        }        @Override        public Object getAttribute(String s) {            return null;        }        @Override        public Enumeration&lt;String&gt; getAttributeNames() {            return null;        }        @Override        public String getCharacterEncoding() {            return null;        }        @Override        public void setCharacterEncoding(String s) throws UnsupportedEncodingException {        }        @Override        public int getContentLength() {            return 0;        }        @Override        public long getContentLengthLong() {            return 0;        }        @Override        public String getContentType() {            return null;        }        @Override        public ServletInputStream getInputStream() throws IOException {            return null;        }        @Override        public String getParameter(String s) {            return null;        }        @Override        public Enumeration&lt;String&gt; getParameterNames() {            return null;        }        @Override        public String[] getParameterValues(String s) {            return new String[0];        }        @Override        public Map&lt;String, String[]&gt; getParameterMap() {            return null;        }        @Override        public String getProtocol() {            return null;        }        @Override        public String getScheme() {            return null;        }        @Override        public String getServerName() {            return null;        }        @Override        public int getServerPort() {            return 0;        }        @Override        public BufferedReader getReader() throws IOException {            return null;        }        @Override        public String getRemoteAddr() {            return null;        }        @Override        public String getRemoteHost() {            return null;        }        @Override        public void setAttribute(String s, Object o) {        }        @Override        public void removeAttribute(String s) {        }        @Override        public Locale getLocale() {            return null;        }        @Override        public Enumeration&lt;Locale&gt; getLocales() {            return null;        }        @Override        public boolean isSecure() {            return false;        }        @Override        public RequestDispatcher getRequestDispatcher(String s) {            return null;        }        @Override        public String getRealPath(String s) {            return null;        }        @Override        public int getRemotePort() {            return 0;        }        @Override        public String getLocalName() {            return null;        }        @Override        public String getLocalAddr() {            return null;        }        @Override        public int getLocalPort() {            return 0;        }        @Override        public ServletContext getServletContext() {            return null;        }        @Override        public AsyncContext startAsync() throws IllegalStateException {            return null;        }        @Override        public AsyncContext startAsync(ServletRequest servletRequest, ServletResponse servletResponse) throws IllegalStateException {            return null;        }        @Override        public boolean isAsyncStarted() {            return false;        }        @Override        public boolean isAsyncSupported() {            return false;        }        @Override        public AsyncContext getAsyncContext() {            return null;        }        @Override        public DispatcherType getDispatcherType() {            return null;        }    };}</code></pre><p>创建response对象</p><pre><code class="java">private static HttpServletResponse createResponse() {    return new HttpServletResponse() {        @Override        public void addCookie(Cookie cookie) {        }        @Override        public boolean containsHeader(String s) {            return false;        }        @Override        public String encodeURL(String s) {            return null;        }        @Override        public String encodeRedirectURL(String s) {            return null;        }        @Override        public String encodeUrl(String s) {            return null;        }        @Override        public String encodeRedirectUrl(String s) {            return null;        }        @Override        public void sendError(int i, String s) throws IOException {        }        @Override        public void sendError(int i) throws IOException {        }        @Override        public void sendRedirect(String s) throws IOException {        }        @Override        public void setDateHeader(String s, long l) {        }        @Override        public void addDateHeader(String s, long l) {        }        @Override        public void setHeader(String s, String s1) {        }        @Override        public void addHeader(String s, String s1) {        }        @Override        public void setIntHeader(String s, int i) {        }        @Override        public void addIntHeader(String s, int i) {        }        @Override        public void setStatus(int i) {        }        @Override        public void setStatus(int i, String s) {        }        @Override        public int getStatus() {            return 0;        }        @Override        public String getHeader(String s) {            return null;        }        @Override        public Collection&lt;String&gt; getHeaders(String s) {            return null;        }        @Override        public Collection&lt;String&gt; getHeaderNames() {            return null;        }        @Override        public String getCharacterEncoding() {            return null;        }        @Override        public String getContentType() {            return null;        }        @Override        public ServletOutputStream getOutputStream() throws IOException {            return null;        }        @Override        public PrintWriter getWriter() throws IOException {            return null;        }        @Override        public void setCharacterEncoding(String s) {        }        @Override        public void setContentLength(int i) {        }        @Override        public void setContentLengthLong(long l) {        }        @Override        public void setContentType(String s) {        }        @Override        public void setBufferSize(int i) {        }        @Override        public int getBufferSize() {            return 0;        }        @Override        public void flushBuffer() throws IOException {        }        @Override        public void resetBuffer() {        }        @Override        public boolean isCommitted() {            return false;        }        @Override        public void reset() {        }        @Override        public void setLocale(Locale locale) {        }        @Override        public Locale getLocale() {            return null;        }    };}</code></pre><p>最终的主方法</p><pre><code class="java">    public static void main(String[] args) throws Exception {        //0、加载项目（类加载）、容器、HashMap        Map&lt;String, Object&gt; webAppMap = ProjectLoader.load();//        Map&lt;String, Object&gt; webAppMap = Collections.emptyMap();        //1、绑定端口，JDK提供的网络操作的API        ServerSocket serverSocket = new ServerSocket(8080);        System.out.println(&quot;服务器启动成功!&quot;);        //在等待请求        while (!serverSocket.isClosed()) {            //2、等待请求，当有请求时将建立socket连接（建立客户端、服务端的连接（            Socket socket = serverSocket.accept();            //3、使用线程来处理请求            executorService.execute(() -&gt; {                        try {                            InputStream inputStream = socket.getInputStream();                            System.out.println(&quot;收到请求：&quot;);                            BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream, &quot;utf-8&quot;));                            //字符串                            String msg = null;                            StringBuilder requestInfo = new StringBuilder();                            while ((msg = reader.readLine()) != null) {                                if (msg.length() == 0) break;                                requestInfo.append(msg).append(&quot;\r\n&quot;);                            }                            System.out.println(requestInfo);                            //对请求的头进行解析                            //获取请求的第一行                            String firstLine = requestInfo.toString().split(&quot;\r\n&quot;)[0];                            System.out.println(firstLine);                            //防止浏览器发空过的请求过来                            if (firstLine.length() &lt; 1) {                                return;                            }                            String servletPath = firstLine.split(&quot; &quot;)[1];                            //servlet映射                            Map&lt;String, String&gt; servletMapping = (Map&lt;String, String&gt;) webAppMap.get(&quot;servlet-mapping&quot;);                            //Servlet实例                            Map&lt;String, Object&gt; servletInstances = (Map&lt;String, Object&gt;) webAppMap.get(&quot;servlet&quot;);                            //是否有正确的url对应的Servlet                            if (servletMapping.containsKey(servletPath)) {                                String servletName = servletMapping.get(servletPath);                                HttpServlet httpServlet = (HttpServlet) servletInstances.get(servletName);                                HttpServletRequest httpServletRequest = createRequest();                                HttpServletResponse httpServletResponse = createResponse();                                httpServlet.service(httpServletRequest, httpServletResponse);                                OutputStream outputStream = socket.getOutputStream();                                byte[] response = &quot;请求成功!&quot;.getBytes();                                outputStream.write(&quot;HTTP/1.1 200 OK \r\n&quot;.getBytes());                                outputStream.write(&quot;Content-Type:text/html;charset=utf-8 \r\n&quot;.getBytes());                                outputStream.write((&quot;Content-Length:&quot; + response.length + &quot;\r\n&quot;).getBytes());                                outputStream.write(&quot;\r\n&quot;.getBytes());                                outputStream.write(response);                                outputStream.flush();                                System.out.println(&quot;----END&quot;);                            } else {                                //要与浏览器进行“互动” ,HTTP 协议                                OutputStream outputStream = socket.getOutputStream();                                byte[] response = &quot;对不起，没有对应的Servlet请求信息!&quot;.getBytes();                                outputStream.write(&quot;HTTP/1.1 200 OK \r\n&quot;.getBytes());                                outputStream.write(&quot;Content-Type:text/html;charset=utf-8 \r\n&quot;.getBytes());                                outputStream.write((&quot;Content-Length:&quot; + response.length + &quot;\r\n&quot;).getBytes());                                outputStream.write(&quot;\r\n&quot;.getBytes());                                outputStream.write(response);                                outputStream.flush();                                System.out.println(&quot;----END&quot;);                            }                        } catch (IOException e) {                            e.printStackTrace();                        } catch (ServletException e1) {                            e1.printStackTrace();                        }                    }            );        }    }</code></pre>]]></content>
    
    
    <categories>
      
      <category>tomcat</category>
      
    </categories>
    
    
    <tags>
      
      <tag>tomcat</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>tomcat嵌入式与性能优化</title>
    <link href="/2020/05/06/tomcat%E5%B5%8C%E5%85%A5%E5%BC%8F%E4%B8%8E%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    <url>/2020/05/06/tomcat%E5%B5%8C%E5%85%A5%E5%BC%8F%E4%B8%8E%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="嵌入式tomcat"><a href="#嵌入式tomcat" class="headerlink" title="嵌入式tomcat"></a>嵌入式tomcat</h2><p>一般的tomcat启动中的组件非常多，启动流程步骤比较复杂，但是往往我们一般就只需要简单快速的部署一个Web项目，所以简单实用的嵌入式Tomcat就诞生而来。</p><p><strong>部署复杂度</strong></p><p>如果按照传统部署，我们需要下载Tomcat,同时需要配置服务器，同时还需要修改端口，同时也要避免应用系统的jar包与服务器中存在的lib包的冲突，所有的这些都会增加部署的复杂度，并且这种配置大部分还是一次性的，不可重用。如果你遇到大规模的服务器集群环境（部署N多个应用）时，会增加我们的运维成本，如果按照嵌入式启动，这种方式几乎是一键式的，可以把以上问题轻松的解决。</p><p><strong>架构约束</strong></p><p>Tomcat启动的时候默认不单单只启动了HTTP协议，还有AJP协议等等，如果我们就只想简简单单的启动一个HTTP服务，同时不想启动那些多组件，可以使用嵌入式Tomcat，避免在部署启动时的架构约束。</p><p><strong>微服务架构</strong></p><p>现在微服务已经是主流的架构，其中微服务中每项服务都拥有自己的进程并利用轻量化机制实现通讯。这些服务都是围绕业务功能建立，可以自动化部署或独立部署。将微服务架构与Tomcat技术相结合，可以轻松将系统部署到云服务器上。当前SpringBoot支持的嵌入式服务器组件就是Tomcat。</p><h2 id="嵌入式启动实战"><a href="#嵌入式启动实战" class="headerlink" title="嵌入式启动实战"></a>嵌入式启动实战</h2><p>pom文件中</p><pre><code class="xml">&lt;!--嵌入式Tomcat --&gt;&lt;dependency&gt;  &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt;  &lt;artifactId&gt;tomcat-embed-core&lt;/artifactId&gt;  &lt;version&gt;8.5.34&lt;/version&gt;&lt;/dependency&gt;&lt;!--嵌入式Tomcat的JSP 支持--&gt;&lt;dependency&gt;  &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt;  &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt;  &lt;version&gt;8.5.34&lt;/version&gt;&lt;/dependency&gt;</code></pre><p> 启动类</p><pre><code class="java">/** * 手动的创建一个servlet，然后加入到tomcat中 */public class ServletDemo {    public static void main(String[] args) throws Exception {        //自定义的一个Servlet(专门处理http请求)        HttpServlet httpServlet = new HttpServlet() {            @Override            public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException {                res.getWriter().write(&quot;hello world!&quot;);            }        };        //引入嵌入式Tomcat        Tomcat tomcat = new Tomcat();        //部署应用的context        Context context = tomcat.addContext(&quot;/demo&quot;,null);        //相当于往应用中添加Servlet        tomcat.addServlet(context,&quot;hello&quot;,httpServlet);        //相当于添加了servletMapping 映射信息        context.addServletMappingDecoded(&quot;/hello&quot;,&quot;hello&quot;);        //启动Tomcat  ---生命周期        tomcat.init();        tomcat.start();        //用于阻塞Tomcat,等待请求过来        tomcat.getServer().await();        //http://localhost:8080/demo/hello    }}</code></pre><pre><code class="java">/** * 要用嵌入式启动的方式启动一个SpringMVc的项目 */public class WebAppDemo {    public static void main(String[] args) throws  Exception{        Tomcat tomcat = new Tomcat();        tomcat.addWebapp(&quot;/ref&quot;,&quot;D:\\work_tomcat\\ref-comet&quot;);        tomcat.getConnector().setPort(80);        tomcat.init();        tomcat.start();        tomcat.getServer().await();    }}</code></pre><h2 id="tomcat性能优化"><a href="#tomcat性能优化" class="headerlink" title="tomcat性能优化"></a>tomcat性能优化</h2><h3 id="server-xml优化"><a href="#server-xml优化" class="headerlink" title="server.xml优化"></a>server.xml优化</h3><p>tomcat其实自带了参数说明文档</p><img src="/2020/05/06/tomcat%E5%B5%8C%E5%85%A5%E5%BC%8F%E4%B8%8E%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic1.png" srcset="/img/loading.gif" class=""><p>这时会出现一个英文的tomcat配置参数文档界面，这个界面中包含了所有tomcat配置信息。</p><img src="/2020/05/06/tomcat%E5%B5%8C%E5%85%A5%E5%BC%8F%E4%B8%8E%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic2.png" srcset="/img/loading.gif" class=""><h4 id="Connector连接器优化"><a href="#Connector连接器优化" class="headerlink" title="Connector连接器优化"></a>Connector连接器优化</h4><ul><li><p>IO模型优化策略：连接器模式改为NIO模式,NIO模式最大化压榨了CPU，把时间片更好利用起来，NIO适合大量长连接。</p></li><li><p>最大线程优化策略：maxThreads属性默认设置为200，可以根据生产计算机上的处理器数量线性增加。在具有四个处理器的计算机上，将此值设置为800到1000之间的任何值都不会导致问题。如果配置的数量最终远远超过所需的线程数，则当服务器负载较低时，线程池将自然缩减线程数。</p></li><li><p>压缩gzip连接器传输：客户端和服务器之间的任何主要是文本的通信，无论是HTML，XML还是简单的Unicode，都可以使用简单的标准GZIP算法定期压缩高达90％。这可以对减少网络流量产生巨大影响，允许响应更快地发送回客户端，同时允许更多网络带宽可用于其他网络繁重的应用程序。设置方式为：</p><pre><code class="xml">&lt;Connector port=&quot;80&quot; protocol=&quot;HTTP/1.1&quot;      connectionTimeout=&quot;20000&quot;      redirectPort=&quot;8443&quot; executor=&quot;tomcatThreadPool&quot; URIEncoding=&quot;utf-8&quot;            compression=&quot;on&quot;            compressionMinSize=&quot;50&quot; noCompressionUserAgents=&quot;gozilla, traviata&quot;            compressableMimeType=&quot;text/html,text/xml,text/javascript,text/css,text/plain&quot; /&gt;</code></pre></li></ul><h4 id="配置Executor线程池"><a href="#配置Executor线程池" class="headerlink" title="配置Executor线程池"></a>配置Executor线程池</h4><p>Executor必须出现在Connector之前。配置方式如下：</p><pre><code class="xml">&lt;Executor     name=&quot;tomcatThreadPool&quot;&lt;!--线程名称--&gt;    namePrefix=&quot;catalina-exec-&quot;    maxThreads=&quot;150&quot;&lt;!--最大处理连接数线程--&gt;    minSpareThreads=&quot;4&quot; /&gt;&lt;!--保留最少线程数--&gt;&lt;!-- 将原有的Connector 替换为带有线程池的Connector如下,其实servlet.xml已经有了,只要打开就可以了,将原来的去掉   --&gt;&lt;Connector     executor=&quot;tomcatThreadPool&quot;    port=&quot;8080&quot;    protocol=&quot;HTTP/1.1&quot;    connectionTimeout=&quot;20000&quot;    redirectPort=&quot;8443&quot;    minProcessors=&quot;5&quot;&lt;!-- 同时处理请求的最小数 --&gt;    maxProcessors=&quot;75&quot;&lt;!-- 同时处理请求的最大数 --&gt;    acceptCount=&quot;1000&quot; /&gt;&lt;!-- 接受最大并发数量 ,超过这个数量就会返回连接被拒绝 --&gt;</code></pre><p>详细的配置可以在tomcat配置信息的Executor页面中查看。</p><h4 id="去掉value访问tomcat记录"><a href="#去掉value访问tomcat记录" class="headerlink" title="去掉value访问tomcat记录"></a>去掉value访问tomcat记录</h4><pre><code class="xml">&lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot;               prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot;               pattern=&quot;%h %l %u %t &quot;%r&quot; %s %b&quot; /&gt;</code></pre><p>可以删除servler.xml中的value节点，来删除日志访问记录以提高性能。</p><h4 id="关闭自动重载，热部署方式"><a href="#关闭自动重载，热部署方式" class="headerlink" title="关闭自动重载，热部署方式"></a>关闭自动重载，热部署方式</h4><p>关闭自动重载，默认为true（不同版本中有差异），自动加载会增加运行是 开销并且很容易内存溢出。</p><h3 id="web-xml优化"><a href="#web-xml优化" class="headerlink" title="web.xml优化"></a>web.xml优化</h3><h4 id="去掉不必要的servlet"><a href="#去掉不必要的servlet" class="headerlink" title="去掉不必要的servlet"></a>去掉不必要的servlet</h4><p>如果当前应用是REST应用（微服务），可以去掉不必要的资源如JspServlet和seesion。</p><h4 id="JspServlet优化"><a href="#JspServlet优化" class="headerlink" title="JspServlet优化"></a>JspServlet优化</h4><ol><li>checkInterval - 如果“development”属性为false且“checkInterval”大于0，则使用后台编译。“checkInterval”是查看JSP页面(包括其附属文件)是否需要重新编译的两次检查时间间隔（单位：秒）。缺省值为0秒。</li><li>classdebuginfo - 类文件在编译时是否显示调试(debugging)信息？ true 或false，缺省为true。</li><li>classpath - 编译servlet时要使用的类路径，当ServletContext 属性org.apache.jasper.Constants.SERVLET_CLASSPATH未设置的情况下，该参数才有效。在Tomcat中使用到Jasper时，该属性总被设置。缺省情况下，该路径基于你当前的web应用动态生成。</li><li>compiler – Ant将要使用的JSP页面编译器，请查阅Ant文档获取更多信息。如果该参数未设置，那么默认的Eclipse JDT Java编译器将被用来代替Ant。没有缺省值。</li><li>compilerSourceVM - 编译源文件时采用哪一个JDK版本？(缺省为 JDK 1.4)</li><li>compilerTargetVM - 运行类文件时采用哪一个JDK版本？(缺省为 JDK 1.4)</li><li>development - 是否让Jasper用于开发模式？如果是，检查JSPs修改的频率，将通过设置modificationTestInterval 参数来完成。true 或false，缺省为true。</li><li>displaySourceFragment - 异常信息中是否包含出错的源代码片段？true 或false，缺省为true。</li><li>dumpSmap - JSR45调试的SMAP信息是否转存到文件？true 或false，缺省为false。当suppressSmap 为true时，该参数为false。</li><li>enablePooling - 确定是否共享标签处理器，true或false，缺省为true。</li><li>engineOptionsClass - 允许指定的类来配置Jasper。如果没有指定，则使用默认的Servlet内置参数(EmbeddedServletOptions)。</li><li>errorOnUseBeanInvalidClassAttribute - 在一个useBean action中，当类属性的值不是一个合法的bean class时，Jasper是否抛出异常？true或false，缺省为true。</li><li>fork - 是否让Ant派生出JSP页面多个编译，它们将运行在一个独立于Tomcat的JVM上。true 或者false, 缺省为true。</li><li>enStringAsCharArray - 是否把字符串转换为字符数组？在某些情况下会改善性能。缺省为false.</li><li>eClassId - 当使用标签时，发送给Internet Explorer的class-id的值。缺省为：8AD9C840-044E-11D1-B3E9-00805F499D93。</li><li>javaEncoding - 生成java源文件时采用的Java文件编码。缺省为UTF-8。</li><li>keepgenerated - 是否保存每个页面生成的java源代码，而不删除。true 或 false，缺省为true。</li><li>mappedfile - 是否对每个输入行都用一条print语句来生成静态内容，以方便调试。true 或 false，缺省为true。</li><li>modificationTestInterval - 检查JSP页面修改的间隔时间（单位：秒），在间隔时间内，JSP及其包含的页面将不会检查。当间隔时间为0时，JSP每一次访问都会被检查。仅仅适用于开发模式（参数development为true）。缺省为4秒。从JSP每次开始访问开始计时，N秒以后检查，变化就编译，每次访问都刷新开始时间，默认4秒</li><li>scratchdir - 当编译JSP页面时使用的scratch 目录。缺省为当前WEB应用的工作目录。</li><li>suppressSmap - 是否禁止JSR45调试时生成SMAP信息？true 或 false，缺省为false。</li><li>trimSpaces - 是否去掉模板文本中行为和指令之间的空格。缺省为false。 · xpoweredBy - 确定生成的Servlet是否加上X-Powered-By 响应头？true 或 false，缺省为false。</li></ol><h2 id="tomcat常见问题解决"><a href="#tomcat常见问题解决" class="headerlink" title="tomcat常见问题解决"></a>tomcat常见问题解决</h2><h3 id="迁移指南"><a href="#迁移指南" class="headerlink" title="迁移指南"></a>迁移指南</h3><img src="/2020/05/06/tomcat%E5%B5%8C%E5%85%A5%E5%BC%8F%E4%B8%8E%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic3.png" srcset="/img/loading.gif" class=""><h3 id="安全通告"><a href="#安全通告" class="headerlink" title="安全通告"></a>安全通告</h3><img src="/2020/05/06/tomcat%E5%B5%8C%E5%85%A5%E5%BC%8F%E4%B8%8E%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic4.png" srcset="/img/loading.gif" class=""><h2 id="tomcat常见的面试题"><a href="#tomcat常见的面试题" class="headerlink" title="tomcat常见的面试题"></a>tomcat常见的面试题</h2><h3 id="tomcat有哪几种部署方式？"><a href="#tomcat有哪几种部署方式？" class="headerlink" title="tomcat有哪几种部署方式？"></a>tomcat有哪几种部署方式？</h3><p><strong>隐式部署</strong></p><p>直接丢文件夹、war、jar到webapps目录，tomcat会根据文件夹名称自动生成虚拟路径，简单，但是需要重启Tomcat服务器，包括要修改端口和访问路径的也需要重启。</p><p><strong>显式部署</strong></p><p>添加context元素</p><p>server.xml中的Host加入一个Context（指定路径和文件地址），例如：</p><pre><code class="xml">&lt;Host name=&quot;localhost&quot;&gt;&lt;Context path=&quot;/comet&quot; docBase=&quot;D:\work_tomcat\ref-comet.war&quot; /&gt;</code></pre><p>即/comet 这个虚拟路径映射到了D:\work_tomcat\ref-comet目录下(war会解压成文件)，修改完servler.xml需要重启tomcat 服务器。</p><p>创建xml文件</p><p>在conf/Catalina/localhost中创建xml文件，访问路径为文件名，例如：</p><p>在localhost目录下新建demo.xml，内容为：</p><pre><code class="xml">&lt;Context docBase=&quot;D:\work_tomcat\ref-comet&quot; /&gt;</code></pre><p>不需要写path，虚拟目录就是文件名demo，path默认为/demo，添加demo.xml不需要重启 tomcat服务器。</p><p><strong>三种方式比较：</strong></p><ul><li><p>隐式部署：可以很快部署,需要人手动移动Web应用到webapps下，在实际操作中不是很人性化</p></li><li><p>添加context元素 : 配置速度快,需要配置两个路径，如果path为空字符串，则为缺省配置,每次修改server.xml文件后都要重新启动Tomcat服务器，重新部署.</p></li><li><p>创建xml文件:服务器后台会自动部署，修改一次后台部署一次，不用重复启动Tomcat服务器,该方式显得更为智能化。</p></li></ul><h3 id="tomcat核心组件是哪些？"><a href="#tomcat核心组件是哪些？" class="headerlink" title="tomcat核心组件是哪些？"></a>tomcat核心组件是哪些？</h3><p>Tomcat的核心组件是链接器(connector)和容器(Container)，链接器(connector)封装了底层的网络请求(Socket请求及相应处理)，提供了统一的接口。容器(Container)则专注处理Servlet，Tomcat本质上就是Servlet容器。</p><h3 id="tomcat的Valve"><a href="#tomcat的Valve" class="headerlink" title="tomcat的Valve"></a>tomcat的Valve</h3><p>在一个大的组件中直接处理这些繁杂的逻辑处理,使用管道（pipeline）可以把把多个对象连接起来，而Valve(阀门)整体看起来就像若干个阀门嵌套在管道中，而处理逻辑放在阀门上。 </p><p>管道(Pipeline)就像一个工厂中的生产线，负责调配工人（valve）的位置，valve则是生产线上负责不同操作的工人。</p><h3 id="tomcat-有哪几种Connector-运行模式-优化-？"><a href="#tomcat-有哪几种Connector-运行模式-优化-？" class="headerlink" title="tomcat 有哪几种Connector 运行模式(优化)？"></a>tomcat 有哪几种Connector 运行模式(优化)？</h3><ol><li>bio(blocking I/O) 同步阻塞I/O （tomcat8.5版本已经移除）</li><li>nio(non-blocking I/O) 同步非阻塞I/O</li><li>Nio2/AIO  异步非阻塞I/0</li><li>apr(Apache Portable Runtime/Apache可移植运行库)</li></ol><p>对于I/0选择，要根据业务场景来定，一般高并发场景下，APR和NIO2的性能要优于NIO和BIO，（linux操作系统支持的NIO2由于是一个假的，并没有真正实现AIO，所以一般linux上推荐使用NIO，如果是APR的话，需要安装APR库，而Windows上默认安装了），所以在8.5的版本中默认是NIO。</p><h3 id="tomcat容器是如何创建servlet类实例？用到了什么原理？"><a href="#tomcat容器是如何创建servlet类实例？用到了什么原理？" class="headerlink" title="tomcat容器是如何创建servlet类实例？用到了什么原理？"></a>tomcat容器是如何创建servlet类实例？用到了什么原理？</h3><p>当容器启动时，会读取在webapps目录下所有的web应用中的web.xml文件，然后对xml文件进行解析，并读取servlet注册信息。然后，将每个应用中注册的servlet类都进行加载，并通过反射的方式实例化（也有可能是在第一次请求时实例化）。</p><h3 id="tomcat中JVM如何调优"><a href="#tomcat中JVM如何调优" class="headerlink" title="tomcat中JVM如何调优"></a>tomcat中JVM如何调优</h3><p>一般我们优化启动时的堆内存设置,Windows下,在文件{tomcat_home}/bin/catalina.bat，Unix下，在文件$CATALINA_HOME/bin/catalina.sh的前面，增加如下设置：</p><pre><code>JAVA_OPTS=”‘$JAVA_OPTS” -Xms[初始化内存大小] -Xmx[可以使用的最大内存]</code></pre><p>一般说来，你应该使用物理内存的 80% 作为堆大小。建议设置为70％；建议设置[[初始化内存大小]等于[可以使用的最大内存]，这样可以减少平凡分配堆而降低性能。</p><h3 id="tomcat中类加载的顺序"><a href="#tomcat中类加载的顺序" class="headerlink" title="tomcat中类加载的顺序"></a>tomcat中类加载的顺序</h3><p>当应用需要到某个类时，则会按照下面的顺序进行类加载：</p><ol><li><p>使用bootstrap引导类加载器加载</p></li><li><p>使用system系统类加载器加载</p></li><li><p>使用应用类加载器在WEB-INF/classes中加载</p></li><li><p>使用应用类加载器在WEB-INF/lib中加载</p></li><li><p>使用common类加载器在CATALINA_HOME/lib中加载</p></li></ol><h3 id="什么是双亲委派模型？"><a href="#什么是双亲委派模型？" class="headerlink" title="什么是双亲委派模型？"></a>什么是双亲委派模型？</h3><p><strong>定义：</strong>双亲委派模型的工作过程为：如果一个类加载器收到了类请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父加载器去完成，每一层都是如此，因此所有类加载的请求都会传到启动类加载器，只有当父加载器无法完成该请求时，子加载器才去自己加载。</p><p><strong>实现方式：</strong>该模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。子类加载器不是以继承的关系来实现，而是通过组合关系来复用父加载器的代码。</p><p><strong>意义：</strong>好处双亲委派模型的好处就是java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如：Object,无论那个类加载器去加载该类，最终都是由启动类加载器进行加载的，因此Object类在程序的各种类加载环境中都是一个类。如果不用改模型，那么java.lang.Object类存放在classpath中，那么系统中就会出现多个Object类，程序变得很混乱。</p><h3 id="既然tomcat不遵循双亲委派机制，那么如果我自己定义一个恶意的HashMap，会不会有风险呢？"><a href="#既然tomcat不遵循双亲委派机制，那么如果我自己定义一个恶意的HashMap，会不会有风险呢？" class="headerlink" title="既然tomcat不遵循双亲委派机制，那么如果我自己定义一个恶意的HashMap，会不会有风险呢？"></a>既然tomcat不遵循双亲委派机制，那么如果我自己定义一个恶意的HashMap，会不会有风险呢？</h3><p>不会有风险，如果有，Tomcat都运行这么多年了，tomcat不遵循双亲委派机制，只是自定义的webAppclassLoader不遵循，但上层的类加载器还是遵守双亲委派的，</p>]]></content>
    
    
    <categories>
      
      <category>tomcat</category>
      
    </categories>
    
    
    <tags>
      
      <tag>tomcat</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>tomcat源码解析</title>
    <link href="/2020/04/30/tomcat%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    <url>/2020/04/30/tomcat%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h2 id="tomcat源码目录"><a href="#tomcat源码目录" class="headerlink" title="tomcat源码目录"></a>tomcat源码目录</h2><ul><li><p>catalina目录：catalina包含所有的Servlet容器实现，以及涉及到安全、会话、集群、部署管理Servlet容器的各个方面，同时，它还包含了启动入口。</p></li><li><p>coyote目录：coyote是Tomcat链接器框架的名称，是Tomcat服务器提供的客户端访问的外部接口，客户端通过Coyote与服务器建立链接、发送请求并接收响应。</p></li><li><p>El目录，提供java表达式语言</p></li><li><p>Jasper模块提供JSP引擎</p></li><li><p>Naming模块提供JNDI的服务</p></li><li><p>Juli提供服务器日志的服务</p></li><li><p>tomcat提供外部调用的接口api</p></li></ul><h2 id="tomcat组件的生命周期管理"><a href="#tomcat组件的生命周期管理" class="headerlink" title="tomcat组件的生命周期管理"></a>tomcat组件的生命周期管理</h2><p>tomcat的架构设计是清晰的、模块化、它拥有很多组件，加入在启动Tomcat时一个一个组件启动，很容易遗漏组件，同时还会对后面的动态组件拓展带来麻烦。如果采用我们传统的方式的话，组件在启动过程中如果发生异常，会很难管理，比如你的下一个组件调用了start()方法，但是如果它的上级组件还没有start()甚至还没有init()的话，Tomcat的启动会非常难管理，因此，Tomcat的设计者提出一个解决方案：使用生命周期统一接口Lifecycle定义一些状态常量，然后将启动、停止、关闭及所有与生命周期相关的方法都组织到一起，这样就可以很方便管理tomcat各个容器组件的生命周期。</p><p>LifecycleBase实现了Lifecycle接口，在init()方法中初始化之前会进行状态检查：</p><pre><code class="java">@Overridepublic final synchronized void init() throws LifecycleException {    //防止组件启动时状态不对    if (!state.equals(LifecycleState.NEW)) {        invalidTransition(Lifecycle.BEFORE_INIT_EVENT);    }    try {        //设置初始化状态        setStateInternal(LifecycleState.INITIALIZING, null, false);        initInternal();        //设置初始化完成        setStateInternal(LifecycleState.INITIALIZED, null, false);    } catch (Throwable t) {        handleSubClassException(t, &quot;lifecycleBase.initFail&quot;, toString());    }}</code></pre><p>init()方法中会调用子类的initInternal()方法，这里使用了模版方法设计模式，LifecycleBase为骨架类，initInternal()的具体实现在子类中，spring中也使用了这种设计模式。</p><p>start()方法中同样会进行相应的判断。</p><pre><code class="java">@Overridepublic final synchronized void start() throws LifecycleException {    // 统一进行生命周期的管理    if (LifecycleState.STARTING_PREP.equals(state) || LifecycleState.STARTING.equals(state) ||            LifecycleState.STARTED.equals(state)) {        if (log.isDebugEnabled()) {            Exception e = new LifecycleException();            log.debug(sm.getString(&quot;lifecycleBase.alreadyStarted&quot;, toString()), e);        } else if (log.isInfoEnabled()) {            log.info(sm.getString(&quot;lifecycleBase.alreadyStarted&quot;, toString()));        }        return;    }    // 检查组件生命周期状态    if (state.equals(LifecycleState.NEW)) {        init();    } else if (state.equals(LifecycleState.FAILED)) {        stop();    } else if (!state.equals(LifecycleState.INITIALIZED) &amp;&amp;            !state.equals(LifecycleState.STOPPED)) {        invalidTransition(Lifecycle.BEFORE_START_EVENT);    }    try {        // 设置组件状态        setStateInternal(LifecycleState.STARTING_PREP, null, false);        // 调用具体实现类的方法        startInternal();        // 统一进行生命周期的管理        if (state.equals(LifecycleState.FAILED)) {            // 失败，调用stop()方法完成清理            stop();        } else if (!state.equals(LifecycleState.STARTING)) {            // 不是已经在启动的状态            invalidTransition(Lifecycle.AFTER_START_EVENT);        } else {            // 设置组件状态            setStateInternal(LifecycleState.STARTED, null, false);        }    } catch (Throwable t) {        // This is an &#39;uncontrolled&#39; failure so put the component into the        // FAILED state and throw an exception.        handleSubClassException(t, &quot;lifecycleBase.startFail&quot;, toString());    }}</code></pre><p>tomcat内部架构中各个核心组件有包含与被包含关系，例如：Server包含了Service，Service又包含了Container和Connector，这个结构有一点像数据结构中的树，树的根结点没有父节点，其他节点有且仅有一个父节点，每一个父节点有0至多个子节点。所以，我们可以通过父容器启动它的子容器，这样只要启动根容器，就可以把其他所有的容器都启动，从而达到了统一的启动，停止、关闭的效果。</p><h2 id="tomcat组件分析"><a href="#tomcat组件分析" class="headerlink" title="tomcat组件分析"></a>tomcat组件分析</h2><h3 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h3><p>继承结构：</p><img src="/2020/04/30/tomcat%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/pic6.png" srcset="/img/loading.gif" class=""><p>Server是tomcat最顶层的容器，代表整个服务器，Tomcat中的标准实现为StandardServer类。</p><h3 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h3><p>继承结构：</p><img src="/2020/04/30/tomcat%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/pic7.png" srcset="/img/loading.gif" class=""><p>其中LifecycleMBeanBase用于监督对象状态。</p><p>Service中请求监听和请求处理分开为两个模块：</p><img src="/2020/04/30/tomcat%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/pic8.png" srcset="/img/loading.gif" class=""><p>Connector负责请求监听，Container负责请求处理，一个Service可以有多个Connector，但只能有一个Container。</p><h3 id="Connector"><a href="#Connector" class="headerlink" title="Connector"></a>Connector</h3><img src="/2020/04/30/tomcat%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/pic8.png" srcset="/img/loading.gif" class=""><p>Connector使用ProtocolHandler来处理请求，ProtocolHandler包含三个部件：</p><ul><li>Endpoint：用来处理底层的Scoket的网络连接。</li><li>Processor：用于将Endpoint接收到的Socket封装为Request</li><li>Adapter：作为适配器将Reqeust将为ServletRequest交给Container进行具体的处理。</li></ul><h3 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h3><img src="/2020/04/30/tomcat%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/pic9.png" srcset="/img/loading.gif" class=""><ul><li>Engine：引擎，在servler.xml中定义了一个名为Catalina的Engline，只能有一个。</li><li>Host：站点、虚拟主机，一个Engline包含多个Host的设计，使得一个服务器实例可以承担多个域名的服务，是很灵活的设计</li><li>Context：应用，默认配置下webapps下的每个目录都是一个应用。</li><li>Wrapper：一个Servlet。</li></ul><h2 id="tomcat启动流程"><a href="#tomcat启动流程" class="headerlink" title="tomcat启动流程"></a>tomcat启动流程</h2><p>tomcat组件的启动流程：</p><img src="/2020/04/30/tomcat%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/pic1.png" srcset="/img/loading.gif" class=""><h3 id="入口类Bootstrap"><a href="#入口类Bootstrap" class="headerlink" title="入口类Bootstrap"></a>入口类Bootstrap</h3><p>start.sh会执行catalina.sh，catalina.sh会调用Bootstrap类中的main()方法。</p><pre><code class="java">public static void main(String args[]) {    //初始化阶段 init()方法    synchronized (daemonLock) {        if (daemon == null) {            // Don&#39;t set daemon until init() has completed            Bootstrap bootstrap = new Bootstrap();            try {                bootstrap.init();            } catch (Throwable t) {                handleThrowable(t);                t.printStackTrace();                return;            }            daemon = bootstrap;        } else {            // When running as a service the call to stop will be on a new            // thread so make sure the correct class loader is used to            // prevent a range of class not found exceptions.            Thread.currentThread().setContextClassLoader(daemon.catalinaLoader);        }    }    //运行阶段 start()    try {        String command = &quot;start&quot;;        if (args.length &gt; 0) {            command = args[args.length - 1];        }        if (command.equals(&quot;startd&quot;)) {            args[args.length - 1] = &quot;start&quot;;            daemon.load(args);            daemon.start();        } else if (command.equals(&quot;stopd&quot;)) {            args[args.length - 1] = &quot;stop&quot;;            daemon.stop();        } else if (command.equals(&quot;start&quot;)) {            daemon.setAwait(true);            daemon.load(args);            daemon.start();            if (null == daemon.getServer()) {                System.exit(1);            }        } else if (command.equals(&quot;stop&quot;)) {            daemon.stopServer(args);        } else if (command.equals(&quot;configtest&quot;)) {            daemon.load(args);            if (null == daemon.getServer()) {                System.exit(1);            }            System.exit(0);        } else {            log.warn(&quot;Bootstrap: command \&quot;&quot; + command + &quot;\&quot; does not exist.&quot;);        }    } catch (Throwable t) {        // Unwrap the Exception for clearer error reporting        if (t instanceof InvocationTargetException &amp;&amp;                t.getCause() != null) {            t = t.getCause();        }        handleThrowable(t);        t.printStackTrace();        System.exit(1);    }}</code></pre><p>main()方法首先会调用init()方法及start()方法，init()方法中会通过反射加载Catalina。</p><pre><code class="java">public void init() throws Exception {    //类加载器初始化    initClassLoaders();    //设置线程上下文类加载器，来解决有可能的ClassNotFoundException问题    Thread.currentThread().setContextClassLoader(catalinaLoader);    SecurityClassLoad.securityClassLoad(catalinaLoader);    // 加载启动类Catalina并调用其process()方法    if (log.isDebugEnabled())        log.debug(&quot;Loading startup class&quot;);    Class&lt;?&gt; startupClass = catalinaLoader.loadClass(&quot;org.apache.catalina.startup.Catalina&quot;);    Object startupInstance = startupClass.getConstructor().newInstance();    // 设置共享类加载器sharedLoader    if (log.isDebugEnabled())        log.debug(&quot;Setting startup class properties&quot;);    String methodName = &quot;setParentClassLoader&quot;;    Class&lt;?&gt; paramTypes[] = new Class[1];    paramTypes[0] = Class.forName(&quot;java.lang.ClassLoader&quot;);    Object paramValues[] = new Object[1];    // 把shared加载器传递给catalina    paramValues[0] = sharedLoader;    Method method =        startupInstance.getClass().getMethod(methodName, paramTypes);    method.invoke(startupInstance, paramValues);    catalinaDaemon = startupInstance;}</code></pre><p>start()方法中会通过反射调用Catalina的start方法。</p><pre><code class="java">public void start() throws Exception {    if (catalinaDaemon == null) {        init();    }    Method method = catalinaDaemon.getClass().getMethod(&quot;start&quot;, (Class [])null);    method.invoke(catalinaDaemon, (Object [])null);}</code></pre><h3 id="Catalina"><a href="#Catalina" class="headerlink" title="Catalina"></a>Catalina</h3><p>Bootstrap的init()方法会调用到Catalina的load()方法，load()方法中会通过文件流的方式加载各种文件及配置信息，最后调用Server的init()方法，同样的，start()方法中会调用Servler的start()方法，这里不在进行详细分析。</p><h3 id="Server-1"><a href="#Server-1" class="headerlink" title="Server"></a>Server</h3><p>这里使用了模版方法设计模式，start()方法将调用子类中的startInternal()方法。StandardServer中的startInternal()方法会循环调用所有的Service的start()方法，同样的initInternal()方法中也会调用所有Service的init()方法。</p><pre><code class="java">protected void startInternal() throws LifecycleException {    fireLifecycleEvent(CONFIGURE_START_EVENT, null);    setState(LifecycleState.STARTING);    globalNamingResources.start();    // Start our defined Services    synchronized (servicesLock) {        for (int i = 0; i &lt; services.length; i++) {            services[i].start();        }    }}</code></pre><h3 id="Service-1"><a href="#Service-1" class="headerlink" title="Service"></a>Service</h3><p>StandardService中的startInternal()方法，该方法首先会启动容器，然后启动线程执行器，自定义连接器。</p><pre><code class="java">    @Override    protected void startInternal() throws LifecycleException {        if(log.isInfoEnabled())            log.info(sm.getString(&quot;standardService.start.name&quot;, this.name));        setState(LifecycleState.STARTING);        // 首先启动的是容器        if (engine != null) {            synchronized (engine) {                engine.start();            }        }        // 线程执行器        synchronized (executors) {            for (Executor executor: executors) {                executor.start();            }        }        mapperListener.start();        // 启动自定义的连接器        synchronized (connectorsLock) {            for (Connector connector: connectors) {                try {                    // If it has already failed, don&#39;t try and start it                    if (connector.getState() != LifecycleState.FAILED) {                        connector.start();                    }                } catch (Exception e) {                    log.error(sm.getString(                            &quot;standardService.connector.startFailed&quot;,                            connector), e);                }            }        }    }</code></pre><h2 id="tomcat的请求处理过程"><a href="#tomcat的请求处理过程" class="headerlink" title="tomcat的请求处理过程"></a>tomcat的请求处理过程</h2><ol><li>用户点击网页内容，请求被发送到本机端口8080，被在那里监听的Coyote HTTP/1.1 Connector获得。</li><li>Connector把该请求交给它所在的Service的Engine来处理，并等待Engine的回应。</li><li>Engine获得请求localhost/test/index.jsp，匹配所有的虚拟主机Host。</li><li>Engine匹配到名为localhost的Host（即使匹配不到也把请求交给该Host处理，因为该Host被定义为该Engine的默认主机），名为localhost的Host获得请求/test/index.jsp，匹配它所拥有的所有的Context。Host匹配到路径为/test的Context（如果匹配不到就把该请求交给路径名为“ ”的Context去处理）。</li><li>path=“/test”的Context获得请求/index.jsp，在它的mapping table中寻找出对应的Servlet。Context匹配到URL PATTERN为*.jsp的Servlet,对应于JspServlet类。</li><li>构造HttpServletRequest对象和HttpServletResponse对象，作为参数调用JspServlet的doGet()或doPost()。执行业务逻辑、数据存储等程序。</li><li>Context把执行完之后的HttpServletResponse对象返回给Host。</li><li>Host把HttpServletResponse对象返回给Engine。</li><li>Engine把HttpServletResponse对象返回Connector。</li><li>Connector把HttpServletResponse对象返回给客户Browser。</li></ol><h2 id="管道模式"><a href="#管道模式" class="headerlink" title="管道模式"></a>管道模式</h2><h3 id="管道与阀门"><a href="#管道与阀门" class="headerlink" title="管道与阀门"></a>管道与阀门</h3><p>在一个比较复杂的大型系统中，如果一个对象或数据流需要进行繁杂的逻辑处理，我们可以选择在一个大的组件中直接处理这些繁杂的逻辑处理，这个方式虽然达到目的，但是拓展性和可重用性差。因为牵一发而动全身。</p><p>管道是就像一条管道把多个对象连接起来，整体看起来就像若干个阀门嵌套在管道中，而处理逻辑放在阀门上。它的结构和实现是非常值得我们学习和借鉴的。</p><h3 id="管道的实现"><a href="#管道的实现" class="headerlink" title="管道的实现"></a>管道的实现</h3><p>首先需要定义阀门接口，阀门接口中包含下一个阀门的引用，每个阀门完成自己的逻辑后将调用下一个阀门的方法，直到基础阀门，基础阀门的方法中不再对下一个阀门进行调用。管道接口中保存有第一个阀门及基础阀门的引用，基础阀门的将作为阀门添加时的顺序比较，第一个阀门将用于管道调用的开始，管道调用开始于第一个管道，终止于基础管道。</p><p>管道接口：</p><pre><code class="java">public interface Pipeline {    //获取第一个阀门    public Valve getFirst();    public Valve getBasic();    //设置阀门    public void setBasic(Valve valve);    //添加阀门    public void addVave(Valve valve);}</code></pre><p>阀门接口</p><pre><code class="java">public interface Valve {    public Valve getNext();    public void setNext(Valve valve);    public void invoke(String handing);}</code></pre><p>管道接口的实现：</p><pre><code class="java">public class StandardPipeline implements  Pipeline {    //阀门（非基础，定义一个first）    protected Valve first = null;    //基础阀门    protected Valve basic = null;    @Override    public Valve getBasic() {        return basic;    }    @Override    public void setBasic(Valve valve) {        this.basic=valve;    }    @Override    public Valve getFirst() {        return first;    }    //添加阀门，链式构建阀门的执行顺序（先定制、最后基础阀门）    @Override    public void addVave(Valve valve) {        if(first == null){            first = valve;            valve.setNext(basic);        }else{            Valve current =first;            while(current !=null){                if(current.getNext() == basic){                    current.setNext(valve);                    valve.setNext(basic);                }                current = current.getNext();            }        }    }}</code></pre><p>基础阀门</p><pre><code class="java">public class StandardValve implements Valve {    protected  Valve next =null;    @Override    public Valve getNext() {        return next;    }    @Override    public void setNext(Valve valve) {        this.next =valve;    }    @Override    public void invoke(String request) {        System.out.println(&quot;基础阀门处理&quot;);    }}</code></pre><p>第一个阀门</p><pre><code class="java">public class FirstValve implements Valve {    protected  Valve next =null;    @Override    public Valve getNext() {        return next;    }    @Override    public void setNext(Valve valve) {        this.next =valve;    }    @Override    public void invoke(String request) {        System.out.println(&quot;阀门1处理&quot;);        getNext().invoke(request);    }}</code></pre><p>第二个阀门</p><pre><code class="java">public class SecondValve implements Valve {    protected  Valve next =null;    @Override    public Valve getNext() {        return next;    }    @Override    public void setNext(Valve valve) {        this.next =valve;    }    @Override    public void invoke(String request) {        System.out.println(&quot;阀门2处理&quot;);        getNext().invoke(request);    }}</code></pre><p>测试类</p><pre><code class="java">public class Demo {    public static void main(String[] args) {        String request =&quot;这个是一个Servlet请求&quot;;        //new出一个管道        StandardPipeline pipeline = new StandardPipeline();        //三个阀门(一个基础、2个定制)        StandardValve standardValve = new StandardValve();        FirstValve firstValve = new FirstValve();        SecondValve secondValve = new SecondValve();        //设置基础阀门(定制阀门)        pipeline.setBasic(standardValve);        //设置非基础阀门        pipeline.addVave(firstValve);        pipeline.addVave(secondValve);        //调用对象管道中的第一个阀门        pipeline.getFirst().invoke(request);    }}</code></pre><h2 id="tomcat中的管道"><a href="#tomcat中的管道" class="headerlink" title="tomcat中的管道"></a>tomcat中的管道</h2><img src="/2020/04/30/tomcat%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/pic3.png" srcset="/img/loading.gif" class=""><p>其中的Engine、Host、Context、warpper分别对应StandardEngineValve、StandardHostValve、StandardContextValve、StandardWrapperValve四种阀门。</p><h3 id="管道处理流程"><a href="#管道处理流程" class="headerlink" title="管道处理流程"></a>管道处理流程</h3><img src="/2020/04/30/tomcat%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/pic4.png" srcset="/img/loading.gif" class=""><p>接收到请求后在CoyoteAdapter的service()方法中的<code>connector.getContainer().getPipeline().getFirst().invoke(request, response);</code>将获取管道并开始阀门的调用过程对reqeust、response进行处理。</p><p>StandardEngineValue类中的invoke()方法。</p><pre><code class="java">@Overridepublic final void invoke(Request request, Response response)    throws IOException, ServletException {    // 拿到Engline中包含的host    Host host = request.getHost();    if (host == null) {        response.sendError            (HttpServletResponse.SC_BAD_REQUEST,             sm.getString(&quot;standardEngine.noHost&quot;,                          request.getServerName()));        return;    }    if (request.isAsyncSupported()) {        request.setAsyncSupported(host.getPipeline().isAsyncSupported());    }    // 将request，response交给下一个阀门    host.getPipeline().getFirst().invoke(request, response);}</code></pre><p>tomcat的Pipeline处理是这样的：</p><ol><li><p>在生产线上的第一个工人拿到生产原料后，二话不说就人给下一个工人，下一个工人也是一样直接扔给下一个工人，直到最后一个工人，而最后一个工人被安排为上面提过的StandardValve，他要完成的是把生产资料运给自己所在包含的container的Pipeline上去。 </p></li><li><p>四个container就相当于有四个生产线（Pipeline），当StandardWrapperValve拿到资源开始调用servlet，返回后，再一步一步按照刚才丢生产原料是的顺序的倒序一次执行。</p></li></ol><h3 id="自定义tomcat阀门"><a href="#自定义tomcat阀门" class="headerlink" title="自定义tomcat阀门"></a>自定义tomcat阀门</h3><p>管道机制给我们带来了更好的拓展性，例如，你要添加一个额外的逻辑处理阀门是很容易的。自定义个阀门PrintIPValve，只要继承ValveBase并重写invoke方法即可。注意在invoke方法中一定要执行调用下一个阀门的操作，否则会出现异常。</p><pre><code class="java">public class PrintIPValve extends ValveBase{    @Override    public void invoke(Request request, Response response) throws IOException, ServletException {        System.out.println(&quot;------自定义阀门PrintIPValve:&quot;+request.getRemoteAddr());        getNext().invoke(request,response);    }}</code></pre><p>配置Tomcat的核心配置文件server.xml,这里把阀门配置到Engine容器下，作用范围就是整个引擎，也可以根据作用范围配置在Host或者是Context下</p><pre><code>&lt;Valve className=&quot;org.apache.catalina.valves.PrintIPValve&quot; /&gt;</code></pre><p>源码中可以直接生效，但是如果是运行版本，可以将这个类导出成一个Jar包放入Tomcat/lib目录下，也可以直接将.class文件打包进catalina.jar包中。</p><h3 id="tomcat中提供常用的阀门"><a href="#tomcat中提供常用的阀门" class="headerlink" title="tomcat中提供常用的阀门"></a>tomcat中提供常用的阀门</h3><p>AccessLogValve：请求访问日志阀门，通过此阀门可以记录所有客户端的访问日志，包括远程主机IP，远程主机名，请求方法，请求协议，会话ID，请求时间，处理时长，数据包大小等。它提供任意参数化的配置，可以通过任意组合来定制访问日志的格式。</p><p>JDBCAccessLogValve：同样是记录访问日志的阀门，但是它有助于将访问日志通过JDBC持久化到数据库中。</p><p>ErrorReportValve：这是一个讲错误以HTML格式输出的阀门。</p><p>PersistentValve：这是对每一个请求的会话实现持久化的阀门。</p><p>RemoteAddrValve：访问控制阀门。可以通过配置决定哪些IP可以访问WEB应用。</p><p>RemoteHostValve：访问控制阀门，通过配置觉得哪些主机名可以访问WEB应用。</p><p>RemoteIpValve：针对代理或者负载均衡处理的一个阀门，一般经过代理或者负载均衡转发的请求都将自己的IP添加到请求头”X-Forwarded-For”中，此时，通过阀门可以获取访问者真实的IP。</p><p>SemaphoreValve：这个是一个控制容器并发访问的阀门，可以作用在不同容器上。</p><h2 id="JVM中的类加载机制"><a href="#JVM中的类加载机制" class="headerlink" title="JVM中的类加载机制"></a>JVM中的类加载机制</h2><p><strong>类加载：</strong>主要是将.class文件中的二进制字节读入到JVM中</p><p>我们可以看到因为这个定义，所以并没有规定一定是要磁盘加载文件，可以通过网络，内存什么的加载。只要是二进制流字节数据，JVM就可以加载。</p><p><strong>类加载过程：</strong></p><ol><li><p>通过类的全限定名获取该类的二进制字节流；</p></li><li><p>将字节流所代表的静态结构转化为方法区的运行时数据结构</p></li><li><p>在内存中生成一个该类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口</p></li></ol><p><strong>类加载器</strong>：</p><p>JVM设计者把“类加载”这个动作放到java虚拟机外部去实现，以便让应用程序决定如何获取所需要的类。实现这个动作的代码模块成为“类加载器”</p><p><strong>类的唯一性：</strong></p><p>对于任何一个类，都需要由加载它的类加载器和这个类来确定其在JVM中的唯一性。也就是说，两个类来源于同一个Class文件，并且被同一个类加载器加载，这两个类才相等。</p><p>注意：这里所谓的“相等”，一般使用instanceof关键字做判断。</p><p><strong>双亲委派模型：</strong></p><ul><li><p><strong>定义：</strong>双亲委派模型的工作过程为：如果一个类加载器收到了类请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父加载器去完成，每一层都是如此，因此所有类加载的请求都会传到启动类加载器，只有当父加载器无法完成该请求时，子加载器才去自己加载。</p></li><li><p><strong>实现方式：</strong>该模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。子类加载器不是以继承的关系来实现，而是通过组合关系来复用父加载器的代码。</p></li><li><p><strong>意义：</strong>好处双亲委派模型的好处就是java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如：Object,无论那个类加载器去加载该类，最终都是由启动类加载器进行加载的，因此Object类在程序的各种类加载环境中都是一个类。如果不用改模型，那么java.lang.Object类存放在classpath中，那么系统中就会出现多个Object类，程序变得很混乱。</p></li></ul><h5 id="类加载器的分类："><a href="#类加载器的分类：" class="headerlink" title="类加载器的分类："></a>类加载器的分类：</h5><p>从虚拟机的角度来说，有两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader）,该加载器使用C++语言实现，属于虚拟机自身的一部分。另一部分就是所有其它的类加载器，这些类加载器是由Java语言实现，独立于JVM外部，并且全部继承抽象类java.lang.ClassLoader.</p><p>  从java开发人员的角度看，大部分java程序会用到以下三种系统提供的类加载器：</p><ol><li><p>启动类加载器（Bootstrap ClassLoader）:负责加载JAVA_HOME\lib目录中并且能被虚拟机识别的类库加载到JVM内存中，如果名称不符合的类库即使在lib目录中也不会被加载。该类加载器无法被java程序直接引用。</p></li><li><p>扩展类加载器(Extension ClassLoader):该加载器主要负责加载JAVA_HOME\lib\ext目录中的类库，开发者可以使用扩展加载器。 </p></li><li><p>应用程序类加载器（Application ClassLoader）:该列加载器也称为系统加载器，它负责加载用户类路径(Classpath)上所指定的类库，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。</p></li></ol><h2 id="tomcat类加载的特性"><a href="#tomcat类加载的特性" class="headerlink" title="tomcat类加载的特性"></a>tomcat类加载的特性</h2><p><strong>隔离性</strong>：Web应用类库相互隔离，避免依赖库或者应用包相互影响，比如有两个Web应用，一个采用了Spring 4，一个采用了Spring 5，如果采用同一个类加载器，Web应用将会由于jar包覆盖而无法启动成功。</p><p><strong>灵活性</strong>：Web应用之间的类加载器相互独立，如果一个Web应用重新部署时，该应用的类加载器重新加载，不能影响其他web应用。</p><p><strong>性能</strong>：如果在一个Tomcat部署多个应用，多个应用中都有相同的类库依赖。那么可以把这相同的类库让Common类加载器进行加载。</p><h2 id="tomcat中的类加载器"><a href="#tomcat中的类加载器" class="headerlink" title="tomcat中的类加载器"></a>tomcat中的类加载器</h2>{% asset_img pic5.png %}<p>Tomcat提供3个基础类加载器（common、catalina、shared）和Web应用类加载器。</p><ul><li><strong>Common Loader</strong>：Tomcat最基本的类加载器，加载<code>/common/*</code>路径中的class可以被Tomcat容器本身以及各个Webapp访问；</li><li><strong>Catalina Loader</strong>：Tomcat容器私有的类加载器，加载<code>/server/*</code>路径中的class对于Webapp不可见；</li><li><strong>Shared Loader</strong>：各个Webapp共享的类加载器，加载<code>/WebApp/WEB-INF/*</code>路径中的class对于所有Webapp可见，但是对于Tomcat容器不可见；</li><li><strong>WebappClass Loader</strong>：各个Webapp私有的类加载器，加载路径中的class只对当前Webapp可见；</li></ul><p>Tomcat通过Common类加载器实现了Jar包在应用服务器与Web应用之间的共享，通过Shared类加载器实现了Jar包在Web应用之间的共享，再过Catalina类加载器加载服务器依赖的类。</p><p>当应用需要到某个类时，则会按照下面的顺序进行类加载</p><ol><li>使用BootStrap ClassLoader加载</li><li>使用system系统类加载器加载</li><li>使用Webapp ClassLoader在WEB-INF/classes中加载</li><li>使用Webapp ClassLoader在WEB-INF/lib中加载</li><li>使用Common ClassLoader在CATALINA_HOME/lib中加载</li></ol><h3 id="类加载器的创建"><a href="#类加载器的创建" class="headerlink" title="类加载器的创建"></a>类加载器的创建</h3><p>3个基础类加载器的加载路径在catalina.properties配置，默认情况下，3个基础类加载器的实例都是一个。</p><pre><code class="java">public void init() throws Exception {    //类加载器初始化    initClassLoaders();    //设置线程上下文类加载器，来解决有可能的ClassNotFoundException问题    Thread.currentThread().setContextClassLoader(catalinaLoader);    SecurityClassLoad.securityClassLoad(catalinaLoader);    // 加载启动类Catalina并调用其process()方法    if (log.isDebugEnabled())        log.debug(&quot;Loading startup class&quot;);    Class&lt;?&gt; startupClass = catalinaLoader.loadClass(&quot;org.apache.catalina.startup.Catalina&quot;);    Object startupInstance = startupClass.getConstructor().newInstance();    // 设置共享类加载器sharedLoader    if (log.isDebugEnabled())        log.debug(&quot;Setting startup class properties&quot;);    String methodName = &quot;setParentClassLoader&quot;;    Class&lt;?&gt; paramTypes[] = new Class[1];    paramTypes[0] = Class.forName(&quot;java.lang.ClassLoader&quot;);    Object paramValues[] = new Object[1];    // 把shared加载器传递给catalina    paramValues[0] = sharedLoader;    Method method =        startupInstance.getClass().getMethod(methodName, paramTypes);    method.invoke(startupInstance, paramValues);    catalinaDaemon = startupInstance;}</code></pre><h3 id="类加载器初始化"><a href="#类加载器初始化" class="headerlink" title="类加载器初始化"></a>类加载器初始化</h3><p>Bootstartp的initClassLoaders()方法会在Boostrap的init()方法中调用，初始化三个类加载器以及确定父子关系。</p><pre><code class="java">//初始化三个类加载器以及确定父子关系private void initClassLoaders() {    try {        // commonLoader的加载路径为common.loader        commonLoader = createClassLoader(&quot;common&quot;, null);        if (commonLoader == null) {            // no config file, default to this loader - we might be in a &#39;single&#39; env.            commonLoader = this.getClass().getClassLoader();        }        // 加载路径为server.loader，默认为空，父类加载器为commonLoader        catalinaLoader = createClassLoader(&quot;server&quot;, commonLoader);        // 加载路径为shared.loader，默认为空，父类加载器为commonLoader        sharedLoader = createClassLoader(&quot;shared&quot;, commonLoader);    } catch (Throwable t) {        handleThrowable(t);        log.error(&quot;Class loader creation threw exception&quot;, t);        System.exit(1);    }}</code></pre><p>initClassLoaders()方法会调用createClassLoader()方法会根据catalina.properties中的内容创建对应的类加载器，如果为空则返回传入的父加载器。</p><pre><code class="java">private ClassLoader createClassLoader(String name, ClassLoader parent)    throws Exception {    String value = CatalinaProperties.getProperty(name + &quot;.loader&quot;);    if ((value == null) || (value.equals(&quot;&quot;)))        return parent;    value = replace(value);    List&lt;Repository&gt; repositories = new ArrayList&lt;&gt;();    String[] repositoryPaths = getPaths(value);    for (String repository : repositoryPaths) {        // Check for a JAR URL repository        try {            @SuppressWarnings(&quot;unused&quot;)            URL url = new URL(repository);            repositories.add(new Repository(repository, RepositoryType.URL));            continue;        } catch (MalformedURLException e) {            // Ignore        }        // Local repository        if (repository.endsWith(&quot;*.jar&quot;)) {            repository = repository.substring                (0, repository.length() - &quot;*.jar&quot;.length());            repositories.add(new Repository(repository, RepositoryType.GLOB));        } else if (repository.endsWith(&quot;.jar&quot;)) {            repositories.add(new Repository(repository, RepositoryType.JAR));        } else {            repositories.add(new Repository(repository, RepositoryType.DIR));        }    }    return ClassLoaderFactory.createClassLoader(repositories, parent);}</code></pre><p>catalina.properties中的内容</p><pre><code class="properties">common.loader=&quot;${catalina.base}/lib&quot;,&quot;${catalina.base}/lib/*.jar&quot;,&quot;${catalina.home}/lib&quot;,&quot;${catalina.home}/lib/*.jar&quot;server.loader=shared.loader=</code></pre><p>所以默认情况这三个类加载器是同一个实例，可以通过修改配置创建3个不同的类加载机制，使它们各司其职，如果不希望这些包对Web应用可见，因此我们可以配置server.loader，创建独立的Catalina类加载器。</p><h3 id="类加载工厂"><a href="#类加载工厂" class="headerlink" title="类加载工厂"></a>类加载工厂</h3><p>因为类加载需要做很多事情，比如读取字节数组、验证、解析、初始化等。Java提供的URLClassLoader类能够方便的将Jar、Class或者网络资源加载到内存中。Tomcat中使用一个工厂类，ClassLoaderFactory把创建类加载器的细节进行封装，可以通过它方便的创建自定义类加载器。</p><p>上述createClassLoader()方法中的<code>return ClassLoaderFactory.createClassLoader(repositories, parent);</code>方法就是使用类加载工厂来创建类加载器。</p><pre><code class="java">public static ClassLoader createClassLoader(List&lt;Repository&gt; repositories,                                            final ClassLoader parent)    throws Exception {    if (log.isDebugEnabled())        log.debug(&quot;Creating new class loader&quot;);    // Construct the &quot;class path&quot; for this class loader    Set&lt;URL&gt; set = new LinkedHashSet&lt;&gt;();    if (repositories != null) {        for (Repository repository : repositories)  {            if (repository.getType() == RepositoryType.URL) {                URL url = buildClassLoaderUrl(repository.getLocation());                if (log.isDebugEnabled())                    log.debug(&quot;  Including URL &quot; + url);                set.add(url);            } else if (repository.getType() == RepositoryType.DIR) {                File directory = new File(repository.getLocation());                directory = directory.getCanonicalFile();                if (!validateFile(directory, RepositoryType.DIR)) {                    continue;                }                URL url = buildClassLoaderUrl(directory);                if (log.isDebugEnabled())                    log.debug(&quot;  Including directory &quot; + url);                set.add(url);            } else if (repository.getType() == RepositoryType.JAR) {                File file=new File(repository.getLocation());                file = file.getCanonicalFile();                if (!validateFile(file, RepositoryType.JAR)) {                    continue;                }                URL url = buildClassLoaderUrl(file);                if (log.isDebugEnabled())                    log.debug(&quot;  Including jar file &quot; + url);                set.add(url);            } else if (repository.getType() == RepositoryType.GLOB) {                File directory=new File(repository.getLocation());                directory = directory.getCanonicalFile();                if (!validateFile(directory, RepositoryType.GLOB)) {                    continue;                }                if (log.isDebugEnabled())                    log.debug(&quot;  Including directory glob &quot;                        + directory.getAbsolutePath());                String filenames[] = directory.list();                if (filenames == null) {                    continue;                }                for (int j = 0; j &lt; filenames.length; j++) {                    String filename = filenames[j].toLowerCase(Locale.ENGLISH);                    if (!filename.endsWith(&quot;.jar&quot;))                        continue;                    File file = new File(directory, filenames[j]);                    file = file.getCanonicalFile();                    if (!validateFile(file, RepositoryType.JAR)) {                        continue;                    }                    if (log.isDebugEnabled())                        log.debug(&quot;    Including glob jar file &quot;                            + file.getAbsolutePath());                    URL url = buildClassLoaderUrl(file);                    set.add(url);                }            }        }    }    // Construct the class loader itself    final URL[] array = set.toArray(new URL[set.size()]);    if (log.isDebugEnabled())        for (int i = 0; i &lt; array.length; i++) {            log.debug(&quot;  location &quot; + i + &quot; is &quot; + array[i]);        }    return AccessController.doPrivileged(            new PrivilegedAction&lt;URLClassLoader&gt;() {                @Override                public URLClassLoader run() {                    if (parent == null)                        return new URLClassLoader(array);                    else                        return new URLClassLoader(array, parent);                }            });}</code></pre><p>createClassLoader()方法会依据RepositoryType来执行不同的创建方法。</p><pre><code class="java">public enum RepositoryType {    DIR, //表示整个目录下的资源，包括所有Class、jar包以及其他类型资源    GLOB, //表示整个目录下的所有jar包资源    JAR, //表示单个jar包资源    URL //表示从URL上获取jar包资源}</code></pre><p>使用加载器工厂的好处</p><ol><li>ClassLoadFactory有一个内部Repository，它就是表示资源的类，资源的类型用一个RepositoryType的枚举表示。</li><li>在检查jar包的时候，如果检查的URL地址有异常就忽略掉，可以确保部分类加载正确。</li></ol><h3 id="类加载器绑定到线程"><a href="#类加载器绑定到线程" class="headerlink" title="类加载器绑定到线程"></a>类加载器绑定到线程</h3><p>JVM提供了java.lang.Thread类的setContextClassLoader方法来绑定一个线程上下文类加载器（Thread Context ClassLoader），用于在运行时动态载入其他类，如果创建线程时未设置，将会从父线程中继承一个，所以大部分情况下，都是系统默认的ContextClassLoad。</p><p>一般在实际的系统上，使用线程上下文类加载器，可以设置不同的加载方式，这个也是Java灵活的类加载方式的体现，也可以很轻松的打破双亲委派模式，同时也会避免类加载的异常。</p><p>tomcat也使用了这种方式，来解决Commons ClassLoader需要Webapp ClassLoader中的类的情况。WebappLoader只会加载自己目录下的class文件，不会传递给父容器，所以tomcat将Webapp ClassLoader与线程绑定，使用线程上下文加载器，可以让父类加载器请求子类加载器去完成类加载的动作，不得不说，这是个巧妙的设计。</p><h3 id="tomcat的热加载"><a href="#tomcat的热加载" class="headerlink" title="tomcat的热加载"></a>tomcat的热加载</h3><p>StandardContext.startInternal()方法中还会调用threadStart()方法，threadStart()方法将创建一个线程，这个线程的while循环中，不断的调用方法，然后进行睡眠，以这种类似于定时器的方式，来执行任务，如重新加载等。</p><pre><code class="java">protected void threadStart() {    if (thread != null)        return;    if (backgroundProcessorDelay &lt;= 0)        return;    threadDone = false;    String threadName = &quot;ContainerBackgroundProcessor[&quot; + toString() + &quot;]&quot;;    thread = new Thread(new ContainerBackgroundProcessor(), threadName);    thread.setDaemon(true);    thread.start();}</code></pre><p>threadStart()方法调用链比较长，这里只分析WebappLoader的backgroudProcess()方法，该方法将完成类的重新加载。</p><pre><code class="java">public void backgroundProcess() {    if (reloadable &amp;&amp; modified()) {        try {            //设置线程类加载器的类加载器WebappClassLoader            Thread.currentThread().setContextClassLoader                (WebappLoader.class.getClassLoader());            if (context != null) {                //重新加载的方法                context.reload();            }        } finally {            if (context != null &amp;&amp; context.getLoader() != null) {                Thread.currentThread().setContextClassLoader                    (context.getLoader().getClassLoader());            }        }    }}</code></pre>]]></content>
    
    
    <categories>
      
      <category>tomcat</category>
      
    </categories>
    
    
    <tags>
      
      <tag>tomcat</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>tomcat体系架构</title>
    <link href="/2020/04/30/tomcat%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/"/>
    <url>/2020/04/30/tomcat%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/</url>
    
    <content type="html"><![CDATA[<h2 id="web容器"><a href="#web容器" class="headerlink" title="web容器"></a>web容器</h2><p>Web服务器一般指网站服务器，是指驻留于因特网上某种类型计算机的程序，可以向浏览器等Web客户端提供文档，也可以放置网站文件，提供给用户浏览或下载。</p><img src="/2020/04/30/tomcat%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/pic1.png" srcset="/img/loading.gif" class=""><p>Web服务器的特点：</p><ul><li><p>服务器是一种被动程序：只有当Internet上运行其他计算机中的浏览器发出的请求时，服务器才会响应。</p></li><li><p>服务器一般使用HTTP（超文本传输协议）与客户机浏览器进行信息交流，这就是人们常把它们称为HTTP服务器的原因。</p></li><li><p>Web服务器不仅能够存储信息，还能在用户通过Web浏览器提供的信息的基础上运行脚本和程序。</p></li></ul><h2 id="tomcat介绍"><a href="#tomcat介绍" class="headerlink" title="tomcat介绍"></a>tomcat介绍</h2><p>tomcat是一款开源轻量级Web应用服务器,是一款优秀的Servlet容器实现。</p><p>Servlet（Server Applet）是Java Servlet的简称，称为小服务程序或服务连接器，用Java编写的服务器端程序，具有独立于平台和协议的特性，主要功能在于交互式地浏览和生成数据，生成动态Web内容。</p><p>Servlet严格来讲是指Java语言实现的一个接口，一般情况下我们说的Servlet是指任何实现了这个Servlet接口的类。</p><ul><li>实例化并调用init()方法初始化该Servlet，一般Servlet只初始化一次(只有一个对象)</li><li>service()（根据请求方法不同调用doGet() 或者 doPost()，此外还有doHead()、doPut()、doTrace()、doDelete()、doOptions()、destroy())。</li><li>当 Server 不再需要 Servlet 时（一般当 Server 关闭时），Server调用Servlet的destroy()方法。</li></ul><h3 id="tomcat版本对照"><a href="#tomcat版本对照" class="headerlink" title="tomcat版本对照"></a>tomcat版本对照</h3><table><thead><tr><th></th><th><strong>6.X</strong></th><th><strong>7.X</strong></th><th><strong>8.X</strong></th><th><strong>8.5X</strong></th><th><strong>9.X</strong></th></tr></thead><tbody><tr><td>JDK</td><td>&gt;=1.5</td><td>&gt;=1.6</td><td>&gt;=1.7</td><td>&gt;=1.7</td><td>&gt;=1.8</td></tr><tr><td>Servlet</td><td>2.5</td><td>3.0</td><td>3.1</td><td>3.1</td><td>4.0</td></tr><tr><td>JSP</td><td>2.1</td><td>2.2</td><td>2.3</td><td>2.3</td><td>2.3</td></tr><tr><td>WebSocket</td><td>N</td><td>1.1</td><td>1.1</td><td>1.1</td><td>1.1</td></tr></tbody></table><p>8.5版本特点：</p><ul><li>支持Servlet3.1</li><li>默认采用NIO，移除BIO</li><li>支持NIO2(AIO)</li><li>支持HTTP/2协议</li><li>默认采用异步日志处理</li></ul><h2 id="tomcat部署方式"><a href="#tomcat部署方式" class="headerlink" title="tomcat部署方式"></a>tomcat部署方式</h2><h3 id="隐式部署"><a href="#隐式部署" class="headerlink" title="隐式部署"></a>隐式部署</h3><p>直接丢文件夹、war、jar到webapps目录，tomcat会根据文件夹名称自动生成虚拟路径，简单，但是需要重启Tomcat服务器，包括要修改端口和访问路径的也需要重启。</p><h3 id="显式部署"><a href="#显式部署" class="headerlink" title="显式部署"></a>显式部署</h3><p>添加context元素</p><p>server.xml中的Host加入一个Context（指定路径和文件地址），例如：</p><pre><code class="xml">&lt;Context path=&quot;/comet&quot; docBase=&quot;D:\work_tomcat\ref-comet.war&quot; /&gt;</code></pre><p>即/comet 这个虚拟路径映射到了D:\work_tomcat\ref-comet目录下(war会解压成文件)，修改完servler.xml需要重启tomcat 服务器。</p><p>创建xml文件</p><p>在conf/Catalina/localhost中创建xml文件，访问路径为文件名，例如：</p><p>在localhost目录下新建demo.xml，内容为：</p><pre><code class="xml">&lt;Context docBase=&quot;D:\work_tomcat\ref-comet&quot; /&gt;</code></pre><p>这时不需要指定路径，虚拟目录就是文件名demo，path默认为/demo，添加demo.xml不需要重启 tomcat服务器。</p><p>三种方式比较：</p><ul><li><p>隐式部署：部署速度比较快，需要手动移动Web应用到webapps下，在实际操作中不是很人性化。</p></li><li><p>添加context元素：需要配置两个路径，如果path为空字符串，则为缺省配置，每次修改server.xml文件后都要重新启动Tomcat服务器，重新部署。</p></li><li><p>创建xml文件：服务器后台会自动部署，修改一次后台部署一次，不用重复启动Tomcat服务器，该方式显得更为智能化。</p></li></ul><h2 id="tomcat目录结构"><a href="#tomcat目录结构" class="headerlink" title="tomcat目录结构"></a>tomcat目录结构</h2><h3 id="bin目录"><a href="#bin目录" class="headerlink" title="bin目录"></a>bin目录</h3><ul><li><p>startup文件，主要是检查catalina.bat/sh 执行所需环境，并调用catalina.bat 批处理文件。启动tomcat。</p></li><li><p>catalina文件，真正启动Tomcat文件，可以在里面设置jvm参数。后面性能调优会重点讲</p></li><li><p>shutdown文件，关闭Tomcat</p></li><li><p>version文件：查看当前tomcat的版本号，</p></li><li><p>configtest文件：校验tomcat配置文件server.xml的格式、内容等是否合法、正确。</p></li><li><p>service文件：安装tomcat服务，可用net start tomcat 启动</p></li></ul><p>脚本version.sh、startup.sh、shutdown.sh、configtest.sh都是对catalina.sh的包装，内容大同小异，差异在于功能介绍和调用catalina.sh时的参数不同。</p><h3 id="config目录"><a href="#config目录" class="headerlink" title="config目录"></a>config目录</h3><ul><li><p>web.xml</p><p>Tomcat中所有应用默认的部署描述文件，主要定义了基础的Servlet和MIME映射(mime-mapping 文件类型，其实就是Tomcat处理的文件类型),如果部署的应用中不包含Web.xml，那么Tomcat将使用此文件初始化部署描述，反之，Tomcat会在启动时将默认描述与定义描述配置进行合并。常用于：</p><ul><li><p>加载一些tomcat内置的servlet</p></li><li><p>DefaultServlet默认的,加载静态文件 html,js,jpg等静态文件。</p></li><li><p>JspServlet专门处理jsp。</p></li></ul></li><li><p>context.xml</p><p>用于自定义所有Web应用均需要加载的Context配置，如果Web应用指定了自己的context.xml，那么该文件的配置将被覆盖。</p><p>context.xml与server.xml中配置context的区别：server.xml是不可动态重加载的资源，服务器一旦启动了以后，要修改这个文件，就得重启服务器才能重新加载。而context.xml文件则不然，tomcat服务器会定时去扫描这个文件。一旦发现文件被修改（时间戳改变了），就会自动重新加载这个文件，而不需要重启服务器。</p></li><li><p>catalina.policy</p><p>权限相关Permission ，Tomcat是跑在jvm上的，所以有些默认的权限。</p></li><li><p>tomcat-users.xml</p><p>配置Tomcat的server的manager信息。</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;tomcat-users xmlns=&quot;http://tomcat.apache.org/xml&quot;              xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;              xsi:schemaLocation=&quot;http://tomcat.apache.org/xml tomcat-users.xsd&quot;              version=&quot;1.0&quot;&gt;&lt;role rolename=&quot;manager-gui&quot;/&gt;&lt;user username=&quot;manager&quot; password=&quot;manager&quot; roles=&quot;manager-gui&quot;/&gt;&lt;/tomcat-users&gt;</code></pre></li><li><p>logging.properties</p><p>设置tomcat日志，控制输出或者不输出内容到文件，但不能阻止生成文件，阻止生成文件可以注释掉。</p></li></ul><h3 id="webapps目录"><a href="#webapps目录" class="headerlink" title="webapps目录"></a>webapps目录</h3><p>存放web项目的目录，其中每个文件夹都是一个项目；如果这个目录下已经存在了目录，那么都是tomcat自带的。项目。其中ROOT是一个特殊的项目，在地址栏中没有给出项目目录时，对应的就是ROOT项目。<a href="http://localhost:8080/examples，进入示例项目。其中examples就是项目名，即文件夹的名字。" target="_blank" rel="noopener">http://localhost:8080/examples，进入示例项目。其中examples就是项目名，即文件夹的名字。</a></p><h3 id="lib目录"><a href="#lib目录" class="headerlink" title="lib目录"></a>lib目录</h3><p>Tomcat的类库，里面是一大堆jar文件。如果需要添加Tomcat依赖的jar文件，可以把它放到这个目录中，当然也可以把应用依赖的jar文件放到这个目录中，这个目录中的jar所有项目都可以共享，但这样你的应用放到其他Tomcat下时就不能再共享这个目录下的Jar包了，所以建议只把Tomcat需要的Jar包放到这个目录下；</p><h3 id="work目录"><a href="#work目录" class="headerlink" title="work目录"></a>work目录</h3><p>运行时生成的文件，最终运行的文件都在这里。通过webapps中的项目生成的！可以把这个目录下的内容删除，再次运行时会生再次生成work目录。当客户端用户访问一个JSP文件时，Tomcat会通过JSP生成Java文件，然后再编译Java文件生成class文件，生成的java和class文件都会存放到这个目录下。</p><h3 id="temp目录"><a href="#temp目录" class="headerlink" title="temp目录"></a>temp目录</h3><p>存放Tomcat的临时文件，这个目录下的东西在停止Tomcat后会删除！</p><h3 id="logs目录"><a href="#logs目录" class="headerlink" title="logs目录"></a>logs目录</h3><p>这个目录中都是日志文件，记录了Tomcat启动和关闭的信息，如果启动Tomcat时有错误，异常也会记录在日志文件中</p><p>localhost-xxx.log    Web应用的内部程序日志，建议保留</p><p>catalina-xxx.log    控制台日志</p><p>host-manager.xxx.log    Tomcat管理页面中的host-manager的操作日志，建议关闭</p><p>localhost_access_log_xxx.log    用户请求Tomcat的访问日志（这个文件在conf/server.xml里配置），建议关闭</p><h3 id="server-xml文件"><a href="#server-xml文件" class="headerlink" title="server.xml文件"></a>server.xml文件</h3><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!-- Server代表一个 Tomcat 实例。可以包含一个或多个 Services，其中每个Service都有自己的Engines和Connectors。       port=&quot;8005&quot;指定一个端口，这个端口负责监听关闭tomcat的请求  --&gt;&lt;Server port=&quot;8005&quot; shutdown=&quot;SHUTDOWN&quot;&gt;&lt;!-- 监听器 --&gt;&lt;Listener className=&quot;org.apache.catalina.startup.VersionLoggerListener&quot; /&gt;&lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot; /&gt;&lt;Listener className=&quot;org.apache.catalina.core.JreMemoryLeakPreventionListener&quot; /&gt;&lt;Listener className=&quot;org.apache.catalina.mbeans.GlobalResourcesLifecycleListener&quot; /&gt;&lt;Listener className=&quot;org.apache.catalina.core.ThreadLocalLeakPreventionListener&quot; /&gt;&lt;!-- 全局命名资源，定义了UserDatabase的一个JNDI(java命名和目录接口)，通过pathname的文件得到一个用户授权的内存数据库 --&gt;&lt;GlobalNamingResources&gt;&lt;Resource name=&quot;UserDatabase&quot; auth=&quot;Container&quot;               type=&quot;org.apache.catalina.UserDatabase&quot;               description=&quot;User database that can be updated and saved&quot;               factory=&quot;org.apache.catalina.users.MemoryUserDatabaseFactory&quot;               pathname=&quot;conf/tomcat-users.xml&quot; /&gt;&lt;/GlobalNamingResources&gt;&lt;!-- Service它包含一个&lt;Engine&gt;元素,以及一个或多个&lt;Connector&gt;,这些Connector元素共享用同一个Engine元素 --&gt;&lt;Service name=&quot;Catalina&quot;&gt;&lt;!--          每个Service可以有一个或多个连接器&lt;Connector&gt;元素，         第一个Connector元素定义了一个HTTP Connector,它通过8080端口接收HTTP请求;第二个Connector元素定         义了一个JD Connector,它通过8009端口接收由其它服务器转发过来的请求.     --&gt;&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;                connectionTimeout=&quot;20000&quot;                redirectPort=&quot;8443&quot; /&gt;&lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt;&lt;!-- 每个Service只能有一个&lt;Engine&gt;元素 --&gt;&lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot;&gt;&lt;Realm className=&quot;org.apache.catalina.realm.LockOutRealm&quot;&gt;&lt;Realm className=&quot;org.apache.catalina.realm.UserDatabaseRealm&quot;                resourceName=&quot;UserDatabase&quot;/&gt;&lt;/Realm&gt;&lt;!-- 默认host配置，有几个域名就配置几个Host，但是这种只能是同一个端口号 --&gt;&lt;Host name=&quot;localhost&quot;  appBase=&quot;webapps&quot;             unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;     　　&lt;!-- Tomcat的访问日志，默认可以关闭掉它，它会在logs文件里生成localhost_access_log的访问日志 --&gt;&lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot;                prefix=&quot;localhost_access_log&quot; suffix=&quot;.txt&quot;                pattern=&quot;%h %l %u %t &quot;%r&quot; %s %b&quot; /&gt;&lt;/Host&gt;&lt;Host name=&quot;www.hzg.com&quot;  appBase=&quot;webapps&quot;             unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;&lt;Context path=&quot;&quot; docBase=&quot;/myweb1&quot; /&gt;&lt;Valve className=&quot;org.apache.catalina.valves.AccessLogValve&quot; directory=&quot;logs&quot;                prefix=&quot;hzg_access_log&quot; suffix=&quot;.txt&quot;                pattern=&quot;%h %l %u %t &quot;%r&quot; %s %b&quot; /&gt;&lt;/Host&gt;&lt;/Engine&gt;&lt;/Service&gt;&lt;/Server&gt;</code></pre><h4 id="server-xml中日志的patter解释"><a href="#server-xml中日志的patter解释" class="headerlink" title="server.xml中日志的patter解释"></a>server.xml中日志的patter解释</h4><p>有效的日志格式模式可以参见下面内容，如下字符串，其对应的信息由指定的响应内容取代：</p><ul><li><p>％a - 远程IP地址</p></li><li><p>％A - 本地IP地址</p></li><li><p>％b - 发送的字节数，不包括HTTP头，或“ - ”如果没有发送字节</p></li><li><p>％B - 发送的字节数，不包括HTTP头</p></li><li><p>％h - 远程主机名</p></li><li><p>％H - 请求协议</p></li><li><p>％l (小写的L)- 远程逻辑从identd的用户名（总是返回’ - ‘）</p></li><li><p>％m - 请求方法</p></li><li><p>％p - 本地端口</p></li><li><p>％q - 查询字符串（在前面加上一个“？”如果它存在，否则是一个空字符串</p></li><li><p>％r - 第一行的要求</p></li><li><p>％s - 响应的HTTP状态代码</p></li><li><p>％S - 用户会话ID</p></li><li><p>％t - 日期和时间，在通用日志格式</p></li><li><p>％u - 远程用户身份验证</p></li><li><p>％U - 请求的URL路径</p></li><li><p>％v - 本地服务器名</p></li><li><p>％D - 处理请求的时间（以毫秒为单位）</p></li><li><p>％T - 处理请求的时间（以秒为单位）</p></li><li><p>％I （大写的i） - 当前请求的线程名称</p></li></ul><h2 id="tomcat组件及架构"><a href="#tomcat组件及架构" class="headerlink" title="tomcat组件及架构"></a>tomcat组件及架构</h2><img src="/2020/04/30/tomcat%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/pic2.png" srcset="/img/loading.gif" class=""><table><thead><tr><th><strong>组件名称</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>Server</td><td>代表整个tomcat服务器，一个Tomcat只有一个Servcer。</td></tr><tr><td>Service</td><td>Server中的一个逻辑功能层，维护多个Connector和一个Container，一个Server可以包含多个Service。</td></tr><tr><td>Connector</td><td>连接器，监听转换Socket请求，将请求交给Container处理，支持不同协议以及不同的I/O方式，是Service的核心组件之一，一个Service可以有多个Connector。</td></tr><tr><td>Container</td><td>Service的另一个核心组件，按照层级有Engine、Host、Context、Wrapper四种，一个Service只有一个Engine，主要作用是执行业务逻辑。</td></tr><tr><td>Engine</td><td>Servler中层级最高的容器对象</td></tr><tr><td>Host</td><td>Servlet引擎中的虚拟机，主要与域名有关，一个服务器有多个域名是可以使用多个Host</td></tr><tr><td>Context</td><td>用于表示ServletContext,一个ServletContext表示一个独立的Web应用</td></tr><tr><td>Wrapper</td><td>用于表示Web应用中定义的Servlet</td></tr><tr><td>Executor</td><td>Tomcat组件间可以共享的线程池</td></tr></tbody></table><h3 id="请求的运行过程"><a href="#请求的运行过程" class="headerlink" title="请求的运行过程"></a>请求的运行过程</h3><img src="/2020/04/30/tomcat%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/pic3.png" srcset="/img/loading.gif" class=""><h3 id="connector连接器"><a href="#connector连接器" class="headerlink" title="connector连接器"></a>connector连接器</h3><p>Connector链接器封装了底层的网络请求(Socket请求及相应处理),提供了统一的接口，使Container容器与具体的请求协议以及I/O方式解耦。Connector将Socket输入转换成Request对象，交给Container容器进行处理，处理请求后，Container通过Connector提供的Response对象将结果写入输出流。因为无论是Request对象还是Response对象都没有实现Servlet规范对应的接口，Container会将它们进一步分装成ServletRequest和ServletResponse.</p><img src="/2020/04/30/tomcat%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84/pic4.png" srcset="/img/loading.gif" class=""><p>三种传输协议</p><ul><li>HTTP：HTTP/1.1协议</li><li>AJP协议：主要与Apache HTTP Server集成，主要用于处理静态资源，AJP采用二进制传输可读性文本，使用保持持久性的TCP链接，使得AJP占用更少的带宽，并且链接开销要小得多，但是由于AJP采用持久化链接，因此有效的连接数较HTTP要更多。</li><li>HTTP2：HTTP/2.0协议，下一代HTTP协议，目前市场不成熟。</li></ul><p>三种I/O方式</p><ul><li>NIO：采用JDK的NIO类库实现</li><li>NIO2(AIO)：采用JDK1.7的NIO2类库实现</li><li>APR：采用APR(Apache可移植运行库)</li></ul><table><thead><tr><th><strong>protocol</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>HTTP/1.1</td><td>默认值</td></tr><tr><td>org.apache.coyote.http11.Http11NioProtocol</td><td>http+Nio的方式</td></tr><tr><td>org.apache.coyote.http11.Http11Nio2Protocol</td><td>http+Nio2的方式（AIO）</td></tr><tr><td>org.apache.coyote.http11.Http11AprProtocol</td><td>http+Apr的方式</td></tr></tbody></table><p>对于I/0选择，要根据业务场景来定，一般高并发场景下，APR和NIO2的性能要优于NIO和BIO，（linux操作系统支持的NIO2由于是一个假的，并没有真正实现AIO，所以一般linux上推荐使用NIO，如果是APR的话，需要安装APR库，而Windows上默认安装了），所以在8.5的版本中默认是NIO。</p>]]></content>
    
    
    <categories>
      
      <category>tomcat</category>
      
    </categories>
    
    
    <tags>
      
      <tag>tomcat</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>redis的高可用</title>
    <link href="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    <url>/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="redis主从原理"><a href="#redis主从原理" class="headerlink" title="redis主从原理"></a>redis主从原理</h2><h3 id="主从拓扑"><a href="#主从拓扑" class="headerlink" title="主从拓扑"></a>主从拓扑</h3><h4 id="一主一从"><a href="#一主一从" class="headerlink" title="一主一从"></a>一主一从</h4><p>主节点的写入命令会同步到从节点，当需要持久化时，可以只在从节点开启AOF。</p><h4 id="一主多从"><a href="#一主多从" class="headerlink" title="一主多从"></a>一主多从</h4><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic2.png" srcset="/img/loading.gif" class=""><p>针对读较多的场景，读由多个从节点来分担，但节点越多，主节点同步到多节点的次数也越多，影响带宽，也加重主节点的稳定。</p><h4 id="树状主从"><a href="#树状主从" class="headerlink" title="树状主从"></a>树状主从</h4><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic3.png" srcset="/img/loading.gif" class=""><p>用来解决一主多从主节点的推送压力，主节点只推送一次数据到从节点B，再由从节点B推送到C和D，减轻主节点推送的压力</p><h3 id="复制原理"><a href="#复制原理" class="headerlink" title="复制原理"></a>复制原理</h3><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic4.png" srcset="/img/loading.gif" class=""><h3 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h3><p>redis 2.8版本以上使用psync命令完成同步，复制方式分为全量与部分复制</p><ul><li><p>全量复制：一般用于初次复制场景（第一次建立SLAVE后全量）。</p></li><li><p>部分复制：网络出现问题，从节点再次连主节点时，主节点补发缺少的数据，每次数据增加同步。</p></li></ul><p>心跳：主从有长连接心跳，主节点默认每10S向从节点发ping命令，<code>repl-ping-slave-period</code>属性可以控制发送频率。</p><h2 id="redis哨兵机制"><a href="#redis哨兵机制" class="headerlink" title="redis哨兵机制"></a>redis哨兵机制</h2><p>高可用一般指服务的冗余，当某个服务节点故障时，可以自动切换到另外一个节点上，不影响用户体验。</p><p>redis主从复制结构主节点故障时，仍需要人工重新在从节点中执行<code>slaveof no one</code>后变为新主节点，其他的节点成为新主节点的丛节点，并从新节点复制数据，然后通知我们的应用程序更新了主节点的地址。这种处理方式无法实现高可用，使用哨兵机制可以在主节点出现故障时，由redis sentinel自动完成故障发现和转移，并通知应用方，实现高可用性。</p><p>注意：在代码中连接redis时，需要连接哨兵节点，由哨兵节点动态的选择redis主节点。</p><h3 id="监控机制"><a href="#监控机制" class="headerlink" title="监控机制"></a>监控机制</h3><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic5.png" srcset="/img/loading.gif" class=""><p>哨兵的数量一般是奇数个，当节点出现故障是，首先使用Raft算法实现选举机制，选出一个哨兵节点来完成转移和通知。</p><p>哨兵有三个定时监控任务完成对各节点的发现和监控：</p><ul><li>每个哨兵节点每10秒会向主节点和从节点发送info命令获取最拓扑结构图，哨兵配置时只要配置对主节点的监控即可，通过向主节点发送info，获取从节点的信息，并当有新的从节点加入时可以马上感知到。</li><li>每个哨兵节点每隔2秒会向redis数据节点的指定频道上发送该哨兵节点对于主节点的判断以及当前哨兵节点的信息，同时每个哨兵节点也会订阅该频道，来了解其它哨兵节点的信息及对主节点的判断，其实就是通过消息publish和subscribe来完成的。</li><li>每隔1秒每个哨兵会向主节点、从节点及其余哨兵节点发送一次ping命令做一次心跳检测，这个也是哨兵用来判断节点是否正常的重要依据。</li></ul><p>主观下线：哨兵节点每隔1秒对主节点和从节点、其它哨兵节点发送ping做心跳检测，当这些心跳检测时间超过<code>down-after-milliseconds</code>时，哨兵节点则认为该节点故障或下线，但这这可能会存在误判。</p><p>客观下线：当主观下线的节点是主节点时，此时该哨兵节点会通过指令<code>sentinelis-masterdown-by-addr</code>寻求其它哨兵节点对主节点的判断，当认为该节点出现故障的哨兵数当超过<code>quorum</code>（法定人数）个数时，就是客观下线。</p><h3 id="哨兵领导者选举流程"><a href="#哨兵领导者选举流程" class="headerlink" title="哨兵领导者选举流程"></a>哨兵领导者选举流程</h3><ol><li>每个在线的哨兵节点都可以成为领导者，当它发现主节点下线时，会向其它哨兵发<code>is-master-down-by-addr</code>命令，征求判断并要求将自己设置为领导者，由领导者处理故障转移；</li><li>当其它哨兵收到此命令时，可以同意或者拒绝它成为领导者；</li><li>如果哨兵3发现自己在选举的票数大于等于num(sentinels)/2+1时，将成为领导者，如果没有超过，继续选举；</li></ol><h3 id="故障转移机制"><a href="#故障转移机制" class="headerlink" title="故障转移机制"></a>故障转移机制</h3><ol><li>由Sentinel节点定期监控发现主节点是否出现了故障，sentinel会向master发送心跳PING来确认master是否存活，如果master在一定时间范围内不回应PONG或者是回复了一个错误消息，那么这个sentinel会主观地（单方面地）认为这个master已经不可用了。</li><li>当主节点出现故障，此时3个Sentinel节点共同选举了Sentinel3节点为领导，负载处理主节点的故障转移。</li><li>由Sentinel3领导者节点执行故障转移，过程和主从复制一样，但是自动执行。</li></ol><h3 id="故障处理流程"><a href="#故障处理流程" class="headerlink" title="故障处理流程"></a>故障处理流程</h3><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic6.png" srcset="/img/loading.gif" class=""><ol><li>将slave-1脱离原从节点，升级主节点，</li><li>将从节点slave-2指向新的主节点。</li><li>通知客户端主节点已更换。</li><li>将原主节点（oldMaster）变成从节点，指向新的主节点。</li></ol><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic7.png" srcset="/img/loading.gif" class=""><h3 id="主节点的选择方式"><a href="#主节点的选择方式" class="headerlink" title="主节点的选择方式"></a>主节点的选择方式</h3><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic8.png" srcset="/img/loading.gif" class=""><ol><li>过滤掉不健康的(下线或断线)，没有回复过哨兵ping响应的从节点</li><li>选择slave-priority从节点优先级最高（redis.conf）</li><li>选择复制偏移量最大，指复制最完整的从节点</li></ol><h2 id="redis分布式数据库"><a href="#redis分布式数据库" class="headerlink" title="redis分布式数据库"></a>redis分布式数据库</h2><p>RedisCluster是Redis的分布式解决方案，在3.0版本后推出的方案，有效地解决了Redis分布式的需求，当遇到单机内存、并发等瓶颈时，可使用此方案来解决这些问题。</p><h3 id="分布式数据库概念"><a href="#分布式数据库概念" class="headerlink" title="分布式数据库概念"></a>分布式数据库概念</h3><p>分布式数据库把整个数据按分区规则映射到多个节点，即把数据划分到多个节点上，每个节点负责整体数据的一个子集。</p><p>比如我们库有900条用户数据，有3个redis节点，将900条分成3份，分别存入到3个redis节点</p><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic10.png" srcset="/img/loading.gif" class=""><h3 id="分区规则"><a href="#分区规则" class="headerlink" title="分区规则"></a>分区规则</h3><p>常见的分区规则哈希分区和顺序分区，redis集群使用了哈希分区，顺序分区暂用不到，不做具体说明。</p><p>RedisCluster采用了哈希分区的“虚拟槽分区”方式（哈希分区分节点取余、一致性哈希分区和虚拟槽分区）。</p><h3 id="虚拟槽分区"><a href="#虚拟槽分区" class="headerlink" title="虚拟槽分区"></a>虚拟槽分区</h3><p>槽：slot</p><p>RedisCluster采用此分区，所有的键根据哈希函数(CRC16[key]&amp;16383)映射到0－16383槽内，共16384个槽位，每个节点维护部分槽及槽所映射的键值数据</p><p>哈希函数: Hash()=CRC16[key]&amp;16383</p><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic11.png" srcset="/img/loading.gif" class=""><h3 id="槽、键、数据关系"><a href="#槽、键、数据关系" class="headerlink" title="槽、键、数据关系"></a>槽、键、数据关系</h3><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic12.png" srcset="/img/loading.gif" class=""><h3 id="RedisCluster的缺陷"><a href="#RedisCluster的缺陷" class="headerlink" title="RedisCluster的缺陷"></a>RedisCluster的缺陷</h3><ul><li><p>键的批量操作支持有限，比如mset, mget，如果多个键映射在不同的槽就会出错。</p></li><li><p>键事务支持有限，当多个键分布在不同节点时无法使用事务，同一节点是支持事务</p></li><li><p>键是数据分区的最小粒度，不能将一个很大的键值对映射到不同的节点</p></li><li><p>不支持多数据库，标号为0的数据库。</p></li><li><p>复制结构只支持单层结构，不支持树型结构。</p></li></ul><h3 id="集群节点之间的通信"><a href="#集群节点之间的通信" class="headerlink" title="集群节点之间的通信"></a>集群节点之间的通信</h3><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic13.png" srcset="/img/loading.gif" class=""><p>节点之间采用Gossip协议进行通信，节点彼此之间不断通信交换消息，当主从角色变化或新增节点，彼此通过ping/pong进行通信知道全部节点的最新状态并达到集群同步</p><p>Gossip协议的主要职责就是信息交换，信息交换的载体就是节点之间彼此发送的Gossip消息，常用的Gossip消息有ping消息、pong消息、meet消息、fail消息</p><ul><li><p>meet消息：用于通知新节点加入，消息发送者通知接收者加入到当前集群，meet消息通信完后，接收节点会加入到集群中，并进行周期性ping pong交换</p></li><li><p>ping消息：集群内交换最频繁的消息，集群内每个节点每秒向其它节点发ping消息，用于检测节点是在在线和状态信息，ping消息发送封装自身节点和其他节点的状态数据；</p></li><li><p>pong消息，当接收到ping meet消息时，作为响应消息返回给发送方，用来确认正常通信，pong消息也封闭了自身状态数据；</p></li><li><p>fail消息：当节点判定集群内的另一节点下线时，会向集群内广播一个fail消息</p></li></ul><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic14.png" srcset="/img/loading.gif" class=""><p>以上的所有消息格式为：消息头、消息体，消息头包含发送节点自身状态数据（比如节点ID、槽映射、节点角色、是否下线等），接收节点根据消息头可以获取到发送节点的相关数据。</p><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic15.png" srcset="/img/loading.gif" class=""><p>Gossip协议信息的交换机制具有天然的分布式特性，但ping pong发送的频率很高。</p><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic16.png" srcset="/img/loading.gif" class=""><h4 id="命令重定向"><a href="#命令重定向" class="headerlink" title="命令重定向"></a>命令重定向</h4><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic17.png" srcset="/img/loading.gif" class=""><h4 id="主观下线流程"><a href="#主观下线流程" class="headerlink" title="主观下线流程"></a>主观下线流程</h4><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic18.png" srcset="/img/loading.gif" class=""><h4 id="客观下线流程"><a href="#客观下线流程" class="headerlink" title="客观下线流程"></a>客观下线流程</h4><p>节点真正的下线，集群内多个节点都认为该节点不可用，达成共识，将它下线，如果下线的节点为主节点，还要对它进行故障转移</p><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic19.png" srcset="/img/loading.gif" class=""><h4 id="故障恢复"><a href="#故障恢复" class="headerlink" title="故障恢复"></a>故障恢复</h4><p>故障主节点下线后，如果下线节点的是主节点，则需要在它的从节点中选一个替换它，保证集群的高可用</p><img src="/2020/04/30/redis%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/pic20.png" srcset="/img/loading.gif" class="">]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>redis的弱事务</title>
    <link href="/2020/04/29/redis%E7%9A%84%E5%BC%B1%E4%BA%8B%E5%8A%A1/"/>
    <url>/2020/04/29/redis%E7%9A%84%E5%BC%B1%E4%BA%8B%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<h2 id="RESP协议"><a href="#RESP协议" class="headerlink" title="RESP协议"></a>RESP协议</h2><p>Redis服务器与客户端通过RESP(REdisSerializationProtocol)协议通信。主要以下特点：实现简单、解析快、人类可读。RESP底层采用的是TCP的连接方式，通过tcp进行数据传输，然后根据解析规则解析相应信息，完成交互。</p><p>我们可以测试下，首先运行一个serverSocket监听6379，来接收redis客户端的请求信息，实现如下：</p><p>服务端程序如下：</p><pre><code class="java">public class ServerRedis{  public static void main(String[] args){    try {      ServerSocket server = new ServerSocket(6379);      Socket rec = server.accept();      byte[] result = new byte[2048];      rec.getInputStream().read(result);      System.out.println(new String(result))    } catch (IOException e){      e.printStackTrace();    }  }}</code></pre><p>客户端程序如下：</p><pre><code class="java">public class JedisTest{  public static void main(String[] args){    Jedis jedis = new Jedis(&quot;127.0.0.1&quot;,6379);    jedis.set(&quot;key&quot;,&quot;value&quot;);    jedis.close();  }}</code></pre><p>服务端打印的信息如下：</p><pre><code>*3$3SET$3key$5value</code></pre><p>其中*表示后面有几组数据，set key value共三组，所以为*3</p><p>$表示本组数据的长度，所以SET、key为3，value为5</p><h2 id="数据库表数据存储到redis"><a href="#数据库表数据存储到redis" class="headerlink" title="数据库表数据存储到redis"></a>数据库表数据存储到redis</h2><p>原理就是将数据库中查询出的数据按照RESP协议处理，然后使用PIPE管道导入到redis。</p><p>流程如下:</p><ul><li>使用用户名和密码登陆连接数据库</li><li>登陆成功后执行order.sql的select语句得到查询结果集result</li><li>使用密码登陆Redis</li><li>Redis登陆成功后，使用PIPE管道将result导入redis。</li></ul><p>操作指令如下:<br><code>mysql -utest -ptest stress --default-character-set=utf8 --skip-column-names --raw &lt; order.sql | redis-cli -h 192.168.42.111 -p 6379 -a 12345678 --pipe</code></p><p>–raw是指将order.sql中的文件按行执行。</p><p>order.sql文件</p><pre><code class="mysql">SELECT CONCAT( &#39;*10\r\n&#39;,   &#39;$&#39;, LENGTH(redis_cmd), &#39;\r\n&#39;, redis_cmd, &#39;\r\n&#39;,   &#39;$&#39;, LENGTH(redis_key), &#39;\r\n&#39;, redis_key, &#39;\r\n&#39;,   &#39;$&#39;, LENGTH(hkey1),&#39;\r\n&#39;,hkey1,&#39;\r\n&#39;,   &#39;$&#39;, LENGTH(hval1),&#39;\r\n&#39;,hval1,&#39;\r\n&#39;,   &#39;$&#39;, LENGTH(hkey2),&#39;\r\n&#39;,hkey2,&#39;\r\n&#39;,   &#39;$&#39;, LENGTH(hval2),&#39;\r\n&#39;,hval2,&#39;\r\n&#39;,   &#39;$&#39;, LENGTH(hkey3),&#39;\r\n&#39;,hkey3,&#39;\r\n&#39;,   &#39;$&#39;, LENGTH(hval3),&#39;\r\n&#39;,hval3,&#39;\r\n&#39;,   &#39;$&#39;, LENGTH(hkey4),&#39;\r\n&#39;,hkey4,&#39;\r\n&#39;,   &#39;$&#39;, LENGTH(hval4),&#39;\r\n&#39;,hval4,&#39;\r&#39;)FROM ( SELECT &#39;HSET&#39; AS redis_cmd, CONCAT(&#39;order:info:&#39;,orderid) AS redis_key, &#39;ordertime&#39; AS hkey1, ordertime AS hval1, &#39;ordermoney&#39; AS hkey2, ordermoney AS hval2, &#39;orderstatus&#39; AS hkey3, orderstatus AS hval3, &#39;version&#39; AS hkey4, `version` AS hval4 FROM `order`) AS t</code></pre><h2 id="socket连接redis"><a href="#socket连接redis" class="headerlink" title="socket连接redis"></a>socket连接redis</h2><pre><code class="java">public class SocketRedis {    public static String set(Socket socket,String key, String value) throws IOException {        StringBuffer str = new StringBuffer();        str.append(&quot;*3&quot;).append(&quot;\r\n&quot;);        str.append(&quot;$3&quot;).append(&quot;\r\n&quot;);        str.append(&quot;SET&quot;).append(&quot;\r\n&quot;);        str.append(&quot;$&quot;).append(key.getBytes().length).append(&quot;\r\n&quot;);        str.append(key).append(&quot;\r\n&quot;);        str.append(&quot;$&quot;).append(value.getBytes().length).append(&quot;\r\n&quot;);        str.append(value).append(&quot;\r\n&quot;);        socket.getOutputStream().write(str.toString().getBytes());        byte[] response = new byte[2048];        socket.getInputStream().read(response);        return new String(response);    }    public static String get(Socket socket,String key) throws IOException {        StringBuffer str = new StringBuffer();        str.append(&quot;*2&quot;).append(&quot;\r\n&quot;);        str.append(&quot;$3&quot;).append(&quot;\r\n&quot;);        str.append(&quot;GET&quot;).append(&quot;\r\n&quot;);        str.append(&quot;$&quot;).append(key.getBytes().length).append(&quot;\r\n&quot;);        str.append(key).append(&quot;\r\n&quot;);        socket.getOutputStream().write(str.toString().getBytes());        byte[] response = new byte[2048];        socket.getInputStream().read(response);        return new String(response);    }    public static void main(String[] args) throws IOException {        Socket socket = new Socket(&quot;127.0.0.1&quot;,6379);        set(socket,&quot;test&quot;,&quot;value&quot;);        System.out.println(get(socket,&quot;test&quot;));    }}</code></pre><h2 id="PIPELINE操作"><a href="#PIPELINE操作" class="headerlink" title="PIPELINE操作"></a>PIPELINE操作</h2><p>单指令批量操作执行过程</p><p>每次执行命令前都需要通过网络发送命令、获取结果，网络开销大，对执行时间有比较大的影响。</p><p>pipeline可以将多个指令封装，然后请求到redis，返回结果，这样只需要通过网络发送、返回一次，减少了网络开销。</p><p>使用方法</p><pre><code class="java">public class ServiceTest {    public static void delNoPipe(String...keys){        Jedis jedis = new Jedis(RedisTools.ip,RedisTools.port);        Pipeline pipelined = jedis.pipelined();        for(String key:keys){            pipelined.del(key);//redis?        }        pipelined.sync();//        jedis.close();    }}</code></pre><h2 id="redis事务"><a href="#redis事务" class="headerlink" title="redis事务"></a>redis事务</h2><p>pipeline其实是对多条命令的组合，为了保证它的原子性，redis提供了简单的事务。使用方法为将一组需要一起执行的命令放到multi和exec两个命令之间，其中multi代表事务开始，exec代表事务结束，discard取消事务，watch命令用于监视key，如果事务执行之前key被改动，事务将被打断（取消），对应的有unwatch命令，用于取消watch操作。</p><p>如果事务执行中，出现命令错误，导致事务不能正常结束，就会发生回滚。但如果出现类型错误，事务可以正常结束，就不会在进行回滚。</p><h2 id="redis发布与订阅"><a href="#redis发布与订阅" class="headerlink" title="redis发布与订阅"></a>redis发布与订阅</h2><p>redis提供了“发布、订阅”模式的消息机制，其中消息订阅者与发布者不直接通信，发布者向指定的频道（channel）发布消息，订阅该频道的每个客户端都可以接收到消息。</p><p>redis主要提供发布消息、订阅频道、取消订阅以及按照模式订阅和取消订阅，和很多专业的消息队列kafka rabbitmq相比比较简单，比如无法实现消息规程和回溯，可以使用在简单的应用。</p><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><ul><li>发布消息：<code>publish {channel} {message}</code></li><li>订阅消息：<code>subscrible {channel}</code></li><li>查看订阅数：<code>pubsub numsub {channel}</code></li><li>取消订阅：<code>unsubscribe {channel}</code></li><li>按模式（模糊匹配）订阅和取消订阅：<code>psubscribe ch*</code> <code>punsubscribe ch*</code></li></ul><h2 id="键的迁移"><a href="#键的迁移" class="headerlink" title="键的迁移"></a>键的迁移</h2><p>把部分数据迁移到另一台redis服务器，</p><ul><li><code>move {key} {db}</code> ：db为数据库编号，reids共有16个库， 编号为0－15，这种模式不建议在生产环境使用。数据库切换可以使用<code>select {db}</code>。</li><li><code>dump {key}</code>：在迁出的数据库上使用<code>dum {key}</code>，然后将获取到的值value复制到迁入的数据库，使用<code>restore {key} {time} {value}</code>。</li><li><code>migrate {迁入的目标ip} {端口} {key} {db} {timeout} copy|replace</code>：migrate命令是将dump、restore、del三个命令进行组合，从而简化了操作流程。migrate命令具有原子性，从Redis 3.0.6版本后已经支持迁移多个键的功能。migrate命令的数据传输直接在源Redis和目标Redis上完成，目标Redis完成restore后会发送OK给源Redis。</li></ul><h2 id="key的遍历"><a href="#key的遍历" class="headerlink" title="key的遍历"></a>key的遍历</h2><h3 id="全量遍历"><a href="#全量遍历" class="headerlink" title="全量遍历"></a>全量遍历</h3><p><code>keys  *</code>：返回所有的键, *匹配任意字符多个字符，全局匹配 ，可以使用正则表达式</p><p><code>keys n?me</code>：?问号代表只匹配一个字符 </p><p><code>keys [j,l]*</code>：返回以j、l开头的所有键</p><h3 id="渐进式遍历"><a href="#渐进式遍历" class="headerlink" title="渐进式遍历"></a>渐进式遍历</h3><p><code>scan 0 match n* count 5</code>：匹配以n开头的键，最大是取5条，第一次0开始，相当于一页一页的取，第二次取时将0改为返回的游标，当最后游标返回0时，键被取完。</p><p>scan相比keys具备有以下特点:</p><ol><li>通过游标分布进行的，不会阻塞线程;</li><li>提供limit参数，可以控制每次返回结果的最大条数，limit不准，返回的结果可多可少;</li><li>同keys一样，Scan也提供模式匹配功能;</li><li>服务器不需要为游标保存状态，游标的唯一状态就是scan返回给客户端的游标整数;</li><li>scan返回的结果可能会有重复，需要客户端去重复;</li><li>scan遍历的过程中如果有数据修改，改动后的数据能不能遍历到是不确定的;</li><li>单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零;</li></ol><h3 id="其他数据结构的遍历"><a href="#其他数据结构的遍历" class="headerlink" title="其他数据结构的遍历"></a>其他数据结构的遍历</h3><p>除scan字符串外：还有以下命令，用法和scan一样。</p><ul><li>SCAN 命令用于迭代当前数据库中的数据库键。</li><li>SSCAN 命令用于迭代集合键中的元素。</li><li>HSCAN 命令用于迭代哈希键中的键值对。</li><li>ZSCAN 命令用于迭代有序集合中的元素（包括元素成员和元素分值）。</li></ul>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>redis性能测试</title>
    <link href="/2020/04/29/redis%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    <url>/2020/04/29/redis%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<h2 id="redis慢查询"><a href="#redis慢查询" class="headerlink" title="redis慢查询"></a>redis慢查询</h2><p>与mysql一样，当执行时间超过极大值时，会将发生时间耗时命令记录。</p><img src="/2020/04/29/redis%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/pic1.png" srcset="/img/loading.gif" class=""><p>redis命令生命周期为发送、排队、执行、返回，慢查询只统计执行步骤的时间。</p><h3 id="慢查询的设置"><a href="#慢查询的设置" class="headerlink" title="慢查询的设置"></a>慢查询的设置</h3><p>慢查询极值的设置有两种方式</p><ul><li><p>使用<code>config set slowlog-log-slower-than 10000</code>命令修改，单位为微妙，redis重启后会失效。</p></li><li><p>修改redis.conf文件中的<code>slowlog-log-slower-than 10000</code>修改保存即可，设置为0时记录所有命令，-1时命令都不记录。</p></li></ul><p><code>slowlog-log-slower-than</code>默认为10毫秒，根据redis并发量来调整，对于高并发比建议为1毫秒。</p><p>慢查询记录是存在队列中的，可以通过<code>slow-max-len</code>设置存放记录的最大条数，比如设置的<code>slow-max-len＝10</code>，当有第11条慢查询命令插入时，队列的第一条命令就会出列，第11条入列， 可以设置方式与极值设置相同，可以<code>config set</code>动态设置，也可以修改redis.conf完成配置。线上可加大<code>slow-max-len</code>的值，记录慢查询存长命令时redis会做截断，不会占用大量内存，线上可设置1000以上。</p><p>慢查询是先进先出的队列，访问日志记录出列丢失，需定期执行slowlog get,将结果存储到其它设备中（如mysql）。</p><h3 id="慢查询命令"><a href="#慢查询命令" class="headerlink" title="慢查询命令"></a>慢查询命令</h3><ul><li>获取队列里慢查询的命令：<code>slowlog get</code></li><li>获取慢查询列表当前的长度：<code>slowlog len</code></li><li>对慢查询列表清理（重置）：<code>slowlog reset</code></li></ul><h2 id="redis性能测试"><a href="#redis性能测试" class="headerlink" title="redis性能测试"></a>redis性能测试</h2><p>可以使用redis的bin目录中的redis-benchmark命令进行测试</p><ul><li><code>redis-benchmark -h 192.168.42.111 -p 6379 -c 100 -n 10000</code>：100个并发连接，10000个请求，检测服务器性能 </li><li><code>redis-benchmark -h 192.168.42.111 -p 6379 -q -d 100</code>：测试存取大小为100字节的数据包的性能</li><li><code>redis-benchmark -h 192.168.42.111 -p 6379 -t set,get -n 100000 -q</code>：只测试 set,lpush操作的性能</li><li><code>redis-benchmark -h 192.168.42.111 -p 6379 -n 100000 -q script load &quot;redis.call(&#39;set&#39;,&#39;foo&#39;,&#39;bar&#39;)&quot;</code>：只测试某些数值存取的性能</li></ul>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>redis+lua实现抢红包</title>
    <link href="/2020/04/29/redis-lua%E5%AE%9E%E7%8E%B0%E6%8A%A2%E7%BA%A2%E5%8C%85/"/>
    <url>/2020/04/29/redis-lua%E5%AE%9E%E7%8E%B0%E6%8A%A2%E7%BA%A2%E5%8C%85/</url>
    
    <content type="html"><![CDATA[<h2 id="业务需求"><a href="#业务需求" class="headerlink" title="业务需求"></a>业务需求</h2><ol><li>将所有红包全部存储到Redis。</li><li>记录红包被抢的详情信息。</li><li>用户只能抢一次红包，不能重复抢红包。</li></ol><h2 id="结构设计"><a href="#结构设计" class="headerlink" title="结构设计"></a>结构设计</h2><img src="/2020/04/29/redis-lua%E5%AE%9E%E7%8E%B0%E6%8A%A2%E7%BA%A2%E5%8C%85/pic1.png" srcset="/img/loading.gif" class=""><img src="/2020/04/29/redis-lua%E5%AE%9E%E7%8E%B0%E6%8A%A2%E7%BA%A2%E5%8C%85/pic2.png" srcset="/img/loading.gif" class=""><img src="/2020/04/29/redis-lua%E5%AE%9E%E7%8E%B0%E6%8A%A2%E7%BA%A2%E5%8C%85/pic3.png" srcset="/img/loading.gif" class=""><h2 id="业务流程"><a href="#业务流程" class="headerlink" title="业务流程"></a>业务流程</h2><img src="/2020/04/29/redis-lua%E5%AE%9E%E7%8E%B0%E6%8A%A2%E7%BA%A2%E5%8C%85/pic4.png" srcset="/img/loading.gif" class=""><p><code>Object object=jedis.eval(getHongBaoScript,4,hongBaoPoolKey,hongBaoDetailListKey,userIdRecordKey,userid);</code></p><pre><code class="lua">if redis.call(&#39;hexists&#39;,KEYS[3],KEYS[4]) ~=0 then  return nilelse  local hongBao = redis.call(&#39;rpop&#39;,KEYS[1]);  if hongBao then    local x = cjson.decode(hongBao);    x[&#39;userId&#39;] = KEYS[4];    local re = cjson.encode(x);    redis.call(&#39;hset&#39;,KEYS[3],KEYS[4],&#39;1&#39;);    redis.call(&#39;lpush&#39;,KEYS[2],re);    return re;  endendreturn nil</code></pre>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>redis+lua实现限流</title>
    <link href="/2020/04/29/redis-lua%E5%AE%9E%E7%8E%B0%E9%99%90%E6%B5%81/"/>
    <url>/2020/04/29/redis-lua%E5%AE%9E%E7%8E%B0%E9%99%90%E6%B5%81/</url>
    
    <content type="html"><![CDATA[<h2 id="lua语言介绍"><a href="#lua语言介绍" class="headerlink" title="lua语言介绍"></a>lua语言介绍</h2><p>LUA脚本语言是C开发的，类似存储过程，使用LUA脚本的好处：</p><ul><li>减少网络开销，在Lua脚本中可以把多个命令放在同一个脚本中运行。</li><li>原子操作，redis会将整个脚本作为一个整体执行，中间不会被其他命令插入。换句话说，编写脚本的过程中无需担心会出现竞态条件。</li><li>复用性，客户端发送的脚本会永远存储在redis中，这意味着其他客户端可以复用这一脚本来完成同样的逻辑。</li></ul><h2 id="Lua在linux中的安装"><a href="#Lua在linux中的安装" class="headerlink" title="Lua在linux中的安装"></a>Lua在linux中的安装</h2><p>到官网下载lua的tar.gz的源码包</p><pre><code class="sh">wget http://www.lua.org/ftp/lua-5.3.5.tar.gztar -zxvf lua-5.3.0.tar.gzcd lua-5.2.0make linuxmake install</code></pre><p>如果报错，说找不到readline/readline.h, 可以通过yum命令安装</p><pre><code class="sh">yum -y install libtermcap-devel ncurses-devel libevent-devel readline-develmake linux  / make install</code></pre><p>最后，直接输入 lua命令即可进入lua的控制台</p><h2 id="lua基本语法"><a href="#lua基本语法" class="headerlink" title="lua基本语法"></a>lua基本语法</h2><ul><li>单行注释  –</li><li>多行注释–[[ –]]</li><li>Lua关键字</li></ul><table><thead><tr><th>and</th><th>break</th><th>do</th><th>else</th></tr></thead><tbody><tr><td>elseif</td><td>end</td><td>false</td><td>for</td></tr><tr><td>function</td><td>if</td><td>in</td><td>local</td></tr><tr><td>nil</td><td>not</td><td>or</td><td>repeat</td></tr><tr><td>return</td><td>then</td><td>true</td><td>until</td></tr><tr><td>while</td><td></td><td></td><td></td></tr></tbody></table><h2 id="lua数据类型"><a href="#lua数据类型" class="headerlink" title="lua数据类型"></a>lua数据类型</h2><p>Lua是动态类型语言，变量不要类型定义只需要为变量赋值。 值可以存储在变量中，作为参数传递或结果返回。</p><p>Lua中有8个基本类型分别为：nil、boolean、number、string、userdata、function、thread和table。</p><table><thead><tr><th>数据类型</th><th>描述</th></tr></thead><tbody><tr><td>nil</td><td>这个最简单，只有值nil属于该类，表示一个无效值（在条件表达式中相当于false）。</td></tr><tr><td>boolean</td><td>包含两个值：false和true。</td></tr><tr><td>number</td><td>表示双精度类型的实浮点数</td></tr><tr><td>string</td><td>字符串由一对双引号或单引号来表示</td></tr><tr><td>function</td><td>由 C 或 Lua 编写的函数</td></tr><tr><td>userdata</td><td>表示任意存储在变量中的C数据结构</td></tr><tr><td>thread</td><td>表示执行的独立线路，用于执行协同程序</td></tr><tr><td>table</td><td>Lua 中的表（table）其实是一个”关联数组”（associative arrays），数组的索引可以是数字或者是字符串。在 Lua 里，table 的创建是通过”构造表达式”来完成，最简单构造表达式是{}，用来创建一个空表。</td></tr></tbody></table><h2 id="lua执行流程"><a href="#lua执行流程" class="headerlink" title="lua执行流程"></a>lua执行流程</h2><h2 id="lua脚本的使用"><a href="#lua脚本的使用" class="headerlink" title="lua脚本的使用"></a>lua脚本的使用</h2><p>redis客户端连接成功后：</p><ul><li><p><code>script load &quot;$(cat xxxx.lua)&quot;</code>：将LUA脚本内容加载到redis， 返回的sha1值。</p></li><li><p><code>evalsha &quot;{sha1}&quot; {key} {arg}</code>：执行sha1值对应的脚本</p></li><li><p><code>script exists {sha1}</code>：检查sha1值的LUA脚本是否加载到redis中， 返回1为已加载成功。</p></li><li><p><code>script flush</code>：清空加载的lua脚本内容。</p></li><li><p><code>script kill</code>：杀掉正在执行的LUA脚本，比如LUA比较耗时阻塞，杀掉。</p></li></ul><h2 id="限流的方式"><a href="#限流的方式" class="headerlink" title="限流的方式"></a>限流的方式</h2><p>限制总并发数：比如数据库连接池、线程池</p><p>限制瞬时并发数：如nginx的limit_conn模块，用来限制瞬时并发连接数</p><p>限制时间窗口内的平均速率：如Guava的RateLimiter、nginx的limit_req模块，限制每秒平均速率</p><p>其它限制：如限制远程接口调用速率、限制MQ的消费速率</p><h2 id="java-redis实现限流"><a href="#java-redis实现限流" class="headerlink" title="java+redis实现限流"></a>java+redis实现限流</h2><p>实现某个ip在一定时间之内在time之内，只能访问limit次</p><pre><code class="java">private boolean accessLimit(String ip,int limit,Jedis jedis){  boolean result=true;  String key=&quot;rate.limit&quot; + ip;  if(jedis.exist(key)){    long afterValue = jedis.incr(key);    if(afterValue &gt; limit){      return false;    }  }eles{    Transaction transaction = jedis.multi();    transaction.incr(key);    transaction.expire(key,time);    transaction.exec();  }  return result;}</code></pre><p>但这种实现方式使用的redis的事务是弱事务不支持回滚，并不能完全保证操作的原子性，当多线程操作同一个key时可能会出现竞态问题。</p><h2 id="redis-lua实现限流"><a href="#redis-lua实现限流" class="headerlink" title="redis+lua实现限流"></a>redis+lua实现限流</h2><p>lua脚本</p><pre><code class="lua">local key =  KEYS[1]local limit = tonumber(ARGV[1])local expire_time = ARGV[2]local is_exists = redis.call(&quot;EXISTS&quot;, key)if is_exists == 1 then    if redis.call(&quot;INCR&quot;, key) &gt; limit then        return 0    else        return 1    endelse    redis.call(&quot;SET&quot;, key, 1)    redis.call(&quot;EXPIRE&quot;, key, expire_time)    return 1end</code></pre>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>redis常见场景设计</title>
    <link href="/2020/04/29/redis%E5%B8%B8%E8%A7%81%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/"/>
    <url>/2020/04/29/redis%E5%B8%B8%E8%A7%81%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<h2 id="key设计的注意事项"><a href="#key设计的注意事项" class="headerlink" title="key设计的注意事项"></a>key设计的注意事项</h2><p>一般以业务功能模块或者表名为前缀，再加上唯一主键，中间以冒号分隔，比如购物车cart:001，表示1号用户的购物车。设计以简短、明了以主， 节约内存。</p><h2 id="redis分布式锁"><a href="#redis分布式锁" class="headerlink" title="redis分布式锁"></a>redis分布式锁</h2><h4 id="加锁"><a href="#加锁" class="headerlink" title="加锁"></a>加锁</h4><p><code>SETNX {key} {value} ex|px {time}</code>指令可以将key的值设为value并指定一个失效时间，SETNX是SET if Not eXists(如果不存在，则 SET)的简写，如果key已经存在，则SETNX不会成功。</p><p>在加锁时通过setnx向特定的key写入一个随机值，并同时设置失效时间，写值成功既加锁成功。</p><p>注意：</p><ul><li>必须给锁设置一个失效时间， 避免死锁问题。</li><li>加锁时必须写入一个随机字符串，用于解锁时避免锁的误删。</li><li>整个过程必须是原子的。</li></ul><h4 id="解锁"><a href="#解锁" class="headerlink" title="解锁"></a>解锁</h4><p>解锁步骤为：</p><ol><li>获取key上的值</li><li>判断value中的随机字符串是否一致</li><li>删除数据</li></ol><p>这三个步骤必须要保证原子性，所以要借助lua脚本执行。</p><p>lua脚本：</p><pre><code class="java">if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then    return redis.call(&quot;del&quot;,KEYS[1])else    return 0end</code></pre><p>具体实现：</p><pre><code class="java">@Servicepublic class RedisLock implements Lock {    private static final String  KEY = &quot;LOCK_KEY&quot;;    @Resource    private JedisConnectionFactory factory;    private ThreadLocal&lt;String&gt; local = new ThreadLocal&lt;&gt;();    @Override    //阻塞式的加锁    public void lock() {        //1.尝试加锁        if(tryLock()){            return;        }        //2.加锁失败，当前任务休眠一段时间        try {            Thread.sleep(10);//性能浪费        } catch (InterruptedException e) {            e.printStackTrace();        }        //3.递归调用，再次去抢锁        lock();    }    @Override    //阻塞式加锁,使用setNx命令返回OK的加锁成功，并生产随机值    public boolean tryLock() {        //产生随机值，标识本次锁编号        String uuid = UUID.randomUUID().toString();        Jedis jedis = (Jedis) factory.getConnection().getNativeConnection();        /**         * key:我们使用key来当锁         * uuid:唯一标识，这个锁是我加的，属于我         * NX：设入模式【SET_IF_NOT_EXIST】--仅当key不存在时，本语句的值才设入         * PX：给key加有效期         * 1000：有效时间为 1 秒         */        String ret = jedis.set(KEY, uuid,&quot;NX&quot;,&quot;PX&quot;,1000);        //设值成功--抢到了锁        if(&quot;OK&quot;.equals(ret)){            local.set(uuid);//抢锁成功，把锁标识号记录入本线程--- Threadlocal            return true;        }        //key值里面有了，我的uuid未能设入进去，抢锁失败        return false;    }    //正确解锁方式    public void unlock() {        //读取lua脚本        String script = FileUtils.getScript(&quot;unlock.lua&quot;);        //获取redis的原始连接        Jedis jedis = (Jedis) factory.getConnection().getNativeConnection();        //通过原始连接连接redis执行lua脚本        jedis.eval(script, Arrays.asList(KEY), Arrays.asList(local.get()));    }    //-----------------------------------------------    @Override    public Condition newCondition() {        return null;    }    @Override    public boolean tryLock(long time, TimeUnit unit)            throws InterruptedException {        return false;    }    @Override    public void lockInterruptibly() throws InterruptedException {    }}</code></pre><h2 id="购物车"><a href="#购物车" class="headerlink" title="购物车"></a>购物车</h2><p>所需要的功能：</p><ul><li><p>全选功能：获取该用户的所有购物车商品</p></li><li><p>商品数量：购物车里商品的总数</p></li><li><p>删除：要能移除购物车里某个商品</p></li><li><p>增加或减少某个商品的数量</p></li></ul><p>设计实现：以当前登录用户ID号做为key，商品ID号为field, 加入购物车数量为value。如<code>hmset cart:001 prod:01 1 prod:02 1</code>。</p><h2 id="堆栈功能"><a href="#堆栈功能" class="headerlink" title="堆栈功能"></a>堆栈功能</h2><p>可以利用List实现堆、栈的先进后出，先进先出功能</p><ul><li>先进后出：存取操作都在队列左端或右端即可，如LPUSH+LPOP</li><li>先进先出：存取操作的两端必须相反，如LPUSH + RPOP</li></ul><h2 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h2><img src="/2020/04/29/redis%E5%B8%B8%E8%A7%81%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/pic1.png" srcset="/img/loading.gif" class=""><p>阻塞队列可以使用BRPOP指令来实现，当队列中没有元素是会一直阻塞。</p><h2 id="生成数据库主键标识"><a href="#生成数据库主键标识" class="headerlink" title="生成数据库主键标识"></a>生成数据库主键标识</h2><p>可以使用incr指令在入库前将对应的主键加1，但redis每秒支持的并发量是有上限的，这么做会对redis的性能有比较大的影响，这时可以通过incry指令一次获取多个主键标识，如<code>incrby serialNo 1000</code>获取1000个标识，放到系统中使用，使用完后再去获取。</p><h2 id="文章列表"><a href="#文章列表" class="headerlink" title="文章列表"></a>文章列表</h2><p>发表文章时将文章ID加入list中，然后通过lrange指令获取，如</p><ul><li><p>XX发布一篇文章ID为999：<code>lpush mes:004 999</code></p></li><li><p>XXX也发布了一条消息ID为1000：<code>lpush mes:004 1000</code></p></li><li><p>获取文章列表实现如下：<code>lrange mes:004 0 5</code></p></li></ul><h2 id="抽奖"><a href="#抽奖" class="headerlink" title="抽奖"></a>抽奖</h2><p>可以使用set实现，将所有参与者加入set中，然后用srandmember或者spop命令随机抽取，如：</p><p>活动id为001，用户id为004</p><ul><li>当004参与抽奖时放入set集合：<code>sadd act:001 004</code></li><li>抽取2名中奖者：<code>srandmember act:001 2</code>或<code>spop act:001 2</code>，spop会移除用户。</li><li>查看有多少用户参加了本次抽奖：<code>smembers act:001</code></li></ul><h2 id="点赞"><a href="#点赞" class="headerlink" title="点赞"></a>点赞</h2><p>点赞的实现也可以借助set，如果有顺序要求可以使用zset</p><p>如张三用户id为01</p><ul><li><p>张三对消息008点赞<code>sadd zan:008  userId:01</code></p></li><li><p>张三取消了对消息008的点赞<code>srem zan:008  userId:01</code></p></li><li><p>检查用户是否点过赞<code>sismember zan:008  userId:01</code></p></li><li><p>获取消息008所有的点赞用户列表<code>smembers zan:008</code></p></li><li><p>消息008的点赞数计算<code>scard zan:008</code></p></li></ul><h2 id="关注"><a href="#关注" class="headerlink" title="关注"></a>关注</h2><ul><li>user1关注的人：<code>sadd user1:care user2,user4,user5,user3</code></li><li>user2关注的人：<code>sadd user2:care user1,user3,user6,user5</code></li><li>user3关注的人：<code>sadd user3:care deer,user6,user5</code></li><li>user1和user2共同关注的人，求交集：<code>sinter user1:care user2:care</code>, 计算结果为 {user3, user5}</li><li>user1关注的人也关注user5，判断user5是否在关注的人的集合中存在：<code>sismember user2:care user5</code>，<code>sismember user3:care user5</code></li><li>user1可能认识的人，也可以先并集后差集：<code>SDIFF user2:care user1:care</code>，结果为{user1.user6}</li></ul><h2 id="每日热搜"><a href="#每日热搜" class="headerlink" title="每日热搜"></a>每日热搜</h2><p>热搜功能可以使用zset来实现，以日期做为Key ：</p><ul><li>点击id为1的话题： <code>zincrby topic:20191022 1 topic:1</code></li><li>展示今日前20排名：<code>zrevrange topic:20191022 0 20 withscores</code></li><li>统计近3日点击数据：<code>zunionstore topic:20191022-20191020 3 topic:20191022 topic:20191021 topic:20191020</code></li><li>展示近3日的排行前9名：<code>zrevrange topic:20191022-20191020 0 9 withscores</code></li></ul>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>redis的指令</title>
    <link href="/2020/04/28/redis%E7%9A%84%E6%8C%87%E4%BB%A4/"/>
    <url>/2020/04/28/redis%E7%9A%84%E6%8C%87%E4%BB%A4/</url>
    
    <content type="html"><![CDATA[<h2 id="指令使用"><a href="#指令使用" class="headerlink" title="指令使用"></a>指令使用</h2><h3 id="通用指令"><a href="#通用指令" class="headerlink" title="通用指令"></a>通用指令</h3><ol><li>查看所有键：keys * </li><li>键总数：dbsize //如果存在大量键，线上禁止使用此指令</li><li>检查键是否存在：exists {key} //存在返回1，不存在返回0</li><li>删除键：del {key} //返回删除键个数，删除不存在键返回0</li><li>键过期：expire {key} {seconds}</li><li>查看剩余过期时间：ttl {key}</li><li>键的数据结构类型：type {key}</li><li>切换数据库：select {0-15} //默认为0</li></ol><h3 id="字符串指令"><a href="#字符串指令" class="headerlink" title="字符串指令"></a>字符串指令</h3><ul><li><p>设值指令：</p><ul><li><code>set {key} {value} ex|px {time}</code>：ex秒，px毫秒，设置键并指定过期时间</li><li><code>setnx {key} {value}</code>：不存在key时，返回1设置成功，存在的话失败0，可做分布式锁。</li><li><code>set {key} {value}</code> ：存在key时，返回1成功</li><li><code>mset {key1} {value1} {key2} {value2}</code> ：批量设值</li></ul></li><li><p>获值指令：</p><ul><li><code>get {key}</code>：存在则返回 value, 不存在返回 nil</li><li><code>mget {key1} {key2} {key3}</code>：</li></ul></li><li><p>计数指令：</p><ul><li><code>incr {key}</code>：key必须为整数，非整数返回错误，无 key键从将创建key加1，有key将加1</li><li><code>decr {key}</code>：整数key减1</li><li><code>incrby {key} {num}</code>：整数key+num</li><li><code>decrby {key} {num}</code>：整数key-num</li><li><code>incrbyfloat {key} {score}</code>：浮点型 key+score</li></ul></li><li><p>追加指令：append {key} {value}：</p></li><li><p>获取长度：strlen {key}</p></li><li><p>截取字符串：getrange {key} {start} {end}</p></li><li><p>获取编码格式：object encodeing {key} \embstr小于等于39字符，raw大于39字符，int数字类型且字长小于8</p></li></ul><h3 id="hash指令"><a href="#hash指令" class="headerlink" title="hash指令"></a>hash指令</h3><ul><li>设值指令：<code>hset {key} {hkey} {hvalue}</code></li><li>取值指令：<code>hget {key} {hkey}</code></li><li>删值指令：<code>hdel {key} {hkey}</code></li><li>计算个数：<code>hdel {key} {hkey}</code></li><li>判断hkey是否存在：<code>hexists {key} {hkey}</code></li><li>获取所有hkey：<code>hkeys {key}</code></li><li>获取所有hvalue：<code>hvals {key}</code></li><li>获取所有hkey跟hvalue：<code>hgetall {key}</code></li><li>整型hvalue增加num：<code>hincrby {key} {hkey} {num}</code></li><li>浮点型hvalue增加num：<code>hincrbyfloat {key} {hkey} {num}</code></li><li>内部编码：<code>object encoding {key}</code> //当hkey个数少且没有大的hvalue时，内部编码为ziplist，当hvalue大于64字节，内部编码由ziplist变成hashtable。</li></ul><h3 id="列表指令"><a href="#列表指令" class="headerlink" title="列表指令"></a>列表指令</h3><ul><li>添加命令<ul><li><code>rpush {key} {value1} {value2} {value3}</code>：从右向左插入value，返回值为插入个数</li><li><code>lpush {key} {value1} {value2} {value3}</code>：从左向右插入value</li><li><code>linsert {key} before {value1} {value2}</code> ：在value1之前插入value2</li></ul></li><li>查找指令<ul><li><code>lrange {key} {start} {end}</code> ：从左到右获取列中的元素</li><li><code>llen {key}</code>：返回当前列表长度</li><li><code>lpop {key}</code>：删除最左边的元素</li><li><code>rpop {key}</code>：删除最右边的元素</li><li><code>lrem key {count} {value}</code>：删除指定元素</li></ul></li><li>内部编码：在3.2版本以后，redis提供了quicklist内部编码，它结合了ziplist和linkedlist两者的优势，之前的ziplist是存在BUG的，使用quicklist内部编码效率更高。</li></ul><h3 id="集合指令"><a href="#集合指令" class="headerlink" title="集合指令"></a>集合指令</h3><ul><li><p><code>exists {key}</code>：检查键值是否存在</p></li><li><p><code>sadd {key} {value1} {value2} {value3}</code>：插入元素，返回值为插入个数，若加入相同的元素，则不会加入插入个数。</p></li><li><p><code>smembers {key}</code>：获取key的所有元素，返回结果无序</p></li><li><p><code>srem {key} {value}</code>：返回 1，删除value</p></li><li><p><code>scard {key}</code>：计算元素个数</p></li><li><p><code>sismember {key} {value}</code>：判断元素是否在集合存在，存在返回 1，不存在 0</p></li><li><p><code>srandmember {key} {num}</code>：随机返回num个元素</p></li><li><p><code>spop {key} {num}</code>：随机返回num个元素并将元素从集合中删除</p></li><li><p><code>sinter {key1} {key2} {key3}</code>：求集合交集</p></li><li><p><code>sunion {key1} {key2} {key3}</code>：求集合并集</p></li><li><p><code>sdiff {key1} {key2}</code>：求key1和key2差集</p></li><li><p><code>sinterstore {key3} {key1} {key2}</code>：将key1、key2的交集保存到key3</p></li><li><p><code>sunionstore {key3} {key1} {key2}</code>：将key1、key2的并合集保存key3</p></li><li><p><code>sdiffstore {key3} {key1} {key2}</code>：将key1、key2的差集保存key3</p></li></ul><p>内部编码：当元素个数少（小于512个）且都为整数，使用intset减少内存的使用，当超过512个或不为整数（比如ab）时，编码为hashtable。</p><h3 id="有序集合"><a href="#有序集合" class="headerlink" title="有序集合"></a>有序集合</h3><ul><li><code>zadd {key} {score1} {skey1} {score2} {skey2}</code>：添加到集合</li><li><code>zadd {key} nx {score} {skey}</code>：键skey须不存在，主要用于添加</li><li><code>zadd {key} xx incr {score} {skey}</code>：键skey必须存在，主要用于修改</li><li><code>zadd {key} xx ch incr {score} {skey}</code>：返回score的和，此时的score可以为负</li><li><code>zrange {key} 0 -1 withscores</code>：正序查看所有成员</li><li><code>zrevrange {key} 0 -1 withscores</code>：倒序查看所有成员</li><li><code>zcard {key}</code>：计算成员个数</li><li><code>zrangebyscore {key} {score1} {score2} withscores</code>：正序返回指定分数范围的成员</li><li><code>zrevrangebyscore {key} {score2} {score1} withscores</code>：倒序返回指定分数范围的成员</li><li><code>zrangebyscore {key} {score1} +inf withscores</code>：正序返回score1到无限大</li><li><code>zrevrangebyscore {key} {score1} -inf withscores</code>：倒序返回无限小到score1</li><li><code>zcount {key} {score1} {score2}</code>：返回指定分数范围的成员个数</li><li><code>zremrangebyrank {key} {index1} {index2}</code>：分数升序排列，删除第index1跟index2的数据</li><li><code>zremrangebyscore {key} {score1} {score2}</code>：删除分数在score1到score2范围的成员</li><li><code>zremrangebyscore {key} {score1} +inf</code>：删除分数大于score1的成员</li><li><code>zinterstore destination numkeys key ... [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX]</code>：有序集合交集，destination：交集产生新的元素存储键名称，numkeys：要做交集计算的键个数，key：元素键值，weights：每个被选中的键对应值乘weight,默认为1。</li><li><code>zunionstore destination numkeys key ... [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX]</code>：有序集合并集，destination:交集产生新的元素存储键名称，numkeys:要做交集计算的键个数，key:元素键值，weights：每个被选中的键对应值乘weight,默认为1。</li></ul>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>redis的基本介绍</title>
    <link href="/2020/04/28/redis%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/"/>
    <url>/2020/04/28/redis%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<h2 id="redis介绍"><a href="#redis介绍" class="headerlink" title="redis介绍"></a>redis介绍</h2><p>redis是一种基于键值对(key-value)数据库，其中value可以为string、hash、list、set、zset等多种数据结构，可以满足很多应用场景。还提供了键过期，发布订阅，事务，流水线，等附加功能。</p><p>流水线：Redis的流水线功能允许客户端一次将多个命令请求发送给服务器，并将被执行的多个命令请求的结果在一个命令回复中全部返回给客户端，使用这个功能可以有效地减少客户端在执行多个命令时需要与服务器进行通信的次数。</p><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><ol><li>速度快，数据放在内存中，官方给出的读写性能10万/S，与机器性能也有关。<ul><li>数据放内存中是速度快的主要原因。</li><li>C语言实现，与操作系统距离近。</li><li>使用了单线程架构，预防多线程可能产生的竞争问题。</li><li>协议简单。</li></ul></li><li>键值对的数据结构丰富。</li><li>丰富的功能：见上功能</li><li>简单稳定：单线程</li><li>持久化：发生断电或机器故障，数据可能会丢失，持久化到硬盘</li><li>主从复制：实现多个相同数据的redis副本</li><li>高可用和分布式：哨兵机制实现高可用，保证redis节点故障发现和自动转移</li><li>客户端语言多：java、php、python、c、c++、nodejs等</li></ol><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><ul><li>缓存：合理使用缓存加快数据访问速度，降低后端数据源压力 </li><li>排行榜：按照热度排名，按照发布时间排行，主要用到列表和有序集合</li><li>计数器应用：视频网站播放数，网站浏览数，使用 redis 计数 </li><li>社交网络：赞、踩、粉丝、下拉刷新</li><li>消息队列：发布和订阅</li></ul><h2 id="可执行文件介绍"><a href="#可执行文件介绍" class="headerlink" title="可执行文件介绍"></a>可执行文件介绍</h2><table><thead><tr><th>可执行文件</th><th>作用</th></tr></thead><tbody><tr><td>redis-server</td><td>启动redis</td></tr><tr><td>redis-cli</td><td>redis命令行客户端</td></tr><tr><td>redis-benchmark</td><td>基准测试工具</td></tr><tr><td>redis-check-aof</td><td>AOF持久化文件检测和修复工具</td></tr><tr><td>redis-check-dump</td><td>RDB持久化文件检测和修复工具</td></tr><tr><td>redis-sentinel</td><td>启动哨兵</td></tr></tbody></table><h2 id="redis的启动"><a href="#redis的启动" class="headerlink" title="redis的启动"></a>redis的启动</h2><h3 id="redis-server启动"><a href="#redis-server启动" class="headerlink" title="redis-server启动"></a>redis-server启动</h3><ul><li>默认配置：redis-server，日志输出版本信息，端口：6379</li><li>运行启动：redis-server –port 6380 不建议</li><li>配置文件启动:redis-server/opt/redis/redis.conf灵活生产环境使用这种</li></ul><h3 id="redis-cli启动"><a href="#redis-cli启动" class="headerlink" title="redis-cli启动"></a>redis-cli启动</h3><ul><li>交互式：redis-cli -h {host} -p {prot}连接到redis服务，没有h默认连 127.0.0.1，没有 p 默认连 6379 。</li><li>命令式：redis-cli -h 127.0.0.1 -p 6379 get hello，取key=hello的value</li><li>停止redis 服务： redis-cli shutdown<br>注意：<ul><li>关闭时：断开连接，持久化文件生成，相对安全</li><li>还可以用 kill 关闭，此方式不会做持久化，还会造成缓冲区非法关闭，可能会造成 AOF 和丢失数据</li><li>关闭前生成持久化文件：使用 redis-cli -a 123456 登录进去，再shutdown nosave|save</li></ul></li></ul><h2 id="版本号说明"><a href="#版本号说明" class="headerlink" title="版本号说明"></a>版本号说明</h2><ul><li>版本号第二位为奇数，为非稳定版本（2.7、2.9、3.1），第二位偶数，为稳定版本（2.6、2.8、3.0）</li><li>当前奇数版本是下一个稳定版本的开发版本，如 2.9 是 3.0 的开发版本</li></ul><h2 id="缓存雪崩和穿透"><a href="#缓存雪崩和穿透" class="headerlink" title="缓存雪崩和穿透"></a>缓存雪崩和穿透</h2><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>为节约内存，Redis一般会做定期清除操作。比如james值过期，当查询key=james的值，此时Redis没有数据，如果有5000个用户并发来查询key=james，就全部都会到Mysql里去查，导致Mysql压力过大这就是缓存雪崩。</p><p>解决方案有两种：设置热点数据永远不过期或者加互斥锁，保证只能有一个用户进入mysql查询，其他用户等待该用户查询完加入缓存后，从缓存中获取数据。</p><img src="/2020/04/28/redis%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/pic1.png" srcset="/img/loading.gif" class=""><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><img src="/2020/04/28/redis%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/pic2.png" srcset="/img/loading.gif" class=""><p>如果请求一个不存在的订单号会，redis中没有该数据，会直接到mysql中查询，可以将对订单表所有数据查询出来放到布隆过滤器，每次查订单表前，先到过滤器里查询当前订单号状态是0还是1，0的话代表数据库没有数据，直接拒绝查询。</p><h2 id="redis持久化"><a href="#redis持久化" class="headerlink" title="redis持久化"></a>redis持久化</h2><p>redis是一个支持持久化的内存数据库，持久化可以避免因进程退出而造成数据丢失，redis支持RDB和AOF两种持久化机制。</p><h3 id="RDB文件的操作"><a href="#RDB文件的操作" class="headerlink" title="RDB文件的操作"></a>RDB文件的操作</h3><p>RDB持久化把当前进程数据生成快照（.rdb）文件保存到硬盘的过程，有手动触发和自动触发两种。</p><p>手动触发有save和bgsave两命令</p><ul><li>save命令：阻塞当前Redis，直到RDB持久化过程完成为止，若内存实例比较大会造成长时间阻塞，线上环境不建议使用。</li><li>bgsave命令：redis进程执行fork操作创建子进程，由子进程完成持久化，阻塞时间很短(微秒级)，是对save命令的优化，在执行redis-cli shutdown关闭redis服务时，如果没有开启AOF持久化，自动执行bgsave运行流程。</li></ul><p>bgsave运行流程</p><img src="/2020/04/28/redis%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/pic3.png" srcset="/img/loading.gif" class=""><p>可以通过<code>config set dir /usr/local</code>命令设置rdb文件保存路径，可以通过<code>bgsave</code>命令将dump.rdb保存到usr/local下，恢复时将dump.rdb放到redis安装目录与redis.conf同级目录，重启redis即可。</p><p>优点：</p><ol><li>压缩后的二进制文，适用于备份、全量复制，用于灾难恢复</li><li>加载RDB恢复数据远快于AOF方式</li></ol><p>缺点：</p><ol><li>无法做到实时持久化，每次都要创建子进程，频繁操作成本过高。</li><li>保存后的二进制文件，存在老版本不兼容新版本rdb文件的问题。</li></ol><h3 id="AOF持久化"><a href="#AOF持久化" class="headerlink" title="AOF持久化"></a>AOF持久化</h3><p>针对RDB不适合实时持久化，redis提供了AOF持久化方式来解决。开启方式为到redis.conf文件中设置：<code>appendonly</code>属性为yes即可，备份数据的默认文件名：<code>appendfilename&quot;appendonly.aof</code>。<br>流程说明：</p><ol><li>所有的写入命令(sethset)会append追加到aof_buf缓冲区中。</li><li>AOF缓冲区向硬盘做sync同步。</li><li>随着AOF文件越来越大，需定期对AOF文件rewrite重写，达到压缩。</li><li>当redis服务重启，可load加载AOF文件进行恢复。</li></ol><img src="/2020/04/28/redis%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/pic4.png" srcset="/img/loading.gif" class=""><p>AOF持久化流程：命令写入(append)，文件同步(sync)，文件重写(rewrite)，重启加载(load)。</p><p>redis的AOF配置详解：</p><ul><li>appendonly yes：启用aof持久化方式。</li><li>appendfsync always：每收到写命令就立即强制写入磁盘，最慢的，但是保证完全的持久化，不推荐使用。</li><li>appendfsync everysec：每秒强制写入磁盘一次，性能和持久化方面做了折中，推荐。</li><li>appendfsync no：完全依赖os，性能最好，持久化没保证（操作系统自身的同步）。</li><li>no-appendfsync-on-rewrite yes：正在导出rdb快照的过程中，要不要停止同步aof。</li><li>auto-aof-rewrite-percentage 100：aof文件大小比起上次重写时的大小，增长率100%时，重写。</li><li>auto-aof-rewrite-min-size 64mb：aof文件，至少超过64M时，重写。</li></ul><p>如何从AOF恢复?</p><ol><li>设置appendonlyyes。</li><li>将appendonly.aof放到dir参数指定的目录。</li><li>启动Redis，Redis会自动加载appendonly.aof文件。</li></ol><img src="/2020/04/28/redis%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/pic5.png" srcset="/img/loading.gif" class=""><p>redis重启时恢复加载AOF与RDB顺序及流程:</p><ol><li>当AOF和RDB文件同时存在时，优先加载AOF。</li><li>若关闭了AOF，加载RDB文件。</li><li>加载AOF/RDB成功，redis重启成功，如果存在错误，redis启动失败并打印错误信息。</li></ol>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>actuator源码解读</title>
    <link href="/2020/04/28/actuator%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"/>
    <url>/2020/04/28/actuator%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<h2 id="actuator源码解读"><a href="#actuator源码解读" class="headerlink" title="actuator源码解读"></a>actuator源码解读</h2><p>actuator的spring.factories中会注册很多带有@Endpoin注解的类。</p><p>通过spring.factories引入的ManagementContextAutoConfiguration中有一个EnableSameManagementContextConfiguration类。</p><pre><code class="java">@Configuration(proxyBeanMethods = false)@EnableManagementContext(ManagementContextType.SAME)static class EnableSameManagementContextConfiguration {}</code></pre><p>这个类的@EnableManagementContext会引入ManagementContextConfigurationImportSelector类</p><pre><code class="java">@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(ManagementContextConfigurationImportSelector.class)@interface EnableManagementContext {</code></pre><p>ManagementContextConfigurationImportSelector类会引入spring.factories中ManagementContextConfiguration类型的所有类</p><pre><code class="java">protected List&lt;String&gt; loadFactoryNames() {   return SpringFactoriesLoader.loadFactoryNames(ManagementContextConfiguration.class, this.classLoader);}</code></pre><p>这里我们只关注WebMvcEndpointManagementContextConfiguration</p><p>WebMvcEndpointManagementContextConfiguration类中会调用getEndpoints()方法获取到带有@Endpoint注解的对象，然后创建WebMvcEndpointHandlerMapping映射关系对象。</p><pre><code class="java">@Bean@ConditionalOnMissingBeanpublic WebMvcEndpointHandlerMapping webEndpointServletHandlerMapping(WebEndpointsSupplier webEndpointsSupplier,      ServletEndpointsSupplier servletEndpointsSupplier, ControllerEndpointsSupplier controllerEndpointsSupplier,      EndpointMediaTypes endpointMediaTypes, CorsEndpointProperties corsProperties,      WebEndpointProperties webEndpointProperties, Environment environment) {   List&lt;ExposableEndpoint&lt;?&gt;&gt; allEndpoints = new ArrayList&lt;&gt;();   Collection&lt;ExposableWebEndpoint&gt; webEndpoints = webEndpointsSupplier.getEndpoints();   allEndpoints.addAll(webEndpoints);   allEndpoints.addAll(servletEndpointsSupplier.getEndpoints());   allEndpoints.addAll(controllerEndpointsSupplier.getEndpoints());   String basePath = webEndpointProperties.getBasePath();   EndpointMapping endpointMapping = new EndpointMapping(basePath);   boolean shouldRegisterLinksMapping = StringUtils.hasText(basePath)         || ManagementPortType.get(environment).equals(ManagementPortType.DIFFERENT);   return new WebMvcEndpointHandlerMapping(endpointMapping, webEndpoints, endpointMediaTypes,         corsProperties.toCorsConfiguration(), new EndpointLinksResolver(allEndpoints, basePath),         shouldRegisterLinksMapping);}</code></pre><p>getEndpoints()最终回调用到EndpointDiscoverer的createEndpointBeans()方法，该方法会拿到有@Endpoint注解的所有的类，然后返回对应的Endpoint。</p><pre><code class="java">private Collection&lt;EndpointBean&gt; createEndpointBeans() {   Map&lt;EndpointId, EndpointBean&gt; byId = new LinkedHashMap&lt;&gt;();   String[] beanNames = BeanFactoryUtils.beanNamesForAnnotationIncludingAncestors(this.applicationContext,         Endpoint.class);   for (String beanName : beanNames) {      if (!ScopedProxyUtils.isScopedTarget(beanName)) {         EndpointBean endpointBean = createEndpointBean(beanName);         EndpointBean previous = byId.putIfAbsent(endpointBean.getId(), endpointBean);         Assert.state(previous == null, () -&gt; &quot;Found two endpoints with the id &#39;&quot; + endpointBean.getId() + &quot;&#39;: &#39;&quot;               + endpointBean.getBeanName() + &quot;&#39; and &#39;&quot; + previous.getBeanName() + &quot;&#39;&quot;);      }   }   return byId.values();}</code></pre><p>WebMvcEndpointHandlerMapping的父类AbstractHandlerMethodMapping实现了InitializingBean接口，spring会在实例化完成后调用其afterPropertiesSet()方法</p><pre><code class="java">public void afterPropertiesSet() {   initHandlerMethods();}</code></pre><p>afterPropertiesSet()方法回到用到子类AbstractWebMvcEndpointHandlerMapping中的initHandlerMethods()方法。</p><pre><code class="java">protected void initHandlerMethods() {   for (ExposableWebEndpoint endpoint : this.endpoints) {      for (WebOperation operation : endpoint.getOperations()) {         registerMappingForOperation(endpoint, operation);      }   }   if (this.shouldRegisterLinksMapping) {      registerLinksMapping();   }}</code></pre><p>initHandlerMethods()方法会调用到registerMappingForOperation()方法，将所有的endpoint绑定到OperationHandler类</p><pre><code class="java">private void registerMappingForOperation(ExposableWebEndpoint endpoint, WebOperation operation) {   WebOperationRequestPredicate predicate = operation.getRequestPredicate();   String path = predicate.getPath();   String matchAllRemainingPathSegmentsVariable = predicate.getMatchAllRemainingPathSegmentsVariable();   if (matchAllRemainingPathSegmentsVariable != null) {      path = path.replace(&quot;{*&quot; + matchAllRemainingPathSegmentsVariable + &quot;}&quot;, &quot;**&quot;);   }   ServletWebOperation servletWebOperation = wrapServletWebOperation(endpoint, operation,         new ServletWebOperationAdapter(operation));   registerMapping(createRequestMappingInfo(predicate, path), new OperationHandler(servletWebOperation),         this.handleMethod);}</code></pre><p>OperationHandler类，所有的请求都会进入其handle()方法，handle()方法最终会调用到通过spring.factories中的创建的带有@Endpoint注解的实例。</p><pre><code class="java">private final class OperationHandler {   private final ServletWebOperation operation;   OperationHandler(ServletWebOperation operation) {      this.operation = operation;   }   @ResponseBody   Object handle(HttpServletRequest request, @RequestBody(required = false) Map&lt;String, String&gt; body) {      return this.operation.handle(request, body);   }   @Override   public String toString() {      return this.operation.toString();   }}</code></pre>]]></content>
    
    
    <categories>
      
      <category>springcloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>actuator</tag>
      
      <tag>源码解读</tag>
      
      <tag>springcloud</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>config源码解读</title>
    <link href="/2020/04/28/config%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"/>
    <url>/2020/04/28/config%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<h2 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h2><p>ConfigServerAutoConfiguration类会通过SPI加载</p><pre><code class="java">@Configuration(proxyBeanMethods = false)@ConditionalOnBean(ConfigServerConfiguration.Marker.class)@EnableConfigurationProperties(ConfigServerProperties.class)@Import({ EnvironmentRepositoryConfiguration.class, CompositeConfiguration.class,      ResourceRepositoryConfiguration.class, ConfigServerEncryptionConfiguration.class,      ConfigServerMvcConfiguration.class, ResourceEncryptorConfiguration.class })public class ConfigServerAutoConfiguration {}</code></pre><h3 id="配置信息的获取"><a href="#配置信息的获取" class="headerlink" title="配置信息的获取"></a>配置信息的获取</h3><p>ConfigServerMvcConfiguration会被引入，并创建一个EnvironmentController</p><pre><code class="java">@Bean@RefreshScopepublic EnvironmentController environmentController(      EnvironmentRepository envRepository, ConfigServerProperties server) {   EnvironmentController controller = new EnvironmentController(         encrypted(envRepository, server), this.objectMapper);   controller.setStripDocumentFromYaml(server.isStripDocumentFromYaml());   controller.setAcceptEmpty(server.isAcceptEmpty());   return controller;}</code></pre><p>EnvironmentController主要用于接收获取配置信息请求，如接收<code>http://localhost:8085/api-gatewary.proeprties</code>请求的properties()方法，该方法会调用labelledProperties()方法获取配置信息。</p><pre><code class="java">@RequestMapping(&quot;/{name}-{profiles}.properties&quot;)public ResponseEntity&lt;String&gt; properties(@PathVariable String name,      @PathVariable String profiles,      @RequestParam(defaultValue = &quot;true&quot;) boolean resolvePlaceholders)      throws IOException {   return labelledProperties(name, profiles, null, resolvePlaceholders);}</code></pre><p>labelledProperties()方法最终会调用到getEnvironment()方法。</p><pre><code class="java">public Environment getEnvironment(String name, String profiles, String label,      boolean includeOrigin) {   name = Environment.normalize(name);   label = Environment.normalize(label);   Environment environment = this.repository.findOne(name, profiles, label,         includeOrigin);   if (!this.acceptEmpty         &amp;&amp; (environment == null || environment.getPropertySources().isEmpty())) {      throw new EnvironmentNotFoundException(&quot;Profile Not found&quot;);   }   return environment;}</code></pre><p>AbstractScmEnvironmentRepository的findOne()方法会由getEnvironment()方法调用，在这里就从github上clone，和更新配置信息并且保存到了本地。</p><pre><code class="java">public synchronized Environment findOne(String application, String profile,      String label, boolean includeOrigin) {   NativeEnvironmentRepository delegate = new NativeEnvironmentRepository(         getEnvironment(), new NativeEnvironmentProperties());   Locations locations = getLocations(application, profile, label);   delegate.setSearchLocations(locations.getLocations());   Environment result = delegate.findOne(application, profile, &quot;&quot;, includeOrigin);   result.setVersion(locations.getVersion());   result.setLabel(label);   return this.cleaner.clean(result, getWorkingDirectory().toURI().toString(),         getUri());}</code></pre><p>JGitEnvironmentRepository的getLocations()方法，该方法是getEnvironment()方法的核心方法，如果本地已经存在对应的配置文件，就会从本地获取，如果本地没有就会从github上获取。</p><pre><code class="java">public synchronized Locations getLocations(String application, String profile,      String label) {   if (label == null) {      label = this.defaultLabel;   }   String version = refresh(label);   return new Locations(application, profile, label, version,         getSearchLocations(getWorkingDirectory(), application, profile, label));}</code></pre><p>refresh()会获取到git仓库的文件并进行检查。</p><pre><code class="java">public String refresh(String label) {   Git git = null;   try {      git = createGitClient();      if (shouldPull(git)) {         FetchResult fetchStatus = fetch(git, label);         if (this.deleteUntrackedBranches &amp;&amp; fetchStatus != null) {            deleteUntrackedLocalBranches(fetchStatus.getTrackingRefUpdates(),                  git);         }         // checkout after fetch so we can get any new branches, tags, ect.         checkout(git, label);         tryMerge(git, label);      }      else {         // nothing to update so just checkout and merge.         // Merge because remote branch could have been updated before         checkout(git, label);         tryMerge(git, label);      }      // always return what is currently HEAD as the version      return git.getRepository().findRef(&quot;HEAD&quot;).getObjectId().getName();   }   catch (RefNotFoundException e) {      throw new NoSuchLabelException(&quot;No such label: &quot; + label, e);   }   catch (NoRemoteRepositoryException e) {      throw new NoSuchRepositoryException(&quot;No such repository: &quot; + getUri(), e);   }   catch (GitAPIException e) {      throw new NoSuchRepositoryException(            &quot;Cannot clone or checkout repository: &quot; + getUri(), e);   }   catch (Exception e) {      throw new IllegalStateException(&quot;Cannot load environment&quot;, e);   }   finally {      try {         if (git != null) {            git.close();         }      }      catch (Exception e) {         this.logger.warn(&quot;Could not close git repository&quot;, e);      }   }}</code></pre><p>createGitClient()，该方法会获取到本地的仓库。如果不存在就会调用copyRepository()方法创建。</p><pre><code class="java">private Git createGitClient() throws IOException, GitAPIException {   File lock = new File(getWorkingDirectory(), &quot;.git/index.lock&quot;);   if (lock.exists()) {      // The only way this can happen is if another JVM (e.g. one that      // crashed earlier) created the lock. We can attempt to recover by      // wiping the slate clean.      this.logger.info(&quot;Deleting stale JGit lock file at &quot; + lock);      lock.delete();   }   if (new File(getWorkingDirectory(), &quot;.git&quot;).exists()) {      return openGitRepository();   }   else {      return copyRepository();   }}</code></pre><p>copyRepository()会调用cloneToBasedir()方法。</p><pre><code class="java">private synchronized Git copyRepository() throws IOException, GitAPIException {   deleteBaseDirIfExists();   getBasedir().mkdirs();   Assert.state(getBasedir().exists(), &quot;Could not create basedir: &quot; + getBasedir());   if (getUri().startsWith(FILE_URI_PREFIX)) {      return copyFromLocalRepository();   }   else {      return cloneToBasedir();   }}</code></pre><p>cloneToBasedir()，向git发送clone指令。</p><pre><code class="java">private Git cloneToBasedir() throws GitAPIException {   CloneCommand clone = this.gitFactory.getCloneCommandByCloneRepository()         .setURI(getUri()).setDirectory(getBasedir());   configureCommand(clone);   try {      return clone.call();   }   catch (GitAPIException e) {      this.logger.warn(&quot;Error occured cloning to base directory.&quot;, e);      deleteBaseDirIfExists();      throw e;   }}</code></pre><h3 id="加密解密"><a href="#加密解密" class="headerlink" title="加密解密"></a>加密解密</h3><p>ConfigServerAutoConfiguration类中还会引入ConfigServerEncryptionConfiguration类，该类会注册服务端加密的controller</p><pre><code class="java">@Configuration(proxyBeanMethods = false)public class ConfigServerEncryptionConfiguration {   @Autowired(required = false)   private TextEncryptorLocator encryptor;   @Autowired   private ConfigServerProperties properties;   @Bean   public EncryptionController encryptionController() {      EncryptionController controller = new EncryptionController(this.encryptor);      controller.setDefaultApplicationName(this.properties.getDefaultApplicationName());      controller.setDefaultProfile(this.properties.getDefaultProfile());      return controller;   }}</code></pre><p>EncryptionController类</p><pre><code class="java">@RequestMapping(value = &quot;encrypt&quot;, method = RequestMethod.POST)public String encrypt(@RequestBody String data,      @RequestHeader(&quot;Content-Type&quot;) MediaType type) {   return encrypt(defaultApplicationName, defaultProfile, data, type);}</code></pre><pre><code class="java">@RequestMapping(value = &quot;decrypt&quot;, method = RequestMethod.POST)public String decrypt(@RequestBody String data,      @RequestHeader(&quot;Content-Type&quot;) MediaType type) {   return decrypt(defaultApplicationName, defaultProfile, data, type);}</code></pre><h2 id="config客户端"><a href="#config客户端" class="headerlink" title="config客户端"></a>config客户端</h2><h3 id="配置信息的获取-1"><a href="#配置信息的获取-1" class="headerlink" title="配置信息的获取"></a>配置信息的获取</h3><p>spi中会引入ConfigServiceBootstrapConfiguration类，该类中会创建ConfigServicePropertySourceLocator对象。</p><pre><code class="java">@Bean@ConditionalOnMissingBean(ConfigServicePropertySourceLocator.class)@ConditionalOnProperty(value = &quot;spring.cloud.config.enabled&quot;, matchIfMissing = true)public ConfigServicePropertySourceLocator configServicePropertySource(      ConfigClientProperties properties) {   ConfigServicePropertySourceLocator locator = new ConfigServicePropertySourceLocator(         properties);   return locator;}</code></pre><p>locate()方法是ConfigServicePropertySourceLocator类中比较重要的一个方法。该方法会通过getRemoteEnvironment()方法获取到Environment对象。</p><pre><code class="java">@Override@Retryable(interceptor = &quot;configServerRetryInterceptor&quot;)public org.springframework.core.env.PropertySource&lt;?&gt; locate(      org.springframework.core.env.Environment environment) {   ConfigClientProperties properties = this.defaultProperties.override(environment);   CompositePropertySource composite = new OriginTrackedCompositePropertySource(         &quot;configService&quot;);   RestTemplate restTemplate = this.restTemplate == null         ? getSecureRestTemplate(properties) : this.restTemplate;   Exception error = null;   String errorBody = null;   try {      String[] labels = new String[] { &quot;&quot; };      if (StringUtils.hasText(properties.getLabel())) {         labels = StringUtils               .commaDelimitedListToStringArray(properties.getLabel());      }      String state = ConfigClientStateHolder.getState();      // Try all the labels until one works      for (String label : labels) {         Environment result = getRemoteEnvironment(restTemplate, properties,               label.trim(), state);         if (result != null) {            log(result);            // result.getPropertySources() can be null if using xml            if (result.getPropertySources() != null) {               for (PropertySource source : result.getPropertySources()) {                  @SuppressWarnings(&quot;unchecked&quot;)                  Map&lt;String, Object&gt; map = translateOrigins(source.getName(),                        (Map&lt;String, Object&gt;) source.getSource());                  composite.addPropertySource(                        new OriginTrackedMapPropertySource(source.getName(),                              map));               }            }            if (StringUtils.hasText(result.getState())                  || StringUtils.hasText(result.getVersion())) {               HashMap&lt;String, Object&gt; map = new HashMap&lt;&gt;();               putValue(map, &quot;config.client.state&quot;, result.getState());               putValue(map, &quot;config.client.version&quot;, result.getVersion());               composite.addFirstPropertySource(                     new MapPropertySource(&quot;configClient&quot;, map));            }            return composite;         }      }      errorBody = String.format(&quot;None of labels %s found&quot;, Arrays.toString(labels));   }   catch (HttpServerErrorException e) {      error = e;      if (MediaType.APPLICATION_JSON            .includes(e.getResponseHeaders().getContentType())) {         errorBody = e.getResponseBodyAsString();      }   }   catch (Exception e) {      error = e;   }   if (properties.isFailFast()) {      throw new IllegalStateException(            &quot;Could not locate PropertySource and the fail fast property is set, failing&quot;                  + (errorBody == null ? &quot;&quot; : &quot;: &quot; + errorBody),            error);   }   logger.warn(&quot;Could not locate PropertySource: &quot;         + (error != null ? error.getMessage() : errorBody));   return null;}</code></pre><p>getRemoteEnvironment()会在locate()方法中调用，会请求配置中心获取到Environment对象。</p><pre><code class="java">private Environment getRemoteEnvironment(RestTemplate restTemplate,      ConfigClientProperties properties, String label, String state) {   String path = &quot;/{name}/{profile}&quot;;   String name = properties.getName();   String profile = properties.getProfile();   String token = properties.getToken();   int noOfUrls = properties.getUri().length;   if (noOfUrls &gt; 1) {      logger.info(&quot;Multiple Config Server Urls found listed.&quot;);   }   Object[] args = new String[] { name, profile };   if (StringUtils.hasText(label)) {      // workaround for Spring MVC matching / in paths      label = Environment.denormalize(label);      args = new String[] { name, profile, label };      path = path + &quot;/{label}&quot;;   }   ResponseEntity&lt;Environment&gt; response = null;   for (int i = 0; i &lt; noOfUrls; i++) {      Credentials credentials = properties.getCredentials(i);      String uri = credentials.getUri();      String username = credentials.getUsername();      String password = credentials.getPassword();      logger.info(&quot;Fetching config from server at : &quot; + uri);      try {         HttpHeaders headers = new HttpHeaders();         headers.setAccept(               Collections.singletonList(MediaType.parseMediaType(V2_JSON)));         addAuthorizationToken(properties, headers, username, password);         if (StringUtils.hasText(token)) {            headers.add(TOKEN_HEADER, token);         }         if (StringUtils.hasText(state) &amp;&amp; properties.isSendState()) {            headers.add(STATE_HEADER, state);         }         final HttpEntity&lt;Void&gt; entity = new HttpEntity&lt;&gt;((Void) null, headers);         response = restTemplate.exchange(uri + path, HttpMethod.GET, entity,               Environment.class, args);      }      catch (HttpClientErrorException e) {         if (e.getStatusCode() != HttpStatus.NOT_FOUND) {            throw e;         }      }      catch (ResourceAccessException e) {         logger.info(&quot;Connect Timeout Exception on Url - &quot; + uri               + &quot;. Will be trying the next url if available&quot;);         if (i == noOfUrls - 1) {            throw e;         }         else {            continue;         }      }      if (response == null || response.getStatusCode() != HttpStatus.OK) {         return null;      }      Environment result = response.getBody();      return result;   }   return null;}</code></pre><h3 id="配置信息的更新"><a href="#配置信息的更新" class="headerlink" title="配置信息的更新"></a>配置信息的更新</h3><p>更新接口会调用到RefreshEndpoint的refresh()方法中。</p><pre><code class="java">@Endpoint(id = &quot;refresh&quot;)public class RefreshEndpoint {   private ContextRefresher contextRefresher;   public RefreshEndpoint(ContextRefresher contextRefresher) {      this.contextRefresher = contextRefresher;   }   @WriteOperation   public Collection&lt;String&gt; refresh() {      Set&lt;String&gt; keys = this.contextRefresher.refresh();      return keys;   }</code></pre><p>resresh()会调用到ContextRefresher中的refresh()方法，该方法首先调用refreshEnvironment()方法刷新Environment对象，然后调用refreshAll()方法刷新scope对象。</p><pre><code class="java">public synchronized Set&lt;String&gt; refresh() {   Set&lt;String&gt; keys = refreshEnvironment();   this.scope.refreshAll();   return keys;}</code></pre><p>refreshEnvironment()方法，该方法会重新从配置中心拉取属性，然后做新旧对比。</p><pre><code class="java">public synchronized Set&lt;String&gt; refreshEnvironment() {   Map&lt;String, Object&gt; before = extract(         this.context.getEnvironment().getPropertySources());   addConfigFilesToEnvironment();   Set&lt;String&gt; keys = changes(before,         extract(this.context.getEnvironment().getPropertySources())).keySet();   this.context.publishEvent(new EnvironmentChangeEvent(this.context, keys));   return keys;}</code></pre><p>refreshAll()方法会调用destroy()方法销毁实例，destory()的过程跟之前的自定义分布中心中的类似，就是从缓存中移除实例。然后调用publishEvent()方法重新发布对象。</p><pre><code>public void refreshAll() {   super.destroy();   this.context.publishEvent(new RefreshScopeRefreshedEvent());}</code></pre>]]></content>
    
    
    <categories>
      
      <category>springcloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码解读</tag>
      
      <tag>springcloud</tag>
      
      <tag>分布式配置中心</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>zuul源码解读</title>
    <link href="/2020/04/28/zuul%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"/>
    <url>/2020/04/28/zuul%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<h2 id="接口调用过程"><a href="#接口调用过程" class="headerlink" title="接口调用过程"></a>接口调用过程</h2><p>ZuulServerAutoConfiguration类也是由spi引入的，该类中会创建ZuulController、ZuulHandlerMapping以及ZuullServlet对象。</p><pre><code class="java">@Beanpublic ZuulController zuulController() {   return new ZuulController();}</code></pre><p>ZuulController实现了controller，所有的请求都会走handleRequest()方法。</p><pre><code class="java">public ModelAndView handleRequest(HttpServletRequest request,      HttpServletResponse response) throws Exception {   try {      // We don&#39;t care about the other features of the base class, just want to      // handle the request      return super.handleRequestInternal(request, response);   }   finally {      // @see com.netflix.zuul.context.ContextLifecycleFilter.doFilter      RequestContext.getCurrentContext().unset();   }}</code></pre><p>handleRequest()方法会调用handleRequestInternal()方法，handleRequestInternal()方法会调用到ZuullServlet中的service()方法。</p><pre><code class="java">protected ModelAndView handleRequestInternal(HttpServletRequest request, HttpServletResponse response) throws Exception {    Assert.state(this.servletInstance != null, &quot;No Servlet instance&quot;);    this.servletInstance.service(request, response);    return null;}</code></pre><p>ZuulServlet中的service()方法，service()方法中涉及到pre、route、post、error过滤器的调用。</p><pre><code class="java">public void service(ServletRequest servletRequest, ServletResponse servletResponse) throws ServletException, IOException {    try {        this.init((HttpServletRequest)servletRequest, (HttpServletResponse)servletResponse);        RequestContext context = RequestContext.getCurrentContext();        context.setZuulEngineRan();        try {            this.preRoute();        } catch (ZuulException var13) {            this.error(var13);            this.postRoute();            return;        }        try {            this.route();        } catch (ZuulException var12) {            this.error(var12);            this.postRoute();            return;        }        try {            this.postRoute();        } catch (ZuulException var11) {            this.error(var11);        }    } catch (Throwable var14) {        this.error(new ZuulException(var14, 500, &quot;UNHANDLED_EXCEPTION_&quot; + var14.getClass().getName()));    } finally {        RequestContext.getCurrentContext().unset();    }}</code></pre><p>preRoute()方法，该方法最终会调用到FilterProcessor的runFilters()方法。该方法会获取到所有对应的过滤器，然后排序，再通过processZuulFilter()方法调用。</p><pre><code class="java">public Object runFilters(String sType) throws Throwable {    if (RequestContext.getCurrentContext().debugRouting()) {        Debug.addRoutingDebug(&quot;Invoking {&quot; + sType + &quot;} type filters&quot;);    }    boolean bResult = false;    List&lt;ZuulFilter&gt; list = FilterLoader.getInstance().getFiltersByType(sType);    if (list != null) {        for (int i = 0; i &lt; list.size(); i++) {            ZuulFilter zuulFilter = list.get(i);            Object result = processZuulFilter(zuulFilter);            if (result != null &amp;&amp; result instanceof Boolean) {                bResult |= ((Boolean) result);            }        }    }    return bResult;}</code></pre><p>processZuulFilter()方法</p><pre><code class="java">public Object processZuulFilter(ZuulFilter filter) throws ZuulException {    RequestContext ctx = RequestContext.getCurrentContext();    boolean bDebug = ctx.debugRouting();    final String metricPrefix = &quot;zuul.filter-&quot;;    long execTime = 0;    String filterName = &quot;&quot;;    try {        long ltime = System.currentTimeMillis();        filterName = filter.getClass().getSimpleName();        RequestContext copy = null;        Object o = null;        Throwable t = null;        if (bDebug) {            Debug.addRoutingDebug(&quot;Filter &quot; + filter.filterType() + &quot; &quot; + filter.filterOrder() + &quot; &quot; + filterName);            copy = ctx.copy();        }        ZuulFilterResult result = filter.runFilter();        ExecutionStatus s = result.getStatus();        execTime = System.currentTimeMillis() - ltime;        switch (s) {            case FAILED:                t = result.getException();                ctx.addFilterExecutionSummary(filterName, ExecutionStatus.FAILED.name(), execTime);                break;            case SUCCESS:                o = result.getResult();                ctx.addFilterExecutionSummary(filterName, ExecutionStatus.SUCCESS.name(), execTime);                if (bDebug) {                    Debug.addRoutingDebug(&quot;Filter {&quot; + filterName + &quot; TYPE:&quot; + filter.filterType() + &quot; ORDER:&quot; + filter.filterOrder() + &quot;} Execution time = &quot; + execTime + &quot;ms&quot;);                    Debug.compareContextState(filterName, copy);                }                break;            default:                break;        }        if (t != null) throw t;        usageNotifier.notify(filter, s);        return o;    } catch (Throwable e) {        if (bDebug) {            Debug.addRoutingDebug(&quot;Running Filter failed &quot; + filterName + &quot; type:&quot; + filter.filterType() + &quot; order:&quot; + filter.filterOrder() + &quot; &quot; + e.getMessage());        }        usageNotifier.notify(filter, ExecutionStatus.FAILED);        if (e instanceof ZuulException) {            throw (ZuulException) e;        } else {            ZuulException ex = new ZuulException(e, &quot;Filter threw Exception&quot;, 500, filter.filterType() + &quot;:&quot; + filterName);            ctx.addFilterExecutionSummary(filterName, ExecutionStatus.FAILED.name(), execTime);            throw ex;        }    }}</code></pre><h2 id="过滤器解析"><a href="#过滤器解析" class="headerlink" title="过滤器解析"></a>过滤器解析</h2><p>spring.factories中还会引入ZuulProxyAutoConfiguration类，该类中会完成路由过滤器的注册</p><pre><code class="java">// route filters@Bean@ConditionalOnMissingBean(RibbonRoutingFilter.class)public RibbonRoutingFilter ribbonRoutingFilter(ProxyRequestHelper helper,      RibbonCommandFactory&lt;?&gt; ribbonCommandFactory) {   RibbonRoutingFilter filter = new RibbonRoutingFilter(helper, ribbonCommandFactory,         this.requestCustomizers);   return filter;}</code></pre><p>RibbonRoutingFilter中的run()方法</p><pre><code class="java">@Overridepublic Object run() {   RequestContext context = RequestContext.getCurrentContext();   this.helper.addIgnoredHeaders();   try {      RibbonCommandContext commandContext = buildCommandContext(context);      ClientHttpResponse response = forward(commandContext);      setResponse(response);      return response;   }   catch (ZuulException ex) {      throw new ZuulRuntimeException(ex);   }   catch (Exception ex) {      throw new ZuulRuntimeException(ex);   }}</code></pre><p>forward()方法会被run()方法调用。该方法会通过ribbonCommandFactory.create()方法获取到RibbonCommand对象，然后调用hystrix中的execute()方法。</p><pre><code class="java">protected ClientHttpResponse forward(RibbonCommandContext context) throws Exception {   Map&lt;String, Object&gt; info = this.helper.debug(context.getMethod(),         context.getUri(), context.getHeaders(), context.getParams(),         context.getRequestEntity());   RibbonCommand command = this.ribbonCommandFactory.create(context);   try {      ClientHttpResponse response = command.execute();      this.helper.appendDebug(info, response.getRawStatusCode(),            response.getHeaders());      return response;   }   catch (HystrixRuntimeException ex) {      return handleException(info, ex);   }}</code></pre>]]></content>
    
    
    <categories>
      
      <category>springcloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码解读</tag>
      
      <tag>springcloud</tag>
      
      <tag>feign</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>feign源码解读</title>
    <link href="/2020/04/28/feign%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"/>
    <url>/2020/04/28/feign%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<h2 id="代理对象的生成"><a href="#代理对象的生成" class="headerlink" title="代理对象的生成"></a>代理对象的生成</h2><p>EnableFeignClients注解</p><pre><code class="java">@Retention(RetentionPolicy.RUNTIME)@Target({ElementType.TYPE})@Documented@Import({FeignClientsRegistrar.class})public @interface EnableFeignClients {</code></pre><p>FeignClientsRegistrar中registerFeignClients()会扫描@FeignClient注解的类，然后调用registerFeignClient()进行注册。</p><pre><code class="java">public void registerFeignClients(AnnotationMetadata metadata,      BeanDefinitionRegistry registry) {   ClassPathScanningCandidateComponentProvider scanner = getScanner();   scanner.setResourceLoader(this.resourceLoader);   Set&lt;String&gt; basePackages;   Map&lt;String, Object&gt; attrs = metadata         .getAnnotationAttributes(EnableFeignClients.class.getName());   AnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(         FeignClient.class);   final Class&lt;?&gt;[] clients = attrs == null ? null         : (Class&lt;?&gt;[]) attrs.get(&quot;clients&quot;);   if (clients == null || clients.length == 0) {      scanner.addIncludeFilter(annotationTypeFilter);      basePackages = getBasePackages(metadata);   }   else {      final Set&lt;String&gt; clientClasses = new HashSet&lt;&gt;();      basePackages = new HashSet&lt;&gt;();      for (Class&lt;?&gt; clazz : clients) {         basePackages.add(ClassUtils.getPackageName(clazz));         clientClasses.add(clazz.getCanonicalName());      }      AbstractClassTestingTypeFilter filter = new AbstractClassTestingTypeFilter() {         @Override         protected boolean match(ClassMetadata metadata) {            String cleaned = metadata.getClassName().replaceAll(&quot;\\$&quot;, &quot;.&quot;);            return clientClasses.contains(cleaned);         }      };      scanner.addIncludeFilter(            new AllTypeFilter(Arrays.asList(filter, annotationTypeFilter)));   }   for (String basePackage : basePackages) {      Set&lt;BeanDefinition&gt; candidateComponents = scanner            .findCandidateComponents(basePackage);      for (BeanDefinition candidateComponent : candidateComponents) {         if (candidateComponent instanceof AnnotatedBeanDefinition) {            // verify annotated class is an interface            AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent;            AnnotationMetadata annotationMetadata = beanDefinition.getMetadata();            Assert.isTrue(annotationMetadata.isInterface(),                  &quot;@FeignClient can only be specified on an interface&quot;);            Map&lt;String, Object&gt; attributes = annotationMetadata                  .getAnnotationAttributes(                        FeignClient.class.getCanonicalName());            String name = getClientName(attributes);            registerClientConfiguration(registry, name,                  attributes.get(&quot;configuration&quot;));            registerFeignClient(registry, annotationMetadata, attributes);         }      }   }}</code></pre><p>registerFeignClient会引入FeignClientFactoryBean类，</p><pre><code class="java">private void registerFeignClient(BeanDefinitionRegistry registry,      AnnotationMetadata annotationMetadata, Map&lt;String, Object&gt; attributes) {   String className = annotationMetadata.getClassName();   BeanDefinitionBuilder definition = BeanDefinitionBuilder         .genericBeanDefinition(FeignClientFactoryBean.class);   validate(attributes);   definition.addPropertyValue(&quot;url&quot;, getUrl(attributes));   definition.addPropertyValue(&quot;path&quot;, getPath(attributes));   String name = getName(attributes);   definition.addPropertyValue(&quot;name&quot;, name);   String contextId = getContextId(attributes);   definition.addPropertyValue(&quot;contextId&quot;, contextId);   definition.addPropertyValue(&quot;type&quot;, className);   definition.addPropertyValue(&quot;decode404&quot;, attributes.get(&quot;decode404&quot;));   definition.addPropertyValue(&quot;fallback&quot;, attributes.get(&quot;fallback&quot;));   definition.addPropertyValue(&quot;fallbackFactory&quot;, attributes.get(&quot;fallbackFactory&quot;));   definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);   String alias = contextId + &quot;FeignClient&quot;;   AbstractBeanDefinition beanDefinition = definition.getBeanDefinition();   boolean primary = (Boolean) attributes.get(&quot;primary&quot;); // has a default, won&#39;t be                                             // null   beanDefinition.setPrimary(primary);   String qualifier = getQualifier(attributes);   if (StringUtils.hasText(qualifier)) {      alias = qualifier;   }   BeanDefinitionHolder holder = new BeanDefinitionHolder(beanDefinition, className,         new String[] { alias });   BeanDefinitionReaderUtils.registerBeanDefinition(holder, registry);}</code></pre><p>feign的切面实现跟mybatis差不多，在FeignClientFactoryBean对有@FeignClient注解的接口生成接口的代理FeignClientFactoryBean实现了factoryBean接口，里面有getObject方法</p><pre><code class="java">@Overridepublic Object getObject() throws Exception {   return getTarget();}</code></pre><p>该方法会获取调用地址，bean的名称，类型后调用loadBalance()方法创建实例。</p><pre><code class="java">&lt;T&gt; T getTarget() {   FeignContext context = this.applicationContext.getBean(FeignContext.class);   Feign.Builder builder = feign(context);   if (!StringUtils.hasText(this.url)) {      if (!this.name.startsWith(&quot;http&quot;)) {         this.url = &quot;http://&quot; + this.name;      }      else {         this.url = this.name;      }      this.url += cleanPath();      return (T) loadBalance(builder, context,            new HardCodedTarget&lt;&gt;(this.type, this.name, this.url));   }   if (StringUtils.hasText(this.url) &amp;&amp; !this.url.startsWith(&quot;http&quot;)) {      this.url = &quot;http://&quot; + this.url;   }   String url = this.url + cleanPath();   Client client = getOptional(context, Client.class);   if (client != null) {      if (client instanceof LoadBalancerFeignClient) {         // not load balancing because we have a url,         // but ribbon is on the classpath, so unwrap         client = ((LoadBalancerFeignClient) client).getDelegate();      }      if (client instanceof FeignBlockingLoadBalancerClient) {         // not load balancing because we have a url,         // but Spring Cloud LoadBalancer is on the classpath, so unwrap         client = ((FeignBlockingLoadBalancerClient) client).getDelegate();      }      builder.client(client);   }   Targeter targeter = get(context, Targeter.class);   return (T) targeter.target(this, builder, context,         new HardCodedTarget&lt;&gt;(this.type, this.name, url));}</code></pre><p>loadBalance()方法调用到Feign类的target()方法</p><pre><code class="java">protected &lt;T&gt; T loadBalance(Feign.Builder builder, FeignContext context,      HardCodedTarget&lt;T&gt; target) {   Client client = getOptional(context, Client.class);   if (client != null) {      builder.client(client);      Targeter targeter = get(context, Targeter.class);      return targeter.target(this, builder, context, target);   }   throw new IllegalStateException(         &quot;No Feign Client for loadBalancing defined. Did you forget to include spring-cloud-starter-netflix-ribbon?&quot;);}</code></pre><p>target()方法会调用newInstance()方法生成代理对象。</p><pre><code class="java">public &lt;T&gt; T target(Target&lt;T&gt; target) {  return build().newInstance(target);}</code></pre><p>newInstance()方法会调用create()方法生成JDK的代理对象，最终会生成有@FeignClient注解的接口的代理</p><pre><code class="java">public &lt;T&gt; T newInstance(Target&lt;T&gt; target) {  Map&lt;String, MethodHandler&gt; nameToHandler = targetToHandlersByName.apply(target);  Map&lt;Method, MethodHandler&gt; methodToHandler = new LinkedHashMap&lt;Method, MethodHandler&gt;();  List&lt;DefaultMethodHandler&gt; defaultMethodHandlers = new LinkedList&lt;DefaultMethodHandler&gt;();  for (Method method : target.type().getMethods()) {    if (method.getDeclaringClass() == Object.class) {      continue;    } else if (Util.isDefault(method)) {      DefaultMethodHandler handler = new DefaultMethodHandler(method);      defaultMethodHandlers.add(handler);      methodToHandler.put(method, handler);    } else {      methodToHandler.put(method, nameToHandler.get(Feign.configKey(target.type(), method)));    }  }  InvocationHandler handler = factory.create(target, methodToHandler);  T proxy = (T) Proxy.newProxyInstance(target.type().getClassLoader(),      new Class&lt;?&gt;[] {target.type()}, handler);  for (DefaultMethodHandler defaultMethodHandler : defaultMethodHandlers) {    defaultMethodHandler.bindTo(proxy);  }  return proxy;}</code></pre><h2 id="代理对象的调用"><a href="#代理对象的调用" class="headerlink" title="代理对象的调用"></a>代理对象的调用</h2><p>Controller中获取到代理实例后，则会调用到HystrixInvocationHandler的invoke()方法，这里跟hystrix基本类似，最后会走到run()方法的钩子方法中</p><pre><code class="java">public Object invoke(Object proxy, final Method method, final Object[] args) throws Throwable {    if (!&quot;equals&quot;.equals(method.getName())) {        if (&quot;hashCode&quot;.equals(method.getName())) {            return this.hashCode();        } else if (&quot;toString&quot;.equals(method.getName())) {            return this.toString();        } else {            HystrixCommand&lt;Object&gt; hystrixCommand = new HystrixCommand&lt;Object&gt;((Setter)this.setterMethodMap.get(method)) {                protected Object run() throws Exception {                    try {                        return ((MethodHandler)HystrixInvocationHandler.this.dispatch.get(method)).invoke(args);                    } catch (Exception var2) {                        throw var2;                    } catch (Throwable var3) {                        throw (Error)var3;                    }                }                protected Object getFallback() {                    if (HystrixInvocationHandler.this.fallbackFactory == null) {                        return super.getFallback();                    } else {                        try {                            Object fallback = HystrixInvocationHandler.this.fallbackFactory.create(this.getExecutionException());                            Object result = ((Method)HystrixInvocationHandler.this.fallbackMethodMap.get(method)).invoke(fallback, args);                            if (HystrixInvocationHandler.this.isReturnsHystrixCommand(method)) {                                return ((HystrixCommand)result).execute();                            } else if (HystrixInvocationHandler.this.isReturnsObservable(method)) {                                return ((Observable)result).toBlocking().first();                            } else if (HystrixInvocationHandler.this.isReturnsSingle(method)) {                                return ((Single)result).toObservable().toBlocking().first();                            } else if (HystrixInvocationHandler.this.isReturnsCompletable(method)) {                                ((Completable)result).await();                                return null;                            } else {                                return HystrixInvocationHandler.this.isReturnsCompletableFuture(method) ? ((Future)result).get() : result;                            }                        } catch (IllegalAccessException var3) {                            throw new AssertionError(var3);                        } catch (ExecutionException | InvocationTargetException var4) {                            throw new AssertionError(var4.getCause());                        } catch (InterruptedException var5) {                            Thread.currentThread().interrupt();                            throw new AssertionError(var5.getCause());                        }                    }                }            };            if (Util.isDefault(method)) {                return hystrixCommand.execute();            } else if (this.isReturnsHystrixCommand(method)) {                return hystrixCommand;            } else if (this.isReturnsObservable(method)) {                return hystrixCommand.toObservable();            } else if (this.isReturnsSingle(method)) {                return hystrixCommand.toObservable().toSingle();            } else if (this.isReturnsCompletable(method)) {                return hystrixCommand.toObservable().toCompletable();            } else {                return this.isReturnsCompletableFuture(method) ? new ObservableCompletableFuture(hystrixCommand) : hystrixCommand.execute();            }        }    } else {        try {            Object otherHandler = args.length &gt; 0 &amp;&amp; args[0] != null ? Proxy.getInvocationHandler(args[0]) : null;            return this.equals(otherHandler);        } catch (IllegalArgumentException var5) {            return false;        }    }}</code></pre><p>SynchronousMethodHandler的invoke()方法</p><pre><code class="java">@Overridepublic Object invoke(Object[] argv) throws Throwable {  RequestTemplate template = buildTemplateFromArgs.create(argv);  Options options = findOptions(argv);  Retryer retryer = this.retryer.clone();  while (true) {    try {      return executeAndDecode(template, options);    } catch (RetryableException e) {      try {        retryer.continueOrPropagate(e);      } catch (RetryableException th) {        Throwable cause = th.getCause();        if (propagationPolicy == UNWRAP &amp;&amp; cause != null) {          throw cause;        } else {          throw th;        }      }      if (logLevel != Logger.Level.NONE) {        logger.logRetry(metadata.configKey(), logLevel);      }      continue;    }  }}</code></pre><p>executeAndDecode()方法会执行execute()方法，该方法会调用到ribbon功能。</p><pre><code class="java">Object executeAndDecode(RequestTemplate template, Options options) throws Throwable {  Request request = targetRequest(template);  if (logLevel != Logger.Level.NONE) {    logger.logRequest(metadata.configKey(), logLevel, request);  }  Response response;  long start = System.nanoTime();  try {    response = client.execute(request, options);    // ensure the request is set. TODO: remove in Feign 12    response = response.toBuilder()        .request(request)        .requestTemplate(template)        .build();  } catch (IOException e) {    if (logLevel != Logger.Level.NONE) {      logger.logIOException(metadata.configKey(), logLevel, e, elapsedTime(start));    }    throw errorExecuting(request, e);  }  long elapsedTime = TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - start);  boolean shouldClose = true;  try {    if (logLevel != Logger.Level.NONE) {      response =          logger.logAndRebufferResponse(metadata.configKey(), logLevel, response, elapsedTime);    }    if (Response.class == metadata.returnType()) {      if (response.body() == null) {        return response;      }      if (response.body().length() == null ||          response.body().length() &gt; MAX_RESPONSE_BUFFER_SIZE) {        shouldClose = false;        return response;      }      // Ensure the response body is disconnected      byte[] bodyData = Util.toByteArray(response.body().asInputStream());      return response.toBuilder().body(bodyData).build();    }    if (response.status() &gt;= 200 &amp;&amp; response.status() &lt; 300) {      if (void.class == metadata.returnType()) {        return null;      } else {        Object result = decode(response);        shouldClose = closeAfterDecode;        return result;      }    } else if (decode404 &amp;&amp; response.status() == 404 &amp;&amp; void.class != metadata.returnType()) {      Object result = decode(response);      shouldClose = closeAfterDecode;      return result;    } else {      throw errorDecoder.decode(metadata.configKey(), response);    }  } catch (IOException e) {    if (logLevel != Logger.Level.NONE) {      logger.logIOException(metadata.configKey(), logLevel, e, elapsedTime);    }    throw errorReading(request, response, e);  } finally {    if (shouldClose) {      ensureClosed(response.body());    }  }}</code></pre><p>LoadBalancerFeignClient的execute()方法</p><pre><code class="java">@Overridepublic Response execute(Request request, Request.Options options) throws IOException {   try {      URI asUri = URI.create(request.url());      String clientName = asUri.getHost();      URI uriWithoutHost = cleanUrl(request.url(), clientName);      FeignLoadBalancer.RibbonRequest ribbonRequest = new FeignLoadBalancer.RibbonRequest(            this.delegate, request, uriWithoutHost);      IClientConfig requestConfig = getClientConfig(options, clientName);      return lbClient(clientName)            .executeWithLoadBalancer(ribbonRequest, requestConfig).toResponse();   }   catch (ClientException e) {      IOException io = findIOException(e);      if (io != null) {         throw io;      }      throw new RuntimeException(e);   }}</code></pre><p>lbClient()方法会调用到CachingSpringLoadBalancerFactory的create()方法，在这个方法里面获取服务列表类进行调用。</p><pre><code class="java">public FeignLoadBalancer create(String clientName) {   FeignLoadBalancer client = this.cache.get(clientName);   if (client != null) {      return client;   }   IClientConfig config = this.factory.getClientConfig(clientName);   ILoadBalancer lb = this.factory.getLoadBalancer(clientName);   ServerIntrospector serverIntrospector = this.factory.getInstance(clientName,         ServerIntrospector.class);   client = this.loadBalancedRetryFactory != null         ? new RetryableFeignLoadBalancer(lb, config, serverIntrospector,               this.loadBalancedRetryFactory)         : new FeignLoadBalancer(lb, config, serverIntrospector);   this.cache.put(clientName, client);   return client;}</code></pre><p>executeWithLoadBalancer()方法会调用到FeignLoadBalancer的execute()方法完成服务调用。</p><pre><code class="java">public T executeWithLoadBalancer(final S request, final IClientConfig requestConfig) throws ClientException {    LoadBalancerCommand&lt;T&gt; command = buildLoadBalancerCommand(request, requestConfig);    try {        return command.submit(            new ServerOperation&lt;T&gt;() {                @Override                public Observable&lt;T&gt; call(Server server) {                    URI finalUri = reconstructURIWithServer(server, request.getUri());                    S requestForServer = (S) request.replaceUri(finalUri);                    try {                        return Observable.just(AbstractLoadBalancerAwareClient.this.execute(requestForServer, requestConfig));                    }                     catch (Exception e) {                        return Observable.error(e);                    }                }            })            .toBlocking()            .single();    } catch (Exception e) {        Throwable t = e.getCause();        if (t instanceof ClientException) {            throw (ClientException) t;        } else {            throw new ClientException(e);        }    }}</code></pre><p>FeignLoadBalancer的execute()方法。</p><pre><code class="java">public RibbonResponse execute(RibbonRequest request, IClientConfig configOverride)      throws IOException {   Request.Options options;   if (configOverride != null) {      RibbonProperties override = RibbonProperties.from(configOverride);      options = new Request.Options(override.connectTimeout(this.connectTimeout),            override.readTimeout(this.readTimeout));   }   else {      options = new Request.Options(this.connectTimeout, this.readTimeout);   }   Response response = request.client().execute(request.toRequest(), options);   return new RibbonResponse(request.getUri(), response);}</code></pre>]]></content>
    
    
    <categories>
      
      <category>springcloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码解读</tag>
      
      <tag>springcloud</tag>
      
      <tag>feign</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hystrix源码解读</title>
    <link href="/2020/04/27/hystrix%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"/>
    <url>/2020/04/27/hystrix%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<h2 id="Hystrix源码"><a href="#Hystrix源码" class="headerlink" title="Hystrix源码"></a>Hystrix源码</h2><p>首先分析下开启Hystrix的注解@EnableCircuitBreaker</p><pre><code class="java">@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(EnableCircuitBreakerImportSelector.class)public @interface EnableCircuitBreaker {}</code></pre><p>该注解会引入EnableCircuitBreakerImportSelector类，SpringFactoryImportSelector是它的的父类，该类selectImports()方法通过springboot的SPI机制引入spring.factories中以@EnableCircuitBreaker为key的所有类。</p><pre><code class="java">public String[] selectImports(AnnotationMetadata metadata) {   if (!isEnabled()) {      return new String[0];   }   AnnotationAttributes attributes = AnnotationAttributes.fromMap(         metadata.getAnnotationAttributes(this.annotationClass.getName(), true));   Assert.notNull(attributes, &quot;No &quot; + getSimpleName() + &quot; attributes found. Is &quot;         + metadata.getClassName() + &quot; annotated with @&quot; + getSimpleName() + &quot;?&quot;);   // Find all possible auto configuration classes, filtering duplicates   List&lt;String&gt; factories = new ArrayList&lt;&gt;(new LinkedHashSet&lt;&gt;(SpringFactoriesLoader         .loadFactoryNames(this.annotationClass, this.beanClassLoader)));   if (factories.isEmpty() &amp;&amp; !hasDefaultFactory()) {      throw new IllegalStateException(&quot;Annotation @&quot; + getSimpleName()            + &quot; found, but there are no implementations. Did you forget to include a starter?&quot;);   }   if (factories.size() &gt; 1) {      // there should only ever be one DiscoveryClient, but there might be more than      // one factory      this.log.warn(&quot;More than one implementation &quot; + &quot;of @&quot; + getSimpleName()            + &quot; (now relying on @Conditionals to pick one): &quot; + factories);   }   return factories.toArray(new String[factories.size()]);}</code></pre><p>HystrixCircuitBreakerConfiguration类再上一步中被引入，该类会创建hystrixCommand注解的切面类HystrixCommandAspect。</p><pre><code class="java">@Configuration(proxyBeanMethods = false)public class HystrixCircuitBreakerConfiguration {   @Bean   public HystrixCommandAspect hystrixCommandAspect() {      return new HystrixCommandAspect();   }   {...}}</code></pre><p>HystrixCommandAspect类，会判断类上是否有@HystrixCommand或者@HystrixCollapser注解，如果有就会进入methodsAnnotatedWithHystrixCommand()环绕增强方法。</p><pre><code class="java">@Around(&quot;hystrixCommandAnnotationPointcut() || hystrixCollapserAnnotationPointcut()&quot;)public Object methodsAnnotatedWithHystrixCommand(final ProceedingJoinPoint joinPoint) throws Throwable {    Method method = getMethodFromTarget(joinPoint);    Validate.notNull(method, &quot;failed to get method from joinPoint: %s&quot;, joinPoint);    if (method.isAnnotationPresent(HystrixCommand.class) &amp;&amp; method.isAnnotationPresent(HystrixCollapser.class)) {        throw new IllegalStateException(&quot;method cannot be annotated with HystrixCommand and HystrixCollapser &quot; +                &quot;annotations at the same time&quot;);    }    MetaHolderFactory metaHolderFactory = META_HOLDER_FACTORY_MAP.get(HystrixPointcutType.of(method));    MetaHolder metaHolder = metaHolderFactory.create(joinPoint);    HystrixInvokable invokable = HystrixCommandFactory.getInstance().create(metaHolder);    ExecutionType executionType = metaHolder.isCollapserAnnotationPresent() ?            metaHolder.getCollapserExecutionType() : metaHolder.getExecutionType();    Object result;    try {        if (!metaHolder.isObservable()) {            result = CommandExecutor.execute(invokable, executionType, metaHolder);        } else {            result = executeObservable(invokable, executionType, metaHolder);        }    } catch (HystrixBadRequestException e) {        throw e.getCause();    } catch (HystrixRuntimeException e) {        throw hystrixRuntimeExceptionToThrowable(metaHolder, e);    }    return result;}</code></pre><p>methodsAnnotatedWithHystrixCommand()方法会调用execute()方法，这里涉及到同步及异步调用。</p><pre><code class="java">public static Object execute(HystrixInvokable invokable, ExecutionType executionType, MetaHolder metaHolder) throws RuntimeException {    Validate.notNull(invokable);    Validate.notNull(metaHolder);    switch (executionType) {        case SYNCHRONOUS: {            return castToExecutable(invokable, executionType).execute();        }        case ASYNCHRONOUS: {            HystrixExecutable executable = castToExecutable(invokable, executionType);            if (metaHolder.hasFallbackMethodCommand()                    &amp;&amp; ExecutionType.ASYNCHRONOUS == metaHolder.getFallbackExecutionType()) {                return new FutureDecorator(executable.queue());            }            return executable.queue();        }        case OBSERVABLE: {            HystrixObservable observable = castToObservable(invokable);            return ObservableExecutionMode.EAGER == metaHolder.getObservableExecutionMode() ? observable.observe() : observable.toObservable();        }        default:            throw new RuntimeException(&quot;unsupported execution type: &quot; + executionType);    }}</code></pre><h3 id="同步调用"><a href="#同步调用" class="headerlink" title="同步调用"></a>同步调用</h3><p>HystrixCommand类中的execute()方法，HystrixCommand类是实现了Hystrix功能的类。</p><pre><code class="java">public R execute() {    try {        return queue().get();    } catch (Exception e) {        throw Exceptions.sneakyThrow(decomposeException(e));    }}</code></pre><p>queue()</p><pre><code class="java"> public Future&lt;R&gt; queue() {     /*      * The Future returned by Observable.toBlocking().toFuture() does not implement the      * interruption of the execution thread when the &quot;mayInterrupt&quot; flag of Future.cancel(boolean) is set to true;      * thus, to comply with the contract of Future, we must wrap around it.      */     final Future&lt;R&gt; delegate = toObservable().toBlocking().toFuture();     final Future&lt;R&gt; f = new Future&lt;R&gt;() {         @Override         public boolean cancel(boolean mayInterruptIfRunning) {             if (delegate.isCancelled()) {                 return false;             }             if (HystrixCommand.this.getProperties().executionIsolationThreadInterruptOnFutureCancel().get()) {                 /*                  * The only valid transition here is false -&gt; true. If there are two futures, say f1 and f2, created by this command                  * (which is super-weird, but has never been prohibited), and calls to f1.cancel(true) and to f2.cancel(false) are                  * issued by different threads, it&#39;s unclear about what value would be used by the time mayInterruptOnCancel is checked.                  * The most consistent way to deal with this scenario is to say that if *any* cancellation is invoked with interruption,                  * than that interruption request cannot be taken back.                  */                 interruptOnFutureCancel.compareAndSet(false, mayInterruptIfRunning);          }             final boolean res = delegate.cancel(interruptOnFutureCancel.get());             if (!isExecutionComplete() &amp;&amp; interruptOnFutureCancel.get()) {                 final Thread t = executionThread.get();                 if (t != null &amp;&amp; !t.equals(Thread.currentThread())) {                     t.interrupt();                 }             }             return res;}         @Override         public boolean isCancelled() {             return delegate.isCancelled();}         @Override         public boolean isDone() {             return delegate.isDone();}         @Override         public R get() throws InterruptedException, ExecutionException {             return delegate.get();         }         @Override         public R get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {             return delegate.get(timeout, unit);         }     };     /* special handling of error states that throw immediately */     if (f.isDone()) {         try {             f.get();             return f;         } catch (Exception e) {             Throwable t = decomposeException(e);             if (t instanceof HystrixBadRequestException) {                 return f;             } else if (t instanceof HystrixRuntimeException) {                 HystrixRuntimeException hre = (HystrixRuntimeException) t;                 switch (hre.getFailureType()) {      case COMMAND_EXCEPTION:      case TIMEOUT:         // we don&#39;t throw these types from queue() only from queue().get() as they are execution errors         return f;      default:         // these are errors we throw from queue() as they as rejection type errors         throw hre;      }             } else {                 throw Exceptions.sneakyThrow(t);             }         }     }     return f; }</code></pre><p>toObservable()方法中使用了RxJava的写法，会定义多个action然后使用defer()方法调用action中的call()方法。这里重点关注applyHystrixSemantics的call()方法。</p><pre><code class="java">public Observable&lt;R&gt; toObservable() {    final AbstractCommand&lt;R&gt; _cmd = this;    //doOnCompleted handler already did all of the SUCCESS work    //doOnError handler already did all of the FAILURE/TIMEOUT/REJECTION/BAD_REQUEST work    final Action0 terminateCommandCleanup = new Action0() {        @Override        public void call() {            if (_cmd.commandState.compareAndSet(CommandState.OBSERVABLE_CHAIN_CREATED, CommandState.TERMINAL)) {                handleCommandEnd(false); //user code never ran            } else if (_cmd.commandState.compareAndSet(CommandState.USER_CODE_EXECUTED, CommandState.TERMINAL)) {                handleCommandEnd(true); //user code did run            }        }    };    //mark the command as CANCELLED and store the latency (in addition to standard cleanup)    final Action0 unsubscribeCommandCleanup = new Action0() {        @Override        public void call() {            if (_cmd.commandState.compareAndSet(CommandState.OBSERVABLE_CHAIN_CREATED, CommandState.UNSUBSCRIBED)) {                if (!_cmd.executionResult.containsTerminalEvent()) {                    _cmd.eventNotifier.markEvent(HystrixEventType.CANCELLED, _cmd.commandKey);                    try {                        executionHook.onUnsubscribe(_cmd);                    } catch (Throwable hookEx) {                        logger.warn(&quot;Error calling HystrixCommandExecutionHook.onUnsubscribe&quot;, hookEx);                    }                    _cmd.executionResultAtTimeOfCancellation = _cmd.executionResult                            .addEvent((int) (System.currentTimeMillis() - _cmd.commandStartTimestamp), HystrixEventType.CANCELLED);                }                handleCommandEnd(false); //user code never ran            } else if (_cmd.commandState.compareAndSet(CommandState.USER_CODE_EXECUTED, CommandState.UNSUBSCRIBED)) {                if (!_cmd.executionResult.containsTerminalEvent()) {                    _cmd.eventNotifier.markEvent(HystrixEventType.CANCELLED, _cmd.commandKey);                    try {                        executionHook.onUnsubscribe(_cmd);                    } catch (Throwable hookEx) {                        logger.warn(&quot;Error calling HystrixCommandExecutionHook.onUnsubscribe&quot;, hookEx);                    }                    _cmd.executionResultAtTimeOfCancellation = _cmd.executionResult                            .addEvent((int) (System.currentTimeMillis() - _cmd.commandStartTimestamp), HystrixEventType.CANCELLED);                }                handleCommandEnd(true); //user code did run            }        }    };    final Func0&lt;Observable&lt;R&gt;&gt; applyHystrixSemantics = new Func0&lt;Observable&lt;R&gt;&gt;() {        @Override        public Observable&lt;R&gt; call() {            if (commandState.get().equals(CommandState.UNSUBSCRIBED)) {                return Observable.never();            }            return applyHystrixSemantics(_cmd);        }    };    final Func1&lt;R, R&gt; wrapWithAllOnNextHooks = new Func1&lt;R, R&gt;() {        @Override        public R call(R r) {            R afterFirstApplication = r;            try {                afterFirstApplication = executionHook.onComplete(_cmd, r);            } catch (Throwable hookEx) {                logger.warn(&quot;Error calling HystrixCommandExecutionHook.onComplete&quot;, hookEx);            }            try {                return executionHook.onEmit(_cmd, afterFirstApplication);            } catch (Throwable hookEx) {                logger.warn(&quot;Error calling HystrixCommandExecutionHook.onEmit&quot;, hookEx);                return afterFirstApplication;            }        }    };    final Action0 fireOnCompletedHook = new Action0() {        @Override        public void call() {            try {                executionHook.onSuccess(_cmd);            } catch (Throwable hookEx) {                logger.warn(&quot;Error calling HystrixCommandExecutionHook.onSuccess&quot;, hookEx);            }        }    };    return Observable.defer(new Func0&lt;Observable&lt;R&gt;&gt;() {        @Override        public Observable&lt;R&gt; call() {             /* this is a stateful object so can only be used once */            if (!commandState.compareAndSet(CommandState.NOT_STARTED, CommandState.OBSERVABLE_CHAIN_CREATED)) {                IllegalStateException ex = new IllegalStateException(&quot;This instance can only be executed once. Please instantiate a new instance.&quot;);                //TODO make a new error type for this                throw new HystrixRuntimeException(FailureType.BAD_REQUEST_EXCEPTION, _cmd.getClass(), getLogMessagePrefix() + &quot; command executed multiple times - this is not permitted.&quot;, ex, null);            }            commandStartTimestamp = System.currentTimeMillis();            if (properties.requestLogEnabled().get()) {                // log this command execution regardless of what happened                if (currentRequestLog != null) {                    currentRequestLog.addExecutedCommand(_cmd);                }            }            final boolean requestCacheEnabled = isRequestCachingEnabled();            final String cacheKey = getCacheKey();            /* try from cache first */            if (requestCacheEnabled) {                HystrixCommandResponseFromCache&lt;R&gt; fromCache = (HystrixCommandResponseFromCache&lt;R&gt;) requestCache.get(cacheKey);                if (fromCache != null) {                    isResponseFromCache = true;                    return handleRequestCacheHitAndEmitValues(fromCache, _cmd);                }            }            Observable&lt;R&gt; hystrixObservable =                    Observable.defer(applyHystrixSemantics)                            .map(wrapWithAllOnNextHooks);            Observable&lt;R&gt; afterCache;            // put in cache            if (requestCacheEnabled &amp;&amp; cacheKey != null) {                // wrap it for caching                HystrixCachedObservable&lt;R&gt; toCache = HystrixCachedObservable.from(hystrixObservable, _cmd);                HystrixCommandResponseFromCache&lt;R&gt; fromCache = (HystrixCommandResponseFromCache&lt;R&gt;) requestCache.putIfAbsent(cacheKey, toCache);                if (fromCache != null) {                    // another thread beat us so we&#39;ll use the cached value instead                    toCache.unsubscribe();                    isResponseFromCache = true;                    return handleRequestCacheHitAndEmitValues(fromCache, _cmd);                } else {                    // we just created an ObservableCommand so we cast and return it                    afterCache = toCache.toObservable();                }            } else {                afterCache = hystrixObservable;            }            return afterCache                    .doOnTerminate(terminateCommandCleanup)     // perform cleanup once (either on normal terminal state (this line), or unsubscribe (next line))                    .doOnUnsubscribe(unsubscribeCommandCleanup) // perform cleanup once                    .doOnCompleted(fireOnCompletedHook);        }    });}</code></pre><p>call()方法中会调用applyHystrixSemantics()方法，会通过allowRequest()方法来判断是否允许请求，如果是信号量策略，会调用getExecutionSemaphore()方法拿到信号量，再调用tryAcquire()判断是否超过最大请求数，然后执行executeCommandAndObserve()方法。如果不是信号量策略tryAcquire()方法会直接返回true，然后在executeCommandAndObserve()方法进行判断。不允许或者已超过最大请求数都会走到handleShortCircuitViaFallback()降级方法。降级方法的逻辑与正常方法基本一致，此处不在赘述，唯一不同的是，如果降级方法超过了设置的最大请求数，会直接拒绝请求抛出异常，所以hystrix能够接收的请求数为二倍的最大请求数，超过就会直接拒绝。</p><pre><code class="java">private Observable&lt;R&gt; applyHystrixSemantics(final AbstractCommand&lt;R&gt; _cmd) {    // mark that we&#39;re starting execution on the ExecutionHook    // if this hook throws an exception, then a fast-fail occurs with no fallback.  No state is left inconsistent    executionHook.onStart(_cmd);    /* determine if we&#39;re allowed to execute */    if (circuitBreaker.allowRequest()) {        final TryableSemaphore executionSemaphore = getExecutionSemaphore();        final AtomicBoolean semaphoreHasBeenReleased = new AtomicBoolean(false);        final Action0 singleSemaphoreRelease = new Action0() {            @Override            public void call() {                if (semaphoreHasBeenReleased.compareAndSet(false, true)) {                    executionSemaphore.release();                }            }        };        final Action1&lt;Throwable&gt; markExceptionThrown = new Action1&lt;Throwable&gt;() {            @Override            public void call(Throwable t) {                eventNotifier.markEvent(HystrixEventType.EXCEPTION_THROWN, commandKey);            }        };        if (executionSemaphore.tryAcquire()) {            try {                /* used to track userThreadExecutionTime */                executionResult = executionResult.setInvocationStartTime(System.currentTimeMillis());                return executeCommandAndObserve(_cmd)                        .doOnError(markExceptionThrown)                        .doOnTerminate(singleSemaphoreRelease)                        .doOnUnsubscribe(singleSemaphoreRelease);            } catch (RuntimeException e) {                return Observable.error(e);            }        } else {            return handleSemaphoreRejectionViaFallback();        }    } else {        return handleShortCircuitViaFallback();    }}</code></pre><h3 id="判断是否允许请求"><a href="#判断是否允许请求" class="headerlink" title="判断是否允许请求"></a>判断是否允许请求</h3><p>allowRequest()方法，刚方法首先会判断熔断器是否开启，如果开启就会返回false，如果关闭会调用isOpen()方法判断是否要开启熔断器，最后根据isOpen()方法及allowSingleTest()方法的返回值决定是否允许请求。allowSingleTest()方法用于判断本次请求是否允许，即熔断器半开状态。</p><pre><code class="java">@Overridepublic boolean allowRequest() {    // 判断熔断器是否开启    if (properties.circuitBreakerForceOpen().get()) {        // properties have asked us to force the circuit open so we will allow NO requests        return false;    }    // 熔断器关闭，继续判断    if (properties.circuitBreakerForceClosed().get()) {        // we still want to allow isOpen() to perform it&#39;s calculations so we simulate normal behavior        isOpen();        // properties have asked us to ignore errors so we will ignore the results of isOpen and just allow all traffic through        return true;    }    return !isOpen() || allowSingleTest();}</code></pre><h4 id="判断是否开启熔断器"><a href="#判断是否开启熔断器" class="headerlink" title="判断是否开启熔断器"></a>判断是否开启熔断器</h4><p>isOpen()方法首先会根据请求数及错误率决定是否开启熔断器，设置熔断器的状态时使用了cas保证线程安全。</p><pre><code class="java">    public boolean isOpen() {        if (circuitOpen.get()) {            // if we&#39;re open we immediately return true and don&#39;t bother attempting to &#39;close&#39; ourself as that is left to allowSingleTest and a subsequent successful test to close            return true;        }        // we&#39;re closed, so let&#39;s see if errors have made us so we should trip the circuit open        HealthCounts health = metrics.getHealthCounts();        // check if we are past the statisticalWindowVolumeThreshold        // 判断请求数        if (health.getTotalRequests() &lt; properties.circuitBreakerRequestVolumeThreshold().get()) {            // we are not past the minimum volume threshold for the statisticalWindow so we&#39;ll return false immediately and not calculate anything            return false;        }        // 判断错误率        if (health.getErrorPercentage() &lt; properties.circuitBreakerErrorThresholdPercentage().get()) {            return false;        } else {            // our failure rate is too high, trip the circuit            if (circuitOpen.compareAndSet(false, true)) {                // if the previousValue was false then we want to set the currentTime                circuitOpenedOrLastTestedTime.set(System.currentTimeMillis());                return true;            } else {                // How could previousValue be true? If another thread was going through this code at the same time a race-condition could have                // caused another thread to set it to true already even though we were in the process of doing the same                // In this case, we know the circuit is open, so let the other thread set the currentTime and report back that the circuit is open                return true;            }        }    }}</code></pre><h4 id="是否允许本次请求（半开状态）"><a href="#是否允许本次请求（半开状态）" class="headerlink" title="是否允许本次请求（半开状态）"></a>是否允许本次请求（半开状态）</h4><p>allowSingleTest()方法用于判断是否允许本次请求，即熔断器半开状态的判断。该方法首先会判断熔断器的状态，即当前时间是否大于熔断器开启时间+熔断器转为半开状态时间。</p><pre><code class="java">public boolean allowSingleTest() {    long timeCircuitOpenedOrWasLastTested = circuitOpenedOrLastTestedTime.get();    // 1) if the circuit is open    // 2) and it&#39;s been longer than &#39;sleepWindow&#39; since we opened the circuit    if (circuitOpen.get() &amp;&amp; System.currentTimeMillis() &gt; timeCircuitOpenedOrWasLastTested + properties.circuitBreakerSleepWindowInMilliseconds().get()) {        // We push the &#39;circuitOpenedTime&#39; ahead by &#39;sleepWindow&#39; since we have allowed one request to try.        // If it succeeds the circuit will be closed, otherwise another singleTest will be allowed at the end of the &#39;sleepWindow&#39;.        if (circuitOpenedOrLastTestedTime.compareAndSet(timeCircuitOpenedOrWasLastTested, System.currentTimeMillis())) {            // if this returns true that means we set the time so we&#39;ll return true to allow the singleTest            // if it returned false it means another thread raced us and allowed the singleTest before we did            return true;        }    }    return false;}</code></pre><h3 id="判断最大请求数"><a href="#判断最大请求数" class="headerlink" title="判断最大请求数"></a>判断最大请求数</h3><pre><code class="java">@Overridepublic boolean tryAcquire() {    int currentCount = count.incrementAndGet();    if (currentCount &gt; numberOfPermits.get()) {        count.decrementAndGet();        return false;    } else {        return true;    }}</code></pre><h3 id="业务方法的执行"><a href="#业务方法的执行" class="headerlink" title="业务方法的执行"></a>业务方法的执行</h3><p>主要是通过executeCommandAndObserve()方法中注册的匿名内部类完成的，包括超时时间的判断，线程数的判断，还有具体的业务方法执行。</p><h4 id="超时时间及线程数的判断"><a href="#超时时间及线程数的判断" class="headerlink" title="超时时间及线程数的判断"></a>超时时间及线程数的判断</h4><p>executeCommandAndObserve()中创建HystrixObservableTimeoutOperator类，并调用其call()方法，该方法会创建一个TimeListener并设置超时时间，然后调用addTimerListener()方法创建线程。</p><pre><code class="java">@Overridepublic Subscriber&lt;? super R&gt; call(final Subscriber&lt;? super R&gt; child) {    final CompositeSubscription s = new CompositeSubscription();    // if the child unsubscribes we unsubscribe our parent as well    child.add(s);    /*     * Define the action to perform on timeout outside of the TimerListener to it can capture the HystrixRequestContext     * of the calling thread which doesn&#39;t exist on the Timer thread.     */    final HystrixContextRunnable timeoutRunnable = new HystrixContextRunnable(originalCommand.concurrencyStrategy, new Runnable() {        @Override        public void run() {            child.onError(new HystrixTimeoutException());        }    });    TimerListener listener = new TimerListener() {        @Override        public void tick() {            // if we can go from NOT_EXECUTED to TIMED_OUT then we do the timeout codepath            // otherwise it means we lost a race and the run() execution completed or did not start            if (originalCommand.isCommandTimedOut.compareAndSet(TimedOutStatus.NOT_EXECUTED, TimedOutStatus.TIMED_OUT)) {                // report timeout failure                originalCommand.eventNotifier.markEvent(HystrixEventType.TIMEOUT, originalCommand.commandKey);                // shut down the original request                s.unsubscribe();                timeoutRunnable.run();                //if it did not start, then we need to mark a command start for concurrency metrics, and then issue the timeout            }        }        @Override        public int getIntervalTimeInMilliseconds() {            return originalCommand.properties.executionTimeoutInMilliseconds().get();        }    };    final Reference&lt;TimerListener&gt; tl = HystrixTimer.getInstance().addTimerListener(listener);    // set externally so execute/queue can see this    originalCommand.timeoutTimer.set(tl);    /**     * If this subscriber receives values it means the parent succeeded/completed     */    Subscriber&lt;R&gt; parent = new Subscriber&lt;R&gt;() {        @Override        public void onCompleted() {            if (isNotTimedOut()) {                // stop timer and pass notification through                tl.clear();                child.onCompleted();            }        }        @Override        public void onError(Throwable e) {            if (isNotTimedOut()) {                // stop timer and pass notification through                tl.clear();                child.onError(e);            }        }        @Override        public void onNext(R v) {            if (isNotTimedOut()) {                child.onNext(v);            }        }        private boolean isNotTimedOut() {            // if already marked COMPLETED (by onNext) or succeeds in setting to COMPLETED            return originalCommand.isCommandTimedOut.get() == TimedOutStatus.COMPLETED ||                    originalCommand.isCommandTimedOut.compareAndSet(TimedOutStatus.NOT_EXECUTED, TimedOutStatus.COMPLETED);        }    };    // if s is unsubscribed we want to unsubscribe the parent    s.add(parent);    return parent;}</code></pre><p>addTimerListener()方法主要是获取到配置的线程池然后创建线程。</p><pre><code class="java">public Reference&lt;TimerListener&gt; addTimerListener(final TimerListener listener) {    startThreadIfNeeded();    // add the listener    Runnable r = new Runnable() {        @Override        public void run() {            try {                listener.tick();            } catch (Exception e) {                logger.error(&quot;Failed while ticking TimerListener&quot;, e);            }        }    };    ScheduledFuture&lt;?&gt; f = executor.get().getThreadPool().scheduleAtFixedRate(r, listener.getIntervalTimeInMilliseconds(), listener.getIntervalTimeInMilliseconds(), TimeUnit.MILLISECONDS);    return new TimerReference(listener, f);}</code></pre><h4 id="业务方法的执行-1"><a href="#业务方法的执行-1" class="headerlink" title="业务方法的执行"></a>业务方法的执行</h4><p>executeCommandWithSpecifiedIsolation()方法</p><pre><code class="java">private Observable&lt;R&gt; executeCommandWithSpecifiedIsolation(final AbstractCommand&lt;R&gt; _cmd) {    if (properties.executionIsolationStrategy().get() == ExecutionIsolationStrategy.THREAD) {        // mark that we are executing in a thread (even if we end up being rejected we still were a THREAD execution and not SEMAPHORE)        return Observable.defer(new Func0&lt;Observable&lt;R&gt;&gt;() {            @Override            public Observable&lt;R&gt; call() {                executionResult = executionResult.setExecutionOccurred();                if (!commandState.compareAndSet(CommandState.OBSERVABLE_CHAIN_CREATED, CommandState.USER_CODE_EXECUTED)) {                    return Observable.error(new IllegalStateException(&quot;execution attempted while in state : &quot; + commandState.get().name()));                }                metrics.markCommandStart(commandKey, threadPoolKey, ExecutionIsolationStrategy.THREAD);                if (isCommandTimedOut.get() == TimedOutStatus.TIMED_OUT) {                    // the command timed out in the wrapping thread so we will return immediately                    // and not increment any of the counters below or other such logic                    return Observable.error(new RuntimeException(&quot;timed out before executing run()&quot;));                }                if (threadState.compareAndSet(ThreadState.NOT_USING_THREAD, ThreadState.STARTED)) {                    //we have not been unsubscribed, so should proceed                    HystrixCounters.incrementGlobalConcurrentThreads();                    threadPool.markThreadExecution();                    // store the command that is being run                    endCurrentThreadExecutingCommand = Hystrix.startCurrentThreadExecutingCommand(getCommandKey());                    executionResult = executionResult.setExecutedInThread();                    /**                     * If any of these hooks throw an exception, then it appears as if the actual execution threw an error                     */                    try {                        executionHook.onThreadStart(_cmd);                        executionHook.onRunStart(_cmd);                        executionHook.onExecutionStart(_cmd);                        return getUserExecutionObservable(_cmd);                    } catch (Throwable ex) {                        return Observable.error(ex);                    }                } else {                    //command has already been unsubscribed, so return immediately                    return Observable.error(new RuntimeException(&quot;unsubscribed before executing run()&quot;));                }            }        }).doOnTerminate(new Action0() {            @Override            public void call() {                if (threadState.compareAndSet(ThreadState.STARTED, ThreadState.TERMINAL)) {                    handleThreadEnd(_cmd);                }                if (threadState.compareAndSet(ThreadState.NOT_USING_THREAD, ThreadState.TERMINAL)) {                    //if it was never started and received terminal, then no need to clean up (I don&#39;t think this is possible)                }                //if it was unsubscribed, then other cleanup handled it            }        }).doOnUnsubscribe(new Action0() {            @Override            public void call() {                if (threadState.compareAndSet(ThreadState.STARTED, ThreadState.UNSUBSCRIBED)) {                    handleThreadEnd(_cmd);                }                if (threadState.compareAndSet(ThreadState.NOT_USING_THREAD, ThreadState.UNSUBSCRIBED)) {                    //if it was never started and was cancelled, then no need to clean up                }                //if it was terminal, then other cleanup handled it            }        }).subscribeOn(threadPool.getScheduler(new Func0&lt;Boolean&gt;() {            @Override            public Boolean call() {                return properties.executionIsolationThreadInterruptOnTimeout().get() &amp;&amp; _cmd.isCommandTimedOut.get() == TimedOutStatus.TIMED_OUT;            }        }));    } else {        return Observable.defer(new Func0&lt;Observable&lt;R&gt;&gt;() {            @Override            public Observable&lt;R&gt; call() {                executionResult = executionResult.setExecutionOccurred();                if (!commandState.compareAndSet(CommandState.OBSERVABLE_CHAIN_CREATED, CommandState.USER_CODE_EXECUTED)) {                    return Observable.error(new IllegalStateException(&quot;execution attempted while in state : &quot; + commandState.get().name()));                }                metrics.markCommandStart(commandKey, threadPoolKey, ExecutionIsolationStrategy.SEMAPHORE);                // semaphore isolated                // store the command that is being run                endCurrentThreadExecutingCommand = Hystrix.startCurrentThreadExecutingCommand(getCommandKey());                try {                    executionHook.onRunStart(_cmd);                    executionHook.onExecutionStart(_cmd);                    return getUserExecutionObservable(_cmd);  //the getUserExecutionObservable method already wraps sync exceptions, so this shouldn&#39;t throw                } catch (Throwable ex) {                    //If the above hooks throw, then use that as the result of the run method                    return Observable.error(ex);                }            }        });    }}</code></pre><p>getUserExecutionObservable()</p><p>该方法最终会调用到HystrixCommand的getExecutionObservable()方法，该方法会调用到HystrixCommand中run()方法，该方法是比较重要的一个钩子方法。</p><pre><code class="java">final protected Observable&lt;R&gt; getExecutionObservable() {    return Observable.defer(new Func0&lt;Observable&lt;R&gt;&gt;() {        @Override        public Observable&lt;R&gt; call() {            try {                return Observable.just(run());            } catch (Throwable ex) {                return Observable.error(ex);            }        }    }).doOnSubscribe(new Action0() {        @Override        public void call() {            // Save thread on which we get subscribed so that we can interrupt it later if needed            executionThread.set(Thread.currentThread());        }    });}</code></pre><p>run()方法会调用到GenericCommand的run()方法，该方法最终会通过反射调用到业务方法。</p><pre><code class="java">@Overrideprotected Object run() throws Exception {    LOGGER.debug(&quot;execute command: {}&quot;, getCommandKey().name());    return process(new Action() {        @Override        Object execute() {            return getCommandAction().execute(getExecutionType());        }    });}</code></pre>]]></content>
    
    
    <categories>
      
      <category>springcloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码解读</tag>
      
      <tag>springcloud</tag>
      
      <tag>hystrix</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ribbon源码解读</title>
    <link href="/2020/04/27/ribbon%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"/>
    <url>/2020/04/27/ribbon%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<h2 id="ribbon基础类的注册"><a href="#ribbon基础类的注册" class="headerlink" title="ribbon基础类的注册"></a>ribbon基础类的注册</h2><p>spring-cloud-netflix-ribbon-2.2.2.RELEASE.jar类的spring.factories会引入RibbonAutoConfiguration类，该类会创建两个比较重要的点：LoadBanlancerClient跟SpringClientFactory，configurations属性也需要注意下。</p><pre><code class="java">@Configuration@Conditional(RibbonAutoConfiguration.RibbonClassesConditions.class)@RibbonClients@AutoConfigureAfter(        name = &quot;org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration&quot;)@AutoConfigureBefore({ LoadBalancerAutoConfiguration.class,        AsyncLoadBalancerAutoConfiguration.class })@EnableConfigurationProperties({ RibbonEagerLoadProperties.class,        ServerIntrospectorProperties.class })public class RibbonAutoConfiguration {    @Autowired(required = false)    private List&lt;RibbonClientSpecification&gt; configurations = new ArrayList&lt;&gt;();    @Autowired    private RibbonEagerLoadProperties ribbonEagerLoadProperties;    @Bean    public HasFeatures ribbonFeature() {        return HasFeatures.namedFeature(&quot;Ribbon&quot;, Ribbon.class);    }    @Bean    public SpringClientFactory springClientFactory() {        SpringClientFactory factory = new SpringClientFactory();        factory.setConfigurations(this.configurations);        return factory;    }    @Bean    @ConditionalOnMissingBean(LoadBalancerClient.class)    public LoadBalancerClient loadBalancerClient() {        return new RibbonLoadBalancerClient(springClientFactory());    }  {...}}</code></pre><p>spring-cloud-commons-2.2.2.RELEASE.jar的spring.factores会引入一个比较重要的类：LoadBalancerAutoConfiguration，LoadBalancerAutoConfiguration类的restTemplateCustomizer()方法会设置拦截器到restTemplate中。</p><pre><code class="java">@Bean@ConditionalOnMissingBeanpublic RestTemplateCustomizer restTemplateCustomizer(      final LoadBalancerInterceptor loadBalancerInterceptor) {   return restTemplate -&gt; {      List&lt;ClientHttpRequestInterceptor&gt; list = new ArrayList&lt;&gt;(            restTemplate.getInterceptors());      list.add(loadBalancerInterceptor);      restTemplate.setInterceptors(list);   };}</code></pre><h2 id="RestTemplate的主流程"><a href="#RestTemplate的主流程" class="headerlink" title="RestTemplate的主流程"></a>RestTemplate的主流程</h2><p>RestTemplate中的execute方法首先会调用到InterceptingClientHttpRequest类中的execute()方法，该方法首先会调用restTemplate中的拦截器的intercept()方法。</p><pre><code class="java">@Overridepublic ClientHttpResponse execute(HttpRequest request, byte[] body) throws IOException {   if (this.iterator.hasNext()) {      ClientHttpRequestInterceptor nextInterceptor = this.iterator.next();      return nextInterceptor.intercept(request, body, this);   }   else {      HttpMethod method = request.getMethod();      Assert.state(method != null, &quot;No standard HTTP method&quot;);      ClientHttpRequest delegate = requestFactory.createRequest(request.getURI(), method);      request.getHeaders().forEach((key, value) -&gt; delegate.getHeaders().addAll(key, value));      if (body.length &gt; 0) {         if (delegate instanceof StreamingHttpOutputMessage) {            StreamingHttpOutputMessage streamingOutputMessage = (StreamingHttpOutputMessage) delegate;            streamingOutputMessage.setBody(outputStream -&gt; StreamUtils.copy(body, outputStream));         }         else {            StreamUtils.copy(body, delegate.getBody());         }      }      return delegate.execute();   }}</code></pre><p>intercept()方法会调用createRequest()方法创建获取到服务之后的调用的request对象。</p><pre><code class="java">@Overridepublic ClientHttpResponse intercept(final HttpRequest request, final byte[] body,      final ClientHttpRequestExecution execution) throws IOException {   final URI originalUri = request.getURI();   String serviceName = originalUri.getHost();   Assert.state(serviceName != null,         &quot;Request URI does not contain a valid hostname: &quot; + originalUri);   return this.loadBalancer.execute(serviceName,         this.requestFactory.createRequest(request, body, execution));}</code></pre><p>intercept()方法会调用到RibbonLoadBalancerClient的execute()方法，RibbonLoadBalancerClient已经在RibbonAutoConfiguration中已经通过@Bean的方式注入。该方法会调用getLoadBalancer()方法获取到服务列表，然后调用getServer()方法获取到要调用的服务。</p><pre><code class="java">public &lt;T&gt; T execute(String serviceId, LoadBalancerRequest&lt;T&gt; request, Object hint)      throws IOException {   ILoadBalancer loadBalancer = getLoadBalancer(serviceId);   Server server = getServer(loadBalancer, hint);   if (server == null) {      throw new IllegalStateException(&quot;No instances available for &quot; + serviceId);   }   RibbonServer ribbonServer = new RibbonServer(serviceId, server,         isSecure(server, serviceId),         serverIntrospector(serviceId).getMetadata(server));   return execute(serviceId, ribbonServer, request);}</code></pre><p>该方法会由execute()方法调用，用于获取到服务之后会进行reqeust的回调。</p><pre><code class="java">@Overridepublic &lt;T&gt; T execute(String serviceId, ServiceInstance serviceInstance,      LoadBalancerRequest&lt;T&gt; request) throws IOException {   Server server = null;   if (serviceInstance instanceof RibbonServer) {      server = ((RibbonServer) serviceInstance).getServer();   }   if (server == null) {      throw new IllegalStateException(&quot;No instances available for &quot; + serviceId);   }   RibbonLoadBalancerContext context = this.clientFactory         .getLoadBalancerContext(serviceId);   RibbonStatsRecorder statsRecorder = new RibbonStatsRecorder(context, server);   try {      T returnVal = request.apply(serviceInstance);      statsRecorder.recordStats(returnVal);      return returnVal;   }   // catch IOException and rethrow so RestTemplate behaves correctly   catch (IOException ex) {      statsRecorder.recordStats(ex);      throw ex;   }   catch (Exception ex) {      statsRecorder.recordStats(ex);      ReflectionUtils.rethrowRuntimeException(ex);   }   return null;}</code></pre><h3 id="获取服务列表"><a href="#获取服务列表" class="headerlink" title="获取服务列表"></a>获取服务列表</h3><p>intercept()方法会调用getLoadBalancer()方法获取ILoadBalancer类型的实例，getLoadBalancer()方法会调用clientFactory的getLoadBalancer()方法，clientFactory已经在RibbonAutoConfiguration中已经通过@Bean的方式注入。</p><pre><code class="java">protected ILoadBalancer getLoadBalancer(String serviceId) {   return this.clientFactory.getLoadBalancer(serviceId);}</code></pre><p>getLoadBalancer()会调用getInstance()方法，该方法根据服务名称创建一个容器，然后把容器跟服务名称放入缓存，所以ribbon在第一次服务名称调用的时候是比较慢的，涉及到创建容器过程，第二次就直接从缓存里面拿容器对象了。这里在调用的时候获取容器的目的是为了拿到最新的服务列表。</p><pre><code class="java">public &lt;T&gt; T getInstance(String name, Class&lt;T&gt; type) {   AnnotationConfigApplicationContext context = getContext(name);   if (BeanFactoryUtils.beanNamesForTypeIncludingAncestors(context,         type).length &gt; 0) {      return context.getBean(type);   }   return null;}</code></pre><p>getInstance()方法会调用getContext()方法。</p><pre><code class="java">protected AnnotationConfigApplicationContext getContext(String name) {   if (!this.contexts.containsKey(name)) {      synchronized (this.contexts) {         if (!this.contexts.containsKey(name)) {            this.contexts.put(name, createContext(name));         }      }   }   return this.contexts.get(name);}</code></pre><p>如果不存在context就会调用createContext()方法创建容器，并加载两个比较重要的类EurekaRibbonClientConfiguration跟RibbonClientConfiguration到容器中，然后触发这两个类重新获取服务列表。</p><pre><code class="java">protected AnnotationConfigApplicationContext createContext(String name) {   AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext();   if (this.configurations.containsKey(name)) {      for (Class&lt;?&gt; configuration : this.configurations.get(name)            .getConfiguration()) {         context.register(configuration);      }   }   for (Map.Entry&lt;String, C&gt; entry : this.configurations.entrySet()) {      if (entry.getKey().startsWith(&quot;default.&quot;)) {         for (Class&lt;?&gt; configuration : entry.getValue().getConfiguration()) {            context.register(configuration);         }      }   }   context.register(PropertyPlaceholderAutoConfiguration.class,         this.defaultConfigType);   context.getEnvironment().getPropertySources().addFirst(new MapPropertySource(         this.propertySourceName,         Collections.&lt;String, Object&gt;singletonMap(this.propertyName, name)));   if (this.parent != null) {      // Uses Environment from parent as well as beans      context.setParent(this.parent);      // jdk11 issue      // https://github.com/spring-cloud/spring-cloud-netflix/issues/3101      context.setClassLoader(this.parent.getClassLoader());   }   context.setDisplayName(generateDisplayName(name));   context.refresh();   return context;}</code></pre><h4 id="EurekaRibbonClientConfiguration类"><a href="#EurekaRibbonClientConfiguration类" class="headerlink" title="EurekaRibbonClientConfiguration类"></a>EurekaRibbonClientConfiguration类</h4><p>EurekaRibbonClientConfiguration的ribbonServerList()方法会创建服务列表</p><pre><code class="java">@Bean@ConditionalOnMissingBeanpublic ServerList&lt;?&gt; ribbonServerList(IClientConfig config,      Provider&lt;EurekaClient&gt; eurekaClientProvider) {   if (this.propertiesFactory.isSet(ServerList.class, serviceId)) {      return this.propertiesFactory.get(ServerList.class, config, serviceId);   }   DiscoveryEnabledNIWSServerList discoveryServerList = new DiscoveryEnabledNIWSServerList(         config, eurekaClientProvider);   DomainExtractingServerList serverList = new DomainExtractingServerList(         discoveryServerList, config, this.approximateZoneFromHostname);   return serverList;}</code></pre><p>DiscoveryEnabledNIWSServerList类会在ribbonServerList()方法中创建，该类中有一个特别重要的方法getInitialListOfServers()。</p><pre><code class="java">public List&lt;DiscoveryEnabledServer&gt; getInitialListOfServers() {    return this.obtainServersViaDiscovery();}</code></pre><p>getInitialListOfServers()方法会调用obtainServersViaDiscovery()方法</p><pre><code class="java">private List&lt;DiscoveryEnabledServer&gt; obtainServersViaDiscovery() {    List&lt;DiscoveryEnabledServer&gt; serverList = new ArrayList();    if (this.eurekaClientProvider != null &amp;&amp; this.eurekaClientProvider.get() != null) {        EurekaClient eurekaClient = (EurekaClient)this.eurekaClientProvider.get();        if (this.vipAddresses != null) {            String[] var3 = this.vipAddresses.split(&quot;,&quot;);            int var4 = var3.length;            for(int var5 = 0; var5 &lt; var4; ++var5) {                String vipAddress = var3[var5];                List&lt;InstanceInfo&gt; listOfInstanceInfo = eurekaClient.getInstancesByVipAddress(vipAddress, this.isSecure, this.targetRegion);                Iterator var8 = listOfInstanceInfo.iterator();                while(var8.hasNext()) {                    InstanceInfo ii = (InstanceInfo)var8.next();                    if (ii.getStatus().equals(InstanceStatus.UP)) {                        if (this.shouldUseOverridePort) {                            if (logger.isDebugEnabled()) {                                logger.debug(&quot;Overriding port on client name: &quot; + this.clientName + &quot; to &quot; + this.overridePort);                            }                            InstanceInfo copy = new InstanceInfo(ii);                            if (this.isSecure) {                                ii = (new Builder(copy)).setSecurePort(this.overridePort).build();                            } else {                                ii = (new Builder(copy)).setPort(this.overridePort).build();                            }                        }                        DiscoveryEnabledServer des = this.createServer(ii, this.isSecure, this.shouldUseIpAddr);                        serverList.add(des);                    }                }                if (serverList.size() &gt; 0 &amp;&amp; this.prioritizeVipAddressBasedServers) {                    break;                }            }        }        return serverList;    } else {        logger.warn(&quot;EurekaClient has not been initialized yet, returning an empty list&quot;);        return new ArrayList();    }}</code></pre><p>obtainServersViaDiscovery()方法会调用getInstancesByVipAddress()方法，该方法会从localRegionApps中或eureka服务端拉取到的服务列表的变量中获取到服务列表。localRegionApps中的服务列表来源于eureka客户端源码中的服务拉取部分。</p><pre><code class="java">@Overridepublic List&lt;InstanceInfo&gt; getInstancesByVipAddress(String vipAddress, boolean secure,                                                   @Nullable String region) {    if (vipAddress == null) {        throw new IllegalArgumentException(                &quot;Supplied VIP Address cannot be null&quot;);    }    Applications applications;    if (instanceRegionChecker.isLocalRegion(region)) {        applications = this.localRegionApps.get();    } else {        applications = remoteRegionVsApps.get(region);        if (null == applications) {            logger.debug(&quot;No applications are defined for region {}, so returning an empty instance list for vip &quot;                    + &quot;address {}.&quot;, region, vipAddress);            return Collections.emptyList();        }    }    if (!secure) {        return applications.getInstancesByVirtualHostName(vipAddress);    } else {        return applications.getInstancesBySecureVirtualHostName(vipAddress);    }}</code></pre><h4 id="RibbonClientConfiguration类"><a href="#RibbonClientConfiguration类" class="headerlink" title="RibbonClientConfiguration类"></a>RibbonClientConfiguration类</h4><p>这个类中有一个非常重要的方法ribbonLoadBalancer()，该方法会将serverList注入，serverList是从EurekaRibbonClientConfiguration中获取的。</p><pre><code class="java">@Bean@ConditionalOnMissingBeanpublic ILoadBalancer ribbonLoadBalancer(IClientConfig config,      ServerList&lt;Server&gt; serverList, ServerListFilter&lt;Server&gt; serverListFilter,      IRule rule, IPing ping, ServerListUpdater serverListUpdater) {   if (this.propertiesFactory.isSet(ILoadBalancer.class, name)) {      return this.propertiesFactory.get(ILoadBalancer.class, config, name);   }   return new ZoneAwareLoadBalancer&lt;&gt;(config, rule, ping, serverList,         serverListFilter, serverListUpdater);}</code></pre><p>ribbonLoadBalancer()方法获取到的实例就是ZoneAwareLoadBalancer实例。在该类实例化的构造函数中，最终会调到其父类的构造函数。</p><pre><code class="java">public DynamicServerListLoadBalancer(IClientConfig clientConfig, IRule rule, IPing ping,                                     ServerList&lt;T&gt; serverList, ServerListFilter&lt;T&gt; filter,                                     ServerListUpdater serverListUpdater) {    super(clientConfig, rule, ping);    this.serverListImpl = serverList;    this.filter = filter;    this.serverListUpdater = serverListUpdater;    if (filter instanceof AbstractServerListFilter) {        ((AbstractServerListFilter) filter).setLoadBalancerStats(getLoadBalancerStats());    }    restOfInit(clientConfig);}</code></pre><p>restOfInit()方法会在构造函数中被调用。</p><pre><code class="java">void restOfInit(IClientConfig clientConfig) {    boolean primeConnection = this.isEnablePrimingConnections();    // turn this off to avoid duplicated asynchronous priming done in BaseLoadBalancer.setServerList()    this.setEnablePrimingConnections(false);    enableAndInitLearnNewServersFeature();    updateListOfServers();    if (primeConnection &amp;&amp; this.getPrimeConnections() != null) {        this.getPrimeConnections()                .primeConnections(getReachableServers());    }    this.setEnablePrimingConnections(primeConnection);    LOGGER.info(&quot;DynamicServerListLoadBalancer for client {} initialized: {}&quot;, clientConfig.getClientName(), this.toString());}</code></pre><p>restOfInit()方法会调用updateListOfServers()方法。</p><pre><code class="java">@VisibleForTestingpublic void updateListOfServers() {    List&lt;T&gt; servers = new ArrayList&lt;T&gt;();    if (serverListImpl != null) {        servers = serverListImpl.getUpdatedListOfServers();        LOGGER.debug(&quot;List of Servers for {} obtained from Discovery client: {}&quot;,                getIdentifier(), servers);        if (filter != null) {            servers = filter.getFilteredListOfServers(servers);            LOGGER.debug(&quot;Filtered List of Servers for {} obtained from Discovery client: {}&quot;,                    getIdentifier(), servers);        }    }    updateAllServerList(servers);}</code></pre><p>updateListOfServers()调用getUpdatedListOfServers()方法，从本地服务列表中获取到了服务列表信息</p><pre><code class="java">public List&lt;DiscoveryEnabledServer&gt; getUpdatedListOfServers() {    return this.obtainServersViaDiscovery();}</code></pre><h3 id="服务选择"><a href="#服务选择" class="headerlink" title="服务选择"></a>服务选择</h3><p>intercept()方法会调用getServer()方法，getServer()方法最终会调用到BaseLoadBalancer中的chooseServer()方法，会根据具体策略中的choose()方法，选择一个服务返回。</p><pre><code class="java">    public Server chooseServer(Object key) {        if (counter == null) {            counter = createCounter();        }        counter.increment();        if (rule == null) {            return null;        } else {            try {                return rule.choose(key);            } catch (Exception e) {                logger.warn(&quot;LoadBalancer [{}]:  Error choosing server for key {}&quot;, name, key, e);                return null;            }        }    }</code></pre>]]></content>
    
    
    <categories>
      
      <category>springcloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码解读</tag>
      
      <tag>springcloud</tag>
      
      <tag>ribbon</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>eureka源码解读</title>
    <link href="/2020/04/27/eureka%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"/>
    <url>/2020/04/27/eureka%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<h2 id="eureka客户端源码解析"><a href="#eureka客户端源码解析" class="headerlink" title="eureka客户端源码解析"></a>eureka客户端源码解析</h2><p>springboot在启动时会通过SPI加载spring.factors</p><pre><code class="properties">org.springframework.boot.autoconfigure.EnableAutoConfiguration=\org.springframework.cloud.netflix.eureka.config.EurekaClientConfigServerAutoConfiguration,\org.springframework.cloud.netflix.eureka.config.EurekaDiscoveryClientConfigServiceAutoConfiguration,\org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration,\org.springframework.cloud.netflix.ribbon.eureka.RibbonEurekaAutoConfiguration,\org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration,\org.springframework.cloud.netflix.eureka.reactive.EurekaReactiveDiscoveryClientConfiguration,\org.springframework.cloud.netflix.eureka.loadbalancer.LoadBalancerEurekaAutoConfigurationorg.springframework.cloud.bootstrap.BootstrapConfiguration=\org.springframework.cloud.netflix.eureka.config.EurekaDiscoveryClientConfigServiceBootstrapConfiguration</code></pre><p>其中的EurekaClientAutoConfiguration类有一个静态内部类EurekaClientConfiguration，EurekaClientConfiguration中的eurekaClient方法会创建一个CloudEurekaClient类。其构造方法如下：</p><pre><code class="java">@Bean(destroyMethod = &quot;shutdown&quot;)@ConditionalOnMissingBean(value = EurekaClient.class,      search = SearchStrategy.CURRENT)public EurekaClient eurekaClient(ApplicationInfoManager manager,      EurekaClientConfig config) {   return new CloudEurekaClient(manager, config, this.optionalArgs,         this.context);}</code></pre><p>CloudEurekaClient类继承了DiscoveryClient，这个类是eureka最重要的类，构造方法中会设置三个比较重要的定时器，负责服务注册、续约、拉取，然后调用initScheduledTasks()方法</p><pre><code class="java">@InjectDiscoveryClient(ApplicationInfoManager applicationInfoManager, EurekaClientConfig config, AbstractDiscoveryClientOptionalArgs args,                Provider&lt;BackupRegistry&gt; backupRegistryProvider, EndpointRandomizer endpointRandomizer) {    if (args != null) {        this.healthCheckHandlerProvider = args.healthCheckHandlerProvider;        this.healthCheckCallbackProvider = args.healthCheckCallbackProvider;        this.eventListeners.addAll(args.getEventListeners());        this.preRegistrationHandler = args.preRegistrationHandler;    } else {        this.healthCheckCallbackProvider = null;        this.healthCheckHandlerProvider = null;        this.preRegistrationHandler = null;    }    this.applicationInfoManager = applicationInfoManager;    InstanceInfo myInfo = applicationInfoManager.getInfo();    clientConfig = config;    staticClientConfig = clientConfig;    transportConfig = config.getTransportConfig();    instanceInfo = myInfo;    if (myInfo != null) {        appPathIdentifier = instanceInfo.getAppName() + &quot;/&quot; + instanceInfo.getId();    } else {        logger.warn(&quot;Setting instanceInfo to a passed in null value&quot;);    }    this.backupRegistryProvider = backupRegistryProvider;    this.endpointRandomizer = endpointRandomizer;    this.urlRandomizer = new EndpointUtils.InstanceInfoBasedUrlRandomizer(instanceInfo);    localRegionApps.set(new Applications());    fetchRegistryGeneration = new AtomicLong(0);    remoteRegionsToFetch = new AtomicReference&lt;String&gt;(clientConfig.fetchRegistryForRemoteRegions());    remoteRegionsRef = new AtomicReference&lt;&gt;(remoteRegionsToFetch.get() == null ? null : remoteRegionsToFetch.get().split(&quot;,&quot;));    if (config.shouldFetchRegistry()) {        this.registryStalenessMonitor = new ThresholdLevelsMetric(this, METRIC_REGISTRY_PREFIX + &quot;lastUpdateSec_&quot;, new long[]{15L, 30L, 60L, 120L, 240L, 480L});    } else {        this.registryStalenessMonitor = ThresholdLevelsMetric.NO_OP_METRIC;    }    if (config.shouldRegisterWithEureka()) {        this.heartbeatStalenessMonitor = new ThresholdLevelsMetric(this, METRIC_REGISTRATION_PREFIX + &quot;lastHeartbeatSec_&quot;, new long[]{15L, 30L, 60L, 120L, 240L, 480L});    } else {        this.heartbeatStalenessMonitor = ThresholdLevelsMetric.NO_OP_METRIC;    }    logger.info(&quot;Initializing Eureka in region {}&quot;, clientConfig.getRegion());    if (!config.shouldRegisterWithEureka() &amp;&amp; !config.shouldFetchRegistry()) {        logger.info(&quot;Client configured to neither register nor query for data.&quot;);        scheduler = null;        heartbeatExecutor = null;        cacheRefreshExecutor = null;        eurekaTransport = null;        instanceRegionChecker = new InstanceRegionChecker(new PropertyBasedAzToRegionMapper(config), clientConfig.getRegion());        // This is a bit of hack to allow for existing code using DiscoveryManager.getInstance()        // to work with DI&#39;d DiscoveryClient        DiscoveryManager.getInstance().setDiscoveryClient(this);        DiscoveryManager.getInstance().setEurekaClientConfig(config);        initTimestampMs = System.currentTimeMillis();        logger.info(&quot;Discovery Client initialized at timestamp {} with initial instances count: {}&quot;,                initTimestampMs, this.getApplications().size());        return;  // no need to setup up an network tasks and we are done    }    try {        // 这里注册了三个比较重要的定时器，负责服务注册、续约和服务拉取        // default size of 2 - 1 each for heartbeat and cacheRefresh        scheduler = Executors.newScheduledThreadPool(2,                new ThreadFactoryBuilder()                        .setNameFormat(&quot;DiscoveryClient-%d&quot;)                        .setDaemon(true)                        .build());        heartbeatExecutor = new ThreadPoolExecutor(                1, clientConfig.getHeartbeatExecutorThreadPoolSize(), 0, TimeUnit.SECONDS,                new SynchronousQueue&lt;Runnable&gt;(),                new ThreadFactoryBuilder()                        .setNameFormat(&quot;DiscoveryClient-HeartbeatExecutor-%d&quot;)                        .setDaemon(true)                        .build()        );  // use direct handoff        cacheRefreshExecutor = new ThreadPoolExecutor(                1, clientConfig.getCacheRefreshExecutorThreadPoolSize(), 0, TimeUnit.SECONDS,                new SynchronousQueue&lt;Runnable&gt;(),                new ThreadFactoryBuilder()                        .setNameFormat(&quot;DiscoveryClient-CacheRefreshExecutor-%d&quot;)                        .setDaemon(true)                        .build()        );  // use direct handoff        eurekaTransport = new EurekaTransport();        scheduleServerEndpointTask(eurekaTransport, args);        AzToRegionMapper azToRegionMapper;        if (clientConfig.shouldUseDnsForFetchingServiceUrls()) {            azToRegionMapper = new DNSBasedAzToRegionMapper(clientConfig);        } else {            azToRegionMapper = new PropertyBasedAzToRegionMapper(clientConfig);        }        if (null != remoteRegionsToFetch.get()) {            azToRegionMapper.setRegionsToFetch(remoteRegionsToFetch.get().split(&quot;,&quot;));        }        instanceRegionChecker = new InstanceRegionChecker(azToRegionMapper, clientConfig.getRegion());    } catch (Throwable e) {        throw new RuntimeException(&quot;Failed to initialize DiscoveryClient!&quot;, e);    }    if (clientConfig.shouldFetchRegistry() &amp;&amp; !fetchRegistry(false)) {        fetchRegistryFromBackup();    }    // call and execute the pre registration handler before all background tasks (inc registration) is started    if (this.preRegistrationHandler != null) {        this.preRegistrationHandler.beforeRegistration();    }    if (clientConfig.shouldRegisterWithEureka() &amp;&amp; clientConfig.shouldEnforceRegistrationAtInit()) {        try {            if (!register() ) {                throw new IllegalStateException(&quot;Registration error at startup. Invalid server response.&quot;);            }        } catch (Throwable th) {            logger.error(&quot;Registration error at startup: {}&quot;, th.getMessage());            throw new IllegalStateException(th);        }    }    // finally, init the schedule tasks (e.g. cluster resolvers, heartbeat, instanceInfo replicator, fetch    initScheduledTasks();    try {        Monitors.registerObject(this);    } catch (Throwable e) {        logger.warn(&quot;Cannot register timers&quot;, e);    }    // This is a bit of hack to allow for existing code using DiscoveryManager.getInstance()    // to work with DI&#39;d DiscoveryClient    DiscoveryManager.getInstance().setDiscoveryClient(this);    DiscoveryManager.getInstance().setEurekaClientConfig(config);    initTimestampMs = System.currentTimeMillis();    logger.info(&quot;Discovery Client initialized at timestamp {} with initial instances count: {}&quot;,            initTimestampMs, this.getApplications().size());}</code></pre><p>initScheduledTasks()，该方法根据配置文件中的属性设置定时器，如心跳间隔等，然后将CacheRefreshThread类设置到定时器中进行服务信息拉取，将HeartbeatThread类设置到定时器中进行服务的注册和续约。</p><pre><code class="java">private void initScheduledTasks() {    if (clientConfig.shouldFetchRegistry()) {        // registry cache refresh timer        int registryFetchIntervalSeconds = clientConfig.getRegistryFetchIntervalSeconds();        int expBackOffBound = clientConfig.getCacheRefreshExecutorExponentialBackOffBound();        cacheRefreshTask = new TimedSupervisorTask(                &quot;cacheRefresh&quot;,                scheduler,                cacheRefreshExecutor,                registryFetchIntervalSeconds,                TimeUnit.SECONDS,                expBackOffBound,                new CacheRefreshThread()        );        scheduler.schedule(                cacheRefreshTask,                registryFetchIntervalSeconds, TimeUnit.SECONDS);    }    if (clientConfig.shouldRegisterWithEureka()) {        int renewalIntervalInSecs = instanceInfo.getLeaseInfo().getRenewalIntervalInSecs();        int expBackOffBound = clientConfig.getHeartbeatExecutorExponentialBackOffBound();        logger.info(&quot;Starting heartbeat executor: &quot; + &quot;renew interval is: {}&quot;, renewalIntervalInSecs);        // Heartbeat timer        heartbeatTask = new TimedSupervisorTask(                &quot;heartbeat&quot;,                scheduler,                heartbeatExecutor,                renewalIntervalInSecs,                TimeUnit.SECONDS,                expBackOffBound,                new HeartbeatThread()        );        scheduler.schedule(                heartbeatTask,                renewalIntervalInSecs, TimeUnit.SECONDS);        // InstanceInfo replicator        instanceInfoReplicator = new InstanceInfoReplicator(                this,                instanceInfo,                clientConfig.getInstanceInfoReplicationIntervalSeconds(),                2); // burstSize        statusChangeListener = new ApplicationInfoManager.StatusChangeListener() {            @Override            public String getId() {                return &quot;statusChangeListener&quot;;            }            @Override            public void notify(StatusChangeEvent statusChangeEvent) {                if (InstanceStatus.DOWN == statusChangeEvent.getStatus() ||                        InstanceStatus.DOWN == statusChangeEvent.getPreviousStatus()) {                    // log at warn level if DOWN was involved                    logger.warn(&quot;Saw local status change event {}&quot;, statusChangeEvent);                } else {                    logger.info(&quot;Saw local status change event {}&quot;, statusChangeEvent);                }                instanceInfoReplicator.onDemandUpdate();            }        };        if (clientConfig.shouldOnDemandUpdateStatusChange()) {            applicationInfoManager.registerStatusChangeListener(statusChangeListener);        }        instanceInfoReplicator.start(clientConfig.getInitialInstanceInfoReplicationIntervalSeconds());    } else {        logger.info(&quot;Not registering with Eureka server per configuration&quot;);    }}</code></pre><h3 id="服务拉取"><a href="#服务拉取" class="headerlink" title="服务拉取"></a>服务拉取</h3><p>CacheRefreshThread类实现了Runnable接口，在run()方法中会调用refreshRegistry()方法</p><pre><code class="java">void refreshRegistry() {    try {        boolean isFetchingRemoteRegionRegistries = isFetchingRemoteRegionRegistries();        boolean remoteRegionsModified = false;        // This makes sure that a dynamic change to remote regions to fetch is honored.        String latestRemoteRegions = clientConfig.fetchRegistryForRemoteRegions();        if (null != latestRemoteRegions) {            String currentRemoteRegions = remoteRegionsToFetch.get();            if (!latestRemoteRegions.equals(currentRemoteRegions)) {                // Both remoteRegionsToFetch and AzToRegionMapper.regionsToFetch need to be in sync                synchronized (instanceRegionChecker.getAzToRegionMapper()) {                    if (remoteRegionsToFetch.compareAndSet(currentRemoteRegions, latestRemoteRegions)) {                        String[] remoteRegions = latestRemoteRegions.split(&quot;,&quot;);                        remoteRegionsRef.set(remoteRegions);                        instanceRegionChecker.getAzToRegionMapper().setRegionsToFetch(remoteRegions);                        remoteRegionsModified = true;                    } else {                        logger.info(&quot;Remote regions to fetch modified concurrently,&quot; +                                &quot; ignoring change from {} to {}&quot;, currentRemoteRegions, latestRemoteRegions);                    }                }            } else {                // Just refresh mapping to reflect any DNS/Property change                instanceRegionChecker.getAzToRegionMapper().refreshMapping();            }        }        boolean success = fetchRegistry(remoteRegionsModified);        if (success) {            registrySize = localRegionApps.get().size();            lastSuccessfulRegistryFetchTimestamp = System.currentTimeMillis();        }        if (logger.isDebugEnabled()) {            StringBuilder allAppsHashCodes = new StringBuilder();            allAppsHashCodes.append(&quot;Local region apps hashcode: &quot;);            allAppsHashCodes.append(localRegionApps.get().getAppsHashCode());            allAppsHashCodes.append(&quot;, is fetching remote regions? &quot;);            allAppsHashCodes.append(isFetchingRemoteRegionRegistries);            for (Map.Entry&lt;String, Applications&gt; entry : remoteRegionVsApps.entrySet()) {                allAppsHashCodes.append(&quot;, Remote region: &quot;);                allAppsHashCodes.append(entry.getKey());                allAppsHashCodes.append(&quot; , apps hashcode: &quot;);                allAppsHashCodes.append(entry.getValue().getAppsHashCode());            }            logger.debug(&quot;Completed cache refresh task for discovery. All Apps hash code is {} &quot;,                    allAppsHashCodes);        }    } catch (Throwable e) {        logger.error(&quot;Cannot fetch registry from server&quot;, e);    }}</code></pre><p>refreshRegistry()方法会调用fetchRegistry()方法进行服务信息的拉取</p><pre><code class="java">private boolean fetchRegistry(boolean forceFullRegistryFetch) {    Stopwatch tracer = FETCH_REGISTRY_TIMER.start();    try {        // If the delta is disabled or if it is the first time, get all        // applications        Applications applications = getApplications();        if (clientConfig.shouldDisableDelta()                || (!Strings.isNullOrEmpty(clientConfig.getRegistryRefreshSingleVipAddress()))                || forceFullRegistryFetch                || (applications == null)                || (applications.getRegisteredApplications().size() == 0)                || (applications.getVersion() == -1)) //Client application does not have latest library supporting delta        {            logger.info(&quot;Disable delta property : {}&quot;, clientConfig.shouldDisableDelta());            logger.info(&quot;Single vip registry refresh property : {}&quot;, clientConfig.getRegistryRefreshSingleVipAddress());            logger.info(&quot;Force full registry fetch : {}&quot;, forceFullRegistryFetch);            logger.info(&quot;Application is null : {}&quot;, (applications == null));            logger.info(&quot;Registered Applications size is zero : {}&quot;,                    (applications.getRegisteredApplications().size() == 0));            logger.info(&quot;Application version is -1: {}&quot;, (applications.getVersion() == -1));            getAndStoreFullRegistry();        } else {            getAndUpdateDelta(applications);        }        applications.setAppsHashCode(applications.getReconcileHashCode());        logTotalInstances();    } catch (Throwable e) {        logger.error(PREFIX + &quot;{} - was unable to refresh its cache! status = {}&quot;, appPathIdentifier, e.getMessage(), e);        return false;    } finally {        if (tracer != null) {            tracer.stop();        }    }    // Notify about cache refresh before updating the instance remote status    onCacheRefreshed();    // Update remote status based on refreshed data held in the cache    updateInstanceRemoteStatus();    // registry was fetched successfully, so return true    return true;}</code></pre><p>fetchRegistry()方法会调用getAndStoreFullRegistry()方法和getAndUpdateDelta()方法进行全量拉取和增量拉取。</p><p>getAndStoreFullRegistry()全量拉取，通过getApplications()方法从服务器获取服务列表后存储到localRegionApps中，后面ribbon、feign、config、zuul都会用到localRegionApps。</p><pre><code class="java">private void getAndStoreFullRegistry() throws Throwable {    long currentUpdateGeneration = fetchRegistryGeneration.get();    logger.info(&quot;Getting all instance registry info from the eureka server&quot;);    Applications apps = null;    EurekaHttpResponse&lt;Applications&gt; httpResponse = clientConfig.getRegistryRefreshSingleVipAddress() == null            ? eurekaTransport.queryClient.getApplications(remoteRegionsRef.get())            : eurekaTransport.queryClient.getVip(clientConfig.getRegistryRefreshSingleVipAddress(), remoteRegionsRef.get());    if (httpResponse.getStatusCode() == Status.OK.getStatusCode()) {        apps = httpResponse.getEntity();    }    logger.info(&quot;The response status is {}&quot;, httpResponse.getStatusCode());    if (apps == null) {        logger.error(&quot;The application is null for some reason. Not storing this information&quot;);    } else if (fetchRegistryGeneration.compareAndSet(currentUpdateGeneration, currentUpdateGeneration + 1)) {        localRegionApps.set(this.filterAndShuffle(apps));        logger.debug(&quot;Got full registry with apps hashcode {}&quot;, apps.getAppsHashCode());    } else {        logger.warn(&quot;Not updating applications as another thread is updating it already&quot;);    }}</code></pre><p>getApplications()方法会调用到getApplicationsInternal()方法，用get请求获取eureka服务端的配置信息。</p><pre><code class="java">private EurekaHttpResponse&lt;Applications&gt; getApplicationsInternal(String urlPath, String[] regions) {    ClientResponse response = null;    String regionsParamValue = null;    try {        WebResource webResource = jerseyClient.resource(serviceUrl).path(urlPath);        if (regions != null &amp;&amp; regions.length &gt; 0) {            regionsParamValue = StringUtil.join(regions);            webResource = webResource.queryParam(&quot;regions&quot;, regionsParamValue);        }        Builder requestBuilder = webResource.getRequestBuilder();        addExtraHeaders(requestBuilder);        response = requestBuilder.accept(MediaType.APPLICATION_JSON_TYPE).get(ClientResponse.class);        Applications applications = null;        if (response.getStatus() == Status.OK.getStatusCode() &amp;&amp; response.hasEntity()) {            applications = response.getEntity(Applications.class);        }        return anEurekaHttpResponse(response.getStatus(), Applications.class)                .headers(headersOf(response))                .entity(applications)                .build();    } finally {        if (logger.isDebugEnabled()) {            logger.debug(&quot;Jersey HTTP GET {}/{}?{}; statusCode={}&quot;,                    serviceUrl, urlPath,                    regionsParamValue == null ? &quot;&quot; : &quot;regions=&quot; + regionsParamValue,                    response == null ? &quot;N/A&quot; : response.getStatus()            );        }        if (response != null) {            response.close();        }    }</code></pre><h3 id="注册和续约"><a href="#注册和续约" class="headerlink" title="注册和续约"></a>注册和续约</h3><p>HeartbeatThread同样实现了Runnable接口，在run()方法中会调用renew()方法。</p><pre><code class="java">boolean renew() {    EurekaHttpResponse&lt;InstanceInfo&gt; httpResponse;    try {        httpResponse = eurekaTransport.registrationClient.sendHeartBeat(instanceInfo.getAppName(), instanceInfo.getId(), instanceInfo, null);        logger.debug(PREFIX + &quot;{} - Heartbeat status: {}&quot;, appPathIdentifier, httpResponse.getStatusCode());        if (httpResponse.getStatusCode() == Status.NOT_FOUND.getStatusCode()) {            REREGISTER_COUNTER.increment();            logger.info(PREFIX + &quot;{} - Re-registering apps/{}&quot;, appPathIdentifier, instanceInfo.getAppName());            long timestamp = instanceInfo.setIsDirtyWithTime();            boolean success = register();            if (success) {                instanceInfo.unsetIsDirty(timestamp);            }            return success;        }        return httpResponse.getStatusCode() == Status.OK.getStatusCode();    } catch (Throwable e) {        logger.error(PREFIX + &quot;{} - was unable to send heartbeat!&quot;, appPathIdentifier, e);        return false;    }}</code></pre><h4 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h4><p>renew()方法中会调用register()方法，register()方法最终会调用到AbstractJerseyEurekaHttpClient类的register()方法发送post请求至eureka进行服务注册</p><pre><code class="java">public EurekaHttpResponse&lt;Void&gt; register(InstanceInfo info) {    String urlPath = &quot;apps/&quot; + info.getAppName();    ClientResponse response = null;    try {        Builder resourceBuilder = jerseyClient.resource(serviceUrl).path(urlPath).getRequestBuilder();        addExtraHeaders(resourceBuilder);        response = resourceBuilder                .header(&quot;Accept-Encoding&quot;, &quot;gzip&quot;)                .type(MediaType.APPLICATION_JSON_TYPE)                .accept(MediaType.APPLICATION_JSON)                .post(ClientResponse.class, info);        return anEurekaHttpResponse(response.getStatus()).headers(headersOf(response)).build();    } finally {        if (logger.isDebugEnabled()) {            logger.debug(&quot;Jersey HTTP POST {}/{} with instance {}; statusCode={}&quot;, serviceUrl, urlPath, info.getId(),                    response == null ? &quot;N/A&quot; : response.getStatus());        }        if (response != null) {            response.close();        }    }}</code></pre><h4 id="续约"><a href="#续约" class="headerlink" title="续约"></a>续约</h4><p>renew()方法中会调用到sendHeartBeat()方法，sendHeartBeat()方法最终也会调用到AbstractJerseyEurekaHttpClientl类的sendHeartBeat()方法，发送put请求将节点状态发到服务端。</p><pre><code class="java">public EurekaHttpResponse&lt;InstanceInfo&gt; sendHeartBeat(String appName, String id, InstanceInfo info, InstanceStatus overriddenStatus) {    String urlPath = &quot;apps/&quot; + appName + &#39;/&#39; + id;    ClientResponse response = null;    try {        WebResource webResource = jerseyClient.resource(serviceUrl)                .path(urlPath)                .queryParam(&quot;status&quot;, info.getStatus().toString())                .queryParam(&quot;lastDirtyTimestamp&quot;, info.getLastDirtyTimestamp().toString());        if (overriddenStatus != null) {            webResource = webResource.queryParam(&quot;overriddenstatus&quot;, overriddenStatus.name());        }        Builder requestBuilder = webResource.getRequestBuilder();        addExtraHeaders(requestBuilder);        response = requestBuilder.put(ClientResponse.class);        EurekaHttpResponseBuilder&lt;InstanceInfo&gt; eurekaResponseBuilder = anEurekaHttpResponse(response.getStatus(), InstanceInfo.class).headers(headersOf(response));        if (response.hasEntity() &amp;&amp;                !HTML.equals(response.getType().getSubtype())) { //don&#39;t try and deserialize random html errors from the server            eurekaResponseBuilder.entity(response.getEntity(InstanceInfo.class));        }        return eurekaResponseBuilder.build();    } finally {        if (logger.isDebugEnabled()) {            logger.debug(&quot;Jersey HTTP PUT {}/{}; statusCode={}&quot;, serviceUrl, urlPath, response == null ? &quot;N/A&quot; : response.getStatus());        }        if (response != null) {            response.close();        }    }}</code></pre><h2 id="eureka服务端源码解析"><a href="#eureka服务端源码解析" class="headerlink" title="eureka服务端源码解析"></a>eureka服务端源码解析</h2><p>ApplicationsResource类通过JAX-RS规范接收客户端请求，注册请求首先会被getApplicationResource()方法接收，getInstanceInfo()方法则接收到服务的续约请求。</p><pre><code class="java">@Path(&quot;{appId}&quot;)public ApplicationResource getApplicationResource(        @PathParam(&quot;version&quot;) String version,        @PathParam(&quot;appId&quot;) String appId) {    CurrentRequestVersion.set(Version.toEnum(version));    try {        return new ApplicationResource(appId, serverConfig, registry);    } finally {        CurrentRequestVersion.remove();    }}{...}@Path(&quot;{id}&quot;)public InstanceResource getInstanceInfo(@PathParam(&quot;id&quot;) String id) {    return new InstanceResource(this, id, serverConfig, registry);}</code></pre><h3 id="服务的注册"><a href="#服务的注册" class="headerlink" title="服务的注册"></a>服务的注册</h3><p>addInstrance()方法会在getApplicationResource()方法之后调用。</p><pre><code class="java">@POST@Consumes({&quot;application/json&quot;, &quot;application/xml&quot;})public Response addInstance(InstanceInfo info,                            @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) {    logger.debug(&quot;Registering instance {} (replication={})&quot;, info.getId(), isReplication);    // validate that the instanceinfo contains all the necessary required fields    if (isBlank(info.getId())) {        return Response.status(400).entity(&quot;Missing instanceId&quot;).build();    } else if (isBlank(info.getHostName())) {        return Response.status(400).entity(&quot;Missing hostname&quot;).build();    } else if (isBlank(info.getIPAddr())) {        return Response.status(400).entity(&quot;Missing ip address&quot;).build();    } else if (isBlank(info.getAppName())) {        return Response.status(400).entity(&quot;Missing appName&quot;).build();    } else if (!appName.equals(info.getAppName())) {        return Response.status(400).entity(&quot;Mismatched appName, expecting &quot; + appName + &quot; but was &quot; + info.getAppName()).build();    } else if (info.getDataCenterInfo() == null) {        return Response.status(400).entity(&quot;Missing dataCenterInfo&quot;).build();    } else if (info.getDataCenterInfo().getName() == null) {        return Response.status(400).entity(&quot;Missing dataCenterInfo Name&quot;).build();    }    // handle cases where clients may be registering with bad DataCenterInfo with missing data    DataCenterInfo dataCenterInfo = info.getDataCenterInfo();    if (dataCenterInfo instanceof UniqueIdentifier) {        String dataCenterInfoId = ((UniqueIdentifier) dataCenterInfo).getId();        if (isBlank(dataCenterInfoId)) {            boolean experimental = &quot;true&quot;.equalsIgnoreCase(serverConfig.getExperimental(&quot;registration.validation.dataCenterInfoId&quot;));            if (experimental) {                String entity = &quot;DataCenterInfo of type &quot; + dataCenterInfo.getClass() + &quot; must contain a valid id&quot;;                return Response.status(400).entity(entity).build();            } else if (dataCenterInfo instanceof AmazonInfo) {                AmazonInfo amazonInfo = (AmazonInfo) dataCenterInfo;                String effectiveId = amazonInfo.get(AmazonInfo.MetaDataKey.instanceId);                if (effectiveId == null) {                    amazonInfo.getMetadata().put(AmazonInfo.MetaDataKey.instanceId.getName(), info.getId());                }            } else {                logger.warn(&quot;Registering DataCenterInfo of type {} without an appropriate id&quot;, dataCenterInfo.getClass());            }        }    }    registry.register(info, &quot;true&quot;.equals(isReplication));    return Response.status(204).build();  // 204 to be backwards compatible}</code></pre><p>addInstrance()方法最终会调用register()方法，完成服务注册。</p><pre><code>public void register(final InstanceInfo info, final boolean isReplication) {    int leaseDuration = Lease.DEFAULT_DURATION_IN_SECS;    if (info.getLeaseInfo() != null &amp;&amp; info.getLeaseInfo().getDurationInSecs() &gt; 0) {        leaseDuration = info.getLeaseInfo().getDurationInSecs();    }    super.register(info, leaseDuration, isReplication);    replicateToPeers(Action.Register, info.getAppName(), info.getId(), info, null, isReplication);}</code></pre><h4 id="服务的本地保存"><a href="#服务的本地保存" class="headerlink" title="服务的本地保存"></a>服务的本地保存</h4><p>register()方法会调用到AbstractInstanceRegistry的register()，将服务信息保存到ConcurrentHashMap中，Key是对应的服务名称，value则是这个服务对应的服务列表信息。</p><pre><code class="java">public void register(InstanceInfo registrant, int leaseDuration, boolean isReplication) {    try {        read.lock();        Map&lt;String, Lease&lt;InstanceInfo&gt;&gt; gMap = registry.get(registrant.getAppName());        REGISTER.increment(isReplication);        if (gMap == null) {            final ConcurrentHashMap&lt;String, Lease&lt;InstanceInfo&gt;&gt; gNewMap = new ConcurrentHashMap&lt;String, Lease&lt;InstanceInfo&gt;&gt;();            gMap = registry.putIfAbsent(registrant.getAppName(), gNewMap);            if (gMap == null) {                gMap = gNewMap;            }        }        Lease&lt;InstanceInfo&gt; existingLease = gMap.get(registrant.getId());        // Retain the last dirty timestamp without overwriting it, if there is already a lease        if (existingLease != null &amp;&amp; (existingLease.getHolder() != null)) {            Long existingLastDirtyTimestamp = existingLease.getHolder().getLastDirtyTimestamp();            Long registrationLastDirtyTimestamp = registrant.getLastDirtyTimestamp();            logger.debug(&quot;Existing lease found (existing={}, provided={}&quot;, existingLastDirtyTimestamp, registrationLastDirtyTimestamp);            // this is a &gt; instead of a &gt;= because if the timestamps are equal, we still take the remote transmitted            // InstanceInfo instead of the server local copy.            if (existingLastDirtyTimestamp &gt; registrationLastDirtyTimestamp) {                logger.warn(&quot;There is an existing lease and the existing lease&#39;s dirty timestamp {} is greater&quot; +                        &quot; than the one that is being registered {}&quot;, existingLastDirtyTimestamp, registrationLastDirtyTimestamp);                logger.warn(&quot;Using the existing instanceInfo instead of the new instanceInfo as the registrant&quot;);                registrant = existingLease.getHolder();            }        } else {            // The lease does not exist and hence it is a new registration            synchronized (lock) {                if (this.expectedNumberOfClientsSendingRenews &gt; 0) {                    // Since the client wants to register it, increase the number of clients sending renews                    this.expectedNumberOfClientsSendingRenews = this.expectedNumberOfClientsSendingRenews + 1;                    updateRenewsPerMinThreshold();                }            }            logger.debug(&quot;No previous lease information found; it is new registration&quot;);        }        Lease&lt;InstanceInfo&gt; lease = new Lease&lt;InstanceInfo&gt;(registrant, leaseDuration);        if (existingLease != null) {            lease.setServiceUpTimestamp(existingLease.getServiceUpTimestamp());        }        gMap.put(registrant.getId(), lease);        recentRegisteredQueue.add(new Pair&lt;Long, String&gt;(                System.currentTimeMillis(),                registrant.getAppName() + &quot;(&quot; + registrant.getId() + &quot;)&quot;));        // This is where the initial state transfer of overridden status happens        if (!InstanceStatus.UNKNOWN.equals(registrant.getOverriddenStatus())) {            logger.debug(&quot;Found overridden status {} for instance {}. Checking to see if needs to be add to the &quot;                            + &quot;overrides&quot;, registrant.getOverriddenStatus(), registrant.getId());            if (!overriddenInstanceStatusMap.containsKey(registrant.getId())) {                logger.info(&quot;Not found overridden id {} and hence adding it&quot;, registrant.getId());                overriddenInstanceStatusMap.put(registrant.getId(), registrant.getOverriddenStatus());            }        }        InstanceStatus overriddenStatusFromMap = overriddenInstanceStatusMap.get(registrant.getId());        if (overriddenStatusFromMap != null) {            logger.info(&quot;Storing overridden status {} from map&quot;, overriddenStatusFromMap);            registrant.setOverriddenStatus(overriddenStatusFromMap);        }        // Set the status based on the overridden status rules        InstanceStatus overriddenInstanceStatus = getOverriddenInstanceStatus(registrant, existingLease, isReplication);        registrant.setStatusWithoutDirty(overriddenInstanceStatus);        // If the lease is registered with UP status, set lease service up timestamp        if (InstanceStatus.UP.equals(registrant.getStatus())) {            lease.serviceUp();        }        registrant.setActionType(ActionType.ADDED);        recentlyChangedQueue.add(new RecentlyChangedItem(lease));        registrant.setLastUpdatedTimestamp();        invalidateCache(registrant.getAppName(), registrant.getVIPAddress(), registrant.getSecureVipAddress());        logger.info(&quot;Registered instance {}/{} with status {} (replication={})&quot;,                registrant.getAppName(), registrant.getId(), registrant.getStatus(), isReplication);    } finally {        read.unlock();    }}</code></pre><h4 id="服务的复制"><a href="#服务的复制" class="headerlink" title="服务的复制"></a>服务的复制</h4><p>replicateToPeers()方法会在register()中调用，该方法会获取到所有eureka节点，并调用replicateInstanceActionsToPeers()方法同步给所有节点。</p><pre><code class="java">private void replicateToPeers(Action action, String appName, String id,                              InstanceInfo info /* optional */,                              InstanceStatus newStatus /* optional */, boolean isReplication) {    Stopwatch tracer = action.getTimer().start();    try {        if (isReplication) {            numberOfReplicationsLastMin.increment();        }        // If it is a replication already, do not replicate again as this will create a poison replication        if (peerEurekaNodes == Collections.EMPTY_LIST || isReplication) {            return;        }        for (final PeerEurekaNode node : peerEurekaNodes.getPeerEurekaNodes()) {            // If the url represents this host, do not replicate to yourself.            if (peerEurekaNodes.isThisMyUrl(node.getServiceUrl())) {                continue;            }            replicateInstanceActionsToPeers(action, appName, id, info, newStatus, node);        }    } finally {        tracer.stop();    }}</code></pre><p>replicateInstanceActionsToPeers()方法，该方法只是简单的同步，并没有相应的机制保证一定成功，所以eureka只能保证CAP中的AP即可用行和分区容错性，不能保证一致性。</p><pre><code class="java">private void replicateInstanceActionsToPeers(Action action, String appName,                                             String id, InstanceInfo info, InstanceStatus newStatus,                                             PeerEurekaNode node) {    try {        InstanceInfo infoFromRegistry;        CurrentRequestVersion.set(Version.V2);        switch (action) {            case Cancel:                node.cancel(appName, id);                break;            case Heartbeat:                InstanceStatus overriddenStatus = overriddenInstanceStatusMap.get(id);                infoFromRegistry = getInstanceByAppAndId(appName, id, false);                node.heartbeat(appName, id, infoFromRegistry, overriddenStatus, false);                break;            case Register:                node.register(info);                break;            case StatusUpdate:                infoFromRegistry = getInstanceByAppAndId(appName, id, false);                node.statusUpdate(appName, id, newStatus, infoFromRegistry);                break;            case DeleteStatusOverride:                infoFromRegistry = getInstanceByAppAndId(appName, id, false);                node.deleteStatusOverride(appName, id, infoFromRegistry);                break;        }    } catch (Throwable t) {        logger.error(&quot;Cannot replicate information to {} for action {}&quot;, node.getServiceUrl(), action.name(), t);    } finally {        CurrentRequestVersion.remove();    }}</code></pre><h3 id="服务的续约"><a href="#服务的续约" class="headerlink" title="服务的续约"></a>服务的续约</h3><p>addInstrance()方法会在getInstanceInfo()方法之后调用，该方法会完成服务的心跳时间、心跳次数、状态等属性的更新，这里不在赘述。</p><pre><code class="java">@PUTpublic Response renewLease(        @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication,        @QueryParam(&quot;overriddenstatus&quot;) String overriddenStatus,        @QueryParam(&quot;status&quot;) String status,        @QueryParam(&quot;lastDirtyTimestamp&quot;) String lastDirtyTimestamp) {    boolean isFromReplicaNode = &quot;true&quot;.equals(isReplication);    boolean isSuccess = registry.renew(app.getName(), id, isFromReplicaNode);    // Not found in the registry, immediately ask for a register    if (!isSuccess) {        logger.warn(&quot;Not Found (Renew): {} - {}&quot;, app.getName(), id);        return Response.status(Status.NOT_FOUND).build();    }    // Check if we need to sync based on dirty time stamp, the client    // instance might have changed some value    Response response;    if (lastDirtyTimestamp != null &amp;&amp; serverConfig.shouldSyncWhenTimestampDiffers()) {        response = this.validateDirtyTimestamp(Long.valueOf(lastDirtyTimestamp), isFromReplicaNode);        // Store the overridden status since the validation found out the node that replicates wins        if (response.getStatus() == Response.Status.NOT_FOUND.getStatusCode()                &amp;&amp; (overriddenStatus != null)                &amp;&amp; !(InstanceStatus.UNKNOWN.name().equals(overriddenStatus))                &amp;&amp; isFromReplicaNode) {            registry.storeOverriddenStatusIfRequired(app.getAppName(), id, InstanceStatus.valueOf(overriddenStatus));        }    } else {        response = Response.ok().build();    }    logger.debug(&quot;Found (Renew): {} - {}; reply status={}&quot;, app.getName(), id, response.getStatus());    return response;}</code></pre>]]></content>
    
    
    <categories>
      
      <category>springcloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码解读</tag>
      
      <tag>springcloud</tag>
      
      <tag>eureka</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>springcloud链路追踪</title>
    <link href="/2020/04/27/springcloud%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/"/>
    <url>/2020/04/27/springcloud%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/</url>
    
    <content type="html"><![CDATA[<h2 id="链路追踪"><a href="#链路追踪" class="headerlink" title="链路追踪"></a>链路追踪</h2><p>其实链路追踪就是日志追踪，微服务下日志跟踪，微服务系统之间的调用变得非常复杂，往往一个功能的调用要涉及到多台微服务主机的调用，那么日志追踪也就要在多台主机之间进行，人为的去每台主机查看日志这种工作几乎是不能完成的工作，所以需要有专门的日志监控工具，这里讲的就是zipkin工具，最终使使用elk监控。</p><p>增加pom依赖，sleuth可以完成对各个日志监控平台的整合，如阿里鹰眼，elk</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>配置信息</p><pre><code class="properties">#向zipkin发送日志时的抽样比率spring.sleuth.sampler.percentage=1.0#若在同一个注册中心的话可以启用自动发现，省略 base-url#spring.zipkin.locator.discovery.enabled=true#指定zipkin地址spring.zipkin.base-url=http://localhost:9411/</code></pre><p>然后直接启动zipkin.jar，既可以看到调用信息。</p>]]></content>
    
    
    <categories>
      
      <category>springcloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>springcloud</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>springcloud服务网关zuul</title>
    <link href="/2020/04/26/springcloud%E6%9C%8D%E5%8A%A1%E7%BD%91%E5%85%B3zuul/"/>
    <url>/2020/04/26/springcloud%E6%9C%8D%E5%8A%A1%E7%BD%91%E5%85%B3zuul/</url>
    
    <content type="html"><![CDATA[<h2 id="Zuul服务网关的搭建"><a href="#Zuul服务网关的搭建" class="headerlink" title="Zuul服务网关的搭建"></a>Zuul服务网关的搭建</h2><p>zuul是springcloud项目的流量入口，理论上所有进入到微服务系统的请求都要经过Zuul来过滤和路由。</p><p>pom</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>启动类</p><pre><code class="java">@SpringBootApplication@EnableZuulProxypublic class MicroZuulApplication {}</code></pre><p>配置文件</p><pre><code class="properties">spring.application.name=micro-zuulserver.port=8071eureka.client.serviceUrl.defaultZone=http://admin:admin@localhost:8763/eureka/# 使用路径方式匹配路由规则# 结构：zuul.routes.&lt;customName&gt;.path=xxx# 其中customName自定义。通常使用要调用的服务名称，方便后期管理# 可使用的通配符有：* ** ?# ?单个字符# ** 任意多个字符，包含多级路径zuul.routes.micro-web.path=/web/**zuul.routes.micro-order.path=/order/**# 结构：zuul.routes.&lt;customName&gt;.url=xxx# 用于配置符合path的请求路径路由到的服务地址#zuul.routes.micro-order.url=http://localhost:8080/# 结构：zuul.routes.&lt;customName&gt;.serviceId=xxx# 用于配置符合path的请求路径路由到的服务名称zuul.routes.micro-web.serviceId=micro-webzuul.routes.micro-order.serviceId=micro-order# 配置不被zuul管理的服务列表，多个服务名称使用，分隔。#zuul.ignored-services=eureka-application-service# 通配方式配置排除列表# zuul.ignored-services=*# 通配方式排除网关代理路径。所有符合ignored-patterns下的请求路径都不被zuul网关代理#zuul.ignored-patterns=/**/local/**# 配置请求路径前缀，所有基于此前缀的请求都由zuul网关提供代理#zuul.prefix=/api#过滤指定的headers信息，默认为Cookie、Set-Cookie、Authorization这三个信息#为空的代表不需要过滤请求头信息zuul.routes.micro-web.sensitive-headers=management.endpoint.health.show-details=alwaysmanagement.endpoint.shutdown.enabled=truemanagement.endpoints.web.exposure.include=*</code></pre><p>配置完成后可以通过<code>http://localhost:8071/actuator/routes</code>接口查看路由信息，也可以使用hystrix的路由监控功能，监控端点为：<code>http://localhost:8071/actuator/hystrix.stream</code>。zuul是集成了hystrix跟ribbon，可以直接进行相应的配置，如超时时间。</p><h2 id="动态路由"><a href="#动态路由" class="headerlink" title="动态路由"></a>动态路由</h2><p>需要结合分布式配置中心使用。</p><p>pom</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;    &lt;version&gt;LATEST&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>配置信息</p><pre><code class="properties">#指定对应的环境spring.cloud.config.profile=zuul#github分支名称spring.cloud.config.label=master#configserver单机情况下的配置#spring.cloud.config.uri=http://localhost:8085/#开启config server服务发现功能spring.cloud.config.discovery.enabled=true#config server服务名称spring.cloud.config.discovery.service-id=config-server#如果连接不上获取配置有问题，快速响应失败spring.cloud.config.fail-fast=true#默认重试的间隔时间，默认1000msspring.cloud.config.retry.multiplier=1000#下一间隔时间的乘数，默认是 1.1#spring.cloud.config.retry.initial-interval=1#最大间隔时间，默认2000msspring.cloud.config.retry.max-interval=2000#最大重试次数，默认 6 次spring.cloud.config.retry.max-attempts=6spring.rabbitmq.host=localhostspring.rabbitmq.port=5672spring.rabbitmq.username=guestspring.rabbitmq.password=guestspring.cloud.bus.refresh.enabled=truespring.cloud.bus.trace.enabled=true</code></pre><p>启动类</p><pre><code class="java">@SpringBootApplication@EnableZuulProxypublic class MicroZuulApplication {    public static void main(String[] args) {        SpringApplication.run(MicroZuulApplication.class, args);    }    @Bean    @RefreshScope    @ConfigurationProperties(&quot;zuul&quot;)    @Primary    public ZuulProperties zuulProperties(){        return new ZuulProperties();    }}</code></pre><p>修改配置后调用刷新接口：<code>http://localhost:8071/actuator/bus-refresh</code>就可以完成自动刷新。</p><h2 id="Zuul过滤器"><a href="#Zuul过滤器" class="headerlink" title="Zuul过滤器"></a>Zuul过滤器</h2><p>Zuul大部分功能都是通过过滤器来实现的，Zuul定义了4种标准的过滤器类型，这些过滤器类型对应于请求的典型生命周期。</p><ul><li><p><strong>pre</strong>：这种过滤器在请求被路由之前调用。可利用这种过滤器实现身份验证、在集群中选择请求的微服务，记录调试信息等。</p></li><li><p><strong>routing</strong>：这种过滤器将请求路由到微服务。这种过滤器用于构建发送给微服务的请求，并使用apachehttpclient或netflixribbon请求微服务。</p></li><li><p><strong>post</strong>：这种过滤器在路由到微服务以后执行。这种过滤器可用来为响应添加标准的httpheader、收集统计信息和指标、将响应从微服务发送给客户端等。</p></li><li><p><strong>error</strong>：在其他阶段发送错误时执行该过滤器。</p></li></ul><img src="/2020/04/26/springcloud%E6%9C%8D%E5%8A%A1%E7%BD%91%E5%85%B3zuul/pic1.png" srcset="/img/loading.gif" class=""><p>如使用前置过滤器完成accessToken的验证</p><pre><code class="java">@Slf4j@Componentpublic class AccessFilter extends ZuulFilter {    @Override    public String filterType() {        return FilterConstants.PRE_TYPE;    }    @Override    public int filterOrder() {        return 0;    }    @Override    public boolean shouldFilter() {        return RequestContext.getCurrentContext().sendZuulResponse();    }    @Override    public Object run() throws ZuulException {        //获取上下文        RequestContext ctx = RequestContext.getCurrentContext();        //获取Request        HttpServletRequest request = ctx.getRequest();        //获取请求参数accessToken        String accessToken = request.getParameter(&quot;accessToken&quot;);        //使用String工具类        if (StringUtils.isBlank(accessToken)) {            log.warn(&quot;accessToken is empty&quot;);            //设置为false不进行路由            ctx.setSendZuulResponse(false);            ctx.setResponseStatusCode(401);            try {                ctx.getResponse().getWriter().write(&quot;accessToken is empty&quot;);            } catch (Exception e) {            }            return null;        }        log.info(&quot;access is ok&quot;);        return null;    }}</code></pre><h2 id="SpringCloud-Admin"><a href="#SpringCloud-Admin" class="headerlink" title="SpringCloud Admin"></a>SpringCloud Admin</h2><p>pom文件</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.2.6.RELEASE&lt;/version&gt;    &lt;/parent&gt;    &lt;groupId&gt;pers.zgc&lt;/groupId&gt;    &lt;artifactId&gt;micro-admin&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;name&gt;micro-admin&lt;/name&gt;    &lt;!-- FIXME change it to the project&#39;s website --&gt;    &lt;url&gt;http://www.example.com&lt;/url&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;        &lt;spring-cloud.version&gt;Hoxton.SR3&lt;/spring-cloud.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;de.codecentric&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt;            &lt;version&gt;LATEST&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;de.codecentric&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-admin-server-ui&lt;/artifactId&gt;            &lt;version&gt;LATEST&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;dependencyManagement&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;                &lt;type&gt;pom&lt;/type&gt;                &lt;scope&gt;import&lt;/scope&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/dependencyManagement&gt;    &lt;build&gt;        &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt;            &lt;plugins&gt;                &lt;!-- clean lifecycle, see https://maven.apache.org/ref/current/maven-core/lifecycles.html#clean_Lifecycle --&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.1.0&lt;/version&gt;                &lt;/plugin&gt;                &lt;!-- default lifecycle, jar packaging: see https://maven.apache.org/ref/current/maven-core/default-bindings.html#Plugin_bindings_for_jar_packaging --&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.0.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.8.0&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;                    &lt;version&gt;2.22.1&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.0.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt;                    &lt;version&gt;2.5.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt;                    &lt;version&gt;2.8.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;!-- site lifecycle, see https://maven.apache.org/ref/current/maven-core/lifecycles.html#site_Lifecycle --&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.7.1&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-project-info-reports-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.0.0&lt;/version&gt;                &lt;/plugin&gt;            &lt;/plugins&gt;        &lt;/pluginManagement&gt;    &lt;/build&gt;&lt;/project&gt;</code></pre><p>配置信息</p><pre><code class="properties">spring.application.name=micro-adminserver.port=8888#是否注册到eurekaeureka.client.registerWithEureka=true#是否从eureka拉取注册信息eureka.client.fetchRegistry=trueeureka.client.serviceUrl.defaultZone=http://admin:admin@localhost:8763/eureka/#安全配置spring.security.user.name=adminspring.security.user.password=admineureka.instance.metadata-map.user.name=${spring.security.user.name}eureka.instance.metadata-map.user.password=${spring.security.user.password}</code></pre><p>配置类</p><pre><code class="java">@Configurationpublic class SecuritySecureConfig extends WebSecurityConfigurerAdapter {    private final String adminContextPath;    public SecuritySecureConfig(AdminServerProperties adminServerProperties) {        this.adminContextPath = adminServerProperties.getContextPath();    }    @Override    protected void configure(HttpSecurity http) throws Exception {        SavedRequestAwareAuthenticationSuccessHandler successHandler = new SavedRequestAwareAuthenticationSuccessHandler();        successHandler.setTargetUrlParameter(&quot;redirectTo&quot;);        http.authorizeRequests()                .antMatchers(adminContextPath + &quot;/assets/**&quot;).permitAll()                .antMatchers(adminContextPath + &quot;/login&quot;).permitAll()                .anyRequest().authenticated()                .and()                .formLogin().loginPage(adminContextPath + &quot;/login&quot;).successHandler(successHandler).and()                .logout().logoutUrl(adminContextPath + &quot;/logout&quot;).and()                .httpBasic().and()                .csrf().disable();    }}</code></pre><p>启动类</p><pre><code class="java">@EnableAdminServer@EnableEurekaClient@SpringBootApplicationpublic class MicroAdminApplication {    public static void main(String[] args) {        SpringApplication.run(MicroAdminApplication.class, args);    }}</code></pre>]]></content>
    
    
    <categories>
      
      <category>springcloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>springcloud</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>springcloud分布式配置中心</title>
    <link href="/2020/04/25/springcloud%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"/>
    <url>/2020/04/25/springcloud%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/</url>
    
    <content type="html"><![CDATA[<h2 id="分布式配置中心的作用"><a href="#分布式配置中心的作用" class="headerlink" title="分布式配置中心的作用"></a>分布式配置中心的作用</h2><ul><li>抽取出公共配置，做到一处修改各处生效的目标。</li><li>配置文件的热加载，修改了配置文件后各个模块动态刷新，不需要重启服务器。</li></ul><h2 id="分布式配置中心的基本使用"><a href="#分布式配置中心的基本使用" class="headerlink" title="分布式配置中心的基本使用"></a>分布式配置中心的基本使用</h2><p>与hystrix的监控相同，配置中心可以不注册到eureka</p><h3 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h3><p>pom文件</p><pre><code class="xml">&lt;dependency&gt;  &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;  &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>启动类</p><pre><code class="java">@EnableConfigServer@SpringBootApplicationpublic class ConfigApplication {    public static void main(String[] args) {        SpringApplication.run(ConfigApplication.class, args);    }}</code></pre><p>github连接配置</p><pre><code class="properties">spring.cloud.config.server.git.uri=https://github.com/zgc97107/micro-configspring.cloud.config.server.git.search-paths=configspring.cloud.config.server.git.username=347398631@qq.comspring.cloud.config.server.git.password=zhao19971107</code></pre><h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><p>pom文件</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;    &lt;version&gt;LATEST&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>配置文件</p><pre><code class="properties">#指定对应的环境spring.cloud.config.profile=dev#github分支名称spring.cloud.config.label=master#configserver单机情况下的配置spring.cloud.config.uri=http://localhost:8085/#如果连接不上获取配置有问题，快速响应失败spring.cloud.config.fail-fast=true#本地缓存目录#spring.cloud.config.server.git.basedir=C:/work/config/tmp#强制从GitHub中拉取配置信息，不走缓存spring.cloud.config.server.git.force-pull=true</code></pre><p>具体使用</p><pre><code class="java">@RestController@RequestMapping(&quot;/user&quot;)public class UserController {    private org.slf4j.Logger logger = LoggerFactory.getLogger(getClass());    @Autowired    UserService userService;    @Value(&quot;${username}&quot;)    private String username;    @Value(&quot;${redis.password}&quot;)    private String redispass;    @Autowired    Environment environment;    @RequestMapping(&quot;/queryContent&quot;)    public List&lt;ConsultContent&gt; queryContent(HttpServletRequest request) {        logger.info(&quot;==================已经调用==========&quot; + request.getRemotePort());        logger.info(&quot;@Value======username======&quot; + username);        logger.info(&quot;Environment======username======&quot; + environment.getProperty(&quot;username&quot;));        logger.info(&quot;@Value======redispass======&quot; + redispass);        logger.info(&quot;Environment======redispass======&quot; + environment.getProperty(&quot;redis.password&quot;));        return userService.queryContent();    }}</code></pre><p>通过@Value跟environment.getProperty()方式都可以获取到。</p><h2 id="重试功能"><a href="#重试功能" class="headerlink" title="重试功能"></a>重试功能</h2><p>客户端jar包导入</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.retry&lt;/groupId&gt;    &lt;artifactId&gt;spring-retry&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>配置</p><pre><code class="properties">#默认重试的间隔时间，默认1000msspring.cloud.config.retry.multiplier=1000#下一间隔时间的乘数，默认是 1.1spring.cloud.config.retry.initial-interval=1.1#最大间隔时间，默认2000msspring.cloud.config.retry.max-interval=2000#最大重试次数，默认 6 次spring.cloud.config.retry.max-attempts=6</code></pre><h2 id="配置信息的加密"><a href="#配置信息的加密" class="headerlink" title="配置信息的加密"></a>配置信息的加密</h2><p>在配置中心中，有些信息是比较敏感的，比如密码信息，在配置密码信息的时候有必要对密码信息加密以免密码信息泄露，springcloud配置中心也支持配置信息加密的，这里一RSA非对称加密举例。</p><h3 id="服务端-1"><a href="#服务端-1" class="headerlink" title="服务端"></a>服务端</h3><ol><li><p>本地生成秘钥对：进入到jdk的keytool目录中：<code>jdk1.8.0_92\jre\bin\keytool</code></p></li><li><p>执行指令生成秘钥文件：<code>keytool -genkeypair -alias config-server -keyalg RSA -keystore config-server.keystore -validity 365</code>，指令执行成功后会在当前目录生成一个config-server.keystore文件。</p></li><li><p>将文件config-server.keystore复制到配置中心服务端的resources目录下</p></li><li><p>在pom文件的build标签下中添加设置，避免maven重新编译.keystore文件</p><pre><code class="xml">&lt;resources&gt;    &lt;resource&gt;        &lt;directory&gt;src/main/java&lt;/directory&gt;        &lt;includes&gt;            &lt;include&gt;**/*.properties&lt;/include&gt;            &lt;include&gt;**/*.xml&lt;/include&gt;        &lt;/includes&gt;        &lt;filtering&gt;false&lt;/filtering&gt;    &lt;/resource&gt;    &lt;resource&gt;        &lt;directory&gt;src/main/resources&lt;/directory&gt;        &lt;includes&gt;            &lt;include&gt;**/*.properties&lt;/include&gt;            &lt;include&gt;**/*.xml&lt;/include&gt;            &lt;include&gt;**/*.txt&lt;/include&gt;            &lt;include&gt;**/*.keystore&lt;/include&gt;        &lt;/includes&gt;        &lt;filtering&gt;false&lt;/filtering&gt;    &lt;/resource&gt;&lt;/resources&gt;</code></pre></li><li><p>配置文件中</p><pre><code class="properties">encrypt.key-store.location=config-server.keystoreencrypt.key-store.alias=config-serverencrypt.key-store.password=123456encrypt.key-store.secret=123456</code></pre></li></ol><h3 id="加密和解密接口"><a href="#加密和解密接口" class="headerlink" title="加密和解密接口"></a>加密和解密接口</h3><p>配置完成后，服务端会提供信息加密和解密接口：</p><ul><li>加密接口：<code>http://localhost:8085/encrypt</code>，请求方式POST，请求参数需要放到body中。</li><li>解密接口：<code>http://localhost:8085/decrypt</code>，请求方式POST，所需参数为加密接口返回的参数。</li></ul><p>注意：将配置信息通过加密接口加密后，设置到git时需要在密文前增加{cipher}标识。</p><h2 id="配置中心高可用"><a href="#配置中心高可用" class="headerlink" title="配置中心高可用"></a>配置中心高可用</h2><p>首先将配置中心注册到eureka中，来实现配置中心的服务化，然后启动多个配置中心即可。在配置之前需要将上面指定的配置中心uri删除。</p><h3 id="客户端-1"><a href="#客户端-1" class="headerlink" title="客户端"></a>客户端</h3><pre><code class="properties">#开启config server服务发现功能spring.cloud.config.discovery.enabled=true#config server服务名称spring.cloud.config.discovery.service-id=config-server</code></pre><h3 id="服务端-2"><a href="#服务端-2" class="headerlink" title="服务端"></a>服务端</h3><p>需要引入并开启Eureka客户端功能，并向eureka注册</p><p>pom</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>properties</p><pre><code class="properties">spring.application.name=config-servereureka.client.serviceUrl.defaultZone=http://admin:admin@localhost:8763/eureka/</code></pre><p>启动类</p><pre><code class="java">@EnableEurekaClient@EnableConfigServer@SpringBootApplicationpublic class MicroConfigApplication {    public static void main(String[] args) {        SpringApplication.run(MicroConfigApplication.class, args);    }}</code></pre><p>注意：此处有个坑，如果在配置文件bootstrap.properties文件中同时含有以下内容，会导致eureka中的服务状态变为unkown！可以将该配置注释掉，或者迁移至application.properties中。</p><pre><code class="properties">#开启健康检测eureka.client.healthcheck.enabled=true</code></pre><p>关于这个坑springcloud官网的解释</p><img src="/2020/04/25/springcloud%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/pic1.png" srcset="/img/loading.gif" class=""><p>大意为，<code>eureka.client.healthcheck.enabled=true</code>应该设置在application.yml中，如果设置在bootstrap.yml文件中时可能会有UNKNOW的情况出现。</p><h2 id="动态加载刷新"><a href="#动态加载刷新" class="headerlink" title="动态加载刷新"></a>动态加载刷新</h2><p>这是一个革命性的功能，可以在运行期间修改配置文件后，不需要重启就能使最新的配置文件生效。</p><h3 id="Environment的动态刷新"><a href="#Environment的动态刷新" class="headerlink" title="Environment的动态刷新"></a>Environment的动态刷新</h3><p>动态刷新其实要有一个契机，其实这个契机就是手动调用刷新接口，如果你想刷新哪台主机的配置，就调用哪台注解的刷新接口。刷新接口为：<code>http://localhost:8081/actuator/refresh</code>，请求方式为POST。</p><h3 id="Value属性的动态刷新"><a href="#Value属性的动态刷新" class="headerlink" title="@Value属性的动态刷新"></a>@Value属性的动态刷新</h3><p>在调用刷新接口后，@Value注入的属性依然不会改变，因为@Value注入的属性是项目启动就已经确定的。如果要使@Value属性也刷新，就必须要在类上面加上@RefreshScope注解。加上该注解后，在调用刷新接口时，就会重新生成实例。</p><p>但是这种方式在需要刷新的集群机器数量比较多时会比较繁琐，此时可以使用Springcloud中提供消息总线，当需要刷新时只要调用一次刷新接口即可然后借助消息的广播来生效即可。</p><h3 id="消息总线"><a href="#消息总线" class="headerlink" title="消息总线"></a>消息总线</h3><p>pom文件</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>properties文件</p><pre><code class="properties">spring.rabbitmq.host=localhostspring.rabbitmq.port=5672spring.rabbitmq.username=guestspring.rabbitmq.password=guestspring.cloud.bus.refresh.enabled=truespring.cloud.bus.trace.enabled=true</code></pre><p>然后调用：<code>http://localhost:8081/actuator/bus-refresh</code>接口就可以通知到所有使用总线的服务。</p><p>也可以在git中配置，实现内容变动时自动调用接口。配置方式为Settings-&gt;Webhooks-&gt;Add webhook，然后输入url后点击Add webhook。</p><h2 id="自定义的分布式配置中心"><a href="#自定义的分布式配置中心" class="headerlink" title="自定义的分布式配置中心"></a>自定义的分布式配置中心</h2><p>原理是利用zookeeper节点的通知机制，完成对Environment中属性的修改及bean中@Value属性的修改，并将使用自定义作用域的对象销毁，然后重新生成，完成@Value的动态更新。如果要使@Value属性的动态更新，需要在类上加上@Scope(“refresh”)注解。</p><p>此处遗留问题：</p><ul><li>使用@Autowired属性注入的类中使用@Scope(“refresh”)能不能成功刷新。</li><li>使用redis的通知机制代替zookeeper的通知机制。</li></ul><p>引入jar包</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.apache.curator&lt;/groupId&gt;    &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt;    &lt;version&gt;2.11.0&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>核心类</p><p>该类实现了ApplicationContextAware接口，将在类初始化完成并调用IOC、DI之后调用init()方法，在调用时会通过setApplicationContext()将上下文对象传入。</p><pre><code class="java">@Compoentpublic class CuratorUtil implements ApplicationContextAware {    private static String connnectStr = &quot;192.168.67.139:2181&quot;;    private static CuratorFramework client;    private static String path = &quot;/config&quot;;    @Value((&quot;${zookeeper.config.enable:false}&quot;))    private boolean enbale;    @Autowired    Environment environment;    private static String zkPropertyName = &quot;zookeeperSource&quot;;    private static String scopeName = &quot;refresh&quot;;    private static ConfigurableApplicationContext applicationContext;    private ConcurrentHashMap map = new ConcurrentHashMap();    private BeanDefinitionRegistry beanDefinitionRegistry;    @PostConstruct    public void init() {        if (!enbale) return;        RefreshScopeRegistry refreshScopeRegistry = (RefreshScopeRegistry) applicationContext.getBean(&quot;refreshScopeRegistry&quot;);        beanDefinitionRegistry = refreshScopeRegistry.getBeanDefinitionRegistry();        client = CuratorFrameworkFactory.                builder().                connectString(connnectStr).                sessionTimeoutMs(5000).                retryPolicy(new ExponentialBackoffRetry(1000, 3)).                build();        client.start();        try {            Stat stat = client.checkExists().forPath(path);            if (stat == null) {                //创建zookeeper配置节点                client.create().creatingParentsIfNeeded().withMode(CreateMode.PERSISTENT).                        forPath(path, &quot;zookeeper config&quot;.getBytes());                TimeUnit.SECONDS.sleep(1);            } else {                //将zookeeper配置节点下面的子节点加载到spring容器的属性对象中                addChildToSpringProperty(client, path);            }//            nodeCache(client,path);            //注册节点监听监听器            childNodeCache(client, path);        } catch (Exception e) {            e.printStackTrace();        }    }    private void addChildToSpringProperty(CuratorFramework client, String path) {        if (!checkExistsSpringProperty()) {            //如果不存在zookeeper的配置属性对象则创建            createZookeeperSpringProperty();        }        //把config目录下的子节点添加到 zk的PropertySource对象中        MutablePropertySources propertySources = applicationContext.getEnvironment().getPropertySources();        PropertySource&lt;?&gt; propertySource = propertySources.get(zkPropertyName);        ConcurrentHashMap zkmap = (ConcurrentHashMap) propertySource.getSource();        try {            List&lt;String&gt; strings = client.getChildren().forPath(path);            for (String string : strings) {                zkmap.put(string, client.getData().forPath(path + &quot;/&quot; + string));            }        } catch (Exception e) {            e.printStackTrace();        }    }    /**     * 将节点中的信息添加到spring中     */    private void createZookeeperSpringProperty() {        MutablePropertySources propertySources = applicationContext.getEnvironment().getPropertySources();        OriginTrackedMapPropertySource zookeeperSource = new OriginTrackedMapPropertySource(zkPropertyName, map);        propertySources.addLast(zookeeperSource);    }    private boolean checkExistsSpringProperty() {        MutablePropertySources propertySources = applicationContext.getEnvironment().getPropertySources();        for (PropertySource&lt;?&gt; propertySource : propertySources) {            if (zkPropertyName.equals(propertySource.getName())) {                return true;            }        }        return false;    }    private void childNodeCache(CuratorFramework client, String path) {        try {            final PathChildrenCache pathChildrenCache = new PathChildrenCache(client, path, false);            pathChildrenCache.start(PathChildrenCache.StartMode.POST_INITIALIZED_EVENT);            pathChildrenCache.getListenable().addListener(new PathChildrenCacheListener() {                @Override                public void childEvent(CuratorFramework client, PathChildrenCacheEvent event) throws Exception {                    switch (event.getType()) {                        case CHILD_ADDED:                            System.out.println(&quot;增加了节点&quot;);                            addEnv(event.getData(), client);                            break;                        case CHILD_REMOVED:                            System.out.println(&quot;删除了节点&quot;);                            delEnv(event.getData());                            break;                        case CHILD_UPDATED:                            System.out.println(&quot;更新了节点&quot;);                            addEnv(event.getData(), client);                            break;                        default:                            break;                    }                    //对refresh作用域的实例进行刷新                    refreshBean();                }            });        } catch (Exception e) {            e.printStackTrace();        }    }    private void refreshBean() {        String[] beanDefinitionNames = applicationContext.getBeanDefinitionNames();        for (String beanDefinitionName : beanDefinitionNames) {            BeanDefinition beanDefinition = beanDefinitionRegistry.getBeanDefinition(beanDefinitionName);            if (scopeName.equals(beanDefinition.getScope())) {                //先删除                applicationContext.getBeanFactory().destroyScopedBean(beanDefinitionName);                //在实例化                applicationContext.getBean(beanDefinitionName);            }        }    }    private void delEnv(ChildData childData) {        ChildData next = childData;        String childpath = next.getPath();        MutablePropertySources propertySources = applicationContext.getEnvironment().getPropertySources();        for (PropertySource&lt;?&gt; propertySource : propertySources) {            if (zkPropertyName.equals(propertySource.getName())) {                OriginTrackedMapPropertySource ps = (OriginTrackedMapPropertySource) propertySource;                ConcurrentHashMap chm = (ConcurrentHashMap) ps.getSource();                chm.remove(childpath.substring(path.length() + 1));            }        }    }    private void addEnv(ChildData childData, CuratorFramework client) {        ChildData next = childData;        String childpath = next.getPath();        String data = null;        try {            data = new String(client.getData().forPath(childpath));        } catch (Exception e) {            e.printStackTrace();        }        MutablePropertySources propertySources = applicationContext.getEnvironment().getPropertySources();        for (PropertySource&lt;?&gt; propertySource : propertySources) {            if (zkPropertyName.equals(propertySource.getName())) {                OriginTrackedMapPropertySource ps = (OriginTrackedMapPropertySource) propertySource;                ConcurrentHashMap chm = (ConcurrentHashMap) ps.getSource();                chm.put(childpath.substring(path.length() + 1), data);            }        }    }    private void nodeCache(final CuratorFramework client, final String path) {        try {            //第三个参数是是否压缩            //就是对path节点进行监控，是一个事件模板            final NodeCache nodeCache = new NodeCache(client, path, false);            nodeCache.start();            //这个就是事件注册            nodeCache.getListenable().addListener(new NodeCacheListener() {                @Override                public void nodeChanged() throws Exception {                    byte[] data = nodeCache.getCurrentData().getData();                    String path1 = nodeCache.getCurrentData().getPath();                    Object put = map.put(path1.replace(&quot;/&quot;, &quot;&quot;), new String(data));                    MutablePropertySources propertySources = applicationContext.getEnvironment().getPropertySources();                    OriginTrackedMapPropertySource zookeeperSource = new OriginTrackedMapPropertySource(&quot;zookeeper source&quot;, map);                    propertySources.addLast(zookeeperSource);                }            });        } catch (Exception e) {            e.printStackTrace();        }    }    @Override    public void setApplicationContext(ApplicationContext context) throws BeansException {        CuratorUtil.applicationContext = (ConfigurableApplicationContext) context;    }}</code></pre><p>自定义作用域</p><p>remove()方法将在销毁时调用，get()方法为获取时调用。</p><pre><code class="java">public class RefreshScope implements Scope {    private ConcurrentHashMap map = new ConcurrentHashMap();    @Override    public Object get(String name, ObjectFactory&lt;?&gt; objectFactory) {        if (map.containsKey(name)) {            return map.get(name);        }        Object object = objectFactory.getObject();        map.put(name, object);        return object;    }    @Override    public Object remove(String name) {        return map.remove(name);    }    @Override    public void registerDestructionCallback(String name, Runnable callback) {    }    @Override    public Object resolveContextualObject(String key) {        return null;    }    @Override    public String getConversationId() {        return null;    }}</code></pre><p>自定义作用域的注册</p><pre><code class="java">@Data@Componentpublic class RefreshScopeRegistry implements BeanDefinitionRegistryPostProcessor {    private BeanDefinitionRegistry beanDefinitionRegistry;    @Override    public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException {        this.beanDefinitionRegistry = registry;    }    @Override    public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException {        beanFactory.registerScope(&quot;refresh&quot;,new RefreshScope());    }}</code></pre>]]></content>
    
    
    <categories>
      
      <category>springcloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>springcloud</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>springcloud中feign的使用</title>
    <link href="/2020/04/24/springcloud%E4%B8%ADfeign%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2020/04/24/springcloud%E4%B8%ADfeign%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="简单使用"><a href="#简单使用" class="headerlink" title="简单使用"></a>简单使用</h2><h3 id="提供方"><a href="#提供方" class="headerlink" title="提供方"></a>提供方</h3><p>controller</p><pre><code class="java">@Slf4j@RestControllerpublic class OrderController {    @Autowired    private OrderService orderService;    @RequestMapping(&quot;/feign/order/listAll&quot;)    public String listAll(){        return orderService.listAll();    }}</code></pre><h3 id="消费方"><a href="#消费方" class="headerlink" title="消费方"></a>消费方</h3><p>pom文件</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>service接口（该service不需要实现类）</p><pre><code class="java">@FeignClient(name = &quot;MICRO-ORDER&quot;,path = &quot;/feign&quot;)public interface OrderService {    @GetMapping(&quot;/order/listAll&quot;)    String listAll();}</code></pre><p>controller</p><pre><code class="java">@RestController@RequestMapping(&quot;/order&quot;)public class OrderController {    @Autowired    private OrderService orderFeignService;    @GetMapping(&quot;/listAll&quot;)    public String listAll(){        return orderFeignService.listAll();    }}</code></pre><p>启动类</p><pre><code class="java">@SpringBootApplication@EnableCircuitBreaker@EnableEurekaClient@EnableFeignClients(clients = OrderService.class)public class MicroWebApplication {</code></pre><h2 id="参数传递"><a href="#参数传递" class="headerlink" title="参数传递"></a>参数传递</h2><p>消费方</p><pre><code class="java">@FeignClient(name = &quot;MICRO-ORDER&quot;, path = &quot;/feign&quot;)public interface OrderService {    @GetMapping(&quot;/order/listAll&quot;)    String listAll();    @GetMapping(&quot;/order/getById&quot;)    String getById(@RequestParam(&quot;id&quot;) Integer id);    @PostMapping(&quot;/order/save&quot;)    String save(@RequestBody Map&lt;String, String&gt; paramMap);}</code></pre><p>提供方</p><pre><code class="java">@Slf4j@RestControllerpublic class OrderController {    @Autowired    private OrderService orderService;    @RequestMapping(&quot;/feign/order/listAll&quot;)    public String listAll() {        return orderService.listAll();    }    @PostMapping(&quot;/feign/order/save&quot;)    public String save(@RequestBody Map&lt;String, String&gt; paramMap) {        return paramMap.keySet().stream().map(key -&gt; key + paramMap.get(key)).collect(Collectors.joining());    }    @RequestMapping(&quot;/feign/order/getById&quot;)    public String getById(@RequestParam(&quot;id&quot;) Integer id) {        return id + &quot;&quot;;    }}</code></pre><h2 id="开启熔断功能"><a href="#开启熔断功能" class="headerlink" title="开启熔断功能"></a>开启熔断功能</h2><p>feign其实是对hystrix和ribbon的整合，@FeignClient中的每一个方法进行了服务隔离。</p><p>在properties中</p><pre><code class="properties">#feign开启熔断器feign.hystrix.enabled=true#开启feign压缩功能feign.compression.request.enabled=true#feign.compression.request.mime-types=text/xml,application/xml,application/json#feign.compression.request.min-request-size=2048feign.compression.response.enabled=true</code></pre><h2 id="公共接口抽取"><a href="#公共接口抽取" class="headerlink" title="公共接口抽取"></a>公共接口抽取</h2><p>可以在项目的公共jar包中加入公共接口类，然后在提供方和消费方实现公共接口即可。</p><p>定义公共接口</p><pre><code class="java">@RequestMapping(&quot;/feign/teacher&quot;)public interface TeacherService {    @GetMapping(&quot;/getAllTeacher&quot;)    String getAllTeacher();    @PostMapping(&quot;/saveTeacher&quot;)    String saveTeacher(@RequestBody Teacher Teacher);    @GetMapping(&quot;/getTeacherById&quot;)    String getTeacherById(@RequestParam(&quot;id&quot;) Integer id);    @GetMapping(&quot;/getTeacherByName/{name}&quot;)    String getTeacherByName(@PathVariable(&quot;name&quot;) String name);    @GetMapping(&quot;/errorMessage&quot;)    String errorMessage(@RequestParam(&quot;id&quot;) Integer id);}</code></pre><p>提供方</p><pre><code class="java">@FeignClient(name = &quot;MICRO-ORDER&quot;)public interface TeacherServiceFeign extends TeacherService {}</code></pre><p>消费方</p><pre><code class="java">@RestControllerpublic class TeacherController implements TeacherService {    @Override    public String getAllTeacher() {        return &quot;micro-order.getAllTeacher&quot;;    }    @Override    public String saveTeacher(@RequestBody Teacher Teacher) {        return &quot;micro-order.saveTeacher&quot;;    }    @Override    public String getTeacherById(@RequestParam(&quot;id&quot;) Integer id) {        return &quot;micro-order.getTeacherById&quot;;    }    @Override    public String getTeacherByName(@PathVariable(&quot;name&quot;) String name) {        return &quot;micro-order.getTeacherByName&quot;;    }    @Override    public String errorMessage(@RequestParam(&quot;id&quot;) Integer id) {        return &quot;micro-order.errorMessage&quot;;    }}</code></pre><h2 id="服务降级"><a href="#服务降级" class="headerlink" title="服务降级"></a>服务降级</h2><h3 id="设置fallback属性"><a href="#设置fallback属性" class="headerlink" title="设置fallback属性"></a>设置fallback属性</h3><p>使用方法</p><pre><code class="java">@FeignClient(name = &quot;MICRO-ORDER&quot;, path = &quot;/feign&quot;, fallback = OrderServiceFallback.class)public interface OrderService {    @GetMapping(&quot;/order/listAll&quot;)    String listAll();    @GetMapping(&quot;/order/getById&quot;)    String getById(@RequestParam(&quot;id&quot;) Integer id);    @PostMapping(&quot;/order/save&quot;)    String save(@RequestBody Map&lt;String, String&gt; paramMap);}</code></pre><pre><code class="java">@Slf4j@Componentpublic class OrderServiceFallback implements OrderService {    @Override    public String listAll() {        return &quot;请求失败&quot;;    }    @Override    public String getById(@RequestParam(&quot;id&quot;) Integer id) {        log.info(&quot;id:{}&quot;, id);        return &quot;请求失败&quot;;    }    @Override    public String save(@RequestBody Map&lt;String, String&gt; paramMap) {        paramMap.forEach((key, value) -&gt; {            log.info(&quot;key:{},value:{}&quot;, key, value);        });        return &quot;请求失败&quot;;    }}</code></pre><p>当出现异常时，会调用OrderServiceFallback中对应的方法，但这种方式无法获取到出现的异常。</p><h3 id="设置fallbackFactory属性"><a href="#设置fallbackFactory属性" class="headerlink" title="设置fallbackFactory属性"></a>设置fallbackFactory属性</h3><p>这种方法可以获取到异常信息，推荐使用。</p><pre><code class="java">@FeignClient(name = &quot;MICRO-ORDER&quot;, path = &quot;/feign&quot;        ,fallbackFactory = OrderServiceFallbackFactory.class)public interface OrderService {    @GetMapping(&quot;/order/listAll&quot;)    String listAll();    @GetMapping(&quot;/order/getById&quot;)    String getById(@RequestParam(&quot;id&quot;) Integer id);    @PostMapping(&quot;/order/save&quot;)    String save(@RequestBody Map&lt;String, String&gt; paramMap);}</code></pre><pre><code class="java">@Slf4j@Servicepublic class OrderServiceFallback implements OrderService {    @Override    public String listAll() {        return &quot;请求失败&quot;;    }    @Override    public String getById(@RequestParam(&quot;id&quot;) Integer id) {        log.info(&quot;id:{}&quot;, id);        return &quot;请求失败&quot;;    }    @Override    public String save(@RequestBody Map&lt;String, String&gt; paramMap) {        paramMap.forEach((key, value) -&gt; {            log.info(&quot;key:{},value:{}&quot;, key, value);        });        return &quot;请求失败&quot;;    }}</code></pre><h3 id="feign的全局过滤器"><a href="#feign的全局过滤器" class="headerlink" title="feign的全局过滤器"></a>feign的全局过滤器</h3><p>调用顺序在降级方法前，当服务提供方返回的状态码不是200时就会触发，可以进行异常的包装。</p><pre><code class="java">@Configurationpublic class FeignErrMessageFilter {    @Bean    public ErrorDecoder errorDecoder() {        return new FeignErrorDecoder();    }    /**     * 当调用服务时，如果服务返回的状态码不是200，就会进入到Feign的ErrorDecoder中     * 只有这种方式才能获取所有的被feign包装过的异常信息     * 这里如果创建的Exception是HystrixBadRequestException,则不会走熔断逻辑，不记入熔断统计     */    class FeignErrorDecoder implements ErrorDecoder {        private Logger logger = LoggerFactory.getLogger(FeignErrorDecoder.class);        @Override        public Exception decode(String s, Response response) {            RuntimeException runtimeException = null;            try {                String retMsg = Util.toString(response.body().asReader());                logger.info(retMsg);                runtimeException = new RuntimeException(retMsg);            } catch (IOException e) {                e.printStackTrace();            }            return runtimeException;        }    }}</code></pre><h2 id="超时时间的设置"><a href="#超时时间的设置" class="headerlink" title="超时时间的设置"></a>超时时间的设置</h2><p>feign整合了hystrix和ribbon，如果接口调用时间超过了ribbon的超时时间，ribbon就会重试。注意，重试的时间会累加，如果超过了hystrix的超时时间就会触发hystrix的降级方法不再重试。</p><pre><code class="properties">#单位ms，请求连接超时时间ribbon.ConnectTimeout=1000#单位ms，请求处理超时时间ribbon.ReadTimeout=3000#全局的超时时间hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=5000</code></pre>]]></content>
    
    
    <categories>
      
      <category>springcloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>springcloud</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>springcloud熔断降级组件hystrix</title>
    <link href="/2020/04/24/springcloud%E7%86%94%E6%96%AD%E9%99%8D%E7%BA%A7%E7%BB%84%E4%BB%B6hystrix/"/>
    <url>/2020/04/24/springcloud%E7%86%94%E6%96%AD%E9%99%8D%E7%BA%A7%E7%BB%84%E4%BB%B6hystrix/</url>
    
    <content type="html"><![CDATA[<h2 id="服务雪崩"><a href="#服务雪崩" class="headerlink" title="服务雪崩"></a>服务雪崩</h2><p>当整个微服务系统中有一个节点出现异常情况，就会导致调用它的上游系统出现响应延迟，高并发情况下的响应延迟会迅速消耗掉tomcat的连接数，使得上游节点不能正常的接收请求，这就是服务雪崩。</p><p>节点异常的发生原因多种多样，比如不合理的容量设计、高并发下某一个方法响应变慢、服务器的资源耗尽等，所以很难从源头上完全杜绝雪崩的发生，但是服务之间的强依赖也是雪崩的根本原因之一，解决服务之间强依赖关系也可以解决雪崩问题。</p><h2 id="服务隔离"><a href="#服务隔离" class="headerlink" title="服务隔离"></a>服务隔离</h2><p>如果整个系统雪崩是由于某个接口响应不及时导致的，那么就可以对这个接口进行隔离，比如限制这个接口占用连接的上限，这样就不会消耗掉所有的tomcat连接，其他接口依然能够正常响应。</p><p>Hystrix位于服务调用方和服务提供方之间，来控制对提供方的调用。</p><p>pom文件中引入</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>启动类开启hystrix熔断功能</p><pre><code class="java">@SpringBootApplication@EnableCircuitBreaker@EnableEurekaClientpublic class MicroWebApplication {</code></pre><p>代码使用</p><pre><code class="java">@HystrixCommand@Overridepublic String queryOrder() {    String SERVICE_NAME = &quot;micro-order&quot;;    return restTemplate.getForObject(&quot;http://&quot; + SERVICE_NAME + &quot;/queryOrder&quot;, String.class);}</code></pre><h2 id="Hystrix服务隔离策略"><a href="#Hystrix服务隔离策略" class="headerlink" title="Hystrix服务隔离策略"></a>Hystrix服务隔离策略</h2><p>Hystrix的服务隔离策略可以在@HystrixCommand注解中设置</p><pre><code class="java">@HystrixCommand(commandProperties = {        @HystrixProperty(name = &quot;execution.isolation.strategy&quot;,value = &quot;THREAD&quot;)})</code></pre><p><code>execution.isolation.strategy</code>属性代表使用的隔离策略，共有两种：</p><ul><li>THREAD：线程池隔离策略，接收到请求时交由线程池执行，是Hystrix的默认隔离策略。注意，这时的用户线程和请求线程是两个线程。</li><li>SEMAPHORE：信号量隔离策略是采用一个全局变量来控制并发量，用CAS锁机制来保证安全，接收到请求后全局变量加1，当加到与跟配置中的大小相等时不再接受用户请求了。</li></ul><p>THREAD的响应速度会比SEMAPHORE快，但资源占用也比较高，如果追求响应速度可以使用THREAD，如果追求资源消耗可以使用SEMAPHORE。</p><p>注意，Hystix的全局并发量默认为10，如果超过就会报异常。两种策略的设置全局并发量方式也不相同，线程池策略的设置方式如下</p><pre><code class="java">@HystrixCommand(        commandProperties = {                @HystrixProperty(name = &quot;execution.isolation.strategy&quot;, value = &quot;THREAD&quot;)        },        threadPoolProperties = {                @HystrixProperty(name = &quot;coreSize&quot;, value = &quot;100&quot;)        })</code></pre><p>信号量策略的设置如下</p><pre><code class="java">@HystrixCommand(        commandProperties = {                @HystrixProperty(name = &quot;execution.isolation.strategy&quot;, value = &quot;SEMAPHORE&quot;),                @HystrixProperty(name = &quot;execution.isolation.semaphore.maxConcurrentRequests&quot;,value = &quot;100&quot;)        })</code></pre><p>@HystrixCommand注解中的其他几个属性</p><ul><li><p>groupKey：groupKey相同时将使用同一个线程池</p></li><li><p>threadPoolKey：用来指定使用的线程池，优先级要高于groupKey</p></li><li><p>commandKey：可以配合配置文件使用来指定某一个HystrixCommand的配置，如</p></li></ul><pre><code class="java">@HystrixCommand(        commandKey = &quot;queryOrder&quot;,        fallbackMethod = &quot;queryOrderFallback&quot;,        commandProperties = {                @HystrixProperty(name = &quot;execution.isolation.strategy&quot;, value = &quot;THREAD&quot;),                @HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value = &quot;10000&quot;)        },        threadPoolProperties = {                @HystrixProperty(name = &quot;coreSize&quot;, value = &quot;9&quot;)        })</code></pre><p>配置文件中</p><pre><code class="properties">#全局的超时时间hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=5000#hystrix.command.&lt;commandKey&gt;作为前缀表示针对commandKey的Hystrix配置，commandKey默认是采用Feign的客户端的方法名字作为标识#queryOrder的超时时间hystrix.command.queryOrder.execution.isolation.thread.timeoutInMilliseconds=6000</code></pre><h2 id="并发测试"><a href="#并发测试" class="headerlink" title="并发测试"></a>并发测试</h2><p>并发测试可以模拟多个线程同时请求的情况。</p><p>对应的jar包</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.databene&lt;/groupId&gt;    &lt;artifactId&gt;contiperf&lt;/artifactId&gt;    &lt;version&gt;2.3.4&lt;/version&gt;&lt;/dependency&gt;</code></pre><h3 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h3><p>使用方法</p><pre><code class="java">@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = MicroWebApplication.class)@WebAppConfigurationpublic class Test {    @Autowired    OrderService orderService;    @Rule    public ContiPerfRule contiPerfRule = new ContiPerfRule();    @org.junit.Test     /**     * invocations：调用次数     * threads：线程数      */    @PerfTest(invocations = 5,threads = 5)    public void hystrixTest2() {        log.info(Thread.currentThread().getName() + &quot;==&gt;&quot; + orderService.queryOrder());    }}</code></pre><p>注意Hystrix默认的时间非常短，可以通过<code>@HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value = &quot;10000&quot;</code>重新设置超时时间来避免超时报错</p><pre><code class="java">@HystrixCommand(        commandProperties = {                @HystrixProperty(name = &quot;execution.isolation.strategy&quot;, value = &quot;THREAD&quot;),                @HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value = &quot;10000&quot;)        },        threadPoolProperties = {                @HystrixProperty(name = &quot;coreSize&quot;, value = &quot;9&quot;)        })</code></pre><h2 id="Hystrix服务降级"><a href="#Hystrix服务降级" class="headerlink" title="Hystrix服务降级"></a>Hystrix服务降级</h2><p>服务降级相当于对服务调用过程的出现的异常进行友好封装抛一个友好的信息给前端。可以通过<code>@HystrixCommand</code>的<code>fallbackMethod</code>属性来指定。指定的降级方法可以使用<code>@HystrixCommand</code>注解再修饰，完成服务的再降级。</p><pre><code class="java">@HystrixCommand(        fallbackMethod = &quot;queryOrderFallback&quot;,        commandProperties = {                @HystrixProperty(name = &quot;execution.isolation.strategy&quot;, value = &quot;THREAD&quot;),                @HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value = &quot;10000&quot;)        },        threadPoolProperties = {                @HystrixProperty(name = &quot;coreSize&quot;, value = &quot;9&quot;)        })</code></pre><h2 id="Hystrix数据监控"><a href="#Hystrix数据监控" class="headerlink" title="Hystrix数据监控"></a>Hystrix数据监控</h2><p>Hystrix进行服务熔断时会对调用结果进行统计，比如超时数、bad请求数、降级数、异常数等等都会有统计，hystrix-dashboard就是展示hystrix统计结果的服务。</p><h3 id="被监控工程的配置"><a href="#被监控工程的配置" class="headerlink" title="被监控工程的配置"></a>被监控工程的配置</h3><p>pom文件中需要引入</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>并在配置文件中加入</p><pre><code class="properties">management.endpoint.health.show-details=alwaysmanagement.endpoint.shutdown.enabled=truemanagement.endpoints.web.exposure.include=*</code></pre><p>数据统计地址；<a href="http://localhost:8091/actuator/hystrix.stream" target="_blank" rel="noopener">http://localhost:8091/actuator/hystrix.stream</a></p><h3 id="Dashboard工程搭建"><a href="#Dashboard工程搭建" class="headerlink" title="Dashboard工程搭建"></a>Dashboard工程搭建</h3><p>pom</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.2.6.RELEASE&lt;/version&gt;    &lt;/parent&gt;    &lt;groupId&gt;pers.zgc&lt;/groupId&gt;    &lt;artifactId&gt;springcloud-dashboard&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;name&gt;springcloud-dashboard&lt;/name&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt;        &lt;spring-cloud.version&gt;Hoxton.SR3&lt;/spring-cloud.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;dependencyManagement&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;                &lt;type&gt;pom&lt;/type&gt;                &lt;scope&gt;import&lt;/scope&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/dependencyManagement&gt;    &lt;build&gt;        &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt;            &lt;plugins&gt;                &lt;!-- clean lifecycle, see https://maven.apache.org/ref/current/maven-core/lifecycles.html#clean_Lifecycle --&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.1.0&lt;/version&gt;                &lt;/plugin&gt;                &lt;!-- default lifecycle, jar packaging: see https://maven.apache.org/ref/current/maven-core/default-bindings.html#Plugin_bindings_for_jar_packaging --&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.0.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.8.0&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;                    &lt;version&gt;2.22.1&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.0.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt;                    &lt;version&gt;2.5.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt;                    &lt;version&gt;2.8.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;!-- site lifecycle, see https://maven.apache.org/ref/current/maven-core/lifecycles.html#site_Lifecycle --&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.7.1&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-project-info-reports-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.0.0&lt;/version&gt;                &lt;/plugin&gt;            &lt;/plugins&gt;        &lt;/pluginManagement&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;</code></pre><p>application.properties</p><pre><code class="properties">server.port=9990management.endpoint.health.show-details=alwaysmanagement.endpoint.shutdown.enabled=truemanagement.endpoints.web.exposure.include=*</code></pre><p>启动类</p><pre><code class="java">@SpringBootApplication@EnableHystrixDashboardpublic class DashboardApplication {    public static void main(String[] args) {        SpringApplication.run(DashboardApplication.class, args);    }}</code></pre><p>启动之后进入监控地址：<a href="http://localhost:9990/hystrix，然后title中输入监控名称，点击Monitor" target="_blank" rel="noopener">http://localhost:9990/hystrix，然后title中输入监控名称，点击Monitor</a> Stream即可。</p><h2 id="Hystrix熔断"><a href="#Hystrix熔断" class="headerlink" title="Hystrix熔断"></a>Hystrix熔断</h2><p>Hystrix熔断常用于并发比较高的接口，避免在网络抖动时接口响应超时导致大量连接占用的情况，熔断器开启后会直接访问降级方法，不再请求接口加快响应时间。注意，熔断器适合的场景是高并发的场景，在并发量不高的场景下使用Ribbon的重试功能更加合适。</p><p>熔断器默认是开启的，触发的条件：在滚动窗口时间内，请求数达到断路器最小请求数，失败率达到断路器设置的百分比。滚动窗口的默认时间为10000ms，最小请求数默认为20次，失败率默认为50%</p><p>熔断器的三个状态：</p><ul><li>关闭状态：关闭状态时用户请求是可以到达服务提供方的</li><li>开启状态：开启状态时用户请求是不能到达服务提供方的，直接会走降级方法</li><li>半开状态：当hystrix熔断器开启时，过一段时间后（默认为5秒），熔断器就会由开启状态变成半开状态。半开状态的熔断器是可以将用户请求传递给服务提供方的，这时候如果远程调用返回成功，那么熔断器就会有半开状态变成关闭状态，反之，如果调用失败，熔断器就会有半开状态变成开启状态。</li></ul>]]></content>
    
    
    <categories>
      
      <category>springcloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>springcloud</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>springcloud注册中心eureka和负载均衡ribbon</title>
    <link href="/2020/04/23/springcloud%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83eureka%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1ribbon/"/>
    <url>/2020/04/23/springcloud%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83eureka%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1ribbon/</url>
    
    <content type="html"><![CDATA[<h2 id="Eureka用户认证"><a href="#Eureka用户认证" class="headerlink" title="Eureka用户认证"></a>Eureka用户认证</h2><p>eureka加入认证功能，在连接时会验证用户名密码。</p><h3 id="服务端配置"><a href="#服务端配置" class="headerlink" title="服务端配置"></a>服务端配置</h3><p>pom中添加</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>application.properties</p><pre><code class="properties">security.basic.enabled=truespring.security.user.name=adminspring.security.user.password=admin</code></pre><p>添加配置类</p><pre><code class="java">@EnableWebSecuritypublic class WebSecurityConfigurer extends WebSecurityConfigurerAdapter {    @Override    protected void configure(HttpSecurity http) throws Exception {        //关闭csrf        http.csrf().disable();        //开启认证：URL格式登录必须是httpBasic        http.authorizeRequests().anyRequest().authenticated().and().httpBasic();    }}</code></pre><h3 id="客户端配置"><a href="#客户端配置" class="headerlink" title="客户端配置"></a>客户端配置</h3><p>properties中的连接改为</p><pre><code>eureka.client.serviceUrl.defaultZone=http://admin:admin@localhost:8763/eureka/</code></pre><h2 id="服务的续约和保活"><a href="#服务的续约和保活" class="headerlink" title="服务的续约和保活"></a>服务的续约和保活</h2><p>当客户端启动向eureka注册本身服务列表后，需要隔段时间发送一次心跳给eureka服务端来证明自己还活着，当eureka收到这个心跳请求后才会知道客户端还活着，继续维护该客户端的服务列表信息。一旦因为某些原因导致客户端没有按时发送心跳给eureka服务端，这时候eureka可能就会认为客户端已经挂掉，就有可能把该服务从服务列表中删除掉。</p><h3 id="客户端配置-1"><a href="#客户端配置-1" class="headerlink" title="客户端配置"></a>客户端配置</h3><pre><code class="properties">#服务续约，心跳的时间间隔eureka.instance.lease-renewal-interval-in-seconds=30#如果从前一次发送心跳时间起，90秒没接受到新的心跳，将剔除服务eureka.instance.lease-expiration-duration-in-seconds=90#表示eureka client间隔多久去拉取服务注册信息，默认为30秒eureka.client.registry-fetch-interval-seconds=30</code></pre><h3 id="服务端的配置"><a href="#服务端的配置" class="headerlink" title="服务端的配置"></a>服务端的配置</h3><pre><code class="properties">#自我保护模式，当出现网格分区，eureka在短时间内丢失过多客户端时，会进入自我保护模式eureka.server.enable-self-preservation=true#Eureka Server 在运行期间会去统计心跳失败比例在15分钟之内是否低于85%，如果低于85%，Eureka Server会将这些实例保护起来eureka.server.renewal-percent-threshold=0.85#eureka server清理无效节点的时间间隔，默认60000毫秒，单位毫秒eureka.server.eviction-interval-timer-in-ms=60000</code></pre><h2 id="Eureka监控检测"><a href="#Eureka监控检测" class="headerlink" title="Eureka监控检测"></a>Eureka监控检测</h2><p>Eureka默认的健康检测只是校验服务连接是否是UP还是DOWN的，客户端只会调用状态为UP状态的服务，但是可能会有服务连接正常，接口调用出现问题的情况，如连接Redis、mongodb、数据库出现问题导致接口调用失败，这时候就需要做自定义的检测。</p><h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><p>pom文件中引入</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>application.properties</p><pre><code class="properties">#开启健康检测eureka.client.healthcheck.enabled=true</code></pre><p>配置类</p><pre><code class="java">@Configurationpublic class MicroOrderHealthIndicator implements HealthIndicator {    @Override    public Health health() {        if (OrderController.canVisitDb) {            return new Health.Builder(Status.UP).build();        } else {            return new Health.Builder(Status.DOWN).build();        }    }}</code></pre><h2 id="服务下线"><a href="#服务下线" class="headerlink" title="服务下线"></a>服务下线</h2><p>比如有些情况是服务主机意外宕机了，无法给eureka发送心跳，但是eureka在没有接受到心跳的情况下依赖维护该服务90s，在这90s之内可能会有客户端调用到该服务，这就可能会导致调用失败。所以eureka提供了接口可以将宕机的服务立即从eureka服务列表中清除掉，避免被服务调用方调用到。</p><p>注意，该请求方式为DELETE，可以用postman请求这个接口，如果需要认证则在Authorization中选择Basic Auth然后输入用户名密码即可。如果服务状态正常，依然在发送心跳，即使调用这个接口也不会删除。</p><pre><code>http://localhost:8763/eureka/apps/{Application}/{Status中的地址}</code></pre><p>还可以缩短eureka服务端中的清理无效节点、客户端拉取服务注册信息的时间间隔。</p><p>服务端</p><pre><code class="properties">#eureka server清理无效节点的时间间隔，默认60000毫秒，单位毫秒eureka.server.eviction-interval-timer-in-ms=60000</code></pre><p>客户端</p><pre><code class="properties">#表示 eureka client 间隔多久去拉取服务注册信息，默认为 30 秒eureka.client.registry-fetch-interval-seconds=30</code></pre><h2 id="Eureka高可用"><a href="#Eureka高可用" class="headerlink" title="Eureka高可用"></a>Eureka高可用</h2><img src="/2020/04/23/springcloud%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83eureka%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1ribbon/pic1.png" srcset="/img/loading.gif" class=""><p>整个微服务中存在多个eureka服务，每个eureka服务都是相互复制的，会把客户端注册进来的服务复制到eureka集群中的其他节点里面来。其实简单来说就是eureka每个节点相互复制。</p><p>eureka1的配置</p><pre><code class="properties">server.port=8761eureka.instance.hostname=eureka-8761#是否注册到eurekaeureka.client.registerWithEureka=true#是否从eureka拉取注册信息eureka.client.fetchRegistry=true#暴露eureka服务的地址eureka.client.serviceUrl.defaultZone=http://admin:admin@eureka-8762:8762/eureka/#自我保护模式，当出现网格分区，eureka在短时间内丢失过多客户端时，会进入自我保护模式eureka.server.enable-self-preservation=true#Eureka Server 在运行期间会去统计心跳失败比例在15分钟之内是否低于85%，如果低于85%，Eureka Server会将这些实例保护起来eureka.server.renewal-percent-threshold=0.85#eureka server清理无效节点的时间间隔，默认60000毫秒，单位毫秒eureka.server.eviction-interval-timer-in-ms=60000security.basic.enabled=truespring.security.user.name=adminspring.security.user.password=admin</code></pre><p>eureka2的配置</p><pre><code class="properties">server.port=8762eureka.instance.hostname=eureka-8762#是否注册到eurekaeureka.client.registerWithEureka=true#是否从eureka拉取注册信息eureka.client.fetchRegistry=true#暴露eureka服务的地址eureka.client.serviceUrl.defaultZone=http://admin:admin@eureka-8761:8761/eureka/#自我保护模式，当出现网格分区，eureka在短时间内丢失过多客户端时，会进入自我保护模式eureka.server.enable-self-preservation=true#Eureka Server 在运行期间会去统计心跳失败比例在15分钟之内是否低于85%，如果低于85%，Eureka Server会将这些实例保护起来eureka.server.renewal-percent-threshold=0.85#eureka server清理无效节点的时间间隔，默认60000毫秒，单位毫秒eureka.server.eviction-interval-timer-in-ms=60000security.basic.enabled=truespring.security.user.name=adminspring.security.user.password=admin</code></pre><p>注意：eureka-8761、eureka-8762需要在本地配置host，对应的地址一般都为127.0.0.1。</p><h2 id="Eureka自我保护模式"><a href="#Eureka自我保护模式" class="headerlink" title="Eureka自我保护模式"></a>Eureka自我保护模式</h2><p>如果开启了自我保护，如果服务没有发送心跳会继续维护90s，如果关闭自我保护在很短一段时间就会删除服务，不会继续维护90s。</p><pre><code class="properties">#自我保护模式，当出现网格分区，eureka在短时间内丢失过多客户端时，会进入自我保护模式eureka.server.enable-self-preservation=true</code></pre><h2 id="Ribbon-API"><a href="#Ribbon-API" class="headerlink" title="Ribbon API"></a>Ribbon API</h2><p>Ribbon是一个独立的组件，用来进行远程接口调用的。Ribbon会从本地列表选择服务来调用。</p><p>配置类中</p><pre><code class="java">    /**     *负载均衡的注解     */    @LoadBalanced    @Bean    RestTemplate restTemplate() {        return new RestTemplate();    }</code></pre><p>具体的调用</p><pre><code class="java">    @Autowired    private RestTemplate restTemplate;    @Override    public String queryOrder() {        String SERVICE_NAME = &quot;micro-order&quot;;        return restTemplate.getForObject(&quot;http://&quot; + SERVICE_NAME + &quot;/queryOrder&quot;, String.class);    }</code></pre><h2 id="Ribbon配置"><a href="#Ribbon配置" class="headerlink" title="Ribbon配置"></a>Ribbon配置</h2><p>配置文件方式：</p><pre><code class="properties">#是否从eureka获取服务列表ribbon.eureka.enabled=true#用于不从eureka获取服务列表，提供服务调用的节点，不建议使用#micro-order.ribbon.listOfServers=localhost:8081,localhost:8082#单位ms，请求连接超时时间micro-order.ribbon.ConnectTimeout=1000#单位mx，请求处理超时时间micro-order.ribbon.ReadTimeout=2000#如果调用失败是否针对所有接口进行重试micro-order.ribbon.OkToRetryOnAllOperations=true#切换实例的重试次数micro-order.ribbon.MaxAutoRetriesNextServer=2#对当前实例的重试次数 当Eureka中可以找到服务，但是服务连接不上时会重试micro-order.ribbon.MaxAutoRetries=2#配置负载均衡策略micro-order.ribbon.NFLoadBalancerRuleClassName=com.netflix.loadbalancer.RoundRobinRule#micro-order.ribbon.NFLoadBalancerPingClassName=com.netflix.loadbalancer.PingUrl</code></pre><p>配置类方式：</p><p>使用@RebbonClients加载配置，这个配置类只针对micro-order服务，可以区别化配置。</p><pre><code class="java">@Configuration@RibbonClients(value = {        @RibbonClient(name = &quot;micro-order&quot;,configuration = RibbonLoadBalanceMicroOrderConfig.class)})public class LoadBalanceConfig {}</code></pre><pre><code class="java">/* * 这个类最好不要出现在启动类的@ComponentScan扫描范围 * 如果出现在@ComponentScan扫描访问，那么这个配置类就是每个服务共用的配置了 * */@Configurationpublic class RibbonLoadBalanceMicroOrderConfig {    //    @RibbonClientName    private String name = &quot;micro-order&quot;;    @Bean    @ConditionalOnClass    public IClientConfig defaultClientConfigImpl() {        DefaultClientConfigImpl config = new DefaultClientConfigImpl();        config.loadProperties(name);        config.set(CommonClientConfigKey.MaxAutoRetries, 2);        config.set(CommonClientConfigKey.MaxAutoRetriesNextServer, 2);        config.set(CommonClientConfigKey.ConnectTimeout, 2000);        config.set(CommonClientConfigKey.ReadTimeout, 4000);        config.set(CommonClientConfigKey.OkToRetryOnAllOperations, true);        return config;    }    /*     * 用于请求前判断服务是否存活，会拉长请求时间，不建议使用     * *///    @Bean    public IPing iPing() {        //这个实现类会去调用服务来判断服务是否存活        return new PingUrl();    }    @Bean    public IRule ribbonRule() {        //线性轮训        new RoundRobinRule();        //可以重试的轮训        new RetryRule();        //根据运行情况来计算权重        new WeightedResponseTimeRule();        //过滤掉故障实例，选择请求数最小的实例        new BestAvailableRule();        return new RandomRule();    }}</code></pre><p>负载均衡策略：</p><ul><li>RoundRobinRule：线性轮询</li><li>RetryRule：可以重试的轮询</li><li>WeightedResponseTimeRule：根据运行情况计算权重</li><li>BestAvailableRule：过滤掉故障实例，选择请求数最小的</li></ul><p>注：涉及到的统计数据来源于actuator。</p><h2 id="Ribbon的单独使用"><a href="#Ribbon的单独使用" class="headerlink" title="Ribbon的单独使用"></a>Ribbon的单独使用</h2><p>Ribbon是一个独立的组件，可以脱离springcloud单独使用。</p><pre><code class="java">    public void test1() {        try {            //myClients随便取值            ConfigurationManager.getConfigInstance().setProperty(&quot;myClients.ribbon.listOfServers&quot;,&quot;localhost:8001,localhost:8002&quot;);            RestClient client = (RestClient)ClientFactory.getNamedClient(&quot;myClients&quot;);            HttpRequest request = HttpRequest.newBuilder().uri(new URI(&quot;/user/queryContent&quot;)).build();            for (int i = 0; i &lt; 10; i++) {                HttpResponse httpResponse = client.executeWithLoadBalancer(request);                String entity = httpResponse.getEntity(String.class);                System.out.println(entity);            }        } catch (URISyntaxException e) {            e.printStackTrace();        } catch (ClientException e) {            e.printStackTrace();        } catch (Exception e) {            e.printStackTrace();        }    }</code></pre><p>需要的jar包：</p><ul><li>com.netflix.ribbon:ribbon-core:2.3.0</li><li>com.netflix.ribbon:ribbon-httpclient:2.3.0</li></ul>]]></content>
    
    
    <categories>
      
      <category>springcloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>springcloud</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>springcloud的简单搭建</title>
    <link href="/2020/04/23/springcloud%E7%9A%84%E7%AE%80%E5%8D%95%E6%90%AD%E5%BB%BA/"/>
    <url>/2020/04/23/springcloud%E7%9A%84%E7%AE%80%E5%8D%95%E6%90%AD%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<h2 id="注册中心的搭建"><a href="#注册中心的搭建" class="headerlink" title="注册中心的搭建"></a>注册中心的搭建</h2><p>pom文件</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.2.6.RELEASE&lt;/version&gt;    &lt;/parent&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;artifactId&gt;springcould-eureka&lt;/artifactId&gt;    &lt;name&gt;springcould-eureka&lt;/name&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt;        &lt;spring-cloud.version&gt;Hoxton.SR3&lt;/spring-cloud.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;            &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;            &lt;artifactId&gt;lombok&lt;/artifactId&gt;            &lt;optional&gt;true&lt;/optional&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;            &lt;scope&gt;test&lt;/scope&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt;                    &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;dependencyManagement&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;                &lt;type&gt;pom&lt;/type&gt;                &lt;scope&gt;import&lt;/scope&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/dependencyManagement&gt;    &lt;build&gt;        &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt;            &lt;plugins&gt;                &lt;!-- clean lifecycle, see https://maven.apache.org/ref/current/maven-core/lifecycles.html#clean_Lifecycle --&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.1.0&lt;/version&gt;                &lt;/plugin&gt;                &lt;!-- default lifecycle, jar packaging: see https://maven.apache.org/ref/current/maven-core/default-bindings.html#Plugin_bindings_for_jar_packaging --&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.0.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.8.0&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;                    &lt;version&gt;2.22.1&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.0.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt;                    &lt;version&gt;2.5.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt;                    &lt;version&gt;2.8.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;!-- site lifecycle, see https://maven.apache.org/ref/current/maven-core/lifecycles.html#site_Lifecycle --&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.7.1&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-project-info-reports-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.0.0&lt;/version&gt;                &lt;/plugin&gt;            &lt;/plugins&gt;        &lt;/pluginManagement&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;</code></pre><p>application.properties</p><pre><code class="properties">server.port=8763eureka.instance.hostname=localhost#是否注册到eurekaeureka.client.registerWithEureka=false#是否从eureka拉取注册信息eureka.client.fetchRegistry=false#暴露eureka服务的地址eureka.client.serviceUrl.defaultZone=http://${eureka.instance.hostname}:${server.port}/eureka/#自我保护模式，当出现网格分区，eureka在短时间内丢失过多客户端时，会进入自我保护模式eureka.server.enable-self-preservation=true#eureka server清理无效节点的时间间隔，默认60000毫秒，单位毫秒#eureka.server.eviction-interval-timer-in-ms=60000</code></pre><p>启动类</p><pre><code class="java">@SpringBootApplication@EnableEurekaServerpublic class EurekaApplication {    public static void main(String[] args) {        SpringApplication.run(EurekaApplication.class, args);    }}</code></pre><h2 id="服务提供方"><a href="#服务提供方" class="headerlink" title="服务提供方"></a>服务提供方</h2><p>pom文件</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.2.6.RELEASE&lt;/version&gt;    &lt;/parent&gt;    &lt;groupId&gt;pers.zgc&lt;/groupId&gt;    &lt;artifactId&gt;micro-order&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;name&gt;micro-order&lt;/name&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt;        &lt;spring-cloud.version&gt;Hoxton.SR3&lt;/spring-cloud.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;            &lt;artifactId&gt;lombok&lt;/artifactId&gt;            &lt;optional&gt;true&lt;/optional&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;dependencyManagement&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;                &lt;type&gt;pom&lt;/type&gt;                &lt;scope&gt;import&lt;/scope&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/dependencyManagement&gt;    &lt;build&gt;        &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt;            &lt;plugins&gt;                &lt;!-- clean lifecycle, see https://maven.apache.org/ref/current/maven-core/lifecycles.html#clean_Lifecycle --&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.1.0&lt;/version&gt;                &lt;/plugin&gt;                &lt;!-- default lifecycle, jar packaging: see https://maven.apache.org/ref/current/maven-core/default-bindings.html#Plugin_bindings_for_jar_packaging --&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.0.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.8.0&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;                    &lt;version&gt;2.22.1&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.0.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt;                    &lt;version&gt;2.5.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt;                    &lt;version&gt;2.8.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;!-- site lifecycle, see https://maven.apache.org/ref/current/maven-core/lifecycles.html#site_Lifecycle --&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.7.1&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-project-info-reports-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.0.0&lt;/version&gt;                &lt;/plugin&gt;            &lt;/plugins&gt;        &lt;/pluginManagement&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;</code></pre><p>boostarp.properties（优先级最高的配置文件）</p><pre><code class="properties">spring.application.name=micro-orderserver.port=8081eureka.client.serviceUrl.defaultZone=http\://localhost\:8763/eureka/</code></pre><p>controller</p><pre><code class="java">@Slf4j@RestControllerpublic class OrderController {    @RequestMapping(&quot;/queryOrder&quot;)    public String queryOrder(){        log.info(&quot;====micro-order====queryOrder&quot;);        return &quot;queryOrder&quot;;    }</code></pre><p>启动类</p><pre><code class="java">@SpringBootApplicationpublic class MicroOrderApplication {    public static void main(String[] args) {        SpringApplication.run(MicroOrderApplication.class, args);    }}</code></pre><h2 id="服务消费方"><a href="#服务消费方" class="headerlink" title="服务消费方"></a>服务消费方</h2><p>pom</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.2.6.RELEASE&lt;/version&gt;    &lt;/parent&gt;    &lt;groupId&gt;pers.zgc&lt;/groupId&gt;    &lt;artifactId&gt;micro-web&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;name&gt;micro-web&lt;/name&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt;        &lt;spring-cloud.version&gt;Hoxton.SR3&lt;/spring-cloud.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;            &lt;artifactId&gt;lombok&lt;/artifactId&gt;            &lt;optional&gt;true&lt;/optional&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;dependencyManagement&gt;        &lt;dependencies&gt;            &lt;dependency&gt;                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;                &lt;type&gt;pom&lt;/type&gt;                &lt;scope&gt;import&lt;/scope&gt;            &lt;/dependency&gt;        &lt;/dependencies&gt;    &lt;/dependencyManagement&gt;    &lt;build&gt;        &lt;pluginManagement&gt;&lt;!-- lock down plugins versions to avoid using Maven defaults (may be moved to parent pom) --&gt;            &lt;plugins&gt;                &lt;!-- clean lifecycle, see https://maven.apache.org/ref/current/maven-core/lifecycles.html#clean_Lifecycle --&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.1.0&lt;/version&gt;                &lt;/plugin&gt;                &lt;!-- default lifecycle, jar packaging: see https://maven.apache.org/ref/current/maven-core/default-bindings.html#Plugin_bindings_for_jar_packaging --&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.0.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.8.0&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;                    &lt;version&gt;2.22.1&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.0.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt;                    &lt;version&gt;2.5.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt;                    &lt;version&gt;2.8.2&lt;/version&gt;                &lt;/plugin&gt;                &lt;!-- site lifecycle, see https://maven.apache.org/ref/current/maven-core/lifecycles.html#site_Lifecycle --&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.7.1&lt;/version&gt;                &lt;/plugin&gt;                &lt;plugin&gt;                    &lt;artifactId&gt;maven-project-info-reports-plugin&lt;/artifactId&gt;                    &lt;version&gt;3.0.0&lt;/version&gt;                &lt;/plugin&gt;            &lt;/plugins&gt;        &lt;/pluginManagement&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;</code></pre><p>bootstrap.properties</p><pre><code class="properties">spring.application.name=micro-webserver.port=8091eureka.client.serviceUrl.defaultZone=http://localhost:8763/eureka/</code></pre><p>controller</p><pre><code class="java">@RestController@RequestMapping(&quot;/order&quot;)public class OrderController {    @Autowired    private OrderService orderService;    @RequestMapping(&quot;/query&quot;)    public String queryOrder() {        return orderService.queryOrder();    }}</code></pre><p>service</p><pre><code class="java">@Servicepublic class OrderServiceImpl implements OrderService {    @Autowired    private RestTemplate restTemplate;    @Override    public String queryOrder() {        String SERVICE_NAME = &quot;micro-order&quot;;        return restTemplate.getForObject(&quot;http://&quot; + SERVICE_NAME + &quot;/queryOrder&quot;, String.class);    }}</code></pre><p>启动类</p><pre><code class="java">@SpringBootApplication@EnableEurekaClientpublic class MicroWebApplication {    @Bean    /**     *负载均衡的注解     */    @LoadBalanced    RestTemplate restTemplate() {        return new RestTemplate();    }    public static void main(String[] args) {        SpringApplication.run(MicroWebApplication.class, args);    }}</code></pre>]]></content>
    
    
    <categories>
      
      <category>springcloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>springcloud</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>架构的演变过程</title>
    <link href="/2020/04/23/%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E5%8F%98%E8%BF%87%E7%A8%8B/"/>
    <url>/2020/04/23/%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E5%8F%98%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h3 id="单体"><a href="#单体" class="headerlink" title="单体"></a>单体</h3><p>我们最先接触的单体架构，整个系统就只有一个工程，打包往往是打成了war包，然后部署到单一tomcat上面，这种就是单体架构，如图:</p><img src="/2020/04/23/%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E5%8F%98%E8%BF%87%E7%A8%8B/pic1.png" srcset="/img/loading.gif" class=""><p>假如系统按照功能划分了，商品模块，购物车模块，订单模块，物流模块等等模块。那么所有模块都会在一个工程里面，这就是单体架构。</p><p>单体架构优点</p><ul><li>结构简单</li><li>部署简单</li><li>所需的硬件资源少</li><li>节省成本</li></ul><p>缺点</p><ul><li>版本迭代慢，往往改动一个代码会影响全局</li><li>不能满足一定并发的访问</li><li>代码维护困难，所有代码在一个工程里面，存在被其他人修改的风险</li></ul><h3 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h3><p>随着业务的拓展，公司的发展，单体架构慢慢的不能满足我们的需求，我们需要对架构进行变动，我们能够想到的最简单的办法就是加机器，对应用横向扩展。</p><img src="/2020/04/23/%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E5%8F%98%E8%BF%87%E7%A8%8B/pic2.png" srcset="/img/loading.gif" class=""><p>这种架构貌似暂时解决了我们的问题，但是用户量慢慢增加后，我们只能通过横向加机器来解决，还是会存在版本迭代慢，代码维护困难的问题。而且用户请求往往是读多写少的情况， 所以可能真正需要扩容的只是商品模块而已，而现在是整个工程都扩容了，这无形中是一种资源的浪费，因为其他模块可能根本不需要扩容就可以满足需求。所以我们有必要对整个工程按照模块进行拆分。</p><h3 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h3><img src="/2020/04/23/%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E5%8F%98%E8%BF%87%E7%A8%8B/pic3.png" srcset="/img/loading.gif" class=""><p>模块拆分后，模块和模块之间是需要通过接口调用的方式进行通信，模块和模块之间通过分流软件进行负载均衡。这个架构解决前面的资源浪费问题和代码管理问题，因为我们是对系统进行拆分，各个模块都有单独的工程，比如我修改商品模块，就不需要担心会不会影响购物车模块。但是这种架构扩展非常麻烦，一旦需要横向加机器，或者减机器都需要修改nginx配置，一旦机器变多了以后，nginx的配置量就是一个不能完成的工作。</p><h3 id="SOA服务治理"><a href="#SOA服务治理" class="headerlink" title="SOA服务治理"></a>SOA服务治理</h3><p>这时候SOA服务治理框架就应运而生，架构图如下:</p><img src="/2020/04/23/%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E5%8F%98%E8%BF%87%E7%A8%8B/pic4.png" srcset="/img/loading.gif" class=""><p>基于注册中心的SOA框架，扩展方便不需要维护分流工具，在启动应用的时会把服务通过http的方式注册到注册中心。<br>在SOA框架中一般会有三种角色</p><ul><li>注册中心：维护服务列表</li><li>服务提供方：服务提供方启动的时候会把自己注册到注册中心</li><li>服务消费方：服务消费方启动的时候会获取注册中心的服务列表，然后从这个服务列表中选择一个去调用。</li></ul><p>微服务工程的缺点:</p><ul><li>项目部署变得非常复杂，必须借助CI（持续集成Jenkins）工具。</li><li>分布式事务问题，接口设计要求较高，往往要考虑幂等问题。</li><li>网络抖动带来的不可控的接口超时。</li></ul><p>微服务项目要求：</p><ul><li>团队分工明确</li><li>项目迭代频繁</li><li>QPS（单位时间查询量）增加。</li></ul>]]></content>
    
    
    <categories>
      
      <category>springcloud</category>
      
    </categories>
    
    
    <tags>
      
      <tag>springcloud</tag>
      
      <tag>架构</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>springboot自定义的启动器</title>
    <link href="/2020/04/23/springboot%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E5%90%AF%E5%8A%A8%E5%99%A8/"/>
    <url>/2020/04/23/springboot%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E5%90%AF%E5%8A%A8%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="定义启动器核心工程"><a href="#定义启动器核心工程" class="headerlink" title="定义启动器核心工程"></a>定义启动器核心工程</h2><p>当需要把一些共用的api封装成jar包的时候，就可以使用自定义启动器来做。自定义启动时用到的就是springboot的SPI原理，springboot会去加载META-INF/spring.factories配置文件中EnableAutoConfiguration为key的所有类，所以首先需要创建配置类。</p><pre><code class="java">@Configuration@EnableCaching@ComponentScan(basePackages = &quot;com.base.redis&quot;)public class RedisConfig {    @Bean    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) {        RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;();        redisTemplate.setConnectionFactory(redisConnectionFactory);        // 设置value的序列化规则和 key的序列化规则        StringRedisSerializer stringSerializer = new StringRedisSerializer();        redisTemplate.setKeySerializer(stringSerializer);        redisTemplate.setValueSerializer(stringSerializer);        redisTemplate.setHashKeySerializer(stringSerializer);        redisTemplate.setHashValueSerializer(stringSerializer);        redisTemplate.afterPropertiesSet();        return redisTemplate;    }    @Bean    public CacheManager cacheManager(RedisConnectionFactory factory, RedisCacheConfiguration redisCacheConfiguration) {        //RedisCacheManager 生成器创建        RedisCacheManager.RedisCacheManagerBuilder builder = RedisCacheManager.builder(factory).cacheDefaults(redisCacheConfiguration);        return builder.build();    }    @Bean    public RedisCacheConfiguration redisCacheConfiguration() {        //加载redis缓存的默认配置        RedisCacheConfiguration configuration = RedisCacheConfiguration.defaultCacheConfig();        configuration = configuration                .entryTtl(Duration.ofDays(1))                .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new FastJsonRedisSerializer&lt;&gt;(Object.class)));        return configuration;    }    @Bean    public HashOperations&lt;String, String, String&gt; hashOperations(RedisTemplate&lt;String, String&gt; redisTemplate) {        return redisTemplate.opsForHash();    }    @Bean    public ValueOperations&lt;String, String&gt; valueOperations(RedisTemplate&lt;String, String&gt; redisTemplate) {        return redisTemplate.opsForValue();    }    @Bean    public ListOperations&lt;String, String&gt; listOperations(RedisTemplate&lt;String, String&gt; redisTemplate) {        return redisTemplate.opsForList();    }    @Bean    public SetOperations&lt;String, String&gt; setOperations(RedisTemplate&lt;String, String&gt; redisTemplate) {        return redisTemplate.opsForSet();    }    @Bean    public ZSetOperations&lt;String, String&gt; zSetOperations(RedisTemplate&lt;String, String&gt; redisTemplate) {        return redisTemplate.opsForZSet();    }}</code></pre><p>然后在resources/META-INF/spring.factories中加入配置类</p><pre><code class="properties">org.springframework.boot.autoconfigure.EnableAutoConfiguration=\  com.base.redis.config.RedisConfig</code></pre><h2 id="自定义starter工程"><a href="#自定义starter工程" class="headerlink" title="自定义starter工程"></a>自定义starter工程</h2><p>该工程中没有代码，只是作为核心工程的启动类，封装和整合核心工程。所以只需要一个引入核心工程的pom文件。</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;com.base.cache&lt;/groupId&gt;    &lt;artifactId&gt;cache-springboot-starter&lt;/artifactId&gt;    &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;    &lt;name&gt;cache-springboot-starter&lt;/name&gt;    &lt;properties&gt;        &lt;java.version&gt;1.8&lt;/java.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.base.redis&lt;/groupId&gt;            &lt;artifactId&gt;redis-cache&lt;/artifactId&gt;            &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;&lt;/project&gt;</code></pre>]]></content>
    
    
    <categories>
      
      <category>springboot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>springboot</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>springboot源码解析</title>
    <link href="/2020/04/22/springboot%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    <url>/2020/04/22/springboot%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h2 id="springboot的启动分析"><a href="#springboot的启动分析" class="headerlink" title="springboot的启动分析"></a>springboot的启动分析</h2><p>main()方法中会调用springboot的run()方法，该方法是spring启动的入口，这里只分析几个重点的方法。</p><ol><li>调用getRunListeners()方法通过SPI机制加载META-INF/spring.factories文件中的类。</li><li>调用createApplicationContext()方法完成上下文对象的创建。</li><li>调用refreshContext()方法，最终会调用到上下文对象的refresh()，与之前不同的是这里在refresh()的onrefresh()方法中会完成tomcat的启动。</li></ol><p>SPI在spring、springboot、tomcat中都有使用，SPI全称为service provider interface，核心思想是服务提供接口的发现。spring主要是从外部文件中发现服务，这么做是由于加载的类文件是由开发者指定的包名下的，是不包括第三方的jar包的，所以spring提供了这种方式来加载jar包中的类文件。</p><pre><code class="java">public ConfigurableApplicationContext run(String... args) {   // 统计时间用的工具类   StopWatch stopWatch = new StopWatch();   stopWatch.start();   ConfigurableApplicationContext context = null;   Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;();   configureHeadlessProperty();   // 获取实现了SpringApplicationRunListener接口的实现类，通过SPI机制加载   // META-INF/spring.factories文件下的类   SpringApplicationRunListeners listeners = getRunListeners(args);   // 首先调用SpringApplicationRunListener的starting方法   listeners.starting();   try {      ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);      // 处理配置数据      ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments);      configureIgnoreBeanInfo(environment);      // 启动时打印banner      Banner printedBanner = printBanner(environment);      // 创建上下文对象      context = createApplicationContext();      // 获取SpringBootExceptionReporter接口的类，异常报告      exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class,            new Class[] { ConfigurableApplicationContext.class }, context);      prepareContext(context, environment, listeners, applicationArguments, printedBanner);      // 核心方法，启动spring容器      refreshContext(context);      afterRefresh(context, applicationArguments);      // 统计结束      stopWatch.stop();      if (this.logStartupInfo) {         new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch);      }      // 调用started      listeners.started(context);      // ApplicationRunner      // CommandLineRunner      // 获取这两个接口的实现类，并调用其run方法      callRunners(context, applicationArguments);   }   catch (Throwable ex) {      handleRunFailure(context, ex, exceptionReporters, listeners);      throw new IllegalStateException(ex);   }   try {      // 最后调用running方法      listeners.running(context);   }   catch (Throwable ex) {      handleRunFailure(context, ex, exceptionReporters, null);      throw new IllegalStateException(ex);   }   return context;}</code></pre><h3 id="getRunListeners-方法"><a href="#getRunListeners-方法" class="headerlink" title="getRunListeners()方法"></a>getRunListeners()方法</h3><p>getSpringFactoriesInstances()是它的主要方法，该方法首先会通过loadFactoryNames()方法加载spring.factories中的内容，然后通过反射实例化。</p><pre><code class="java">private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type, Class&lt;?&gt;[] parameterTypes, Object... args) {   ClassLoader classLoader = getClassLoader();   // Use names and ensure unique to protect against duplicates   Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(SpringFactoriesLoader.loadFactoryNames(type, classLoader));   // 加载后反射实例化   List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names);   AnnotationAwareOrderComparator.sort(instances);   return instances;}</code></pre><h3 id="createApplicationContext-方法"><a href="#createApplicationContext-方法" class="headerlink" title="createApplicationContext()方法"></a>createApplicationContext()方法</h3><p>该方法会加载AnnotationConfigServletWebServerApplicationContext对象。该对象与之前分析的spring基于注解的启动方式中的AnnotationConfigApplicaitonContext对象基本相同，初始化逻辑也基本相同。</p><p>其构造函数中也会创建一个AnnotatedBeanDefinitionReader对象，AnnotatedBeanDefinitionReader的构造函数中会直接调用AnnotationConfigUtils.registerAnnotationConfigProcessors()将一些对象的转为BeanDefinition对象，这里有一个比较重要的对象：ConfigurationClassPostProcessor。</p><pre><code class="java">protected ConfigurableApplicationContext createApplicationContext() {   Class&lt;?&gt; contextClass = this.applicationContextClass;   if (contextClass == null) {      try {         switch (this.webApplicationType) {         case SERVLET:            contextClass = Class.forName(DEFAULT_SERVLET_WEB_CONTEXT_CLASS);            break;         case REACTIVE:            contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS);            break;         default:            contextClass = Class.forName(DEFAULT_CONTEXT_CLASS);         }      }      catch (ClassNotFoundException ex) {         throw new IllegalStateException(               &quot;Unable create a default ApplicationContext, please specify an ApplicationContextClass&quot;, ex);      }   }   return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass);}</code></pre><h3 id="onRefresh-方法"><a href="#onRefresh-方法" class="headerlink" title="onRefresh()方法"></a>onRefresh()方法</h3><p>该方法会调用到ServletWebServerApplicationContext类的onRefresh()方法，该方法完成父类容器的onRefresh()方法后会调用createWebServer()方法创建web容器。</p><pre><code class="java">protected void onRefresh() {   super.onRefresh();   try {      createWebServer();   }   catch (Throwable ex) {      throw new ApplicationContextException(&quot;Unable to start web server&quot;, ex);   }}</code></pre><p>createWebServer()方法</p><p>该方法会调用到Jetty、Undertow、Tomcat的getWebServer()创建方法，这里我们只分析Tomcat的创建方法。</p><pre><code class="java">/* * 创建servlet容器 */private void createWebServer() {   WebServer webServer = this.webServer;   ServletContext servletContext = getServletContext();   if (webServer == null &amp;&amp; servletContext == null) {      ServletWebServerFactory factory = getWebServerFactory();      // 主要看这个方法      this.webServer = factory.getWebServer(getSelfInitializer());   }   else if (servletContext != null) {      try {         getSelfInitializer().onStartup(servletContext);      }      catch (ServletException ex) {         throw new ApplicationContextException(&quot;Cannot initialize servlet context&quot;, ex);      }   }   initPropertySources();}</code></pre><p>getWebServer()方法</p><p>该方法会创建一个Tomcat容器，并完成其工作路径、connection属性的设置。</p><pre><code class="java">public WebServer getWebServer(ServletContextInitializer... initializers) {   if (this.disableMBeanRegistry) {      Registry.disableRegistry();   }   Tomcat tomcat = new Tomcat();   File baseDir = (this.baseDirectory != null) ? this.baseDirectory : createTempDir(&quot;tomcat&quot;);   tomcat.setBaseDir(baseDir.getAbsolutePath());   Connector connector = new Connector(this.protocol);   connector.setThrowOnFailure(true);   tomcat.getService().addConnector(connector);   customizeConnector(connector);   tomcat.setConnector(connector);   tomcat.getHost().setAutoDeploy(false);   configureEngine(tomcat.getEngine());   for (Connector additionalConnector : this.additionalTomcatConnectors) {      tomcat.getService().addConnector(additionalConnector);   }   prepareContext(tomcat.getHost(), initializers);   return getTomcatWebServer(tomcat);}</code></pre><h2 id="springboot的自动化配置分析"><a href="#springboot的自动化配置分析" class="headerlink" title="springboot的自动化配置分析"></a>springboot的自动化配置分析</h2><p>@SpringBootApplication中包含的注解：</p><ul><li>@ComponentScan注解：扫描包路径下的注解</li><li>@EnableAutoConfiguration注解：开启自动配置</li></ul><pre><code class="java">@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),      @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })public @interface SpringBootApplication {</code></pre><h3 id="EnableAutoConfiguration自动配置的实现"><a href="#EnableAutoConfiguration自动配置的实现" class="headerlink" title="@EnableAutoConfiguration自动配置的实现"></a>@EnableAutoConfiguration自动配置的实现</h3><p>该注解会引入AutoConfigurationImportSelector类，这个类将通过spi来引入自动配置类。</p><pre><code class="java">@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration {</code></pre><h4 id="AutoConfigurationImportSelector类"><a href="#AutoConfigurationImportSelector类" class="headerlink" title="AutoConfigurationImportSelector类"></a>AutoConfigurationImportSelector类</h4><p>process()方法</p><p>该方法会由上面注册的ConfigurationClassPostProcessor调用，首先调用getAutoConfigurationEntry()方法获取到自动配置的实体类，然后加入到spring容器，交由spring来管理。</p><pre><code class="java">public void process(AnnotationMetadata annotationMetadata, DeferredImportSelector deferredImportSelector) {   Assert.state(deferredImportSelector instanceof AutoConfigurationImportSelector,         () -&gt; String.format(&quot;Only %s implementations are supported, got %s&quot;,               AutoConfigurationImportSelector.class.getSimpleName(),               deferredImportSelector.getClass().getName()));   AutoConfigurationEntry autoConfigurationEntry = ((AutoConfigurationImportSelector) deferredImportSelector)         .getAutoConfigurationEntry(getAutoConfigurationMetadata(), annotationMetadata);   this.autoConfigurationEntries.add(autoConfigurationEntry);   for (String importClassName : autoConfigurationEntry.getConfigurations()) {      this.entries.putIfAbsent(importClassName, annotationMetadata);   }}</code></pre><p>getAutoConfigurationEntry()方法</p><p>该方法首先会通过getCandidateConfigurations()方法获取到META-INF/spring.factories中所有键为EnableAutoConfiguration.class的类，这里也是SPI的运用。然后对类进行过滤后封装为AutoConfigurationEntry对象。</p><p>springboot主要是通过SPI加载配置文件的方式，把类加载到spring容器完成实例化。</p><pre><code class="java">protected AutoConfigurationEntry getAutoConfigurationEntry(AutoConfigurationMetadata autoConfigurationMetadata,      AnnotationMetadata annotationMetadata) {   if (!isEnabled(annotationMetadata)) {      return EMPTY_ENTRY;   }   AnnotationAttributes attributes = getAttributes(annotationMetadata);   // SPI获取EnableAutoConfiguration为key的所有实现类   List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes);   configurations = removeDuplicates(configurations);   Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes);   checkExcludedClasses(configurations, exclusions);   configurations.removeAll(exclusions);   // 把某些自动配置类过滤掉   configurations = filter(configurations, autoConfigurationMetadata);   fireAutoConfigurationImportEvents(configurations, exclusions);   // 包装成自动配置实体类   return new AutoConfigurationEntry(configurations, exclusions);}</code></pre><h3 id="AOP的自动配置"><a href="#AOP的自动配置" class="headerlink" title="AOP的自动配置"></a>AOP的自动配置</h3><p>AopAutoConfiguration类默认会开启@EnableAspectJAutoProxy注解，注意这里使用了@ConditionalOnProperty注解，判断<code>spring.aop.auto</code>的值，为true和缺失时都会加载，matchIfMissing在cglib的配置中为true，所以默认是采用cglib代理的。如果要使用jdk的需要在配置文件中加入<code>spring.aop.proxy-target-class=false</code>。其他自动配置的代码基本相同，都是采用@Conditional注解来判断是否加载，不再分析。</p><pre><code class="java">@Configuration(proxyBeanMethods = false)@ConditionalOnProperty(prefix = &quot;spring.aop&quot;, name = &quot;auto&quot;, havingValue = &quot;true&quot;, matchIfMissing = true)public class AopAutoConfiguration {   @Configuration(proxyBeanMethods = false)   @ConditionalOnClass(Advice.class)   static class AspectJAutoProxyingConfiguration {      @Configuration(proxyBeanMethods = false)      @EnableAspectJAutoProxy(proxyTargetClass = false)      @ConditionalOnProperty(prefix = &quot;spring.aop&quot;, name = &quot;proxy-target-class&quot;, havingValue = &quot;false&quot;,            matchIfMissing = false)      static class JdkDynamicAutoProxyConfiguration {      }      @Configuration(proxyBeanMethods = false)      @EnableAspectJAutoProxy(proxyTargetClass = true)      @ConditionalOnProperty(prefix = &quot;spring.aop&quot;, name = &quot;proxy-target-class&quot;, havingValue = &quot;true&quot;,            matchIfMissing = true)      static class CglibAutoProxyConfiguration {      }   }   @Configuration(proxyBeanMethods = false)   @ConditionalOnMissingClass(&quot;org.aspectj.weaver.Advice&quot;)   @ConditionalOnProperty(prefix = &quot;spring.aop&quot;, name = &quot;proxy-target-class&quot;, havingValue = &quot;true&quot;,         matchIfMissing = true)   static class ClassProxyingConfiguration {      ClassProxyingConfiguration(BeanFactory beanFactory) {         if (beanFactory instanceof BeanDefinitionRegistry) {            BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory;            AopConfigUtils.registerAutoProxyCreatorIfNecessary(registry);            AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry);         }      }   }}</code></pre><h3 id="Conditional"><a href="#Conditional" class="headerlink" title="@Conditional"></a>@Conditional</h3><p>上面的代码中出现了@ConditionalOnProperty注解，这个是用来判断条件是否满足，通常与@Bean配合使用，完成有条件的初始化类的需求。spring的自动配置类中的组件初始化时，也会通过这个注解来决定是否初始化类。</p><p>常用的有：</p><ul><li><code>@ConditionalOnBean(name=&quot;test&quot;)</code>：当spring容器中有name为test的bean时再进行加载</li><li><code>@ConditionalOnClass(name=&quot;com.demo.TestController&quot;)</code>：当上下文中有com.demo.TestController时再进行加载</li><li><code>@ConditionalOnMissingClass(name=&quot;com.demo.TestController&quot;)</code>：与上面的相反，当上下文中没有com.demo.TestController时再进行加载</li><li><code>@ConditionalOnExpression(&quot;${spring.datasource.max-idle}=10&quot;)</code>：当spring.datasource.max-idle属性的值为10在进行加载</li></ul><p>还可以通过实现Condition接口来自定义Condition</p><pre><code class="java">public class CustomCondition implements Condition {    @Override    public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) {        System.out.println(&quot;=====CustomCondition.matches======&quot;);        String property = context.getEnvironment().getProperty(&quot;spring.redis.jedis.pool.max-active&quot;);        if(&quot;8&quot;.equals(property)) {            return false;        } else {            return true;        }    }}</code></pre><p>然后使用@Conditional注解将值设置为自定义的Condition。</p><pre><code class="java">@Bean@Conditional(value = CustomCondition.class)public User conditionalTest() {    System.out.println(&quot;======ConfigFamliy.conditionalTest&quot;);    return new User();}</code></pre><h4 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h4><p>实现原理也比较简单，spring完成BeanDefinition收集之后，会使用ConfigurationClassPostProcessor进行处理，所以只要在ConfigurationClassPostProcessor完成Condition的功能即可。</p><p>ConfigurationClassPostProcessor会调用到ConfigurationClassParser类的processConfigurationClass()方法，该方法会调用shouldSkip()方法对类进行过滤。</p><pre><code class="java">protected void processConfigurationClass(ConfigurationClass configClass) throws IOException {    // 根据Condition接口来过滤类    if (!this.conditionEvaluator.shouldSkip(configClass.getMetadata(), ConfigurationPhase.PARSE_CONFIGURATION)) {        ConfigurationClass existingClass = (ConfigurationClass)this.configurationClasses.get(configClass);        if (existingClass != null) {            if (configClass.isImported()) {                if (existingClass.isImported()) {                    existingClass.mergeImportedBy(configClass);                }                return;            }            this.configurationClasses.remove(configClass);            this.knownSuperclasses.values().removeIf(configClass::equals);        }        ConfigurationClassParser.SourceClass sourceClass = this.asSourceClass(configClass);        do {            sourceClass = this.doProcessConfigurationClass(configClass, sourceClass);        } while(sourceClass != null);        this.configurationClasses.put(configClass, configClass);    }}</code></pre><p>shouldSkip()方法会获取到该类对应的所有Condition，然后调用matches()方法进行判断。</p><h5 id="matches-方法"><a href="#matches-方法" class="headerlink" title="matches()方法"></a>matches()方法</h5><p>AnnotatedTypeMetadata中包含类的所有信息、ConditionOutcome用来封装匹配之后的结果。getMatchOutcome()会到用到子类</p><pre><code class="java">public final boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) {   String classOrMethodName = getClassOrMethodName(metadata);   try {      // 典型的钩子方法，调到用具体子类中方法。ConditionOutcome 这个类里面包装了是否需      // 跳过和打印的日志      ConditionOutcome outcome = getMatchOutcome(context, metadata);      logOutcome(classOrMethodName, outcome);      recordEvaluation(context, classOrMethodName, outcome);      return outcome.isMatch();   }   catch (NoClassDefFoundError ex) {      throw new IllegalStateException(&quot;Could not evaluate condition on &quot; + classOrMethodName + &quot; due to &quot;            + ex.getMessage() + &quot; not found. Make sure your own configuration does not rely on &quot;            + &quot;that class. This can also happen if you are &quot;            + &quot;@ComponentScanning a springframework package (e.g. if you &quot;            + &quot;put a @ComponentScan in the default package by mistake)&quot;, ex);   }   catch (RuntimeException ex) {      throw new IllegalStateException(&quot;Error processing condition on &quot; + getName(metadata), ex);   }}</code></pre><h6 id="OnClassCondition类的getMatchOutcome-方法"><a href="#OnClassCondition类的getMatchOutcome-方法" class="headerlink" title="OnClassCondition类的getMatchOutcome()方法"></a>OnClassCondition类的getMatchOutcome()方法</h6><p>该方法会使用Class.forname()寻找ConditionalOnClass注解中的类，如果有异常就说明上下文中没有这个类，就过滤掉。</p><pre><code class="java">public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) {   ClassLoader classLoader = context.getClassLoader();   ConditionMessage matchMessage = ConditionMessage.empty();   List&lt;String&gt; onClasses = getCandidates(metadata, ConditionalOnClass.class);   if (onClasses != null) {      // 核心方法，过滤一下，其实就是Class.forname一下ConditionalOnClass注解中的类，如果有异常就说明      // 上下文中没这个类，没有就过滤掉      List&lt;String&gt; missing = filter(onClasses, ClassNameFilter.MISSING, classLoader);      if (!missing.isEmpty()) {         return ConditionOutcome.noMatch(ConditionMessage.forCondition(ConditionalOnClass.class)               .didNotFind(&quot;required class&quot;, &quot;required classes&quot;).items(Style.QUOTE, missing));      }      matchMessage = matchMessage.andCondition(ConditionalOnClass.class)            .found(&quot;required class&quot;, &quot;required classes&quot;)            .items(Style.QUOTE, filter(onClasses, ClassNameFilter.PRESENT, classLoader));   }   List&lt;String&gt; onMissingClasses = getCandidates(metadata, ConditionalOnMissingClass.class);   if (onMissingClasses != null) {      List&lt;String&gt; present = filter(onMissingClasses, ClassNameFilter.PRESENT, classLoader);      if (!present.isEmpty()) {         return ConditionOutcome.noMatch(ConditionMessage.forCondition(ConditionalOnMissingClass.class)               .found(&quot;unwanted class&quot;, &quot;unwanted classes&quot;).items(Style.QUOTE, present));      }      matchMessage = matchMessage.andCondition(ConditionalOnMissingClass.class)            .didNotFind(&quot;unwanted class&quot;, &quot;unwanted classes&quot;)            .items(Style.QUOTE, filter(onMissingClasses, ClassNameFilter.MISSING, classLoader));   }   return ConditionOutcome.match(matchMessage);}</code></pre><h6 id="OnClassCondition类的getMatchOutcome-方法-1"><a href="#OnClassCondition类的getMatchOutcome-方法-1" class="headerlink" title="OnClassCondition类的getMatchOutcome()方法"></a>OnClassCondition类的getMatchOutcome()方法</h6><p>核心方法是判断spring容器中是否有ConditionalOnBean注解中的Bean。</p><pre><code class="java">public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) {   ConditionMessage matchMessage = ConditionMessage.empty();   // 获取类上面的注解   MergedAnnotations annotations = metadata.getAnnotations();   if (annotations.isPresent(ConditionalOnBean.class)) {      // 包装一下      Spec&lt;ConditionalOnBean&gt; spec = new Spec&lt;&gt;(context, metadata, annotations, ConditionalOnBean.class);      // 核心方法，其实就是判断spring容器中是否有ConditionalOnBean注解中的bean      MatchResult matchResult = getMatchingBeans(context, spec);      if (!matchResult.isAllMatched()) {         String reason = createOnBeanNoMatchReason(matchResult);         return ConditionOutcome.noMatch(spec.message().because(reason));      }      matchMessage = spec.message(matchMessage).found(&quot;bean&quot;, &quot;beans&quot;).items(Style.QUOTE,            matchResult.getNamesOfAllMatches());   }   if (metadata.isAnnotated(ConditionalOnSingleCandidate.class.getName())) {      Spec&lt;ConditionalOnSingleCandidate&gt; spec = new SingleCandidateSpec(context, metadata, annotations);      MatchResult matchResult = getMatchingBeans(context, spec);      if (!matchResult.isAllMatched()) {         return ConditionOutcome.noMatch(spec.message().didNotFind(&quot;any beans&quot;).atAll());      }      else if (!hasSingleAutowireCandidate(context.getBeanFactory(), matchResult.getNamesOfAllMatches(),            spec.getStrategy() == SearchStrategy.ALL)) {         return ConditionOutcome.noMatch(spec.message().didNotFind(&quot;a primary bean from beans&quot;)               .items(Style.QUOTE, matchResult.getNamesOfAllMatches()));      }      matchMessage = spec.message(matchMessage).found(&quot;a primary bean from beans&quot;).items(Style.QUOTE,            matchResult.getNamesOfAllMatches());   }   if (metadata.isAnnotated(ConditionalOnMissingBean.class.getName())) {      Spec&lt;ConditionalOnMissingBean&gt; spec = new Spec&lt;&gt;(context, metadata, annotations,            ConditionalOnMissingBean.class);      MatchResult matchResult = getMatchingBeans(context, spec);      if (matchResult.isAnyMatched()) {         String reason = createOnMissingBeanNoMatchReason(matchResult);         return ConditionOutcome.noMatch(spec.message().because(reason));      }      matchMessage = spec.message(matchMessage).didNotFind(&quot;any beans&quot;).atAll();   }   return ConditionOutcome.match(matchMessage);}</code></pre>]]></content>
    
    
    <categories>
      
      <category>springboot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>springboot</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>springboot各种组件的整合</title>
    <link href="/2020/04/22/springboot%E5%90%84%E7%A7%8D%E7%BB%84%E4%BB%B6%E7%9A%84%E6%95%B4%E5%90%88/"/>
    <url>/2020/04/22/springboot%E5%90%84%E7%A7%8D%E7%BB%84%E4%BB%B6%E7%9A%84%E6%95%B4%E5%90%88/</url>
    
    <content type="html"><![CDATA[<h2 id="springboot工程搭建"><a href="#springboot工程搭建" class="headerlink" title="springboot工程搭建"></a>springboot工程搭建</h2><p>springboot工程的搭建十分简单</p><ol><li>继承父工程</li></ol><pre><code class="xml">    &lt;parent&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        &lt;version&gt;2.2.6.RELEASE&lt;/version&gt;        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;    &lt;/parent&gt;</code></pre><ol start="2"><li>导入web启动器</li></ol><pre><code class="xml">        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre><ol start="3"><li>启动类</li></ol><pre><code class="java">@SpringBootApplication(scanBasePackages = {&quot;com.demo.springboot&quot;})public class SpringbootTest extends SpringBootServletInitializer {    /*     * 1、完成Spring容器的启动     * 2、把项目部署到tomcat     * */    public static void main(String[] args) {        ConfigurableApplicationContext applicationContext = SpringApplication.run(SpringbootTest.class,                args);    }    @Override    protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) {        return builder.sources(SpringBootTest.class);    }}</code></pre><h2 id="Servlet、Filter、Listener的整合"><a href="#Servlet、Filter、Listener的整合" class="headerlink" title="Servlet、Filter、Listener的整合"></a>Servlet、Filter、Listener的整合</h2><p>只需要在启动类上加入<code>@ServletComponentScan(basePackages = {&quot;com.demo.springboot&quot;})</code>注解，然后在Servlet、Filter、Listener上加入相应的@WebFilter、@WebListener、@WebServlet注解即可，spring就会在初始化时扫描这些注解并把Servlet、Filter、Listener加入到spring容器中。</p><pre><code class="java">@WebFilter(urlPatterns = &quot;/*&quot;,filterName = &quot;myFilter&quot;)public class MyFilter implements Filter {    @Override    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {        System.out.println(&quot;--------MyFilter----------&quot;);        chain.doFilter(request,response);    }}</code></pre><pre><code class="java">@WebListenerpublic class MyListener implements ServletContextListener {    @Override    public void contextDestroyed(ServletContextEvent contextEvent) {        System.out.println(&quot;contextDestroyed&quot;); }    @Override    public void contextInitialized(ServletContextEvent contextEvent) {        System.out.println(&quot;contextInitialized&quot;); }}</code></pre><pre><code class="java">@WebServlet(urlPatterns = &quot;/jack/*&quot;)public class MyServlet extends HttpServlet {    private static final long serialVersionUID = 1L;    public JackServlet() {        super();    }    protected void doGet(HttpServletRequest request,            HttpServletResponse response) throws ServletException, IOException {        System.out.println(&quot;-----------------doGet-----------------------&quot;);    }    protected void doPost(HttpServletRequest request,            HttpServletResponse response) throws ServletException, IOException {        System.out.println(&quot;------------------doPost----------------------&quot;);    }}</code></pre><h2 id="druid多数据源及数据监控的整合"><a href="#druid多数据源及数据监控的整合" class="headerlink" title="druid多数据源及数据监控的整合"></a>druid多数据源及数据监控的整合</h2><p>Druid对数据库连接的管理比较优秀，而且还提供了可以实时监控数据库连接对象和数据库操作记录的监控界面。通过以下配置后就可以动态的切换数据源，使用方法为在方法上加入<code>@TargetDataSource</code>注解，如切换为ds2数据源<code>@TargetDataSource(name=&quot;ds2&quot;)</code>。durid监控界面的地址为{ip}:{port}/{contextPath}/druid/index.html</p><p>maven中引入jar包</p><pre><code class="xml">        &lt;dependency&gt;            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;            &lt;artifactId&gt;druid&lt;/artifactId&gt;            &lt;version&gt;1.0.26&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.mchange&lt;/groupId&gt;            &lt;artifactId&gt;c3p0&lt;/artifactId&gt;            &lt;version&gt;0.9.5.2&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;mysql&lt;/groupId&gt;            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;            &lt;version&gt;5.1.41&lt;/version&gt;        &lt;/dependency&gt;</code></pre><h3 id="druid配置文件"><a href="#druid配置文件" class="headerlink" title="druid配置文件"></a>druid配置文件</h3><p><code>@ConfigurationProperties(prefix = &quot;spring.druid&quot;,ignoreInvalidFields = true)</code>的作用为读取默认的配置文件application.properties配置，以spring.druid作为前缀读取变量名对应的属性。要使用这个注解必须使用<code>@EnableConfigurationProperties(DruidConfig.class)</code>开启配置文件读取功能</p><p>需要注意默认是读取的application.properties配置文件，配置文件不在默认文件中需要在类中引入配置文件例如：<code>@PropertySource(value = &quot;classpath:druid.properties&quot;)</code></p><pre><code class="java">@Data@Configuration@ConfigurationProperties(prefix = &quot;spring.druid&quot;, ignoreInvalidFields = true)public class DruidConfig {    private String driverClassName;    private String jdbcUrl1;    private String jdbcUrl2;    private String username1;    private String password1;    private String username2;    private String password2;    private int maxActive;    private int minIdle;    private int initialSize;    private Long timeBetweenEvictionRunsMillis;    private Long minEvictableIdleTimeMillis;    private String validationQuery;    private boolean testWhileIdle;    private boolean testOnBorrow;    private boolean testOnReturn;    private boolean poolPreparedStatements;    private Integer maxPoolPreparedStatementPerConnectionSize;    private String filters;    private String connectionProperties;    @Bean(destroyMethod = &quot;close&quot;, initMethod = &quot;init&quot;)    public DataSource getDs1() {        DruidDataSource druidDataSource = new DruidDataSource();        druidDataSource.setDriverClassName(driverClassName);        druidDataSource.setUrl(jdbcUrl1);        druidDataSource.setUsername(username1);        druidDataSource.setPassword(password1);        druidDataSource.setMaxActive(maxActive);        druidDataSource.setInitialSize(initialSize);        druidDataSource.setTimeBetweenConnectErrorMillis(timeBetweenEvictionRunsMillis);        druidDataSource.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis);        druidDataSource.setValidationQuery(validationQuery);        druidDataSource.setTestWhileIdle(testWhileIdle);        druidDataSource.setTestOnBorrow(testOnBorrow);        druidDataSource.setTestOnReturn(testOnReturn);        druidDataSource.setPoolPreparedStatements(poolPreparedStatements);        druidDataSource.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize);        try {            druidDataSource.setFilters(filters);        } catch (SQLException e) {            e.printStackTrace();        }        return druidDataSource;    }    @Bean(destroyMethod = &quot;close&quot;, initMethod = &quot;init&quot;)    public DataSource getDs2() {        DruidDataSource druidDataSource = new DruidDataSource();        druidDataSource.setDriverClassName(driverClassName);        druidDataSource.setUrl(jdbcUrl2);        druidDataSource.setUsername(username2);        druidDataSource.setPassword(password2);        druidDataSource.setMaxActive(maxActive);        druidDataSource.setInitialSize(initialSize);        druidDataSource.setTimeBetweenConnectErrorMillis(timeBetweenEvictionRunsMillis);        druidDataSource.setMinEvictableIdleTimeMillis(minEvictableIdleTimeMillis);        druidDataSource.setValidationQuery(validationQuery);        druidDataSource.setTestWhileIdle(testWhileIdle);        druidDataSource.setTestOnBorrow(testOnBorrow);        druidDataSource.setTestOnReturn(testOnReturn);        druidDataSource.setPoolPreparedStatements(poolPreparedStatements);        druidDataSource.setMaxPoolPreparedStatementPerConnectionSize(maxPoolPreparedStatementPerConnectionSize);        try {            druidDataSource.setFilters(filters);        } catch (SQLException e) {            e.printStackTrace();        }        return druidDataSource;    }    @Bean    public DataSource dynamicDataSource() {        Map&lt;Object, Object&gt; targetDataSources = new HashMap&lt;&gt;();        DataSource ds1 = getDs1();        targetDataSources.put(&quot;ds1&quot;, ds1);        targetDataSources.put(&quot;ds2&quot;, getDs2());        DynamicDataSource dynamicDataSource = new DynamicDataSource();        dynamicDataSource.setTargetDataSources(targetDataSources);        dynamicDataSource.setDefaultTargetDataSource(ds1);        DynamicDataSourceContextHolder.dataSourceIds.add(&quot;ds1&quot;);        DynamicDataSourceContextHolder.dataSourceIds.add(&quot;ds2&quot;);        return dynamicDataSource;    }    /**     * 配置访问druid监控     *     * @return     */    @Bean    public ServletRegistrationBean druidStateViewServlet() {        ServletRegistrationBean servletRegistrationBean = new ServletRegistrationBean(new StatViewServlet(), &quot;/druid/*&quot;);        //初始化参数initParams        //添加白名单        servletRegistrationBean.addInitParameter(&quot;allow&quot;, &quot;&quot;);        //添加ip黑名单        servletRegistrationBean.addInitParameter(&quot;deny&quot;, &quot;192.168.16.111&quot;);        //登录查看信息的账号密码        servletRegistrationBean.addInitParameter(&quot;loginUsername&quot;, &quot;admin&quot;);        servletRegistrationBean.addInitParameter(&quot;loginPassword&quot;, &quot;123&quot;);        //是否能够重置数据        servletRegistrationBean.addInitParameter(&quot;resetEnable&quot;, &quot;false&quot;);        return servletRegistrationBean;    }    /**     * 过滤不需要监控的后缀     *     * @return     */    @Bean    public FilterRegistrationBean druidStatFilter() {        FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(new WebStatFilter());        //添加过滤规则        filterRegistrationBean.addUrlPatterns(&quot;/*&quot;);        //添加不需要忽略的格式信息        filterRegistrationBean.addInitParameter(&quot;exclusions&quot;, &quot;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&quot;);        return filterRegistrationBean;    }}</code></pre><h3 id="application-properties"><a href="#application-properties" class="headerlink" title="application.properties"></a>application.properties</h3><pre><code class="properties">spring.druid.jdbcUrl1=jdbc:mysql://localhost/testspring.druid.jdbcUrl2=jdbc:mysql://localhost/testspring.druid.username1=spring.druid.password1=spring.druid.username2=spring.druid.password2=spring.druid.initialSize=2spring.druid.minIdle=2spring.druid.maxActive=2spring.druid.maxWait=60000spring.druid.timeBetweenEvictionRunsMillis=60000spring.druid.minEvictableIdleTimeMillis=300000spring.druid.validationQuery=SELECT 1 FROM DUALspring.druid.testWhileIdle=truespring.druid.testOnBorrow=falsespring.druid.testOnReturn=falsespring.druid.poolPreparedStatements=truespring.druid.maxPoolPreparedStatementPerConnectionSize=20spring.druid.filters=stat,wallspring.druid.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000</code></pre><h3 id="多数据源切面"><a href="#多数据源切面" class="headerlink" title="多数据源切面"></a>多数据源切面</h3><pre><code class="java">public class DynamicDataSource extends AbstractRoutingDataSource {    @Override    protected Object determineCurrentLookupKey() {        try {            Field targetF = this.getClass().getSuperclass().getDeclaredField(&quot;targetDataSources&quot;);            targetF.setAccessible(true);            Map&lt;Object, Object&gt; targetV = (Map&lt;Object, Object&gt;) targetF.get(this);            String ds = DynamicDataSourceContextHolder.getDataSourceType();            if (ds != null) {                System.out.println(&quot;操作的数据源是： &quot;                        + ds + &quot;-&gt;url:&quot; + ((DruidDataSource) targetV.get(ds)).getUrl());            }            return DynamicDataSourceContextHolder.getDataSourceType();        } catch (NoSuchFieldException e) {            e.printStackTrace();        } catch (IllegalAccessException e) {            e.printStackTrace();        }        return &quot;ds1&quot;;    }}</code></pre><pre><code class="java">@Aspect@Order(-1)@Componentpublic class DynamicDataSourceAspect {    private static final Logger logger = LoggerFactory.getLogger(DynamicDataSourceAspect.class);    @Before(&quot;@annotation(ds)&quot;)    public void changeDataSource(JoinPoint point, TargetDataSource ds) {        //这个就是数据源标识        String dsId = ds.name();        if (!DynamicDataSourceContextHolder.containsDataSource(dsId)) {            logger.error(&quot;数据源[{}]不存在，使用默认数据源 &gt; {}&quot;, ds.name(),                    point.getSignature());        } else {            logger.debug(&quot;使用数据源[{}] &gt; {}&quot;, ds.name(), point.getSignature());            //如果容器中有数据源，那么就把数据源标识设置到ThreadLocal中            DynamicDataSourceContextHolder.setDataSourceType(dsId);        }    }    @After(&quot;@annotation(ds)&quot;)    public void releaseLocal(JoinPoint point, TargetDataSource ds) {        logger.info(&quot;释放ds：&quot; + ds.name() + &quot;的ThreadLocal绑定&quot;);        if (DynamicDataSourceContextHolder.getDataSourceType() != null) {            DynamicDataSourceContextHolder.getContextHolder().remove();        }    }}</code></pre><pre><code class="java">public class DynamicDataSourceContextHolder {    private static final ThreadLocal&lt;String&gt; contextHolder = new ThreadLocal&lt;String&gt;();    public static ThreadLocal&lt;String&gt; getContextHolder() {        return contextHolder;    }    public static List&lt;String&gt; dataSourceIds = new ArrayList&lt;String&gt;();    public static void setDataSourceType(String dataSourceType) {        contextHolder.set(dataSourceType);    }    public static String getDataSourceType() {        return contextHolder.get();    }    public static boolean containsDataSource(String dataSourceId) {        return dataSourceIds.contains(dataSourceId);    }}</code></pre><pre><code class="java">@Target({ElementType.METHOD, ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface TargetDataSource {    String name();}</code></pre><p>如果要使用但数据源也很简单，只要去掉切面注解、dynamicDataSource()方法上的@Bean即可。</p><h2 id="整合ORM框架"><a href="#整合ORM框架" class="headerlink" title="整合ORM框架"></a>整合ORM框架</h2><h3 id="mybatis"><a href="#mybatis" class="headerlink" title="mybatis"></a>mybatis</h3><p>pom文件中引入</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;    &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;RELEASE&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>在启动类添加扫描注解<code>@MapperScan(&quot;com.demo.springboot&quot;)</code></p><p>application.properties</p><pre><code class="properties">#配置该包下的bean别名mybatis.typeAliasesPackage=com.demo.mybatis.bean#解析该路径下的xm建立接口映射关系mybatis.mapperLocations=classpath:mapper/*Mapper.xml</code></pre><p>注：如果出现xml找不到的情况可以在pom文件的build标签中加入以下内容</p><pre><code class="xml">&lt;resources&gt;    &lt;resource&gt;        &lt;directory&gt;src/main/java&lt;/directory&gt;        &lt;includes&gt;            &lt;include&gt;**/*.properties&lt;/include&gt;            &lt;include&gt;**/*.xml&lt;/include&gt;        &lt;/includes&gt;        &lt;filtering&gt;false&lt;/filtering&gt;    &lt;/resource&gt;    &lt;resource&gt;        &lt;directory&gt;src/main/resources&lt;/directory&gt;        &lt;includes&gt;            &lt;include&gt;**/*.properties&lt;/include&gt;            &lt;include&gt;**/*.xml&lt;/include&gt;            &lt;include&gt;**/*.txt&lt;/include&gt;            &lt;include&gt;**/*.keystore&lt;/include&gt;        &lt;/includes&gt;        &lt;filtering&gt;false&lt;/filtering&gt;    &lt;/resource&gt;&lt;/resources&gt;</code></pre><h3 id="JPA"><a href="#JPA" class="headerlink" title="JPA"></a>JPA</h3><p>pom文件中加入</p><pre><code class="xml">        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre><p>application.properties</p><pre><code class="properties">#设置为create时会自动创建表 spring.jpa.hibernate.ddl-auto=update#打印sql语句spring.jpa.show-sql=true</code></pre><p>entity</p><pre><code class="java">@Data@Entity@Table(name = &quot;studnet&quot;)public class Student {    @Id    @GeneratedValue(strategy = GenerationType.IDENTITY)    private Integer id;    @Column(name = &quot;name&quot;)    private String name;    @Column(name = &quot;card_num&quot;)    private String cardNum;}</code></pre><p>dao</p><pre><code class="java">public interface StudentDao extends JpaRepository&lt;Student,Integer&gt; {}</code></pre><p>业务代码中的使用</p><pre><code class="java">@Servicepublic class StudentServiceImpl implements StudentService {    @Autowired    private StudentDao studentDao;    @Override    public void save() {        Student s = new Student();        s.setId(1);        s.setName(&quot;name&quot;);        s.setCardNum(&quot;123123123&quot;);        studentDao.save(s);    }    @Override    public List&lt;Student&gt; getAll() {        return studentDao.findAll();    }}</code></pre><h2 id="整合Atomikos"><a href="#整合Atomikos" class="headerlink" title="整合Atomikos"></a>整合Atomikos</h2><p> Atomikos是一个基于XA协议的分布式事务解决管理框架，其核心思想就是两段提交，一般使用在涉及到的对多个数据源的操作的业务方法中，保证对两个数据源的同时提交和同时回滚。</p><img src="/2020/04/22/springboot%E5%90%84%E7%A7%8D%E7%BB%84%E4%BB%B6%E7%9A%84%E6%95%B4%E5%90%88/pic1.png" srcset="/img/loading.gif" class=""><p>Atomikos就是图中的事务协调器的角色，负责对两个数据源的管理，同时提交或同时回滚。 就是在真正提交之前有一个预提交的过程，就是检测两个数据源是否能够提交， 如果有一个返回 No，那么这个事务就不能提交。</p><p>pom中引入</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-jta-atomikos&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>application.properties文件中</p><pre><code class="properties"># Mysql 1mysql.datasource.test1.url = jdbc:mysql://localhost:3307/test?useUnicode=true&amp;characterEncoding=utf-8mysql.datasource.test1.username = mysql.datasource.test1.password = mysql.datasource.test1.minPoolSize = 3mysql.datasource.test1.maxPoolSize = 25mysql.datasource.test1.maxLifetime = 20000mysql.datasource.test1.borrowConnectionTimeout = 30mysql.datasource.test1.loginTimeout = 30mysql.datasource.test1.maintenanceInterval = 60mysql.datasource.test1.maxIdleTime = 60# Mysql 2mysql.datasource.test2.url =jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf-8mysql.datasource.test2.username =mysql.datasource.test2.password =mysql.datasource.test2.minPoolSize = 3mysql.datasource.test2.maxPoolSize = 25mysql.datasource.test2.maxLifetime = 20000mysql.datasource.test2.borrowConnectionTimeout = 30mysql.datasource.test2.loginTimeout = 30mysql.datasource.test2.maintenanceInterval = 60mysql.datasource.test2.maxIdleTime = 60logging.level.root=info#logging.level.org.springframework.*=debuglogging.level.com.xiangxue.atomikos.db1.dao=debuglogging.level.com.xiangxue.atomikos.db2.dao=debugspring.devtools.restart.enabled=truespring.devtools.restart.additional-paths=src/main/javaspring.devtools.restart.exclude=WEB-INF/**</code></pre><p>数据源创建，这里只列举一个数据源的创建，另一个创建方式与这个相同。</p><pre><code class="java">@Configuration@MapperScan(basePackages = &quot;com.demo.atomikos.db1.dao&quot;, sqlSessionFactoryRef = &quot;test1SqlSessionFactory&quot;,sqlSessionTemplateRef=&quot;test1SqlSessionTemplate&quot;)public class Db1Config {    @Autowired    DBConfig1 testConfig;    @Bean(name = &quot;test1DataSource&quot;)    public DataSource testDataSource() {        MysqlXADataSource mysqlXaDataSource = new MysqlXADataSource();        mysqlXaDataSource.setUrl(testConfig.getUrl());        mysqlXaDataSource.setPinGlobalTxToPhysicalConnection(true);        mysqlXaDataSource.setPassword(testConfig.getPassword());        mysqlXaDataSource.setUser(testConfig.getUsername());        mysqlXaDataSource.setPinGlobalTxToPhysicalConnection(true);        AtomikosDataSourceBean xaDataSource = new AtomikosDataSourceBean();        xaDataSource.setXaDataSource(mysqlXaDataSource);        xaDataSource.setUniqueResourceName(&quot;test1DataSource&quot;);        xaDataSource.setMinPoolSize(testConfig.getMinPoolSize());        xaDataSource.setMaxPoolSize(testConfig.getMaxPoolSize());        xaDataSource.setMaxLifetime(testConfig.getMaxLifetime());        xaDataSource.setBorrowConnectionTimeout(testConfig.getBorrowConnectionTimeout());        try {            xaDataSource.setLoginTimeout(testConfig.getLoginTimeout());        } catch (SQLException e) {            e.printStackTrace();        }        xaDataSource.setMaintenanceInterval(testConfig.getMaintenanceInterval());        xaDataSource.setMaxIdleTime(testConfig.getMaxIdleTime());        xaDataSource.setTestQuery(testConfig.getTestQuery());        return xaDataSource;    }    @Bean(name = &quot;test1SqlSessionFactory&quot;)    public SqlSessionFactory testSqlSessionFactory(@Qualifier(&quot;test1DataSource&quot;) DataSource dataSource)            throws Exception {        SqlSessionFactoryBean bean = new SqlSessionFactoryBean();        bean.setDataSource(dataSource);        return bean.getObject();    }    @Bean(name = &quot;test1SqlSessionTemplate&quot;)    public SqlSessionTemplate testSqlSessionTemplate(            @Qualifier(&quot;test1SqlSessionFactory&quot;) SqlSessionFactory sqlSessionFactory) throws Exception {        return new SqlSessionTemplate(sqlSessionFactory);    }}</code></pre><p>具体使用</p><pre><code class="java">@Servicepublic class AreaServiceImpl implements AreaService {    @Autowired    private CommonMapper1 commonMapper1;    @Autowired    private CommonMapper2 commonMapper2;    @Autowired    TransactionManager transactionManager;    @Transactional    public int saveArea(ConsultConfigArea area) {        System.out.println(transactionManager);        JtaTransactionManager jtaTransactionManager = (JtaTransactionManager)transactionManager;        System.out.println(jtaTransactionManager.getUserTransaction());        UserTransaction userTransaction = jtaTransactionManager.getUserTransaction();        int count = commonMapper1.addArea(area);        int count1 = commonMapper2.addArea(area);        if(true) throw new RuntimeException(&quot;xx&quot;);        return count;    }}</code></pre><p>这里 spring 事务已经交给 atomikos 来管理了，其实就是由 atomikos 中的 JtaTransationManager 来管理事务，重写了 commit 和 Rollback 和 getTransaction 方法，只是 commit 和 Rollback 是对两个数据源的操作而已。</p><h2 id="整合redis"><a href="#整合redis" class="headerlink" title="整合redis"></a>整合redis</h2><p>pom文件</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>application.prperties文件</p><pre><code class="properties">spring.redis.database=0spring.redis.host=192.168.0.1spring.redis.port=6379spring.redis.password=spring.redis.pool.max-active=8spring.redis.pool.max-wait=-1spring.redis.pool.max-idle=8spring.redis.pool.min-idle=0spring.redis.timeout=0</code></pre><p>redis.config</p><pre><code class="java">@Configuration@EnableCachingpublic class RedisConfig {    //缓存管理器    @Bean    public CacheManager cacheManager(RedisConnectionFactory redisConnectionFactory) {        RedisCacheConfiguration redisCacheConfiguration = RedisCacheConfiguration.defaultCacheConfig()                .entryTtl(Duration.ofHours(1)); // 设置缓存有效期一小时        return RedisCacheManager                .builder(RedisCacheWriter.nonLockingRedisCacheWriter(redisConnectionFactory))                .cacheDefaults(redisCacheConfiguration).build();    }    @Bean    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) {        RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;();        // 配置连接工厂        template.setConnectionFactory(factory);        //使用Jackson2JsonRedisSerializer来序列化和反序列化redis的value值（默认使用JDK的序列化方式）        Jackson2JsonRedisSerializer jacksonSeial = new Jackson2JsonRedisSerializer(Object.class);        ObjectMapper om = new ObjectMapper();        // 指定要序列化的域，field,get和set,以及修饰符范围，ANY是都有包括private和public        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);        // 指定序列化输入的类型，类必须是非final修饰的，final修饰的类，比如String,Integer等会跑出异常        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);        jacksonSeial.setObjectMapper(om);        // 值采用json序列化        template.setValueSerializer(jacksonSeial);        //使用StringRedisSerializer来序列化和反序列化redis的key值        template.setKeySerializer(new StringRedisSerializer());        // 设置hash key 和value序列化模式        template.setHashKeySerializer(new StringRedisSerializer());        template.setHashValueSerializer(jacksonSeial);        template.afterPropertiesSet();        return template;    }}</code></pre><p>在业务代码中只要在方法上面加上@Cacheable@CachePut 注解就可以了，spring就会把业务代码的返回结果存到redis中。还可以通过直接注入RedisTemplate来使用。</p><h2 id="整合mongodb"><a href="#整合mongodb" class="headerlink" title="整合mongodb"></a>整合mongodb</h2><p>pom文件</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>application.properteis</p><pre><code class="properties">spring.data.mongodb.uri=mongodb://192.168.0.1:27017/xx_db</code></pre><p>代码案例</p><pre><code class="java">@Servicepublic class MongoServiceImpl implements MongoService&lt;User&gt; {    @Autowired    private MongoTemplate mongoTemplate;    @Override    public String save(User obj) {        mongoTemplate.save(obj);        return &quot;1&quot;;    }}</code></pre><p>mongoTemplate对象同样可以通过依赖注入获取到。</p><h2 id="springboot整合JAX-RS规范"><a href="#springboot整合JAX-RS规范" class="headerlink" title="springboot整合JAX-RS规范"></a>springboot整合JAX-RS规范</h2><p>JAX-RS是JAVAEE6引入的一个新技术。JAX-RS即JavaAPIforRESTfulWebServices，是一个Java编程语言的应用程序接口，支持按照表述性状态转移(REST)架构风格创建Web服务。JAX-RS使用了JavaSE5引入的Java注解来简化Web服务的客户端和服务端的开发和部署。springcloud中就是用了JAX-RS规范，其实就是类似于Servlet规范来接收用户请求的一个规范。</p><p>pom文件</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-jersey&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>代码配置</p><pre><code class="java">@Configurationpublic class JerseyConfig {    @Bean    public ServletRegistrationBean jerseyServlet() {        //设置拦截路径        ServletRegistrationBean registrationBean = new ServletRegistrationBean(new ServletContainer(), &quot;/rest/*&quot;);        //注册controller        registrationBean.addInitParameter(ServletProperties.JAXRS_APPLICATION_CLASS, JerseyResourceConfig.class.getName());        return registrationBean;    }}</code></pre><pre><code class="java">public class JerseyResourceConfig extends ResourceConfig {    public JerseyResourceConfig() {        // 扫描某个类        register(RequestContextFilter.class);        // 扫描包下的所有类        packages(&quot;com.demo.jersey&quot;);    }}</code></pre><p>具体使用</p><pre><code class="java">@Path(&quot;/jersey/&quot;)public class JerseyController {    @Path(&quot;{id}&quot;)    @GET    @Produces(MediaType.APPLICATION_JSON)    public String hello(@PathParam(&quot;id&quot;) Long id) {        return &quot;hello&quot;;    }}</code></pre><h2 id="整合jsp"><a href="#整合jsp" class="headerlink" title="整合jsp"></a>整合jsp</h2><p>pom文件</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt;    &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt;    &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;javax.servlet&lt;/groupId&gt;    &lt;artifactId&gt;jstl&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>application.properties</p><pre><code class="properties">spring.mvc.view.prefix=/WEB-INF/jsp/spring.mvc.view.suffix=.jsp</code></pre><p>创建resources平级目录webapp然后将jsp放入/WEB-INF/jsp/后就可以正常使用。</p><h2 id="整合freemarker"><a href="#整合freemarker" class="headerlink" title="整合freemarker"></a>整合freemarker</h2><p>jar包导入</p><pre><code class="xml">        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre><p>application.properties文件</p><pre><code class="properties">spring.freemarker.allow-request-override=falsespring.freemarker.cache=truespring.freemarker.check-template-location=truespring.freemarker.charset=UTF-8spring.freemarker.content-type=text/htmlspring.freemarker.expose-request-attributes=falsespring.freemarker.expose-session-attributes=falsespring.freemarker.expose-spring-macro-helpers=false</code></pre><p>freemarker默认会加载resources下的.ftl后缀文件</p><h2 id="整合swagger2"><a href="#整合swagger2" class="headerlink" title="整合swagger2"></a>整合swagger2</h2><p>pom文件</p><pre><code class="xml">        &lt;dependency&gt;            &lt;groupId&gt;io.springfox&lt;/groupId&gt;            &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt;            &lt;version&gt;2.9.2&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;io.springfox&lt;/groupId&gt;            &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt;            &lt;version&gt;2.9.2&lt;/version&gt;        &lt;/dependency&gt;</code></pre><p>代码配置</p><pre><code class="java">@Configuration@EnableSwagger2public class SwaggerConfig {    @Bean    public Docket createRestApi() {        return new Docket(DocumentationType.SWAGGER_2)                .pathMapping(&quot;/&quot;)                .select()                .apis(RequestHandlerSelectors.basePackage(&quot;com.demo.controller&quot;))                .paths(PathSelectors.any())                .build().apiInfo(new ApiInfoBuilder()                        .title(&quot;xx公司API文档&quot;)                        .description(&quot;xx公司API文档&quot;)                        .version(&quot;9.0&quot;)                        .contact(new Contact(&quot;test&quot;, &quot;blog.csdn.net&quot;, &quot;aaa@gmail.com&quot;))                        .license(&quot;The Apache License&quot;)                        .licenseUrl(&quot;http://www.baidu.com&quot;)                        .build());    }}</code></pre><p>具体使用</p><pre><code class="java">@Controller@Api(tags = &quot;springboot学习工程相关接口&quot;)public class JackController {    private static final Logger logger = LoggerFactory.getLogger(JackController.class);    @Autowired    AreaService areaService;    @Value(&quot;${application.field:default value jack}&quot;)    private String zhuguangField = &quot;&quot;;    @ApiOperation(&quot;查询地区接口&quot;)    @ApiImplicitParams({            @ApiImplicitParam(name = &quot;param&quot;, value = &quot;地区编码&quot;)    })    @RequestMapping(&quot;/queryArea&quot;)    public @ResponseBody String queryArea(String param) {        List&lt;ConsultConfigArea&gt; areas = areaService.qryArea(new HashMap());        for (ConsultConfigArea area : areas) {            logger.info(area.getAreaCode() + &quot;   &quot; + area.getAreaName() + &quot;   &quot;                    + area.getState());        }        return &quot;OK&quot;;    }}</code></pre><p>文档地址<code>localhost:8080/swagger-ui.html</code></p><h2 id="整合-Actuator监控管理"><a href="#整合-Actuator监控管理" class="headerlink" title="整合 Actuator监控管理"></a>整合 Actuator监控管理</h2><p>Actuator监控是一个用于监控springboot健康状况的工具，可以实时监控的工程的健康和调用情况，通常配合springboot-admin使用。</p><p>pom文件中</p><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>application.properties配置</p><pre><code class="properties">#默认只有info、health接口management.endpoints.web.exposure.include=*</code></pre><p>这个监控不需要使用，是自动统计消息的。可以通过一下请求获取到系统信息：</p><ul><li><p>/health/{component}/{instance}：GET报告程序的健康指标，这些数据由HealthIndicator实现类提供</p></li><li><p>/info：GET获取程序指定发布的信息，这些信息由配置文件中info打头的属性提供</p></li><li><p>/configprops：GET描述配置属性(包含默认值)如何注入到bean</p></li><li><p>/beans：GET描述程序中的bean，及之间的依赖关系</p></li><li><p>/env：GET获取全部环境属性</p></li><li><p>/env/{name}：GET根据名称获取指定的环境属性值</p></li><li><p>/mappings：GET描述全部的URI路径，及和控制器的映射关系</p></li><li><p>/metrics/{requiredMetricName}：GET统计程序的各种度量信息，如内存用量和请求数</p></li><li><p>/httptrace：GET提供基本的http请求跟踪信息，如请求头等</p></li><li><p>/threaddump：GET获取线程活动的快照</p></li><li><p>/conditions：GET提供自动配置报告，记录哪些自动配置通过，哪些没有通过</p></li><li><p>/loggers/{name}：GET查看日志配置信息</p></li><li><p>/auditevents：GET查看系统发布的事件信息</p></li><li><p>/caches/{cache}：GET/DELETE查看系统的缓存管理器，另可根据缓存管理器名称查询;另DELETE操作</p></li><li><p>/scheduledtasks：GET查看系统发布的定时任务信息</p></li><li><p>/features：GET查看Springcloud全家桶组件信息</p></li><li><p>/refresh：POST重启应用程序，慎用</p></li><li><p>/shutdown：POST关闭应用程序，慎用</p></li></ul><h2 id="整合https"><a href="#整合https" class="headerlink" title="整合https"></a>整合https</h2><p>进入到jdk的bin目录中，执行生成证书的指令：</p><pre><code>keytool -genkey -alias spring -keypass 123456 -keyalg RSA -keysize 1024 -validity 365 -keystore E:/springboot.keystore -storepass 123456</code></pre><p>参数介绍：</p><ul><li><p>genkey：表示要创建一个新的密钥。</p></li><li><p>alias：表示keystore的别名。</p></li><li><p>keyalg：表示使用的加密算法是RSA，一种非对称加密算法。</p></li><li><p>keysize：表示密钥的长度。</p></li><li><p>keystore：表示生成的密钥存放位置。validity表示密钥的有效时间，单位为天。</p></li></ul><p>注意：在正式开发过程中，需要申请正式的、能够被浏览器信任的证书。</p><p>然后将生成的证书复制到resource目录，在application.properties配置：</p><pre><code class="properties">server.port=8881server.ssl.key-password=123456server.ssl.key-store=classpath:springboot.keystoreserver.ssl.key-alias=spring</code></pre><p>这时再使用http的访问方式就会出错。</p><h2 id="整合rabbitmq"><a href="#整合rabbitmq" class="headerlink" title="整合rabbitmq"></a>整合rabbitmq</h2><p>pom.xml中</p><pre><code class="properties">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt;</code></pre><p>application.properties</p><pre><code class="properties">spring.rabbitmq.host=192.168.88.139spring.rabbitmq.port=5672spring.rabbitmq.username=adminspring.rabbitmq.password=admin</code></pre><p>配置类</p><pre><code class="java">@Configuration@EnableRabbitpublic class RabbitmqConfig {    /**     * 创建队列Queue     */    @Bean(name = &quot;message&quot;)    public Queue queueMessage(){        return new Queue(&quot;test.message&quot;);    }    /**     * 创建交换器Exchange     */    @Bean    public TopicExchange exchange(){        return new TopicExchange(&quot;exchange.message&quot;);    }    /**     * 创建Exchange跟Queue和routeKey的绑定关系bindings     */    @Bean    Binding bindingExchangeMessage(@Qualifier(&quot;message&quot;)Queue queueMessage,TopicExchange exchange){        return BindingBuilder.bind(queueMessage)                .to(exchange)                .with(&quot;test.message.routeKey&quot;);    }}</code></pre><p>发送消息</p><pre><code class="java">    @Autowired    private AmqpTemplate amqpTemplate;    public void sendMessage(){        amqpTemplate.convertAndSend(&quot;exchange.message&quot;,&quot;test.message.routeKey&quot;,&quot;hello&quot;);    }</code></pre><p>接受消息</p><pre><code class="java">    @RabbitListener(queues = &quot;test.message&quot;)    public void process(String message){        System.out.println(message);    }</code></pre><h2 id="docker化"><a href="#docker化" class="headerlink" title="docker化"></a>docker化</h2><p>pom文件中加入打包插件</p><pre><code class="xml">        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;            &lt;/plugin&gt;            &lt;plugin&gt;                &lt;groupId&gt;com.spotify&lt;/groupId&gt;                &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt;                &lt;configuration&gt;                    &lt;imageName&gt;demo/springboot&lt;/imageName&gt;                    &lt;dockerDirectory&gt;${project.basedir}&lt;/dockerDirectory&gt;                    &lt;resources&gt;                        &lt;resource&gt;                            &lt;targetPath&gt;/&lt;/targetPath&gt;                            &lt;directory&gt;${project.build.directory}&lt;/directory&gt;                            &lt;include&gt;${project.build.finalName}.jar&lt;/include&gt;                        &lt;/resource&gt;                    &lt;/resources&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;</code></pre><p>在项目目录中创建Dockerfile文件</p><pre><code>FROM java:8EXPOSE 8080VOLUME /tmpADD [&quot;*.jar&quot;,&quot;app.jar&quot;]ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;]</code></pre><p>在项目目录下执行指令</p><pre><code>mvn package docker:build</code></pre><p>然后根据镜像来启动容器</p><pre><code>docker run -ti -d -p 8881:8881 --name springboot test/springboot</code></pre><p>查看容器启动日志</p><pre><code>docker logs -f springboot</code></pre>]]></content>
    
    
    <categories>
      
      <category>springboot</category>
      
    </categories>
    
    
    <tags>
      
      <tag>springboot</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>springmvc的请求响应核心</title>
    <link href="/2020/04/21/springmvc%E7%9A%84%E8%AF%B7%E6%B1%82%E5%93%8D%E5%BA%94%E6%A0%B8%E5%BF%83/"/>
    <url>/2020/04/21/springmvc%E7%9A%84%E8%AF%B7%E6%B1%82%E5%93%8D%E5%BA%94%E6%A0%B8%E5%BF%83/</url>
    
    <content type="html"><![CDATA[<h2 id="核心方法的入口"><a href="#核心方法的入口" class="headerlink" title="核心方法的入口"></a>核心方法的入口</h2><p>在servlet规范中，当请求到达servlet时首先会调用service()方法，此方法会根据请求的请求头调用不同的方法。</p><p>DispatcherServlet父类FrameworkServlet中的service()方法最终都会调用到processRequest()方法。通过super.service()方式会调用doPost()或者doGet()方法。本类中的doGet()、doPost()方法也会调用到processRequest()方法。</p><pre><code class="java">   protected void service(HttpServletRequest request, HttpServletResponse response)      throws ServletException, IOException {   HttpMethod httpMethod = HttpMethod.resolve(request.getMethod());   if (httpMethod == HttpMethod.PATCH || httpMethod == null) {      processRequest(request, response);   }   else {      super.service(request, response);   }}    @Override    protected final void doGet(HttpServletRequest request, HttpServletResponse response)            throws ServletException, IOException {        processRequest(request, response);    }    @Override    protected final void doPost(HttpServletRequest request, HttpServletResponse response)            throws ServletException, IOException {        processRequest(request, response);    }</code></pre><p>processRequest()方法</p><p>主要作用为调用doService()方法</p><pre><code class="java">protected final void processRequest(HttpServletRequest request, HttpServletResponse response)      throws ServletException, IOException {   long startTime = System.currentTimeMillis();   Throwable failureCause = null;   LocaleContext previousLocaleContext = LocaleContextHolder.getLocaleContext();   LocaleContext localeContext = buildLocaleContext(request);   RequestAttributes previousAttributes = RequestContextHolder.getRequestAttributes();   ServletRequestAttributes requestAttributes = buildRequestAttributes(request, response, previousAttributes);   WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);   asyncManager.registerCallableInterceptor(FrameworkServlet.class.getName(), new RequestBindingInterceptor());   initContextHolders(request, localeContext, requestAttributes);   try {      doService(request, response);   }   catch (ServletException | IOException ex) {      failureCause = ex;      throw ex;   }   catch (Throwable ex) {      failureCause = ex;      throw new NestedServletException(&quot;Request processing failed&quot;, ex);   }   finally {      resetContextHolders(request, previousLocaleContext, previousAttributes);      if (requestAttributes != null) {         requestAttributes.requestCompleted();      }      logResult(request, response, failureCause, asyncManager);      publishRequestHandledEvent(request, response, startTime, failureCause);   }}</code></pre><p>doService()方法</p><p>该方法在DispatcherServlet中实现，在进行一些属性的设置后回到用到核心方法doDispatch()</p><pre><code class="java">@Overrideprotected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception {   logRequest(request);   // Keep a snapshot of the request attributes in case of an include,   // to be able to restore the original attributes after the include.   Map&lt;String, Object&gt; attributesSnapshot = null;   if (WebUtils.isIncludeRequest(request)) {      attributesSnapshot = new HashMap&lt;&gt;();      Enumeration&lt;?&gt; attrNames = request.getAttributeNames();      while (attrNames.hasMoreElements()) {         String attrName = (String) attrNames.nextElement();         if (this.cleanupAfterInclude || attrName.startsWith(DEFAULT_STRATEGIES_PREFIX)) {            attributesSnapshot.put(attrName, request.getAttribute(attrName));         }      }   }   // Make framework objects available to handlers and view objects.   request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext());   request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver);   request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver);   request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource());   if (this.flashMapManager != null) {      FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response);      if (inputFlashMap != null) {         request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap));      }      request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap());      request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager);   }   try {      //调用到核心流程      doDispatch(request, response);   }   finally {      if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) {         // Restore the original attribute snapshot, in case of an include.         if (attributesSnapshot != null) {            restoreAttributesAfterInclude(request, attributesSnapshot);         }      }   }}</code></pre><h2 id="核心方法doDispatch"><a href="#核心方法doDispatch" class="headerlink" title="核心方法doDispatch()"></a>核心方法doDispatch()</h2><p>springmvc的调用共分七个步骤</p><ol><li>通过getHandler()方法获取到HandlerExecutionChain对象。</li><li>调用getHanlderAdapter()方法根据HandlerExecutionChain获取到HandlerAdapter对象。</li><li>调用applyPreHandle()方法进行前置过滤器校验，如果为false直接返回。</li><li>handle()方法进行具体的业务逻辑调用。</li><li>调用applyPostHandle()方法执行中置过滤器方法。</li><li>调用processDispatchResult()进行视图渲染。</li><li>调用后置拦截器进行最后的收尾工作，一般是资源释放。</li></ol><pre><code class="java">protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception {   HttpServletRequest processedRequest = request;   HandlerExecutionChain mappedHandler = null;   boolean multipartRequestParsed = false;   //异步管理   WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);   try {      ModelAndView mv = null;      Exception dispatchException = null;      try {         //文件上传         processedRequest = checkMultipart(request);         multipartRequestParsed = (processedRequest != request);         //这个方法很重要，重点看         // Determine handler for the current request.         mappedHandler = getHandler(processedRequest);         if (mappedHandler == null) {            noHandlerFound(processedRequest, response);            return;         }         //获取跟HandlerMethod匹配的HandlerAdapter对象         // Determine handler adapter for the current request.         HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());         // Process last-modified header, if supported by the handler.         String method = request.getMethod();         boolean isGet = &quot;GET&quot;.equals(method);         if (isGet || &quot;HEAD&quot;.equals(method)) {            long lastModified = ha.getLastModified(request, mappedHandler.getHandler());            if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) {               return;            }         }         //前置过滤器，如果为false则直接返回         if (!mappedHandler.applyPreHandle(processedRequest, response)) {            return;         }         //调用到Controller具体方法，核心方法调用，重点看看         // Actually invoke the handler.         mv = ha.handle(processedRequest, response, mappedHandler.getHandler());         if (asyncManager.isConcurrentHandlingStarted()) {            return;         }         applyDefaultViewName(processedRequest, mv);        //中置过滤器         mappedHandler.applyPostHandle(processedRequest, response, mv);      }      catch (Exception ex) {         dispatchException = ex;      }      catch (Throwable err) {         // As of 4.3, we&#39;re processing Errors thrown from handler methods as well,         // making them available for @ExceptionHandler methods and other scenarios.         dispatchException = new NestedServletException(&quot;Handler dispatch failed&quot;, err);      }     //视图渲染      processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);   }   catch (Exception ex) {      triggerAfterCompletion(processedRequest, response, mappedHandler, ex);   }   catch (Throwable err) {      triggerAfterCompletion(processedRequest, response, mappedHandler,            new NestedServletException(&quot;Handler processing failed&quot;, err));   }   finally {      if (asyncManager.isConcurrentHandlingStarted()) {         // Instead of postHandle and afterCompletion         if (mappedHandler != null) {            mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response);         }      }      else {         // Clean up any resources used by a multipart request.         if (multipartRequestParsed) {            cleanupMultipart(processedRequest);         }      }   }}</code></pre><h3 id="getHandler-方法"><a href="#getHandler-方法" class="headerlink" title="getHandler()方法"></a>getHandler()方法</h3><p>该方法首先会通过getHandlerInternal()方法获取到HandlerMethod对象，然后调用getHandlerExecutionChain()方法匹配拦截器并将匹配到的拦截器跟HandlerMethod对象封装为HandlerExecutionChain对象并返回。</p><pre><code class="java">public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception {   //根据请求的uri拿到对应的HandlerMethod对象   Object handler = getHandlerInternal(request);   if (handler == null) {      handler = getDefaultHandler();   }   if (handler == null) {      return null;   }   // Bean name or resolved handler?   if (handler instanceof String) {      String handlerName = (String) handler;      handler = obtainApplicationContext().getBean(handlerName);   }   //获取HandlerMethod和过滤器链的包装类   HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request);   if (logger.isTraceEnabled()) {      logger.trace(&quot;Mapped to &quot; + handler);   }   else if (logger.isDebugEnabled() &amp;&amp; !request.getDispatcherType().equals(DispatcherType.ASYNC)) {      logger.debug(&quot;Mapped to &quot; + executionChain.getHandler());   }   //是否是跨域请求,就是查看request请求头中是否有Origin属性   if (CorsUtils.isCorsRequest(request)) {      CorsConfiguration globalConfig = this.corsConfigurationSource.getCorsConfiguration(request);      CorsConfiguration handlerConfig = getCorsConfiguration(handler, request);      CorsConfiguration config = (globalConfig != null ? globalConfig.combine(handlerConfig) : handlerConfig);      executionChain = getCorsHandlerExecutionChain(request, executionChain, config);   }   return executionChain;}</code></pre><h4 id="getHandlerInternal-方法"><a href="#getHandlerInternal-方法" class="headerlink" title="getHandlerInternal()方法"></a>getHandlerInternal()方法</h4><p>getHandlerInternal()方法首先会从请求中获取uri，然后调用lookupHandlerMethod()方法获取到HandlerMethod对象。然后调用createWithResolvedBean()方法创建HandlerMethod中的bean。</p><pre><code class="java">protected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception {   //从request对象中获取uri，/common/query2   String lookupPath = getUrlPathHelper().getLookupPathForRequest(request);   this.mappingRegistry.acquireReadLock();   try {      //根据uri从映射关系中找到对应的HandlerMethod对象      HandlerMethod handlerMethod = lookupHandlerMethod(lookupPath, request);      //把Controller类实例化      return (handlerMethod != null ? handlerMethod.createWithResolvedBean() : null);   }   finally {      this.mappingRegistry.releaseReadLock();   }}</code></pre><h5 id="lookupHandlerMethod-方法"><a href="#lookupHandlerMethod-方法" class="headerlink" title="lookupHandlerMethod()方法"></a>lookupHandlerMethod()方法</h5><p>该方法会根据uri从urlLookup中获取到RequestMappingInfo的List，然后调用addMatchingMappings()方法根据request的信息跟@ReqeustMaping中的信息对HandlerMethod进行匹配，最后将匹配后的RequestMappingInfo对象和匹配到的HandlerMethod对象封装到Match对象中。最后返回HandlerMethod对象。</p><pre><code class="java">protected HandlerMethod lookupHandlerMethod(String lookupPath, HttpServletRequest request) throws Exception {   List&lt;Match&gt; matches = new ArrayList&lt;&gt;();   List&lt;T&gt; directPathMatches = this.mappingRegistry.getMappingsByUrl(lookupPath);   if (directPathMatches != null) {      addMatchingMappings(directPathMatches, matches, request);   }   if (matches.isEmpty()) {      // No choice but to go through all mappings...      addMatchingMappings(this.mappingRegistry.getMappings().keySet(), matches, request);   }   if (!matches.isEmpty()) {      Comparator&lt;Match&gt; comparator = new MatchComparator(getMappingComparator(request));      matches.sort(comparator);      Match bestMatch = matches.get(0);      if (matches.size() &gt; 1) {         if (logger.isTraceEnabled()) {            logger.trace(matches.size() + &quot; matching mappings: &quot; + matches);         }         if (CorsUtils.isPreFlightRequest(request)) {            return PREFLIGHT_AMBIGUOUS_MATCH;         }         Match secondBestMatch = matches.get(1);         //如果两个RequestMappinginfo什么都相同，报错         if (comparator.compare(bestMatch, secondBestMatch) == 0) {            Method m1 = bestMatch.handlerMethod.getMethod();            Method m2 = secondBestMatch.handlerMethod.getMethod();            String uri = request.getRequestURI();            throw new IllegalStateException(                  &quot;Ambiguous handler methods mapped for &#39;&quot; + uri + &quot;&#39;: {&quot; + m1 + &quot;, &quot; + m2 + &quot;}&quot;);         }      }      request.setAttribute(BEST_MATCHING_HANDLER_ATTRIBUTE, bestMatch.handlerMethod);      handleMatch(bestMatch.mapping, lookupPath, request);      return bestMatch.handlerMethod;   }   else {      return handleNoMatch(this.mappingRegistry.getMappings().keySet(), lookupPath, request);   }}</code></pre><h5 id="createWithResolvedBean-方法"><a href="#createWithResolvedBean-方法" class="headerlink" title="createWithResolvedBean()方法"></a>createWithResolvedBean()方法</h5><p>注意：此方法会重新创建一个HandlerMethod对象返回，原有对象不会进行修改。</p><pre><code class="java">public HandlerMethod createWithResolvedBean() {    Object handler = this.bean;    if (this.bean instanceof String) {        Assert.state(this.beanFactory != null, &quot;Cannot resolve bean name without BeanFactory&quot;);        String beanName = (String)this.bean;        handler = this.beanFactory.getBean(beanName);    }    return new HandlerMethod(this, handler);}</code></pre><h4 id="getHandlerExecutionChain-方法"><a href="#getHandlerExecutionChain-方法" class="headerlink" title="getHandlerExecutionChain()方法"></a>getHandlerExecutionChain()方法</h4><p>该方法首先会将HandlerMethod对象包装到HandlerExecutionChain对象中，然后根据uri获取到匹配的拦截器加入到HandlerExecutionChain对象中。</p><pre><code class="java">protected HandlerExecutionChain getHandlerExecutionChain(Object handler, HttpServletRequest request) {   //把HandlerMethod对象包装到HandlerExecutionChain对象中，这个对象中有过滤器对象   HandlerExecutionChain chain = (handler instanceof HandlerExecutionChain ?         (HandlerExecutionChain) handler : new HandlerExecutionChain(handler));   //获取uri   String lookupPath = this.urlPathHelper.getLookupPathForRequest(request);   //是否有过滤器   for (HandlerInterceptor interceptor : this.adaptedInterceptors) {      if (interceptor instanceof MappedInterceptor) {         MappedInterceptor mappedInterceptor = (MappedInterceptor) interceptor;         if (mappedInterceptor.matches(lookupPath, this.pathMatcher)) {            chain.addInterceptor(mappedInterceptor.getInterceptor());         }      }      else {         chain.addInterceptor(interceptor);      }   }   return chain;}</code></pre><p>根据request对象获取handlerMapping对象，然后根据handlerMapping对象获取匹配的HandlerAdapter对象，preHandle过滤器，然后handler方法会调用到controller中的具体方法，然后中置postHandler过滤器，试图渲染，rendler，afterCompletion后置过滤器。</p><h3 id="getHandlerAdapter-方法"><a href="#getHandlerAdapter-方法" class="headerlink" title="getHandlerAdapter()方法"></a>getHandlerAdapter()方法</h3><p>会循环HandlerExecutionChain对象，找到合适的HandlerAdapter对象，这里用到了策略模式。</p><pre><code class="java">protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException {   //根据handlerMethod对象，找到合适的HandlerAdapter对象，这里用到了策略模式   if (this.handlerAdapters != null) {      for (HandlerAdapter adapter : this.handlerAdapters) {         if (adapter.supports(handler)) {            return adapter;         }      }   }   throw new ServletException(&quot;No adapter for handler [&quot; + handler +         &quot;]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler&quot;);}</code></pre><h3 id="applyPreHandle-方法"><a href="#applyPreHandle-方法" class="headerlink" title="applyPreHandle()方法"></a>applyPreHandle()方法</h3><p>该方法会调用HandlerExecutionChain中所有拦截器的preHandle()方法，如果为false直接返回，调用过程中会使用interceptorIndex记录拦截器的下标。常用来进行一些权限校验操作。</p><pre><code>boolean applyPreHandle(HttpServletRequest request, HttpServletResponse response) throws Exception {   HandlerInterceptor[] interceptors = getInterceptors();   if (!ObjectUtils.isEmpty(interceptors)) {      for (int i = 0; i &lt; interceptors.length; i++) {         HandlerInterceptor interceptor = interceptors[i];         if (!interceptor.preHandle(request, response, this.handler)) {            triggerAfterCompletion(request, response, null);            return false;         }         this.interceptorIndex = i;      }   }   return true;}</code></pre><h3 id="handle-方法"><a href="#handle-方法" class="headerlink" title="handle()方法"></a>handle()方法</h3><p>最终会调用到invokeHandlerMethod()方法，这里我们重点关注invokeAndHandle()方法。但要注意，本方法中每次创建一个ModelAndViewContainer对象，这个对象用于对@ModelAttribute注解方法的处理，并把方法返回值传入到ModelAndViewContainer的Map中，用于接来下进行的参数列表解析。最后会调用到getModelAndView()方法获取到ModelAndView对象并返回。</p><pre><code class="java">protected ModelAndView invokeHandlerMethod(HttpServletRequest request,      HttpServletResponse response, HandlerMethod handlerMethod) throws Exception {   ServletWebRequest webRequest = new ServletWebRequest(request, response);   try {      //获取数据绑定工厂      WebDataBinderFactory binderFactory = getDataBinderFactory(handlerMethod);      //Model工厂      ModelFactory modelFactory = getModelFactory(handlerMethod, binderFactory);      //可调用的方法对象      ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod);      if (this.argumentResolvers != null) {         //设置参数解析器         invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers);      }      if (this.returnValueHandlers != null) {         //设置返回值解析器         invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers);      }      //设置参数绑定工厂      invocableMethod.setDataBinderFactory(binderFactory);      //设置参数名称解析类      invocableMethod.setParameterNameDiscoverer(this.parameterNameDiscoverer);      ModelAndViewContainer mavContainer = new ModelAndViewContainer();      mavContainer.addAllAttributes(RequestContextUtils.getInputFlashMap(request));      //调用有@ModelAttribute注解的方法      modelFactory.initModel(webRequest, mavContainer, invocableMethod);      mavContainer.setIgnoreDefaultModelOnRedirect(this.ignoreDefaultModelOnRedirect);      AsyncWebRequest asyncWebRequest = WebAsyncUtils.createAsyncWebRequest(request, response);      asyncWebRequest.setTimeout(this.asyncRequestTimeout);      //异步处理      WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);      asyncManager.setTaskExecutor(this.taskExecutor);      asyncManager.setAsyncWebRequest(asyncWebRequest);      asyncManager.registerCallableInterceptors(this.callableInterceptors);      asyncManager.registerDeferredResultInterceptors(this.deferredResultInterceptors);      if (asyncManager.hasConcurrentResult()) {         Object result = asyncManager.getConcurrentResult();         mavContainer = (ModelAndViewContainer) asyncManager.getConcurrentResultContext()[0];         asyncManager.clearConcurrentResult();         LogFormatUtils.traceDebug(logger, traceOn -&gt; {            String formatted = LogFormatUtils.formatValue(result, !traceOn);            return &quot;Resume with async result [&quot; + formatted + &quot;]&quot;;         });         invocableMethod = invocableMethod.wrapConcurrentResult(result);      }      //Controller方法调用，重点看看      invocableMethod.invokeAndHandle(webRequest, mavContainer);      if (asyncManager.isConcurrentHandlingStarted()) {         return null;      }      return getModelAndView(mavContainer, modelFactory, webRequest);   }   finally {      webRequest.requestCompleted();   }}</code></pre><p>invokeAndHandle()方法</p><p>该方法会调用invokeForRequest()方法获取到返回值，然后使用handleReturnValue()方法对返回值进行处理。处理方式与入参的处理基本相同。如果为视图就会将viewName设置到mavContainer容器中，并将requestHandled属性设置为true。如果返回参数被@ResponseBody注解修饰，就不会设置requestHandled值，requestHandled默认值为false。</p><pre><code class="java">public void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer,      Object... providedArgs) throws Exception {   //具体调用逻辑，重点看   Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs);   setResponseStatus(webRequest);   if (returnValue == null) {      if (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) {         mavContainer.setRequestHandled(true);         return;      }   }   else if (StringUtils.hasText(getResponseStatusReason())) {      mavContainer.setRequestHandled(true);      return;   }   mavContainer.setRequestHandled(false);   Assert.state(this.returnValueHandlers != null, &quot;No return value handlers&quot;);   try {      this.returnValueHandlers.handleReturnValue(            returnValue, getReturnValueType(returnValue), mavContainer, webRequest);   }   catch (Exception ex) {      if (logger.isTraceEnabled()) {         logger.trace(formatErrorForReturnValue(returnValue), ex);      }      throw ex;   }}</code></pre><p>invokeForRequest()方法</p><p>该方法首先通过getMethodArgumentValues()方法获取参数数组，然后使用反射调用并将返回值返回。</p><pre><code class="java">public Object invokeForRequest(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer,      Object... providedArgs) throws Exception {   //获取参数数组,重点看   Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs);   if (logger.isTraceEnabled()) {      logger.trace(&quot;Arguments: &quot; + Arrays.toString(args));   }   return doInvoke(args);}</code></pre><p>getMethodArgumentValues()方法</p><p>该方法会循环处理参数，首先会法判断参数是否有对应的处理类，判断方法为循环调用所有的HandlerMethodArgumentResolver处理类并调用supportsParameter()判断是否支持处理该参数。然后调用resolveArgument()方法获取到对应的处理类，并调用resolveArgument()方法对参数进行处理并包装为MethodParameter对象。</p><pre><code class="java">protected Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer,      Object... providedArgs) throws Exception {   if (ObjectUtils.isEmpty(getMethodParameters())) {      return EMPTY_ARGS;   }   //入参的包装类，里面包装了参数类型，参数名称，参数注解等等信息   MethodParameter[] parameters = getMethodParameters();   Object[] args = new Object[parameters.length];   for (int i = 0; i &lt; parameters.length; i++) {      MethodParameter parameter = parameters[i];      //设置参数名称解析器      parameter.initParameterNameDiscovery(this.parameterNameDiscoverer);      args[i] = findProvidedArgument(parameter, providedArgs);      if (args[i] != null) {         continue;      }      //典型的策略模式，根据parameter能否找到对应参数的处理类，能找到就返回true      if (!this.resolvers.supportsParameter(parameter)) {         throw new IllegalStateException(formatArgumentError(parameter, &quot;No suitable resolver&quot;));      }      try {         //具体参数值解析过程,重点看看         args[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory);      }      catch (Exception ex) {         // Leave stack trace for later, exception may actually be resolved and handled..         if (logger.isDebugEnabled()) {            String error = ex.getMessage();            if (error != null &amp;&amp; !error.contains(parameter.getExecutable().toGenericString())) {               logger.debug(formatArgumentError(parameter, error));            }         }         throw ex;      }   }   return args;}</code></pre><p>getModelAndView()方法</p><p>该方法首先会判断requestHandled属性，如果属性为false就直接返回。</p><pre><code class="java">private ModelAndView getModelAndView(ModelAndViewContainer mavContainer,      ModelFactory modelFactory, NativeWebRequest webRequest) throws Exception {   modelFactory.updateModel(webRequest, mavContainer);   if (mavContainer.isRequestHandled()) {      return null;   }   ModelMap model = mavContainer.getModel();   ModelAndView mav = new ModelAndView(mavContainer.getViewName(), model, mavContainer.getStatus());   if (!mavContainer.isViewReference()) {      mav.setView((View) mavContainer.getView());   }   if (model instanceof RedirectAttributes) {      Map&lt;String, ?&gt; flashAttributes = ((RedirectAttributes) model).getFlashAttributes();      HttpServletRequest request = webRequest.getNativeRequest(HttpServletRequest.class);      if (request != null) {         RequestContextUtils.getOutputFlashMap(request).putAll(flashAttributes);      }   }   return mav;}</code></pre><h3 id="applyPostHandle-方法"><a href="#applyPostHandle-方法" class="headerlink" title="applyPostHandle()方法"></a>applyPostHandle()方法</h3><p>与前置过滤器的调用方法基本相同，不同的是他不需要进行判断，且与前置过滤器不同的是，它的遍历时倒序遍历。注意：中置过滤器中有ModelAndView入参可以对其进行处理。</p><pre><code class="java">void applyPostHandle(HttpServletRequest request, HttpServletResponse response, @Nullable ModelAndView mv)      throws Exception {   HandlerInterceptor[] interceptors = getInterceptors();   if (!ObjectUtils.isEmpty(interceptors)) {      for (int i = interceptors.length - 1; i &gt;= 0; i--) {         HandlerInterceptor interceptor = interceptors[i];         interceptor.postHandle(request, response, this.handler, mv);      }   }}</code></pre><h3 id="processDispatchResult-方法"><a href="#processDispatchResult-方法" class="headerlink" title="processDispatchResult()方法"></a>processDispatchResult()方法</h3><p>该方法最终会落入renderMergedOutputModel()方法中，这里只着重分析这个方法。</p><p>注意，如果ModelAndView为空就会以流的方式响应json数据，不会进入这个方法。首先会调用exposeModelAsRequestAttributes()方法，将model中的对象设置到request中。然后获取到跳转地址，将地址转为RequestDispatcher对象，最后调用RequestDispatcher.forward()进行转发。</p><pre><code class="java">    protected void renderMergedOutputModel(            Map&lt;String, Object&gt; model, HttpServletRequest request, HttpServletResponse response) throws Exception {    // 把响应数据设置到reqeust对象中        // Expose the model object as request attributes.        exposeModelAsRequestAttributes(model, request);        // Expose helpers as request attributes, if any.        exposeHelpers(request);    //获取到跳转地址        // Determine the path for the request dispatcher.        String dispatcherPath = prepareForRendering(request, response);        // Obtain a RequestDispatcher for the target resource (typically a JSP).        RequestDispatcher rd = getRequestDispatcher(request, dispatcherPath);        if (rd == null) {            throw new ServletException(&quot;Could not get RequestDispatcher for [&quot; + getUrl() +                    &quot;]: Check that the corresponding file exists within your web application archive!&quot;);        }        // If already included or response already committed, perform include, else forward.        if (useInclude(request, response)) {            response.setContentType(getContentType());            if (logger.isDebugEnabled()) {                logger.debug(&quot;Including [&quot; + getUrl() + &quot;]&quot;);            }            rd.include(request, response);        }        else {            // Note: The forwarded resource is supposed to determine the content type itself.            if (logger.isDebugEnabled()) {                logger.debug(&quot;Forwarding to [&quot; + getUrl() + &quot;]&quot;);            }            rd.forward(request, response);        }    }</code></pre>]]></content>
    
    
    <categories>
      
      <category>Spring源码解析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码解析</tag>
      
      <tag>spring</tag>
      
      <tag>springmvc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>springmvc的初始化</title>
    <link href="/2020/04/20/springmvc%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96/"/>
    <url>/2020/04/20/springmvc%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="springmvc的初始化入口"><a href="#springmvc的初始化入口" class="headerlink" title="springmvc的初始化入口"></a>springmvc的初始化入口</h2><p>springmvc是基于servlet规范来完成的一个请求响应模块，也是spring中比较大的一个模块，现在已经支持零配置的方式整合，不再需要web.xml和springmvc.xml文件。</p><h3 id="web-xml的替换"><a href="#web-xml的替换" class="headerlink" title="web.xml的替换"></a>web.xml的替换</h3><p>servlet规范中规定当servlet容器启动的时会加载META-INF/services/javax.servlet.ServletContainerInitializer文件中的类。这个类必须实现javax.servlet.ServletContainerInitializer接口，servlet容器在启动后会收集实现@HandlesTypes注解中的接口的实现类，然后传递给onStartup()方法。springmvc就是通过这个规范完成容器初始化。</p><pre><code class="xml">org.springframework.web.SpringServletContainerInitializer</code></pre><p>spring中定义一个了WebApplicationInitializer接口，然后在onStartup()方法中通过反射调用onStart()方法。这里我们着重分析下这个接口的实现类AbstractContextLoaderInitializer跟AbstractDispatcherServletInitializer类。</p><pre><code class="java">@HandlesTypes(WebApplicationInitializer.class)public class SpringServletContainerInitializer implements ServletContainerInitializer {    @Override    public void onStartup(@Nullable Set&lt;Class&lt;?&gt;&gt; webAppInitializerClasses, ServletContext servletContext)            throws ServletException {        List&lt;WebApplicationInitializer&gt; initializers = new LinkedList&lt;&gt;();        if (webAppInitializerClasses != null) {            for (Class&lt;?&gt; waiClass : webAppInitializerClasses) {                // Be defensive: Some servlet containers provide us with invalid classes,                // no matter what @HandlesTypes says...                if (!waiClass.isInterface() &amp;&amp; !Modifier.isAbstract(waiClass.getModifiers()) &amp;&amp;                        WebApplicationInitializer.class.isAssignableFrom(waiClass)) {                    try {                        initializers.add((WebApplicationInitializer)                                ReflectionUtils.accessibleConstructor(waiClass).newInstance());                    }                    catch (Throwable ex) {                        throw new ServletException(&quot;Failed to instantiate WebApplicationInitializer class&quot;, ex);                    }                }            }        }        if (initializers.isEmpty()) {            servletContext.log(&quot;No Spring WebApplicationInitializer types detected on classpath&quot;);            return;        }        servletContext.log(initializers.size() + &quot; Spring WebApplicationInitializers detected on classpath&quot;);        AnnotationAwareOrderComparator.sort(initializers);        for (WebApplicationInitializer initializer : initializers) {            initializer.onStartup(servletContext);        }    }}</code></pre><h3 id="AbstractContextLoaderInitializer类"><a href="#AbstractContextLoaderInitializer类" class="headerlink" title="AbstractContextLoaderInitializer类"></a>AbstractContextLoaderInitializer类</h3><p>AbstractContextLoaderInitializer中的onStartup()方法会调用createRootApplicationContext()方法创建spring上下文，并注册ContextLoaderListener。spring上下文的refresh()方法将由ContextLoaderListener来调用</p><pre><code class="java">public abstract class AbstractContextLoaderInitializer implements WebApplicationInitializer {    /** Logger available to subclasses. */    protected final Log logger = LogFactory.getLog(getClass());    @Override    public void onStartup(ServletContext servletContext) throws ServletException {        registerContextLoaderListener(servletContext);    }    protected void registerContextLoaderListener(ServletContext servletContext) {        //创建spring上下文，注册了SpringContainer        WebApplicationContext rootAppContext = createRootApplicationContext();        if (rootAppContext != null) {            //创建监听器            /*                形如这种配置            * &lt;listener&gt;                  &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;                &lt;!--&lt;listener-class&gt;org.springframework.web.context.request.RequestContextListener&lt;/listener-class&gt;--&gt;              &lt;/listener&gt;            *            * */            ContextLoaderListener listener = new ContextLoaderListener(rootAppContext);            listener.setContextInitializers(getRootApplicationContextInitializers());            servletContext.addListener(listener);        }        else {            logger.debug(&quot;No ContextLoaderListener registered, as &quot; +                    &quot;createRootApplicationContext() did not return an application context&quot;);        }    }    @Nullable    protected abstract WebApplicationContext createRootApplicationContext();    @Nullable    protected ApplicationContextInitializer&lt;?&gt;[] getRootApplicationContextInitializers() {        return null;    }}</code></pre><p>AbstractAnnotationConfigDispatcherServletInitializer中的createRootApplicationContext()方法会调用getRootConfigClasses()方法获取一个configClasses对象，然后创建一个AnnotationConfigWebApplicationContext上下文对象，并向这个上下文对象中注册configClasses对象。这个过程类似于与注解启动spring容器过程相同。getRootConfigClasses()方法会由开发者自己实现，主要作用是将有@CompoentScan注解的类传递给spring用来创建上下文。要注意的是这个上下文对象是spring的上下文对象，不是sprngmvc的上下文，所以应该排除controller对象。</p><pre><code class="java">public abstract class AbstractAnnotationConfigDispatcherServletInitializer        extends AbstractDispatcherServletInitializer {    @Override    @Nullable    protected WebApplicationContext createRootApplicationContext() {        Class&lt;?&gt;[] configClasses = getRootConfigClasses();        if (!ObjectUtils.isEmpty(configClasses)) {            AnnotationConfigWebApplicationContext context = new AnnotationConfigWebApplicationContext();            context.register(configClasses);            return context;        }        else {            return null;        }    }    @Override    protected WebApplicationContext createServletApplicationContext() {        AnnotationConfigWebApplicationContext context = new AnnotationConfigWebApplicationContext();        Class&lt;?&gt;[] configClasses = getServletConfigClasses();        if (!ObjectUtils.isEmpty(configClasses)) {            context.register(configClasses);        }        return context;    }    @Nullable    protected abstract Class&lt;?&gt;[] getRootConfigClasses();    @Nullable    protected abstract Class&lt;?&gt;[] getServletConfigClasses();}</code></pre><p>ContextLoaderListener的contextInitialized()方法会在servlet容器启动时调用。contextInitialized()将调用initWebApplicationContext()调用spring上下文加载的核心方法refresh()。</p><pre><code class="java">public class ContextLoaderListener extends ContextLoader implements ServletContextListener {    public ContextLoaderListener() {    }    public ContextLoaderListener(WebApplicationContext context) {        super(context);    }    @Override    public void contextInitialized(ServletContextEvent event) {        initWebApplicationContext(event.getServletContext());    }    @Override    public void contextDestroyed(ServletContextEvent event) {        closeWebApplicationContext(event.getServletContext());        ContextCleanupListener.cleanupAttributes(event.getServletContext());    }}</code></pre><h3 id="AbstractDispatcherServletInitializer类"><a href="#AbstractDispatcherServletInitializer类" class="headerlink" title="AbstractDispatcherServletInitializer类"></a>AbstractDispatcherServletInitializer类</h3><p>AbstractDispatcherServletInitializer的onStartup()方法中，会创建sprngmvc的上下文对象跟DispatcherServlet对象。Serlvet容器在启动时会调用DispatcherServlet的init()方法，该方法继承自父类HttpServletBean，init()方法最终会调用到springmvc上下文的refresh()方法。springmvc上下文对象初始化时会先获取spring的上下文对象，然后将其设置为父容器，之后getBean()操作中会优先从父容器中获取bean。</p><pre><code class="java">public abstract class AbstractDispatcherServletInitializer extends AbstractContextLoaderInitializer {   public static final String DEFAULT_SERVLET_NAME = &quot;dispatcher&quot;;   @Override   public void onStartup(ServletContext servletContext) throws ServletException {      super.onStartup(servletContext);      //注册DispatcherServlet      registerDispatcherServlet(servletContext);   }   protected void registerDispatcherServlet(ServletContext servletContext) {      String servletName = getServletName();      Assert.hasLength(servletName, &quot;getServletName() must not return null or empty&quot;);      //创建springmvc的上下文，注册了MvcContainer类      WebApplicationContext servletAppContext = createServletApplicationContext();      Assert.notNull(servletAppContext, &quot;createServletApplicationContext() must not return null&quot;);      //创建DispatcherServlet      FrameworkServlet dispatcherServlet = createDispatcherServlet(servletAppContext);      Assert.notNull(dispatcherServlet, &quot;createDispatcherServlet(WebApplicationContext) must not return null&quot;);      dispatcherServlet.setContextInitializers(getServletApplicationContextInitializers());      ServletRegistration.Dynamic registration = servletContext.addServlet(servletName, dispatcherServlet);      if (registration == null) {         throw new IllegalStateException(&quot;Failed to register servlet with name &#39;&quot; + servletName + &quot;&#39;. &quot; +               &quot;Check if there is another servlet registered under the same name.&quot;);      }      /*      * 如果该元素的值为负数或者没有设置，则容器会当Servlet被请求时再加载。         如果值为正整数或者0时，表示容器在应用启动时就加载并初始化这个servlet，         值越小，servlet的优先级越高，就越先被加载      * */      registration.setLoadOnStartup(1);      registration.addMapping(getServletMappings());      registration.setAsyncSupported(isAsyncSupported());      Filter[] filters = getServletFilters();      if (!ObjectUtils.isEmpty(filters)) {         for (Filter filter : filters) {            registerServletFilter(servletContext, filter);         }      }      customizeRegistration(registration);   }   protected String getServletName() {      return DEFAULT_SERVLET_NAME;   }   protected abstract WebApplicationContext createServletApplicationContext();   protected FrameworkServlet createDispatcherServlet(WebApplicationContext servletAppContext) {      return new DispatcherServlet(servletAppContext);   }   @Nullable   protected ApplicationContextInitializer&lt;?&gt;[] getServletApplicationContextInitializers() {      return null;   }   protected abstract String[] getServletMappings();   @Nullable   protected Filter[] getServletFilters() {      return null;   }   protected FilterRegistration.Dynamic registerServletFilter(ServletContext servletContext, Filter filter) {      String filterName = Conventions.getVariableName(filter);      Dynamic registration = servletContext.addFilter(filterName, filter);      if (registration == null) {         int counter = 0;         while (registration == null) {            if (counter == 100) {               throw new IllegalStateException(&quot;Failed to register filter with name &#39;&quot; + filterName + &quot;&#39;. &quot; +                     &quot;Check if there is another filter registered under the same name.&quot;);            }            registration = servletContext.addFilter(filterName + &quot;#&quot; + counter, filter);            counter++;         }      }      registration.setAsyncSupported(isAsyncSupported());      registration.addMappingForServletNames(getDispatcherTypes(), false, getServletName());      return registration;   }   private EnumSet&lt;DispatcherType&gt; getDispatcherTypes() {      return (isAsyncSupported() ?            EnumSet.of(DispatcherType.REQUEST, DispatcherType.FORWARD, DispatcherType.INCLUDE, DispatcherType.ASYNC) :            EnumSet.of(DispatcherType.REQUEST, DispatcherType.FORWARD, DispatcherType.INCLUDE));   }   protected boolean isAsyncSupported() {      return true;   }   protected void customizeRegistration(ServletRegistration.Dynamic registration) {   }}</code></pre><h3 id="springmvc-xml的替换"><a href="#springmvc-xml的替换" class="headerlink" title="springmvc.xml的替换"></a>springmvc.xml的替换</h3><pre><code class="xml">&lt;mvc:annotation-driven&gt;    &lt;mvc:message-converters register-defaults=&quot;true&quot;&gt;        &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt;            &lt;property name=&quot;supportedMediaTypes&quot; value = &quot;text/plain;charset=UTF-8&quot; /&gt;        &lt;/bean&gt;    &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt;</code></pre><p>这个标签总过做了三件事情：</p><ol><li>创建HandlerMapping对象</li><li>创建HandlerAdapter对象</li><li>创建消息转换器加入到HandlerAdapter中</li></ol><p>@EnableWebMvc标签可以完成springmvc.xml中的所有工作。</p><p>该注解中会引入DelegatingWebMvcConfiguration类，该类会通过@Autowired获取到所有的WebMvcConfigurer类。该类的父类WebMvcConfigurationSupport类就是比较核心的类，会替代xml进行完成所有组件的注册。该类十分庞大，主要是通过@Bean的方式将组件注册到上下文对象中。此处我们只分析RequestMappingHandlerMapping的注册，其他组件的注册的流程也基本相同。</p><p>该类的requestMappingHandleMapping()方法进行RequestMappingHandlerMapping的注册，该方法会通过调用getInterceptors()方法获取拦截器，然后设置进去，之后设置的属性还包括跨域等属性，这里着重分析getInterceptors()方法，其他属性的获取方式也基本相同。</p><pre><code class="java">@Beanpublic RequestMappingHandlerMapping requestMappingHandlerMapping() {   RequestMappingHandlerMapping mapping = createRequestMappingHandlerMapping();   mapping.setOrder(0);   mapping.setInterceptors(getInterceptors());   mapping.setContentNegotiationManager(mvcContentNegotiationManager());   mapping.setCorsConfigurations(getCorsConfigurations());   PathMatchConfigurer configurer = getPathMatchConfigurer();   Boolean useSuffixPatternMatch = configurer.isUseSuffixPatternMatch();   if (useSuffixPatternMatch != null) {      mapping.setUseSuffixPatternMatch(useSuffixPatternMatch);   }   Boolean useRegisteredSuffixPatternMatch = configurer.isUseRegisteredSuffixPatternMatch();   if (useRegisteredSuffixPatternMatch != null) {      mapping.setUseRegisteredSuffixPatternMatch(useRegisteredSuffixPatternMatch);   }   Boolean useTrailingSlashMatch = configurer.isUseTrailingSlashMatch();   if (useTrailingSlashMatch != null) {      mapping.setUseTrailingSlashMatch(useTrailingSlashMatch);   }   UrlPathHelper pathHelper = configurer.getUrlPathHelper();   if (pathHelper != null) {      mapping.setUrlPathHelper(pathHelper);   }   PathMatcher pathMatcher = configurer.getPathMatcher();   if (pathMatcher != null) {      mapping.setPathMatcher(pathMatcher);   }   Map&lt;String, Predicate&lt;Class&lt;?&gt;&gt;&gt; pathPrefixes = configurer.getPathPrefixes();   if (pathPrefixes != null) {      mapping.setPathPrefixes(pathPrefixes);   }   return mapping;}</code></pre><p>getInterceptors()方法</p><p>该方法会调用子类DelegatingWebMvcConfiguration的addInterceptors()方法，该类中会通过依赖注入的方式获取到所有实现WebMvcConfigurer接口的类，然后调用其addInterceptors()方法把我们自己定义的Interceptor传递进去。</p><pre><code class="java">@Autowired(required = false)public void setConfigurers(List&lt;WebMvcConfigurer&gt; configurers) {   if (!CollectionUtils.isEmpty(configurers)) {      this.configurers.addWebMvcConfigurers(configurers);   }}protected void addInterceptors(InterceptorRegistry registry) {   this.configurers.addInterceptors(registry);}</code></pre><h2 id="DispatcherServlet中的组件初始化"><a href="#DispatcherServlet中的组件初始化" class="headerlink" title="DispatcherServlet中的组件初始化"></a>DispatcherServlet中的组件初始化</h2><p>DispatcherServlet的父类FrameworkServlet中有一个私有类ContextRefreshListener，这个私有类继承了spring的监听器ApplicationListener&lt;ContextRefreshedEvent&gt;，spring完成初始化会发布一个ContextRefreshedEvent类型的事件来触发这个监听器，监听器监听到这个事件后会在线程中调用私有类的onApplicationEvent()方法。</p><h3 id="onApplicationEvent-方法"><a href="#onApplicationEvent-方法" class="headerlink" title="onApplicationEvent()方法"></a>onApplicationEvent()方法</h3><p>onApplicationEvent()方法会再调用FrameworkServlet类中的onApplicationEvent()方法，在这个方法中会调用onRefresh()方法。</p><pre><code class="java">private class ContextRefreshListener implements ApplicationListener&lt;ContextRefreshedEvent&gt; {   @Override   public void onApplicationEvent(ContextRefreshedEvent event) {      FrameworkServlet.this.onApplicationEvent(event);   }}</code></pre><p>onRefresh()方法</p><p>该方法会调用到子类DispatcherServlet中的方法，最终调用到initStrategies()方法。完成DispatcherServlet组件的设置。</p><pre><code class="java">protected void initStrategies(ApplicationContext context) {   initMultipartResolver(context);   initLocaleResolver(context);   initThemeResolver(context);   initHandlerMappings(context);   initHandlerAdapters(context);   initHandlerExceptionResolvers(context);   initRequestToViewNameTranslator(context);   initViewResolvers(context);   initFlashMapManager(context);}</code></pre><p>initHandlerMappings()方法</p><p>该方法会从上下文中获取到HandlerMapping对象，然后进行排序。如果没有配置HandlerMapping对象，就会加载默认的HandlerMappinig对象。最后设置到handlerMappings属性中。</p><pre><code class="java">private void initHandlerMappings(ApplicationContext context) {   this.handlerMappings = null;   if (this.detectAllHandlerMappings) {      // Find all HandlerMappings in the ApplicationContext, including ancestor contexts.      Map&lt;String, HandlerMapping&gt; matchingBeans =            BeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerMapping.class, true, false);      if (!matchingBeans.isEmpty()) {         this.handlerMappings = new ArrayList&lt;&gt;(matchingBeans.values());         // We keep HandlerMappings in sorted order.         AnnotationAwareOrderComparator.sort(this.handlerMappings);      }   }   else {      try {         HandlerMapping hm = context.getBean(HANDLER_MAPPING_BEAN_NAME, HandlerMapping.class);         this.handlerMappings = Collections.singletonList(hm);      }      catch (NoSuchBeanDefinitionException ex) {         // Ignore, we&#39;ll add a default HandlerMapping later.      }   }   // Ensure we have at least one HandlerMapping, by registering   // a default HandlerMapping if no other mappings are found.   if (this.handlerMappings == null) {      this.handlerMappings = getDefaultStrategies(context, HandlerMapping.class);      if (logger.isTraceEnabled()) {         logger.trace(&quot;No HandlerMappings declared for servlet &#39;&quot; + getServletName() +               &quot;&#39;: using default strategies from DispatcherServlet.properties&quot;);      }   }}</code></pre><h2 id="建立路径与方法的映射关系"><a href="#建立路径与方法的映射关系" class="headerlink" title="建立路径与方法的映射关系"></a>建立路径与方法的映射关系</h2><p>springmvc会在初始化时完成路径与方法的映射，具体是通过AbstractHandlerMethodMapping类的initHandlerMethods()方法来完成。AbstractHandlerMethodMapping类实现了InitializingBean接口，spring在Bean实例化并完成IOC、DI之后调用这个接口的afterPropertiesSet()方法。AbstractHandlerMethodMapping类的afterPropertiesSet()方法中调用了initHandlerMethods()方法。initHandlerMethods()方法会调用processCandidateBean()方法创建url跟method的映射关系。</p><pre><code class="java">protected void initHandlerMethods() {   for (String beanName : getCandidateBeanNames()) {      if (!beanName.startsWith(SCOPED_TARGET_NAME_PREFIX)) {         processCandidateBean(beanName);      }   }   handlerMethodsInitialized(getHandlerMethods());}</code></pre><p>processCandidateBean()</p><p>该方法会判断类上面是否有@Controller、@RequestMapping注解，如果有会调用detectHandlerMethods()方法建立url跟method的映射关系。</p><pre><code class="java">protected void processCandidateBean(String beanName) {   Class&lt;?&gt; beanType = null;   try {      beanType = obtainApplicationContext().getType(beanName);   }   catch (Throwable ex) {      // An unresolvable bean type, probably from a lazy bean - let&#39;s ignore it.      if (logger.isTraceEnabled()) {         logger.trace(&quot;Could not resolve type for bean &#39;&quot; + beanName + &quot;&#39;&quot;, ex);      }   }   //如果类上面有@Controller注解或者@RequestMapping注解   if (beanType != null &amp;&amp; isHandler(beanType)) {      //建立uri和method的映射关系      detectHandlerMethods(beanName);   }}</code></pre><p>detectHandlerMethods()</p><p>该方法首先会获取方法对象和方法上的@RequestMapping注解属性，然后向selectMethods()方法中传入getMappingForMethod()方法用来封装映射关系，Map&lt;Method, T&gt;中的T就是属性的封装对象。最后调用registerHandlerMethod()方法建立映射关系。</p><pre><code class="java">protected void detectHandlerMethods(Object handler) {   Class&lt;?&gt; handlerType = (handler instanceof String ?         obtainApplicationContext().getType((String) handler) : handler.getClass());   if (handlerType != null) {      Class&lt;?&gt; userType = ClassUtils.getUserClass(handlerType);      //获取方法对象和方法上面的@RequestMapping注解属性封装对象的映射关系      Map&lt;Method, T&gt; methods = MethodIntrospector.selectMethods(userType,            (MethodIntrospector.MetadataLookup&lt;T&gt;) method -&gt; {               try {                  return getMappingForMethod(method, userType);               }               catch (Throwable ex) {                  throw new IllegalStateException(&quot;Invalid mapping on handler class [&quot; +                        userType.getName() + &quot;]: &quot; + method, ex);               }            });      if (logger.isTraceEnabled()) {         logger.trace(formatMappings(userType, methods));      }      methods.forEach((method, mapping) -&gt; {         Method invocableMethod = AopUtils.selectInvocableMethod(method, userType);         //建立uri和方法的各种映射关系，反正一条，根据uri要能够找到method对象         registerHandlerMethod(handler, invocableMethod, mapping);      });   }}</code></pre><p>selectMethods()方法</p><p>首先会获取类上的所有method，然后判断method上面是否有@RequestMapping注解，如果有调用外层传入的getMappingForMethod()方法封装成对象返回。</p><pre><code class="java">public static &lt;T&gt; Map&lt;Method, T&gt; selectMethods(Class&lt;?&gt; targetType, final MetadataLookup&lt;T&gt; metadataLookup) {   final Map&lt;Method, T&gt; methodMap = new LinkedHashMap&lt;&gt;();   Set&lt;Class&lt;?&gt;&gt; handlerTypes = new LinkedHashSet&lt;&gt;();   Class&lt;?&gt; specificHandlerType = null;   if (!Proxy.isProxyClass(targetType)) {      specificHandlerType = ClassUtils.getUserClass(targetType);      handlerTypes.add(specificHandlerType);   }   handlerTypes.addAll(ClassUtils.getAllInterfacesForClassAsSet(targetType));   for (Class&lt;?&gt; currentHandlerType : handlerTypes) {      final Class&lt;?&gt; targetClass = (specificHandlerType != null ? specificHandlerType : currentHandlerType);      //循环currentHandlerType类的所有方法      ReflectionUtils.doWithMethods(currentHandlerType, method -&gt; {         Method specificMethod = ClassUtils.getMostSpecificMethod(method, targetClass);         //判断方法上面是否有@RequestMapping注解，如果有封装对象返回         T result = metadataLookup.inspect(specificMethod);         if (result != null) {            Method bridgedMethod = BridgeMethodResolver.findBridgedMethod(specificMethod);            if (bridgedMethod == specificMethod || metadataLookup.inspect(bridgedMethod) == null) {               //建立方法对象和注解封装对象的映射关系               methodMap.put(specificMethod, result);            }         }      }, ReflectionUtils.USER_DECLARED_METHODS);   }   return methodMap;}</code></pre><p>getMappingForMethod()方法</p><p>首先会调用createRequestMappingInfo()方法封装注解信息，然后将类上的@RequestMapping注解也封装成对象，最后将两个对象结合后返回。</p><pre><code class="java">protected RequestMappingInfo getMappingForMethod(Method method, Class&lt;?&gt; handlerType) {   //寻找有@RequestMapping注解的方法，然后注解里面的内容封装成对象   RequestMappingInfo info = createRequestMappingInfo(method);   if (info != null) {      //类上面的@RequestMapping注解也封装成对象      RequestMappingInfo typeInfo = createRequestMappingInfo(handlerType);      if (typeInfo != null) {         //把方法上面的注解属性结合到类上面的RequestMappingInfo对象中         info = typeInfo.combine(info);      }      String prefix = getPathPrefix(handlerType);      if (prefix != null) {         info = RequestMappingInfo.paths(prefix).build().combine(info);      }   }   return info;}</code></pre><p>registerHandlerMethod()方法</p><p>register()方法是registerHandlerMethod()的主要方法。该方法首先会调用createHandlerMethod()方法创建HandlerMethod对象，该对象中封装了类跟方法信息，如果此时类还没有被实例化，就会将beanName跟beanFactory一起封装进去，如果类已经实例化就只会封装实例化之后的bean。然后将uri跟HandlerMethod放到mappingLookup中，url跟RequestMappingInfo信息放入urlLookup中。</p><pre><code class="java">public void register(T mapping, Object handler, Method method) {   this.readWriteLock.writeLock().lock();   try {      //创建HandlerMethod对象，其实      HandlerMethod handlerMethod = createHandlerMethod(handler, method);      //检验是否唯一      assertUniqueMethodMapping(handlerMethod, mapping);      //建立RequestMappingInfo对象和handlerMethod的映射关系      this.mappingLookup.put(mapping, handlerMethod);      List&lt;String&gt; directUrls = getDirectUrls(mapping);      for (String url : directUrls) {         //建立url和RequestMappingInfo映射关系         this.urlLookup.add(url, mapping);      }      String name = null;      if (getNamingStrategy() != null) {         name = getNamingStrategy().getName(handlerMethod, mapping);         addMappingName(name, handlerMethod);      }      //判断method上是否有CrossOrigin注解，把注解里面的属性封装成CorsConfiguration，这个是做跨域访问控制的      CorsConfiguration corsConfig = initCorsConfiguration(handler, method, mapping);      if (corsConfig != null) {         //建立映射关系         this.corsLookup.put(handlerMethod, corsConfig);      }      this.registry.put(mapping, new MappingRegistration&lt;&gt;(mapping, handlerMethod, directUrls, name));   }   finally {      this.readWriteLock.writeLock().unlock();   }}</code></pre>]]></content>
    
    
    <categories>
      
      <category>Spring源码解析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码解析</tag>
      
      <tag>spring</tag>
      
      <tag>springmvc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>spring的缓存切面和异步切面</title>
    <link href="/2020/04/20/spring%E7%9A%84%E7%BC%93%E5%AD%98%E5%88%87%E9%9D%A2%E5%92%8C%E5%BC%82%E6%AD%A5%E5%88%87%E9%9D%A2/"/>
    <url>/2020/04/20/spring%E7%9A%84%E7%BC%93%E5%AD%98%E5%88%87%E9%9D%A2%E5%92%8C%E5%BC%82%E6%AD%A5%E5%88%87%E9%9D%A2/</url>
    
    <content type="html"><![CDATA[<h2 id="缓存切面"><a href="#缓存切面" class="headerlink" title="缓存切面"></a>缓存切面</h2><p>开启缓存注解@EnableCaching</p><p>缓存切面的使用可以通过以下注解：</p><p>@Cacheable：先从缓存中取，如果有则直接返回，如果没有则调用被代理方法拿到返回值然后存到缓存中。<br>@CachePut：只要调用到被代理方法后把返回值存到缓存中。</p><p>@CacheEvict：删除key对应的注解。</p><p>在使用注解是需要通过cacheNames属性指定使用哪一个缓存，因为缓存管理器中可能会有多个缓存要使用的缓存对象。</p><h3 id="切面的注册"><a href="#切面的注册" class="headerlink" title="切面的注册"></a>切面的注册</h3><p>同样的，@EnableCaching注解也会引入CachingConfigurationSelector类</p><pre><code class="java">@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(CachingConfigurationSelector.class)public @interface EnableCaching {</code></pre><p>CachingConfigurationSelector类</p><p>这个类也会引入ProxyCachingConfiguration类来注册切面。</p><pre><code class="java">public class CachingConfigurationSelector extends AdviceModeImportSelector&lt;EnableCaching&gt; {   private static final String PROXY_JCACHE_CONFIGURATION_CLASS =         &quot;org.springframework.cache.jcache.config.ProxyJCacheConfiguration&quot;;   private static final String CACHE_ASPECT_CONFIGURATION_CLASS_NAME =         &quot;org.springframework.cache.aspectj.AspectJCachingConfiguration&quot;;   private static final String JCACHE_ASPECT_CONFIGURATION_CLASS_NAME =         &quot;org.springframework.cache.aspectj.AspectJJCacheConfiguration&quot;;   private static final boolean jsr107Present;   private static final boolean jcacheImplPresent;   static {      ClassLoader classLoader = CachingConfigurationSelector.class.getClassLoader();      jsr107Present = ClassUtils.isPresent(&quot;javax.cache.Cache&quot;, classLoader);      jcacheImplPresent = ClassUtils.isPresent(PROXY_JCACHE_CONFIGURATION_CLASS, classLoader);   }   /**    * Returns {@link ProxyCachingConfiguration} or {@code AspectJCachingConfiguration}    * for {@code PROXY} and {@code ASPECTJ} values of {@link EnableCaching#mode()},    * respectively. Potentially includes corresponding JCache configuration as well.    */   @Override   public String[] selectImports(AdviceMode adviceMode) {      switch (adviceMode) {         case PROXY:            return getProxyImports();         case ASPECTJ:            return getAspectJImports();         default:            return null;      }   }   /**    * Return the imports to use if the {@link AdviceMode} is set to {@link AdviceMode#PROXY}.    * &lt;p&gt;Take care of adding the necessary JSR-107 import if it is available.    */   private String[] getProxyImports() {      List&lt;String&gt; result = new ArrayList&lt;&gt;(3);      result.add(AutoProxyRegistrar.class.getName());      result.add(ProxyCachingConfiguration.class.getName());      if (jsr107Present &amp;&amp; jcacheImplPresent) {         result.add(PROXY_JCACHE_CONFIGURATION_CLASS);      }      return StringUtils.toStringArray(result);   }   /**    * Return the imports to use if the {@link AdviceMode} is set to {@link AdviceMode#ASPECTJ}.    * &lt;p&gt;Take care of adding the necessary JSR-107 import if it is available.    */   private String[] getAspectJImports() {      List&lt;String&gt; result = new ArrayList&lt;&gt;(2);      result.add(CACHE_ASPECT_CONFIGURATION_CLASS_NAME);      if (jsr107Present &amp;&amp; jcacheImplPresent) {         result.add(JCACHE_ASPECT_CONFIGURATION_CLASS_NAME);      }      return StringUtils.toStringArray(result);   }}</code></pre><p>ProxyCachingConfiguration类</p><p>这个类会创建一个缓存的advisor，此时的pointCut为检查类上是否有缓存相关的注解，Inteceptor为CacheInterceptor。同样的缓存切面也需要创建一个cacheManager缓存管理器。</p><pre><code class="java">public class ProxyCachingConfiguration extends AbstractCachingConfiguration {   @Bean(name = CacheManagementConfigUtils.CACHE_ADVISOR_BEAN_NAME)   @Role(BeanDefinition.ROLE_INFRASTRUCTURE)   public BeanFactoryCacheOperationSourceAdvisor cacheAdvisor() {      BeanFactoryCacheOperationSourceAdvisor advisor = new BeanFactoryCacheOperationSourceAdvisor();      advisor.setCacheOperationSource(cacheOperationSource());      advisor.setAdvice(cacheInterceptor());      if (this.enableCaching != null) {         advisor.setOrder(this.enableCaching.&lt;Integer&gt;getNumber(&quot;order&quot;));      }      return advisor;   }   @Bean   @Role(BeanDefinition.ROLE_INFRASTRUCTURE)   public CacheOperationSource cacheOperationSource() {      return new AnnotationCacheOperationSource();   }   @Bean   @Role(BeanDefinition.ROLE_INFRASTRUCTURE)   public CacheInterceptor cacheInterceptor() {      CacheInterceptor interceptor = new CacheInterceptor();      interceptor.configure(this.errorHandler, this.keyGenerator, this.cacheResolver, this.cacheManager);      interceptor.setCacheOperationSource(cacheOperationSource());      return interceptor;   }}</code></pre><h3 id="缓存管理器的创建"><a href="#缓存管理器的创建" class="headerlink" title="缓存管理器的创建"></a>缓存管理器的创建</h3><p>同样的缓存切面也需要一个缓存管理器。缓存管理器中管理了缓存对象，比如redis缓存，map缓存，mongodb缓存，这些缓存对象都实现了Cache接口。</p><p>xml的创建方式</p><pre><code class="xml">&lt;bean id=&quot;cacheManager&quot; class=&quot;org.springframework.cache.support.SimpleCacheManager&quot;&gt;    &lt;property name=&quot;caches&quot;&gt;        &lt;set&gt;            &lt;!-- 这里可以配置多个redis --&gt;            &lt;bean class=&quot;com.xiangxue.jack.cache.RedisCache&quot;&gt;                &lt;property name=&quot;redisTemplate&quot; ref=&quot;redisTemplate&quot; /&gt;                &lt;property name=&quot;name&quot; value=&quot;redisCache&quot;/&gt;                &lt;!-- name对应的名称要在类或方法的注解中使用 --&gt;            &lt;/bean&gt;            &lt;bean class=&quot;org.springframework.cache.concurrent.ConcurrentMapCacheFactoryBean&quot;&gt;                &lt;property name=&quot;name&quot; value=&quot;mapCache&quot;/&gt;            &lt;/bean&gt;            &lt;bean class=&quot;com.xiangxue.jack.cache.MongodbCache&quot;&gt;                &lt;property name=&quot;collection&quot; value=&quot;mongo_cache&quot;/&gt;                &lt;property name=&quot;name&quot; value=&quot;mongoCache&quot;/&gt;                &lt;property name=&quot;mongoTemplate&quot; ref=&quot;mongoTemplate&quot;/&gt;            &lt;/bean&gt;        &lt;/set&gt;    &lt;/property&gt;&lt;/bean&gt;</code></pre><p>注解的创建方式</p><pre><code class="java">@PropertySource(&quot;classpath:redis/redis.properties&quot;)@Componentpublic class RedisConfig {    @Value(&quot;${redis.maxIdle}&quot;)    private Integer maxIdle;    @Value(&quot;${redis.maxWait}&quot;)    private Long maxWaitMillis;    @Value(&quot;${redis.testOnBorrow}&quot;)    private Boolean testOnBorrow;    @Value(&quot;${redis.host}&quot;)    private String hostName;    @Value(&quot;${redis.port}&quot;)    private Integer port;    @Bean    public JedisPoolConfig jedisPoolConfig(){        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();        jedisPoolConfig.setMaxIdle(maxIdle);        jedisPoolConfig.setMaxWaitMillis(maxWaitMillis);        jedisPoolConfig.setTestOnBorrow(testOnBorrow);        return jedisPoolConfig;    }    @Bean    public RedisTemplate&lt;String, String&gt; redisTemplate(JedisConnectionFactory jedisConnectionFactory){        RedisTemplate template = new RedisTemplate();        template.setConnectionFactory(jedisConnectionFactory);        return template;    }    private void setSerializer(StringRedisTemplate template){        @SuppressWarnings({ &quot;rawtypes&quot;, &quot;unchecked&quot; })        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);        ObjectMapper om = new ObjectMapper();        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);        jackson2JsonRedisSerializer.setObjectMapper(om);        template.setValueSerializer(jackson2JsonRedisSerializer);    }    @Bean    public JedisConnectionFactory jedisConnectionFactory(JedisPoolConfig jedisPoolConfig){        JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory();        jedisConnectionFactory.setHostName(hostName);        jedisConnectionFactory.setPort(port);        jedisConnectionFactory.setPoolConfig(jedisPoolConfig);        return jedisConnectionFactory;    }}</code></pre><p>CacheInterceptor与TransactionInterceptor中的流程基本相同只是实现功能不同，不再进行分析</p><h2 id="异步切面"><a href="#异步切面" class="headerlink" title="异步切面"></a>异步切面</h2><p>开启异步注解@EnableAsync，异步的使用也比较简单，直接在方法上加上Async即可，这里需要注意一下，如果采用异步，那么事务传播传播属性就会收到影响，异步是通过创建线程来实现的，这时是拿不到上个事务绑定的连接对象的，只能创建一个新的事务。</p><p>注册切面的过程基本一致，这里我们简单看下他的MethodInterceptor实现类AsyncExecutionInterceptor的invoke()方法</p><p>invoke()方法中会创建一个Callable类，然后将类交给executor去执行，如果返回值是一个Future类型，就会阻塞直到拿到返回值。</p><pre><code class="java">public Object invoke(final MethodInvocation invocation) throws Throwable {   Class&lt;?&gt; targetClass = (invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null);   Method specificMethod = ClassUtils.getMostSpecificMethod(invocation.getMethod(), targetClass);   final Method userDeclaredMethod = BridgeMethodResolver.findBridgedMethod(specificMethod);   AsyncTaskExecutor executor = determineAsyncExecutor(userDeclaredMethod);   if (executor == null) {      throw new IllegalStateException(            &quot;No executor specified and no default executor set on AsyncExecutionInterceptor either&quot;);   }   Callable&lt;Object&gt; task = () -&gt; {      try {         Object result = invocation.proceed();         if (result instanceof Future) {            return ((Future&lt;?&gt;) result).get();         }      }      catch (ExecutionException ex) {         handleError(ex.getCause(), userDeclaredMethod, invocation.getArguments());      }      catch (Throwable ex) {         handleError(ex, userDeclaredMethod, invocation.getArguments());      }      return null;   };   return doSubmit(task, executor, invocation.getMethod().getReturnType());}</code></pre>]]></content>
    
    
    <categories>
      
      <category>Spring源码解析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码解析</tag>
      
      <tag>spring</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>spring的事务解析</title>
    <link href="/2020/04/20/spring%E7%9A%84%E4%BA%8B%E5%8A%A1%E8%A7%A3%E6%9E%90/"/>
    <url>/2020/04/20/spring%E7%9A%84%E4%BA%8B%E5%8A%A1%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h2 id="入口类的注册"><a href="#入口类的注册" class="headerlink" title="入口类的注册"></a>入口类的注册</h2><p>@EnableTransactionManaement注解中会引入TransactionManagementConfigurationSelector类</p><pre><code class="java">@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(TransactionManagementConfigurationSelector.class)public @interface EnableTransactionManagement {</code></pre><p>TransactionManagementConfigurationSelector类的selectImports()方法会在ConfigurationClassPostProcessor接口中调用，向spring中注册事务相关的切面对象。这里只分析比较重要的ProxyTransactionManagementConfiguration类。</p><pre><code class="java">protected String[] selectImports(AdviceMode adviceMode) {   switch (adviceMode) {      case PROXY:         return new String[] {AutoProxyRegistrar.class.getName(),               ProxyTransactionManagementConfiguration.class.getName()};      case ASPECTJ:         return new String[] {determineTransactionAspectClass()};      default:         return null;   }}</code></pre><p>TransactionManagementConfigurationSelector类</p><p>主要功能为：</p><ol><li>注册一个事务的AOP入口类（InfrastructureAdvisorAutoProxyCreator）</li><li>用@Bean的方式创建Advisor类并收集@Transactional注解中的属性设置到Advisor中，再创建一个在调用链中使用的TransactionInterceptor类设置到Advisor中。</li><li>创建一个DataSourceTransationManager事务管理器。</li></ol><p>在注册aop入口类时，如果已经被注册则会比较优先级，优先级比现有的入口类高才会注册进去替换到现有入口。优先级从低到高依次为：InfrastructureAdvisorAutoProxyCreator、AspectJAwareAdvisorAutoProxyGreator、AnnotationAwareAspectJAutoProxyCreator。第一个为事务AOP入口类，第二个为xml配置方式注册的入口类，第三个为注解方式的入口类。</p><pre><code class="java">@Configurationpublic class ProxyTransactionManagementConfiguration extends AbstractTransactionManagementConfiguration {   /*   * 创建事务切面实例   * BeanFactoryTransactionAttributeSourceAdvisor   *   * */   @Bean(name = TransactionManagementConfigUtils.TRANSACTION_ADVISOR_BEAN_NAME)   @Role(BeanDefinition.ROLE_INFRASTRUCTURE)   public BeanFactoryTransactionAttributeSourceAdvisor transactionAdvisor() {      BeanFactoryTransactionAttributeSourceAdvisor advisor = new BeanFactoryTransactionAttributeSourceAdvisor();      advisor.setTransactionAttributeSource(transactionAttributeSource());      //设置通知类      advisor.setAdvice(transactionInterceptor());      if (this.enableTx != null) {         advisor.setOrder(this.enableTx.&lt;Integer&gt;getNumber(&quot;order&quot;));      }      return advisor;   }   @Bean   @Role(BeanDefinition.ROLE_INFRASTRUCTURE)   public TransactionAttributeSource transactionAttributeSource() {      return new AnnotationTransactionAttributeSource();   }   /*   * 创建事务advice   * TransactionInterceptor   * */   @Bean   @Role(BeanDefinition.ROLE_INFRASTRUCTURE)   public TransactionInterceptor transactionInterceptor() {      TransactionInterceptor interceptor = new TransactionInterceptor();      interceptor.setTransactionAttributeSource(transactionAttributeSource());      //事务管理器要跟数据源挂钩，所以需要自己定义      if (this.txManager != null) {         interceptor.setTransactionManager(this.txManager);      }      return interceptor;   }}</code></pre><p>自定义事务管理器的方式：</p><ul><li>实现TransactionManagementConfigurer接口</li></ul><pre><code class="java">@Componentpublic class TransactionManagementConfigurerBean implements TransactionManagementConfigurer {    @Autowired    private DataSource dataSource;    @Override    public PlatformTransactionManager annotationDrivenTransactionManager() {        DataSourceTransactionManager dtm = new DataSourceTransactionManager();        dtm.setDataSource(dataSource);        return dtm;    }}</code></pre><ul><li>创建PlatformTransactionManager类</li></ul><pre><code class="java">@Component@EnableTransactionManagement(proxyTargetClass = false)@MapperScan(basePackages = {&quot;com.xiangxue.jack.dao&quot;},annotationClass = Repository.class)public class EnableTransactionManagementBean {    @Bean    public SqlSessionFactoryBean sqlSessionFactoryBean(DataSource dataSource) {        SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();        sqlSessionFactoryBean.setDataSource(dataSource);        return sqlSessionFactoryBean;    }    @Bean    public PlatformTransactionManager annotationDrivenTransactionManager(DataSource dataSource) {        DataSourceTransactionManager dtm = new DataSourceTransactionManager();        dtm.setDataSource(dataSource);        return dtm;    }}</code></pre><h2 id="TransactionInterceptor的分析"><a href="#TransactionInterceptor的分析" class="headerlink" title="TransactionInterceptor的分析"></a>TransactionInterceptor的分析</h2><p>在之前对aop的分析中，对代理方法的调用最终会落到Interceptor的invoke()方法，invokeWithinTransaction()方法是TransactionInterceptor.invoke()的主要方法，执行具体的事务操作。</p><p>该方法首先会调用getTransactionAttributeSource()获取到@Transactional的属性，然后获取到事务管理器，调用createTransactionIfNecessary()方法创建事务对象，然后进行调用链的火炬传递，最终会进入到被代理方法。如果被代理方法出现异常，就会进入catch中调用cleanupTransactionInfo()方法进行事务的回滚。如果没有异常然后调用commitTransactionAfterReturning()进行事务的提交。在事务提交和回滚的代码中会判断事务状态是否为最新，只要在事务状态为最新时，才会提交或回滚，提交完之后会回收数据库连接。</p><p>在有嵌套事务时内层的commitTransactionAfterReturning()方法会判断是否有savepoint，如果有就会抹掉所有savepoint，这样到达最外层的commitTransactionAfterReturning()时检测不到savepoint，就会全部提交。</p><p>在有嵌套事务时内层的cleanupTransactionInfo()方法会判断是否有savepoint，如果有就会按照savepoint回滚，注意，内层异常会向外层抛出，尽管内层按照回滚点回滚，但由于嵌套事务的connection与外层相同，外层捕获到异常触发cleanupTransactionInfo()后会导致全部回滚。解决方法为在外层手动捕获异常，避免触发cleanupTransactionInfo()。</p><pre><code class="java">protected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass,      final InvocationCallback invocation) throws Throwable {   // If the transaction attribute is null, the method is non-transactional.   //获取事务属性类 AnnotationTransactionAttributeSource   TransactionAttributeSource tas = getTransactionAttributeSource();   //获取方法上面有@Transactional注解的属性   final TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null);   //获取事务管理器   final PlatformTransactionManager tm = determineTransactionManager(txAttr);   final String joinpointIdentification = methodIdentification(method, targetClass, txAttr);   if (txAttr == null || !(tm instanceof CallbackPreferringPlatformTransactionManager)) {      // Standard transaction demarcation with getTransaction and commit/rollback calls.      TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, joinpointIdentification);      Object retVal = null;      try {         // This is an around advice: Invoke the next interceptor in the chain.         // This will normally result in a target object being invoked.         //火炬传递         retVal = invocation.proceedWithInvocation();      }      catch (Throwable ex) {         // target invocation exception         //事务回滚         completeTransactionAfterThrowing(txInfo, ex);         throw ex;      }      finally {         cleanupTransactionInfo(txInfo);      }      //事务提交      commitTransactionAfterReturning(txInfo);      return retVal;   }   // 编程式事务，一般不会走   else {      final ThrowableHolder throwableHolder = new ThrowableHolder();      // It&#39;s a CallbackPreferringPlatformTransactionManager: pass a TransactionCallback in.      try {         Object result = ((CallbackPreferringPlatformTransactionManager) tm).execute(txAttr, status -&gt; {            TransactionInfo txInfo = prepareTransactionInfo(tm, txAttr, joinpointIdentification, status);            try {               return invocation.proceedWithInvocation();            }            catch (Throwable ex) {               if (txAttr.rollbackOn(ex)) {                  // A RuntimeException: will lead to a rollback.                  if (ex instanceof RuntimeException) {                     throw (RuntimeException) ex;                  }                  else {                     throw new ThrowableHolderException(ex);                  }               }               else {                  // A normal return value: will lead to a commit.                  throwableHolder.throwable = ex;                  return null;               }            }            finally {               cleanupTransactionInfo(txInfo);            }         });         // Check result state: It might indicate a Throwable to rethrow.         if (throwableHolder.throwable != null) {            throw throwableHolder.throwable;         }         return result;      }      catch (ThrowableHolderException ex) {         throw ex.getCause();      }      catch (TransactionSystemException ex2) {         if (throwableHolder.throwable != null) {            logger.error(&quot;Application exception overridden by commit exception&quot;, throwableHolder.throwable);            ex2.initApplicationException(throwableHolder.throwable);         }         throw ex2;      }      catch (Throwable ex2) {         if (throwableHolder.throwable != null) {            logger.error(&quot;Application exception overridden by commit exception&quot;, throwableHolder.throwable);         }         throw ex2;      }   }}</code></pre><h3 id="createTransactionIfNecessary-方法"><a href="#createTransactionIfNecessary-方法" class="headerlink" title="createTransactionIfNecessary()方法"></a>createTransactionIfNecessary()方法</h3><p>主要逻辑为调用事务管理器的getTransaction()方法创建事务并返回一个事务状态对象。</p><pre><code class="java">protected TransactionInfo createTransactionIfNecessary(@Nullable PlatformTransactionManager tm,      @Nullable TransactionAttribute txAttr, final String joinpointIdentification) {   // If no name specified, apply method identification as transaction name.   if (txAttr != null &amp;&amp; txAttr.getName() == null) {      txAttr = new DelegatingTransactionAttribute(txAttr) {         @Override         public String getName() {            return joinpointIdentification;         }      };   }   TransactionStatus status = null;   if (txAttr != null) {      if (tm != null) {         //开启事务，这里重点看         status = tm.getTransaction(txAttr);      }      else {         if (logger.isDebugEnabled()) {            logger.debug(&quot;Skipping transactional joinpoint [&quot; + joinpointIdentification +                  &quot;] because no transaction manager has been configured&quot;);         }      }   }   //创建事务信息对象，记录新老事务信息对象   return prepareTransactionInfo(tm, txAttr, joinpointIdentification, status);}</code></pre><h3 id="getTransaction-方法"><a href="#getTransaction-方法" class="headerlink" title="getTransaction()方法"></a>getTransaction()方法</h3><ol><li><p>调用doGetTransaction()方法创建事务对象，如果当前线程已有connection会直接使用这个连接设置到事务对象，如果没有会在dobegin()方法中创建连接并绑定到当前线程，再次进入这个方法时会直接使用这个连接设置到事务对象。</p></li><li><p>调用isExistingTransaction()判断是否存在事务，判断逻辑为事务对象中是否有connection。如果有会直接调用handleExistingTransaction()方法处理已存在的事务并返回处理后的事务对象。</p></li><li><p>判断事务传播属性</p></li><li><p>创建事务状态对象，事务状态对象用于记录事务在运行时的特质，如事务是否是最新的。</p></li><li><p>调用doBegin()方法开启事务</p></li><li><p>调用prepareSynchronization()方法改变事务状态。</p></li></ol><p>传播属性用于告诉spring如何控制事务流转，这里只判断三种：</p><p>PROPAGATION_REQUIRED：如果没有事务就新建一个事务，如果有就加入到当前事务。</p><p>PROPAGATION_REQUIRES_NEW：如果没有事务就新建一个事务，如果有就挂起当前事务。</p><p>PROPAGATION_NESTED：如果有事务就嵌套在事务中执行。</p><pre><code class="java">public final TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException {   //这里重点看，.DataSourceTransactionObject拿到对象   Object transaction = doGetTransaction();   // Cache debug flag to avoid repeated checks.   boolean debugEnabled = logger.isDebugEnabled();   if (definition == null) {      // Use defaults if no transaction definition given.      definition = new DefaultTransactionDefinition();   }   //第一次进来connectionHolder为空的，所以不存在事务   if (isExistingTransaction(transaction)) {      // Existing transaction found -&gt; check propagation behavior to find out how to behave.      return handleExistingTransaction(definition, transaction, debugEnabled);   }   // Check definition settings for new transaction.   if (definition.getTimeout() &lt; TransactionDefinition.TIMEOUT_DEFAULT) {      throw new InvalidTimeoutException(&quot;Invalid transaction timeout&quot;, definition.getTimeout());   }   // No existing transaction found -&gt; check propagation behavior to find out how to proceed.   if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_MANDATORY) {      throw new IllegalTransactionStateException(            &quot;No existing transaction found for transaction marked with propagation &#39;mandatory&#39;&quot;);   }   //第一次进来大部分会走这里、对事务状态进行判断   else if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRED ||         definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW ||         definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) {      //先挂起      SuspendedResourcesHolder suspendedResources = suspend(null);         if (debugEnabled) {            logger.debug(&quot;Creating new transaction with name [&quot; + definition.getName() + &quot;]: &quot; + definition);         }         try {            boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER);            //创建事务状态对象，其实就是封装了事务对象的一些信息，记录事务状态的            DefaultTransactionStatus status = newTransactionStatus(                  definition, transaction, true, newSynchronization, debugEnabled, suspendedResources);            //开启事务,重点看看 DataSourceTransactionObject            doBegin(transaction, definition);            //开启事务后，改变事务状态            prepareSynchronization(status, definition);            return status;      }      catch (RuntimeException | Error ex) {         resume(null, suspendedResources);         throw ex;      }   }   else {      // Create &quot;empty&quot; transaction: no actual transaction, but potentially synchronization.      if (definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT &amp;&amp; logger.isWarnEnabled()) {         logger.warn(&quot;Custom isolation level specified but no actual transaction initiated; &quot; +               &quot;isolation level will effectively be ignored: &quot; + definition);      }      boolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS);      return prepareTransactionStatus(definition, null, true, newSynchronization, debugEnabled, null);   }}</code></pre><h4 id="doGetTransaction-方法"><a href="#doGetTransaction-方法" class="headerlink" title="doGetTransaction()方法"></a>doGetTransaction()方法</h4><p>该方法中首先会创建DataSourceTransactionObject事务对象，设置事务是否允许嵌套，然后调用getResource()方法获取数据库的连接。DataSourceTransactionObject中持有一个包装后的连接对象。传播属性主要用于控制方法是否使用事务，是否使用同一个事务。事务对象的作用是标识当前线程是否有事务，是否是最新的，包装connection对象。是否使用同一个事务是靠控制事务对象的connection来实现的。</p><pre><code class="java">protected Object doGetTransaction() {   //管理connection对象，创建回滚点，按照回滚点回滚，释放回滚点   DataSourceTransactionObject txObject = new DataSourceTransactionObject();   //DataSourceTransactionManager默认是允许嵌套事务的   txObject.setSavepointAllowed(isNestedTransactionAllowed());   //obtainDataSource() 获取数据源对象，其实就是数据库连接块对象   ConnectionHolder conHolder =         (ConnectionHolder) TransactionSynchronizationManager.getResource(obtainDataSource());   txObject.setConnectionHolder(conHolder, false);   return txObject;}</code></pre><p>getResource()方法</p><p>doGetResource()是getResource()方法的主要方法，主要逻辑为从resources对象中获取数据库连接对象。resources对象为Map类型的ThreadLocal容器，Map存储的是连接池对象与连接对象的映射。如果事务传播属性为REQUIRED，则会获取同一个连接对象。</p><pre><code class="java">private static Object doGetResource(Object actualKey) {   Map&lt;Object, Object&gt; map = resources.get();   if (map == null) {      return null;   }   Object value = map.get(actualKey);   // Transparently remove ResourceHolder that was marked as void...   if (value instanceof ResourceHolder &amp;&amp; ((ResourceHolder) value).isVoid()) {      map.remove(actualKey);      // Remove entire ThreadLocal if empty...      if (map.isEmpty()) {         resources.remove();      }      value = null;   }   return value;}</code></pre><h4 id="doBegin-方法"><a href="#doBegin-方法" class="headerlink" title="doBegin()方法"></a>doBegin()方法</h4><p>如果没有数据库连接首先会获取数据库连接，设置到事务对象，然后设置事务的隔离级别、将连接的autoCommit()设置为false开启事务、设置事务是否只读、将事务对象设置为活跃的，最后如果是新创建的事务就调用bindResource()方法绑定连接对象。</p><pre><code class="java">protected void doBegin(Object transaction, TransactionDefinition definition) {   DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction;   Connection con = null;   try {      //如果没有数据库连接      if (!txObject.hasConnectionHolder() ||            txObject.getConnectionHolder().isSynchronizedWithTransaction()) {         //从连接池里面获取连接         Connection newCon = obtainDataSource().getConnection();         if (logger.isDebugEnabled()) {            logger.debug(&quot;Acquired Connection [&quot; + newCon + &quot;] for JDBC transaction&quot;);         }         //把连接包装成ConnectionHolder，然后设置到事务对象中         txObject.setConnectionHolder(new ConnectionHolder(newCon), true);      }      txObject.getConnectionHolder().setSynchronizedWithTransaction(true);      con = txObject.getConnectionHolder().getConnection();      //从数据库连接中获取隔离级别      Integer previousIsolationLevel = DataSourceUtils.prepareConnectionForTransaction(con, definition);      txObject.setPreviousIsolationLevel(previousIsolationLevel);      // Switch to manual commit if necessary. This is very expensive in some JDBC drivers,      // so we don&#39;t want to do it unnecessarily (for example if we&#39;ve explicitly      // configured the connection pool to set it already).      if (con.getAutoCommit()) {         txObject.setMustRestoreAutoCommit(true);         if (logger.isDebugEnabled()) {            logger.debug(&quot;Switching JDBC Connection [&quot; + con + &quot;] to manual commit&quot;);         }         //关闭连接的自动提交，其实这步就是开启了事务         con.setAutoCommit(false);      }      //设置只读事务 从这一点设置的时间点开始（时间点a）到这个事务结束的过程中，其他事务所提交的数据，该事务将看不见！      //设置只读事务就是告诉数据库，我这个事务内没有新增，修改，删除操作只有查询操作，不需要数据库锁等操作，减少数据库压力      prepareTransactionalConnection(con, definition);      //自己提交关闭了，就说明已经开启事务了，事务是活动的      txObject.getConnectionHolder().setTransactionActive(true);      int timeout = determineTimeout(definition);      if (timeout != TransactionDefinition.TIMEOUT_DEFAULT) {         txObject.getConnectionHolder().setTimeoutInSeconds(timeout);      }      // Bind the connection holder to the thread.      if (txObject.isNewConnectionHolder()) {         //如果是新创建的事务，则建立当前线程和数据库连接的关系         TransactionSynchronizationManager.bindResource(obtainDataSource(), txObject.getConnectionHolder());      }   }   catch (Throwable ex) {      if (txObject.isNewConnectionHolder()) {         DataSourceUtils.releaseConnection(con, obtainDataSource());         txObject.setConnectionHolder(null, false);      }      throw new CannotCreateTransactionException(&quot;Could not open JDBC Connection for transaction&quot;, ex);   }}</code></pre><p>bindResource()方法</p><p>将map设置到resources对象中与当前线程绑定，并将连接池对象与连接对象的映射关系放入map中提供给创建事务对象时调用的getResource()方法使用。这里绑定连接池对象与连接对象的是为了处理多数据源的情况。</p><pre><code class="java">public static void bindResource(Object key, Object value) throws IllegalStateException {   Object actualKey = TransactionSynchronizationUtils.unwrapResourceIfNecessary(key);   Assert.notNull(value, &quot;Value must not be null&quot;);   Map&lt;Object, Object&gt; map = resources.get();   // set ThreadLocal Map if none found   if (map == null) {      map = new HashMap&lt;&gt;();      resources.set(map);   }   Object oldValue = map.put(actualKey, value);   // Transparently suppress a ResourceHolder that was marked as void...   if (oldValue instanceof ResourceHolder &amp;&amp; ((ResourceHolder) oldValue).isVoid()) {      oldValue = null;   }   if (oldValue != null) {      throw new IllegalStateException(&quot;Already value [&quot; + oldValue + &quot;] for key [&quot; +            actualKey + &quot;] bound to thread [&quot; + Thread.currentThread().getName() + &quot;]&quot;);   }   if (logger.isTraceEnabled()) {      logger.trace(&quot;Bound value [&quot; + value + &quot;] for key [&quot; + actualKey + &quot;] to thread [&quot; +            Thread.currentThread().getName() + &quot;]&quot;);   }}</code></pre><h4 id="handleExistingTransaction-方法"><a href="#handleExistingTransaction-方法" class="headerlink" title="handleExistingTransaction()方法"></a>handleExistingTransaction()方法</h4><p>主要是根据传播属性对事务进行处理，这里只着重分析PROPAGATION_REQUIRES_NEW跟PROPAGATION_NESTED的情况。</p><p>PROPAGATION_REQUIRES_NEW会挂起当前事务，然后调用dobegin()方法为事务对象重新设置连接。挂起的逻辑比较简单就是将事务对象的connection设置为空，然后解除connection跟线程的绑定关系。</p><p>PROPAGATION_NESTED会将事务状态设置为非最新，然后创建一个savepoint。</p><p>如果是默认传播属性，只将事务状态设置为非最新。</p><pre><code class="java">private TransactionStatus handleExistingTransaction(      TransactionDefinition definition, Object transaction, boolean debugEnabled)      throws TransactionException {   //不允许有事务，直接异常   if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NEVER) {      throw new IllegalTransactionStateException(            &quot;Existing transaction found for transaction marked with propagation &#39;never&#39;&quot;);   }   //以非事务方式执行操作，如果当前存在事务，就把当前事务挂起   if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NOT_SUPPORTED) {      if (debugEnabled) {         logger.debug(&quot;Suspending current transaction&quot;);      }      //挂起当前事务      Object suspendedResources = suspend(transaction);      boolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS);      //修改事务状态信息，把事务的一些信息存储到当前线程中，ThreadLocal中      return prepareTransactionStatus(            definition, null, false, newSynchronization, debugEnabled, suspendedResources);   }   if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW) {      if (debugEnabled) {         logger.debug(&quot;Suspending current transaction, creating new transaction with name [&quot; +               definition.getName() + &quot;]&quot;);      }      //挂起      SuspendedResourcesHolder suspendedResources = suspend(transaction);      try {         boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER);         DefaultTransactionStatus status = newTransactionStatus(               definition, transaction, true, newSynchronization, debugEnabled, suspendedResources);         doBegin(transaction, definition);         prepareSynchronization(status, definition);         return status;      }      catch (RuntimeException | Error beginEx) {         resumeAfterBeginException(transaction, suspendedResources, beginEx);         throw beginEx;      }   }   if (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) {      if (!isNestedTransactionAllowed()) {         throw new NestedTransactionNotSupportedException(               &quot;Transaction manager does not allow nested transactions by default - &quot; +               &quot;specify &#39;nestedTransactionAllowed&#39; property with value &#39;true&#39;&quot;);      }      if (debugEnabled) {         logger.debug(&quot;Creating nested transaction with name [&quot; + definition.getName() + &quot;]&quot;);      }      //默认是可以嵌套事务的      if (useSavepointForNestedTransaction()) {         // Create savepoint within existing Spring-managed transaction,         // through the SavepointManager API implemented by TransactionStatus.         // Usually uses JDBC 3.0 savepoints. Never activates Spring synchronization.         DefaultTransactionStatus status =               prepareTransactionStatus(definition, transaction, false, false, debugEnabled, null);         //创建回滚点         status.createAndHoldSavepoint();         return status;      }      else {         // Nested transaction through nested begin and commit/rollback calls.         // Usually only for JTA: Spring synchronization might get activated here         // in case of a pre-existing JTA transaction.         boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER);         DefaultTransactionStatus status = newTransactionStatus(               definition, transaction, true, newSynchronization, debugEnabled, null);         doBegin(transaction, definition);         prepareSynchronization(status, definition);         return status;      }   }   // Assumably PROPAGATION_SUPPORTS or PROPAGATION_REQUIRED.   if (debugEnabled) {      logger.debug(&quot;Participating in existing transaction&quot;);   }   if (isValidateExistingTransaction()) {      if (definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT) {         Integer currentIsolationLevel = TransactionSynchronizationManager.getCurrentTransactionIsolationLevel();         if (currentIsolationLevel == null || currentIsolationLevel != definition.getIsolationLevel()) {            Constants isoConstants = DefaultTransactionDefinition.constants;            throw new IllegalTransactionStateException(&quot;Participating transaction with definition [&quot; +                  definition + &quot;] specifies isolation level which is incompatible with existing transaction: &quot; +                  (currentIsolationLevel != null ?                        isoConstants.toCode(currentIsolationLevel, DefaultTransactionDefinition.PREFIX_ISOLATION) :                        &quot;(unknown)&quot;));         }      }      if (!definition.isReadOnly()) {         if (TransactionSynchronizationManager.isCurrentTransactionReadOnly()) {            throw new IllegalTransactionStateException(&quot;Participating transaction with definition [&quot; +                  definition + &quot;] is not marked as read-only but existing transaction is&quot;);         }      }   }   boolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER);   return prepareTransactionStatus(definition, transaction, false, newSynchronization, debugEnabled, null);}</code></pre><h2 id="编程式事务"><a href="#编程式事务" class="headerlink" title="编程式事务"></a>编程式事务</h2><p>编程式事务相比注解式事务粒度更细，如果方法流程很长注解式事务会产生连接占用问题，导致整个系统吞吐量下降。注解事务由于隔离级别的不同，可能导致可重复读的问题，比如使用数据库实现的乐观锁，在重复竞争锁时由于都是同一个连接对象，所以每次查询的数据都是一样的，这就会导致一个死循环。</p><p>getTicket()方法递归调用的时候，在可重复读的隔离级别下查询的数据是一样的，永远获取不到锁。</p><pre><code class="java">@Transactional@Overridepublic int getTicket() {    //1、获取锁    List&lt;ZgTicket&gt; zgTickets = commonMapper.queryTicketById(&quot;12306&quot;);    Map lockmap = new HashMap();    lockmap.put(&quot;ticketId&quot;, &quot;12306&quot;);    lockmap.put(&quot;version&quot;, zgTickets.get(0).getVersion());    int i = commonMapper.updateLock(lockmap);    if (i &gt; 0) {        //抢票        ZgTicket zgTicket = zgTickets.get(0);        zgTicket.setTicketCount(2);        int i1 = commonMapper.updateTicket(zgTicket);    } else {        //继续抢        ((TransationService) AopContext.currentProxy()).getTicket();    }    return 0;}</code></pre><p>编程式事务在执行execute()前会自动开启时候，执行后就自动提交了事务。</p><pre><code class="java">@Overridepublic int getTicketModeOne() {    Integer execute = transactionTemplate.execute(status -&gt; {        //1、获取锁        List&lt;ZgTicket&gt; zgTickets = commonMapper.queryTicketById(&quot;12306&quot;);        Map lockmap = new HashMap();        lockmap.put(&quot;ticketId&quot;, &quot;12306&quot;);        lockmap.put(&quot;version&quot;, zgTickets.get(0).getVersion());        int i = commonMapper.updateLock(lockmap);        if (i &gt; 0) {            //抢票            ZgTicket zgTicket = zgTickets.get(0);            zgTicket.setTicketCount(2);            int i1 = commonMapper.updateTicket(zgTicket);        }        return i;    });    if (execute == 0) {        //继续抢        getTicketModeOne();    }    return 0;}</code></pre><p>编程式事务控制粒度更细，不需要事务控制的代码可以不放在execute()方法内。</p><p>还可以手动控制事务</p><pre><code class="java">@AutowiredPlatformTransactionManager platformTransactionManager;public void xxx() {    DefaultTransactionDefinition defaultTransactionDefinition = new DefaultTransactionDefinition();    defaultTransactionDefinition.setPropagationBehavior(0);    TransactionStatus transaction = platformTransactionManager.getTransaction(defaultTransactionDefinition);    try {        System.out.println(&quot;业务代码&quot;);    }catch (Exception e) {        platformTransactionManager.rollback(transaction);    }    platformTransactionManager.commit(transaction);}</code></pre><p>把控制代码可以写到切面中，跟业务代码解耦。</p>]]></content>
    
    
    <categories>
      
      <category>Spring源码解析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码解析</tag>
      
      <tag>spring</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>spring的aop源码解析</title>
    <link href="/2020/04/19/spring%E7%9A%84aop%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
    <url>/2020/04/19/spring%E7%9A%84aop%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h2 id="AOP的入口解析"><a href="#AOP的入口解析" class="headerlink" title="AOP的入口解析"></a>AOP的入口解析</h2><p>在<a href="[http://zgcheng.top/2020/04/15/spring%E5%AE%9E%E4%BE%8B%E5%8C%96bean%E7%9A%84%E8%BF%87%E7%A8%8B/#initializeBean-%E6%96%B9%E6%B3%95](http://zgcheng.top/2020/04/15/spring实例化bean的过程/#initializeBean-方法)">spring实例化bean的过程</a>中我们提到过，applyBeanPostProcessorsAfterInitialization()方法是aop的入口。首先会将原始实例传入该方法，该方法会将原始实例替换为代理实例。该方法也是BeanPostProcessor的运用，最终会落入AbstractAutoProxyCreator类的wrapIfNecessary()方法。</p><h3 id="AbstractAutoProxyCreator类的来源"><a href="#AbstractAutoProxyCreator类的来源" class="headerlink" title="AbstractAutoProxyCreator类的来源"></a>AbstractAutoProxyCreator类的来源</h3><p>在进行aop标签解析时会创建org.springframework.aop.config.AopNamespaceHandler类，该类注册的aspectj-autoproxy解析类AspectJAutoProxyBeanDefinitionParser会注册AnnotationAwareAspectJAutoProxyCreator类，该类就是AbstractAutoProxyCreator的子类。</p><p>@EnableAspectJAutoProxy注解会引入AspectJAutoProxyRegistrar类，该类中有一个registerBeanDefinitions方法，该方法用于注册一个AnnotationAwareAspectJAutoProxyCreator类并进行proxyTargetClass、exposeProxy属性的设置。AUTO_PROXY_CREATOR_BEAN_NAME属性为BeanDefinition的名称。</p><p>AspectJAutoProxyRegistrar构造函数</p><pre><code class="java">class AspectJAutoProxyRegistrar implements ImportBeanDefinitionRegistrar {    /**     * Register, escalate, and configure the AspectJ auto proxy creator based on the value     * of the @{@link EnableAspectJAutoProxy#proxyTargetClass()} attribute on the importing     * {@code @Configuration} class.     */    @Override    public void registerBeanDefinitions(            AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {        //注册注解AOP入口类        AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry);        /*        * * true         * 1、目标对象实现了接口 – 使用CGLIB代理机制         * 2、目标对象没有接口(只有实现类) – 使用CGLIB代理机制         *         * false         * 1、目标对象实现了接口 – 使用JDK动态代理机制(代理所有实现了的接口)         * 2、目标对象没有接口(只有实现类) – 使用CGLIB代理机制        * */        AnnotationAttributes enableAspectJAutoProxy =                AnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class);        if (enableAspectJAutoProxy != null) {            if (enableAspectJAutoProxy.getBoolean(&quot;proxyTargetClass&quot;)) {                AopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry);            }            //是否需要把代理对象暴露出来，简单来说是否需要把代理对象用ThreadLocal存起来，如果是true就是需要            if (enableAspectJAutoProxy.getBoolean(&quot;exposeProxy&quot;)) {                AopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry);            }        }    }}</code></pre><h2 id="AOP的过程解析"><a href="#AOP的过程解析" class="headerlink" title="AOP的过程解析"></a>AOP的过程解析</h2><p>wrapIfNecessary()方法</p><p>该方法会调用getAdvicesAndAdvisorsForBean()方法判断类是否需要代理，如果需要会返回一个不为空的切面数组，然后将切面数组传递给createProxy()方法创建一个代理，在创建之前会将被代理对象封装为SingletonTargetSource对象。为bean创建一个代理类，最终放入一级缓存的是代理类。</p><pre><code class="java">    protected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) {        if (StringUtils.hasLength(beanName) &amp;&amp; this.targetSourcedBeans.contains(beanName)) {            return bean;        }        if (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) {            return bean;        }        if (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) {            this.advisedBeans.put(cacheKey, Boolean.FALSE);            return bean;        }        //创建当前bean的代理，如果这个bean有advice的话，重点看，重要程度5        // Create proxy if we have advice.        Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null);        //如果有切面，则生成该bean的代理        if (specificInterceptors != DO_NOT_PROXY) {            this.advisedBeans.put(cacheKey, Boolean.TRUE);            //把被代理对象bean实例封装到SingletonTargetSource对象中            Object proxy = createProxy(                    bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean));            this.proxyTypes.put(cacheKey, proxy.getClass());            return proxy;        }        this.advisedBeans.put(cacheKey, Boolean.FALSE);        return bean;</code></pre><h3 id="getAdvicesAndAdvisorsForBean-方法"><a href="#getAdvicesAndAdvisorsForBean-方法" class="headerlink" title="getAdvicesAndAdvisorsForBean()方法"></a>getAdvicesAndAdvisorsForBean()方法</h3><p>findEligibleAdvisors()方法收集所有@Aspect注解的所有类，收集完之后循环进行匹配。</p><pre><code class="java">    protected Object[] getAdvicesAndAdvisorsForBean(            Class&lt;?&gt; beanClass, String beanName, @Nullable TargetSource targetSource) {        //找到合格的切面，重点看        List&lt;Advisor&gt; advisors = findEligibleAdvisors(beanClass, beanName);        if (advisors.isEmpty()) {            return DO_NOT_PROXY;        }        return advisors.toArray();    }</code></pre><p>findEligibleAdvisors()方法</p><p>该方法会调用findCandidateAdvisors()方法获取@Aspectj注解的所有类，然后调用findAdvisorsThatCanApply()方法匹配可以作用在类上的切面，然后拿到匹配的切面，再调用sortAdvisors()方法进行排序。findAdvisorsThatCanApply()方法其实就是根据PointCut对类名进行模糊匹配，这时还不对方法名进行匹配，因为这里只是判断类是否需要代理。这里不再对这个方法分析。</p><pre><code class="java">    protected List&lt;Advisor&gt; findEligibleAdvisors(Class&lt;?&gt; beanClass, String beanName) {        //找到候选的切面,其实就是一个寻找有@Aspectj注解的过程，把工程中所有有这个注解的类封装成Advisor返回        List&lt;Advisor&gt; candidateAdvisors = findCandidateAdvisors();        //判断候选的切面是否作用在当前beanClass上面，就是一个匹配过程。。现在就是一个匹配        List&lt;Advisor&gt; eligibleAdvisors = findAdvisorsThatCanApply(candidateAdvisors, beanClass, beanName);        extendAdvisors(eligibleAdvisors);        if (!eligibleAdvisors.isEmpty()) {            //对有@Order@Priority进行排序            eligibleAdvisors = sortAdvisors(eligibleAdvisors);        }        return eligibleAdvisors;    }</code></pre><p>findCandidateAdvisors()方法</p><p>buildAspectJAdvisors()方法是findCandidateAdvisors()方法的主要方法。该方法会获取当前spring容器中的所有BeanName后循环判断bean上是否有@Aspect注解，然后创建获取有@Aspect注解类的实例工厂，然后调用其getAdvisors()方法</p><pre><code class="java">    public List&lt;Advisor&gt; buildAspectJAdvisors() {        List&lt;String&gt; aspectNames = this.aspectBeanNames;        if (aspectNames == null) {            synchronized (this) {                aspectNames = this.aspectBeanNames;                if (aspectNames == null) {                    List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;();                    aspectNames = new ArrayList&lt;&gt;();                    //获取spring容器中的所有bean的名称BeanName                    String[] beanNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(                            this.beanFactory, Object.class, true, false);                    for (String beanName : beanNames) {                        if (!isEligibleBean(beanName)) {                            continue;                        }                        // We must be careful not to instantiate beans eagerly as in this case they                        // would be cached by the Spring container but would not have been weaved.                        Class&lt;?&gt; beanType = this.beanFactory.getType(beanName);                        if (beanType == null) {                            continue;                        }                        //判断类上是否有@Aspect注解                        if (this.advisorFactory.isAspect(beanType)) {                            aspectNames.add(beanName);                            AspectMetadata amd = new AspectMetadata(beanType, beanName);                            if (amd.getAjType().getPerClause().getKind() == PerClauseKind.SINGLETON) {                                //创建获取有@Aspect注解类的实例工厂，负责获取有@Aspect注解类的实例                                MetadataAwareAspectInstanceFactory factory =                                        new BeanFactoryAspectInstanceFactory(this.beanFactory, beanName);                                //创建切面advisor对象                                List&lt;Advisor&gt; classAdvisors = this.advisorFactory.getAdvisors(factory);                                if (this.beanFactory.isSingleton(beanName)) {                                    this.advisorsCache.put(beanName, classAdvisors);                                }                                else {                                    this.aspectFactoryCache.put(beanName, factory);                                }                                advisors.addAll(classAdvisors);                            }                            else {                                // Per target or per this.                                if (this.beanFactory.isSingleton(beanName)) {                                    throw new IllegalArgumentException(&quot;Bean with name &#39;&quot; + beanName +                                            &quot;&#39; is a singleton, but aspect instantiation model is not singleton&quot;);                                }                                MetadataAwareAspectInstanceFactory factory =                                        new PrototypeAspectInstanceFactory(this.beanFactory, beanName);                                this.aspectFactoryCache.put(beanName, factory);                                advisors.addAll(this.advisorFactory.getAdvisors(factory));                            }                        }                    }                    this.aspectBeanNames = aspectNames;                    return advisors;                }            }        }        if (aspectNames.isEmpty()) {            return Collections.emptyList();        }        List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;();        for (String aspectName : aspectNames) {            List&lt;Advisor&gt; cachedAdvisors = this.advisorsCache.get(aspectName);            if (cachedAdvisors != null) {                advisors.addAll(cachedAdvisors);            }            else {                MetadataAwareAspectInstanceFactory factory = this.aspectFactoryCache.get(aspectName);                advisors.addAll(this.advisorFactory.getAdvisors(factory));            }        }        return advisors;    }</code></pre><p>getAdvisors()方法</p><p>该方法会获取到有@Aspect注解的类名称。然后拿到没有@PointCut注解的所有方法，这样做是因为@PointCut并方法大多数情况下是空方法。然后调用getAdvisor()方法获取到advisor对象。</p><pre><code class="java">    public List&lt;Advisor&gt; getAdvisors(MetadataAwareAspectInstanceFactory aspectInstanceFactory) {        //从工厂中获取有@Aspect注解的类Class        Class&lt;?&gt; aspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass();        //从工厂中获取有@Aspect注解的类的名称        String aspectName = aspectInstanceFactory.getAspectMetadata().getAspectName();        validate(aspectClass);        //创建工厂的装饰类，获取实例只会获取一次        // We need to wrap the MetadataAwareAspectInstanceFactory with a decorator        // so that it will only instantiate once.        MetadataAwareAspectInstanceFactory lazySingletonAspectInstanceFactory =                new LazySingletonAspectInstanceFactoryDecorator(aspectInstanceFactory);        List&lt;Advisor&gt; advisors = new ArrayList&lt;&gt;();        //这里循环没有@Pointcut注解的方法        for (Method method : getAdvisorMethods(aspectClass)) {            //非常重要重点看看，重要程度 5            Advisor advisor = getAdvisor(method, lazySingletonAspectInstanceFactory, advisors.size(), aspectName);            if (advisor != null) {                advisors.add(advisor);            }        }        // If it&#39;s a per target aspect, emit the dummy instantiating aspect.        if (!advisors.isEmpty() &amp;&amp; lazySingletonAspectInstanceFactory.getAspectMetadata().isLazilyInstantiated()) {            Advisor instantiationAdvisor = new SyntheticInstantiationAdvisor(lazySingletonAspectInstanceFactory);            advisors.add(0, instantiationAdvisor);        }        //判断属性上是否有引介注解        // Find introduction fields.        for (Field field : aspectClass.getDeclaredFields()) {            //判断属性上是否有DeclareParents注解，如果有返回切面            Advisor advisor = getDeclareParentsAdvisor(field);            if (advisor != null) {                advisors.add(advisor);            }        }        return advisors;    }</code></pre><p>getAdvisor()方法</p><p>getAdvisor()方法会调用getPointCut()方法获取到封装的AspectJAnnotation对象，然后使用InstantiationModelAwarePointcutAdvisorImpl()创建Advisor切面类。</p><pre><code class="java">    public Advisor getAdvisor(Method candidateAdviceMethod, MetadataAwareAspectInstanceFactory aspectInstanceFactory,            int declarationOrderInAspect, String aspectName) {        validate(aspectInstanceFactory.getAspectMetadata().getAspectClass());        //获取pointCut对象，最重要的是从注解中获取表达式        AspectJExpressionPointcut expressionPointcut = getPointcut(                candidateAdviceMethod, aspectInstanceFactory.getAspectMetadata().getAspectClass());        if (expressionPointcut == null) {            return null;        }        //创建Advisor切面类，这才是真正的切面类，一个切面类里面肯定要有1、pointCut 2、advice        //这里pointCut是expressionPointcut， advice 增强方法是 candidateAdviceMethod        return new InstantiationModelAwarePointcutAdvisorImpl(expressionPointcut, candidateAdviceMethod,                this, aspectInstanceFactory, declarationOrderInAspect, aspectName);    }</code></pre><p>getPoint()方法</p><p>getPointCut()方法会去寻找@Pointcut、@Around、@Before、@After、@AfterReturning、@ AfterThrowing注解，并把注解信息封装成AspectJAnnotation对象，然后创建一个PointCut类，并且把前面从注解里面解析的表达式设置进去。</p><pre><code class="java">    private AspectJExpressionPointcut getPointcut(Method candidateAdviceMethod, Class&lt;?&gt; candidateAspectClass) {        //从候选的增强方法里面 candidateAdviceMethod找到注解        //Pointcut.class, Around.class, Before.class, After.class, AfterReturning.class, AfterThrowing.class        //并把注解信息封装成AspectJAnnotation对象        AspectJAnnotation&lt;?&gt; aspectJAnnotation =                AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(candidateAdviceMethod);        if (aspectJAnnotation == null) {            return null;        }        //创建一个PointCut类，并且把前面从注解里面解析的表达式设置进去        AspectJExpressionPointcut ajexp =                new AspectJExpressionPointcut(candidateAspectClass, new String[0], new Class&lt;?&gt;[0]);        ajexp.setExpression(aspectJAnnotation.getPointcutExpression());        if (this.beanFactory != null) {            ajexp.setBeanFactory(this.beanFactory);        }        return ajexp;    }</code></pre><p>InstantiationModelAwarePointcutAdvisorImpl()方法</p><p>getAdvice()方法是他的主要方法，主要是根据不同的注解信息创建不同的Advice类实例。Advice接口是一个空接口，子类实现完全不同。MethodInterceptor接口也实现了Advice接口，只有AspectJMethodBeforeAdvice跟AspectJAfterReturningAdvice没有实现MethodInterceptor接口，原因是这些Advice的MethodInterceptor接口中的invoke()方法需要预留出来，完成执行链回调。LocalVariableTableParameterNameDiscoverer的getParameterNames()方法可以拿到方法参数名称。</p><pre><code class="java">    public Advice getAdvice(Method candidateAdviceMethod, AspectJExpressionPointcut expressionPointcut,            MetadataAwareAspectInstanceFactory aspectInstanceFactory, int declarationOrder, String aspectName) {        //获取有@Aspect注解的类        Class&lt;?&gt; candidateAspectClass = aspectInstanceFactory.getAspectMetadata().getAspectClass();        validate(candidateAspectClass);        //找到candidateAdviceMethod方法上面的注解，并且包装成AspectJAnnotation对象，这个对象中就有注解类型        AspectJAnnotation&lt;?&gt; aspectJAnnotation =                AbstractAspectJAdvisorFactory.findAspectJAnnotationOnMethod(candidateAdviceMethod);        if (aspectJAnnotation == null) {            return null;        }        // If we get here, we know we have an AspectJ method.        // Check that it&#39;s an AspectJ-annotated class        if (!isAspect(candidateAspectClass)) {            throw new AopConfigException(&quot;Advice must be declared inside an aspect type: &quot; +                    &quot;Offending method &#39;&quot; + candidateAdviceMethod + &quot;&#39; in class [&quot; +                    candidateAspectClass.getName() + &quot;]&quot;);        }        if (logger.isDebugEnabled()) {            logger.debug(&quot;Found AspectJ method: &quot; + candidateAdviceMethod);        }        AbstractAspectJAdvice springAdvice;        //根据不同的注解类型创建不同的advice类实例        switch (aspectJAnnotation.getAnnotationType()) {            case AtPointcut:                if (logger.isDebugEnabled()) {                    logger.debug(&quot;Processing pointcut &#39;&quot; + candidateAdviceMethod.getName() + &quot;&#39;&quot;);                }                return null;            case AtAround:                //实现了MethodInterceptor接口                springAdvice = new AspectJAroundAdvice(                        candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);                break;            case AtBefore:                //实现了MethodBeforeAdvice接口，没有实现MethodInterceptor接口                springAdvice = new AspectJMethodBeforeAdvice(                        candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);                break;            case AtAfter:                //实现了MethodInterceptor接口                springAdvice = new AspectJAfterAdvice(                        candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);                break;            case AtAfterReturning:                //实现了AfterReturningAdvice接口，没有实现MethodInterceptor接口                springAdvice = new AspectJAfterReturningAdvice(                        candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);                AfterReturning afterReturningAnnotation = (AfterReturning) aspectJAnnotation.getAnnotation();                if (StringUtils.hasText(afterReturningAnnotation.returning())) {                    springAdvice.setReturningName(afterReturningAnnotation.returning());                }                break;            case AtAfterThrowing:                //实现了MethodInterceptor接口                springAdvice = new AspectJAfterThrowingAdvice(                        candidateAdviceMethod, expressionPointcut, aspectInstanceFactory);                AfterThrowing afterThrowingAnnotation = (AfterThrowing) aspectJAnnotation.getAnnotation();                if (StringUtils.hasText(afterThrowingAnnotation.throwing())) {                    springAdvice.setThrowingName(afterThrowingAnnotation.throwing());                }                break;            default:                throw new UnsupportedOperationException(                        &quot;Unsupported advice type on method: &quot; + candidateAdviceMethod);        }        // Now to configure the advice...        springAdvice.setAspectName(aspectName);        springAdvice.setDeclarationOrder(declarationOrder);        String[] argNames = this.parameterNameDiscoverer.getParameterNames(candidateAdviceMethod);        if (argNames != null) {            springAdvice.setArgumentNamesFromStringArray(argNames);        }        //计算argNames和类型的对应关系        springAdvice.calculateArgumentBindings();        return springAdvice;    }</code></pre><h3 id="createProxy-方法"><a href="#createProxy-方法" class="headerlink" title="createProxy()方法"></a>createProxy()方法</h3><p>该方法首先会判断代理方式，然后调用buildAdvisors()方法将传进来的切面数组包装成advisor切面，然后使用getProxy()此方法会根据生成动态代理的方式创建代理JdkDynamicAopProxy或者ObjenesisCglibAopProxy对象。</p><pre><code class="java">protected Object createProxy(Class&lt;?&gt; beanClass, @Nullable String beanName,      @Nullable Object[] specificInterceptors, TargetSource targetSource) {   if (this.beanFactory instanceof ConfigurableListableBeanFactory) {      AutoProxyUtils.exposeTargetClass((ConfigurableListableBeanFactory) this.beanFactory, beanName, beanClass);   }   //创建代理工厂   ProxyFactory proxyFactory = new ProxyFactory();   proxyFactory.copyFrom(this);   //该属性用来控制代理方式，cglib或JDK动态代理   if (!proxyFactory.isProxyTargetClass()) {      if (shouldProxyTargetClass(beanClass, beanName)) {         //proxyTargetClass 是否对类进行代理，而不是对接口进行代理，设置为true时，使用CGLib代理。         proxyFactory.setProxyTargetClass(true);      }      else {         evaluateProxyInterfaces(beanClass, proxyFactory);      }   }   //把advice类型的增强包装成advisor切面   Advisor[] advisors = buildAdvisors(beanName, specificInterceptors);   proxyFactory.addAdvisors(advisors);   proxyFactory.setTargetSource(targetSource);   customizeProxyFactory(proxyFactory);   ////用来控制代理工厂被配置后，是否还允许修改代理的配置,默认为false   proxyFactory.setFrozen(this.freezeProxy);   if (advisorsPreFiltered()) {      proxyFactory.setPreFiltered(true);   }   //获取代理实例   return proxyFactory.getProxy(getProxyClassLoader());}</code></pre><h4 id="buildAdvisors-方法"><a href="#buildAdvisors-方法" class="headerlink" title="buildAdvisors()方法"></a>buildAdvisors()方法</h4><p>此方法主要作用为扩展，对自己实现MethodInterceptor进行处理。</p><pre><code class="java">protected Advisor[] buildAdvisors(@Nullable String beanName, @Nullable Object[] specificInterceptors) {   // Handle prototypes correctly...   //自定义MethodInterceptor.拿到AnnotationAwareAspectJAutoProxyCreator对象调用setInterceptorNames方法   Advisor[] commonInterceptors = resolveInterceptorNames();   List&lt;Object&gt; allInterceptors = new ArrayList&lt;&gt;();   if (specificInterceptors != null) {      allInterceptors.addAll(Arrays.asList(specificInterceptors));      if (commonInterceptors.length &gt; 0) {         if (this.applyCommonInterceptorsFirst) {            allInterceptors.addAll(0, Arrays.asList(commonInterceptors));         }         else {            allInterceptors.addAll(Arrays.asList(commonInterceptors));         }      }   }   if (logger.isTraceEnabled()) {      int nrOfCommonInterceptors = commonInterceptors.length;      int nrOfSpecificInterceptors = (specificInterceptors != null ? specificInterceptors.length : 0);      logger.trace(&quot;Creating implicit proxy for bean &#39;&quot; + beanName + &quot;&#39; with &quot; + nrOfCommonInterceptors +            &quot; common interceptors and &quot; + nrOfSpecificInterceptors + &quot; specific interceptors&quot;);   }   Advisor[] advisors = new Advisor[allInterceptors.size()];   for (int i = 0; i &lt; allInterceptors.size(); i++) {      //对自定义的advice要进行包装，把advice包装成advisor对象，切面对象      advisors[i] = this.advisorAdapterRegistry.wrap(allInterceptors.get(i));   }   return advisors;}</code></pre><p>wrap()方法</p><p>大部分情况下会进入第一个if中强转后直接返回，如果是自定义实现的MethodInterceptor会包装为DefaultPointcutAdvisor，此对象会被直接设置为全局Advice然后返回。</p><pre><code class="java">public Advisor wrap(Object adviceObject) throws UnknownAdviceTypeException {   if (adviceObject instanceof Advisor) {      return (Advisor) adviceObject;   }   if (!(adviceObject instanceof Advice)) {      throw new UnknownAdviceTypeException(adviceObject);   }   Advice advice = (Advice) adviceObject;   if (advice instanceof MethodInterceptor) {      //用于自定义处理MethodInterceptor      // So well-known it doesn&#39;t even need an adapter.      return new DefaultPointcutAdvisor(advice);   }   for (AdvisorAdapter adapter : this.adapters) {      // Check that it is supported.      if (adapter.supportsAdvice(advice)) {         return new DefaultPointcutAdvisor(advice);      }   }   throw new UnknownAdviceTypeException(advice);}</code></pre><h4 id="getProxy"><a href="#getProxy" class="headerlink" title="getProxy()"></a>getProxy()</h4><h5 id="JdkDynamicAopProxy"><a href="#JdkDynamicAopProxy" class="headerlink" title="JdkDynamicAopProxy"></a>JdkDynamicAopProxy</h5><pre><code class="java">public Object getProxy(@Nullable ClassLoader classLoader) {   if (logger.isTraceEnabled()) {      logger.trace(&quot;Creating JDK dynamic proxy: &quot; + this.advised.getTargetSource());   }   //advised是代理工厂对象   Class&lt;?&gt;[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true);   findDefinedEqualsAndHashCodeMethods(proxiedInterfaces);   return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this);}</code></pre><h5 id="cglib"><a href="#cglib" class="headerlink" title="cglib"></a>cglib</h5><pre><code class="java">public Object getProxy(@Nullable ClassLoader classLoader) {   if (logger.isTraceEnabled()) {      logger.trace(&quot;Creating CGLIB proxy: &quot; + this.advised.getTargetSource());   }   try {      Class&lt;?&gt; rootClass = this.advised.getTargetClass();      Assert.state(rootClass != null, &quot;Target class must be available for creating a CGLIB proxy&quot;);      Class&lt;?&gt; proxySuperClass = rootClass;      if (ClassUtils.isCglibProxyClass(rootClass)) {         proxySuperClass = rootClass.getSuperclass();         Class&lt;?&gt;[] additionalInterfaces = rootClass.getInterfaces();         for (Class&lt;?&gt; additionalInterface : additionalInterfaces) {            this.advised.addInterface(additionalInterface);         }      }      // Validate the class, writing log messages as necessary.      validateClassIfNecessary(proxySuperClass, classLoader);      // Configure CGLIB Enhancer...      Enhancer enhancer = createEnhancer();      if (classLoader != null) {         enhancer.setClassLoader(classLoader);         if (classLoader instanceof SmartClassLoader &amp;&amp;               ((SmartClassLoader) classLoader).isClassReloadable(proxySuperClass)) {            enhancer.setUseCache(false);         }      }      enhancer.setSuperclass(proxySuperClass);      enhancer.setInterfaces(AopProxyUtils.completeProxiedInterfaces(this.advised));      enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE);      enhancer.setStrategy(new ClassLoaderAwareUndeclaredThrowableStrategy(classLoader));      Callback[] callbacks = getCallbacks(rootClass);      Class&lt;?&gt;[] types = new Class&lt;?&gt;[callbacks.length];      for (int x = 0; x &lt; types.length; x++) {         types[x] = callbacks[x].getClass();      }      // fixedInterceptorMap only populated at this point, after getCallbacks call above      enhancer.setCallbackFilter(new ProxyCallbackFilter(            this.advised.getConfigurationOnlyCopy(), this.fixedInterceptorMap, this.fixedInterceptorOffset));      enhancer.setCallbackTypes(types);      // Generate the proxy class and create a proxy instance.      return createProxyClassAndInstance(enhancer, callbacks);   }   catch (CodeGenerationException | IllegalArgumentException ex) {      throw new AopConfigException(&quot;Could not generate CGLIB subclass of &quot; + this.advised.getTargetClass() +            &quot;: Common causes of this problem include using a final class or a non-visible class&quot;,            ex);   }   catch (Throwable ex) {      // TargetSource.getTarget() failed      throw new AopConfigException(&quot;Unexpected AOP exception&quot;, ex);   }}</code></pre><h2 id="AOP方法的调用"><a href="#AOP方法的调用" class="headerlink" title="AOP方法的调用"></a>AOP方法的调用</h2><h3 id="JdkDynamicAopProxy-1"><a href="#JdkDynamicAopProxy-1" class="headerlink" title="JdkDynamicAopProxy"></a>JdkDynamicAopProxy</h3><p>JdkDynamicAopProxy跟被代理对象是一一对应的，对JdkDynamicAopProxy被代理对象的调用会直接进入到invoke()方法中，JdkDynamicAopProxy中含有一个advised代理工厂对象，代理工厂含有所有的切面对象。然后根据advised.exposeProxy进行暴露判断，如果允许暴露可以通过AopContext.currentProxy()获取到被代理的实例。然后调用getInterceptorsAndDynamicInterceptionAdvice()获取执行链。如果没有就直接反射调用，但也会走代理，如果有就会通过proceed()方法调用执行链。TargetSource中封装被代理对象。</p><pre><code class="java">public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {   MethodInvocation invocation;   Object oldProxy = null;   boolean setProxyContext = false;   //从代理工厂中拿到TargetSource对象，该对象包装了被代理实例bean   TargetSource targetSource = this.advised.targetSource;   Object target = null;   try {      //被代理对象的equals方法和hashCode方法是不能被代理的，不会走切面      if (!this.equalsDefined &amp;&amp; AopUtils.isEqualsMethod(method)) {         // The target does not implement the equals(Object) method itself.         return equals(args[0]);      }      else if (!this.hashCodeDefined &amp;&amp; AopUtils.isHashCodeMethod(method)) {         // The target does not implement the hashCode() method itself.         return hashCode();      }      else if (method.getDeclaringClass() == DecoratingProxy.class) {         // There is only getDecoratedClass() declared -&gt; dispatch to proxy config.         return AopProxyUtils.ultimateTargetClass(this.advised);      }      else if (!this.advised.opaque &amp;&amp; method.getDeclaringClass().isInterface() &amp;&amp;            method.getDeclaringClass().isAssignableFrom(Advised.class)) {         // Service invocations on ProxyConfig with the proxy config...         return AopUtils.invokeJoinpointUsingReflection(this.advised, method, args);      }      Object retVal;      if (this.advised.exposeProxy) {         // Make invocation available if necessary.         oldProxy = AopContext.setCurrentProxy(proxy);         setProxyContext = true;      }      // Get as late as possible to minimize the time we &quot;own&quot; the target,      // in case it comes from a pool.      //这个target就是被代理实例      target = targetSource.getTarget();      Class&lt;?&gt; targetClass = (target != null ? target.getClass() : null);      // Get the interception chain for this method.      //从代理工厂中拿过滤器链 Object是一个MethodInterceptor类型的对象，其实就是一个advice对象      List&lt;Object&gt; chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);      // Check whether we have any advice. If we don&#39;t, we can fallback on direct      // reflective invocation of the target, and avoid creating a MethodInvocation.      //如果该方法没有执行链，则说明这个方法不需要被拦截，则直接反射调用      if (chain.isEmpty()) {         // We can skip creating a MethodInvocation: just invoke the target directly         // Note that the final invoker must be an InvokerInterceptor so we know it does         // nothing but a reflective operation on the target, and no hot swapping or fancy proxying.         Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);         retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse);      }      else {         // We need to create a method invocation...         invocation = new ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain);         // Proceed to the joinpoint through the interceptor chain.         retVal = invocation.proceed();      }      // Massage return value if necessary.      Class&lt;?&gt; returnType = method.getReturnType();      if (retVal != null &amp;&amp; retVal == target &amp;&amp;            returnType != Object.class &amp;&amp; returnType.isInstance(proxy) &amp;&amp;            !RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) {         // Special case: it returned &quot;this&quot; and the return type of the method         // is type-compatible. Note that we can&#39;t help if the target sets         // a reference to itself in another returned object.         retVal = proxy;      }      else if (retVal == null &amp;&amp; returnType != Void.TYPE &amp;&amp; returnType.isPrimitive()) {         throw new AopInvocationException(               &quot;Null return value from advice does not match primitive return type for: &quot; + method);      }      return retVal;   }   finally {      if (target != null &amp;&amp; !targetSource.isStatic()) {         // Must have come from TargetSource.         targetSource.releaseTarget(target);      }      if (setProxyContext) {         // Restore old proxy.         AopContext.setCurrentProxy(oldProxy);      }   }}</code></pre><p>getInterceptorsAndDynamicInterceptionAdvice()方法</p><p>该方法中完成对切面的类和方法的匹配，匹配成功后会对切面再次进行包装，主要将非MethodInterceptor对象即@Before、@AfterReturning、@AfterThrowing的Advice包装为MethodInterceptor对象。此处的包装主要是为了方便接下来的调用。</p><pre><code class="java">public List&lt;Object&gt; getInterceptorsAndDynamicInterceptionAdvice(      Advised config, Method method, @Nullable Class&lt;?&gt; targetClass) {   // This is somewhat tricky... We have to process introductions first,   // but we need to preserve order in the ultimate list.   AdvisorAdapterRegistry registry = GlobalAdvisorAdapterRegistry.getInstance();   //从代理工厂中获得该被代理类的所有切面advisor，config就是代理工厂对象   Advisor[] advisors = config.getAdvisors();   List&lt;Object&gt; interceptorList = new ArrayList&lt;&gt;(advisors.length);   Class&lt;?&gt; actualClass = (targetClass != null ? targetClass : method.getDeclaringClass());   Boolean hasIntroductions = null;   for (Advisor advisor : advisors) {      //大部分走这里      if (advisor instanceof PointcutAdvisor) {         // Add it conditionally.         PointcutAdvisor pointcutAdvisor = (PointcutAdvisor) advisor;         //如果切面的pointCut和被代理对象是匹配的，说明是切面要拦截的对象         if (config.isPreFiltered() || pointcutAdvisor.getPointcut().getClassFilter().matches(actualClass)) {            MethodMatcher mm = pointcutAdvisor.getPointcut().getMethodMatcher();            boolean match;            if (mm instanceof IntroductionAwareMethodMatcher) {               if (hasIntroductions == null) {                  hasIntroductions = hasMatchingIntroductions(advisors, actualClass);               }               match = ((IntroductionAwareMethodMatcher) mm).matches(method, actualClass, hasIntroductions);            }            else {               //接下来判断方法是否是切面pointcut需要拦截的方法               match = mm.matches(method, actualClass);            }            //如果类和方法都匹配            if (match) {               //获取到切面advisor中的advice，并且包装成MethodInterceptor类型的对象               MethodInterceptor[] interceptors = registry.getInterceptors(advisor);               if (mm.isRuntime()) {                  // Creating a new object instance in the getInterceptors() method                  // isn&#39;t a problem as we normally cache created chains.                  for (MethodInterceptor interceptor : interceptors) {                     interceptorList.add(new InterceptorAndDynamicMethodMatcher(interceptor, mm));                  }               }               else {                  interceptorList.addAll(Arrays.asList(interceptors));               }            }         }      }      //如果是引介切面      else if (advisor instanceof IntroductionAdvisor) {         IntroductionAdvisor ia = (IntroductionAdvisor) advisor;         if (config.isPreFiltered() || ia.getClassFilter().matches(actualClass)) {            Interceptor[] interceptors = registry.getInterceptors(advisor);            interceptorList.addAll(Arrays.asList(interceptors));         }      }      else {         Interceptor[] interceptors = registry.getInterceptors(advisor);         interceptorList.addAll(Arrays.asList(interceptors));      }   }   return interceptorList;}</code></pre><p>proceed()方法</p><p>该方法首先会判断执行链是否执行完毕，如果执行完毕会直接使用invokeJoinpoint()调用被代理方法。判断方式为当前执行位置是否与执行链长度相等。如果没有执行完毕会调用执行链中Advice的invoke()方法，此时的调用链的顺序与aspect中advice的出现顺序相同，invoke()方法执行完增强的逻辑后会再回调回proceed()方法。AspectJAroundAdvice类型的invoke()方法会直接通过反射调用aroud()方法，在aroud()方法中执行joinPoint.proceed()方法时会回调proceed()方法，MethodBeforeAdviceInterceptor在调用完before()方法后最后会执行proceed()方法，AspectJAfterAdvice类型的invoke()方法会先执行proceed()然后在finally块中调用after()方法。</p><pre><code class="java">public Object proceed() throws Throwable {   // We start with an index of -1 and increment early.   //如果执行链中的advice全部执行完，则直接调用joinPoint方法，就是被代理方法   if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) {      return invokeJoinpoint();   }   Object interceptorOrInterceptionAdvice =         this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex);   if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) {      // Evaluate dynamic method matcher here: static part will already have      // been evaluated and found to match.      InterceptorAndDynamicMethodMatcher dm =            (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice;      Class&lt;?&gt; targetClass = (this.targetClass != null ? this.targetClass : this.method.getDeclaringClass());      if (dm.methodMatcher.matches(this.method, targetClass, this.arguments)) {         return dm.interceptor.invoke(this);      }      else {         // Dynamic matching failed.         // Skip this interceptor and invoke the next in the chain.         return proceed();      }   }   else {      // It&#39;s an interceptor, so we just invoke it: The pointcut will have      // been evaluated statically before this object was constructed.      //调用MethodInterceptor中的invoke方法      return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this);   }}</code></pre><h3 id="cglib-1"><a href="#cglib-1" class="headerlink" title="cglib"></a>cglib</h3><h2 id="自定义实现的MethodInterceptor"><a href="#自定义实现的MethodInterceptor" class="headerlink" title="自定义实现的MethodInterceptor"></a>自定义实现的MethodInterceptor</h2><p>通过使用Spring提供的MethodInterceptor可以实现拦截所有切面方法</p><pre><code class="java">public class MyMethodInterceptor implements MethodInterceptor {    @Override    public Object invoke(MethodInvocation invocation) throws Throwable {        String method = invocation.getMethod().getName();        Object[] arguments = invocation.getArguments();        System.out.println(&quot;全局拦截器触发，method：&quot; + method + &quot;，args：&quot; + arguments);        Object proceed = invocation.proceed();        System.out.println(&quot;执行结果：&quot; + proceed);        return proceed;    }}</code></pre><p>test()方法</p><pre><code class="java">    public void aopTest(){        AnnotationAwareAspectJAutoProxyCreator bean = applicationContext.getBean(AnnotationAwareAspectJAutoProxyCreator.class);        bean.setInterceptorNames(&quot;myMethodInterceptor&quot;);        AopService aopService = applicationContext.getBean(AopService.class);        aopService.testInterceptor();    }</code></pre><p>注意：在之前的aop分析中，spring会根据该类是否有切面来决定是否进入aop入口，aop的入口是在getBean()实例化完成后的initializeBean()方法中，完成aop处理之后会直接将创建的代理类放入缓存，之后的getBean()会直接从缓存中取不会触发实例化方法，也就不会再进入aop。所以，要保证自定义实现的MethodInterceptor能够正常触发，必须要保证setInterceptorNames()方法在getBean()之前完成，而且该类已经有对应的切面。</p>]]></content>
    
    
    <categories>
      
      <category>Spring源码解析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码解析</tag>
      
      <tag>spring</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>spring基于注解的启动方式解析和Bean的作用域</title>
    <link href="/2020/04/18/spring%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84%E5%90%AF%E5%8A%A8%E6%96%B9%E5%BC%8F%E8%A7%A3%E6%9E%90%E5%92%8CBean%E7%9A%84%E4%BD%9C%E7%94%A8%E5%9F%9F/"/>
    <url>/2020/04/18/spring%E5%9F%BA%E4%BA%8E%E6%B3%A8%E8%A7%A3%E7%9A%84%E5%90%AF%E5%8A%A8%E6%96%B9%E5%BC%8F%E8%A7%A3%E6%9E%90%E5%92%8CBean%E7%9A%84%E4%BD%9C%E7%94%A8%E5%9F%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="Bean的作用域"><a href="#Bean的作用域" class="headerlink" title="Bean的作用域"></a>Bean的作用域</h2><p>@Scope注解可以设置bean的作用域，不同的作用域对bean对象的获取方式不同，spring也允许开发者注册自己的作用域，实现对对象作用域的控制。</p><h3 id="doGetBean-的再分析"><a href="#doGetBean-的再分析" class="headerlink" title="doGetBean()的再分析"></a>doGetBean()的再分析</h3><p>如果缓存中获取不到实例且实例作用域不是单例时，spring就会获取到bean的作用域对象，并调用作用域对象的get()方法创建实例。</p><pre><code class="java">protected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType,            @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException {      final String beanName = transformedBeanName(name);    Object bean;    //从缓存中拿实例    // Eagerly check singleton cache for manually registered singletons.    Object sharedInstance = getSingleton(beanName);    //如果缓存里面能拿到实例    if (sharedInstance != null &amp;&amp; args == null) {        if (logger.isTraceEnabled()) {            if (isSingletonCurrentlyInCreation(beanName)) {                logger.trace(&quot;Returning eagerly cached instance of singleton bean &#39;&quot; + beanName +                        &quot;&#39; that is not fully initialized yet - a consequence of a circular reference&quot;);            }            else {                logger.trace(&quot;Returning cached instance of singleton bean &#39;&quot; + beanName + &quot;&#39;&quot;);            }        }        //改方法是FactoryBean接口的调用入口        bean = getObjectForBeanInstance(sharedInstance, name, beanName, null);    }    else {        //如果singletonObjects缓存里面没有，则走下来        // Fail if we&#39;re already creating this bean instance:        // We&#39;re assumably within a circular reference.        //如果是scope 是Prototype的，校验是否有出现循环依赖，如果有则直接报错        if (isPrototypeCurrentlyInCreation(beanName)) {            throw new BeanCurrentlyInCreationException(beanName);        }        // Check if bean definition exists in this factory.        BeanFactory parentBeanFactory = getParentBeanFactory();        if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) {            // Not found -&gt; check parent.            String nameToLookup = originalBeanName(name);            if (parentBeanFactory instanceof AbstractBeanFactory) {                return ((AbstractBeanFactory) parentBeanFactory).doGetBean(                        nameToLookup, requiredType, args, typeCheckOnly);            }            else if (args != null) {                // Delegation to parent with explicit args.                return (T) parentBeanFactory.getBean(nameToLookup, args);            }            else if (requiredType != null) {                // No args -&gt; delegate to standard getBean method.                return parentBeanFactory.getBean(nameToLookup, requiredType);            }            else {                return (T) parentBeanFactory.getBean(nameToLookup);            }        }        if (!typeCheckOnly) {            markBeanAsCreated(beanName);        }        try {            //父子BeanDefinition合并            final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);            checkMergedBeanDefinition(mbd, beanName, args);            //获取依赖对象属性，依赖对象要先实例化            // Guarantee initialization of beans that the current bean depends on.            String[] dependsOn = mbd.getDependsOn();            if (dependsOn != null) {                for (String dep : dependsOn) {                    if (isDependent(beanName, dep)) {                        throw new BeanCreationException(mbd.getResourceDescription(), beanName,                                &quot;Circular depends-on relationship between &#39;&quot; + beanName + &quot;&#39; and &#39;&quot; + dep + &quot;&#39;&quot;);                    }                    registerDependentBean(dep, beanName);                    try {                        //实例化                        getBean(dep);                }                    catch (NoSuchBeanDefinitionException ex) {                        throw new BeanCreationException(mbd.getResourceDescription(), beanName,                                &quot;&#39;&quot; + beanName + &quot;&#39; depends on missing bean &#39;&quot; + dep + &quot;&#39;&quot;, ex);                    }                }            }            //作用域为单例时的实例化            // Create bean instance.            if (mbd.isSingleton()) {                sharedInstance = getSingleton(beanName, () -&gt; {                    try {                        return createBean(beanName, mbd, args);                    }                    catch (BeansException ex) {                        // Explicitly remove instance from singleton cache: It might have been put there                        // eagerly by the creation process, to allow for circular reference resolution.                        // Also remove any beans that received a temporary reference to the bean.                        destroySingleton(beanName);                        throw ex;                    }                });                //该方法是FactoryBean接口的调用入口                bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);            }            else if (mbd.isPrototype()) {                // It&#39;s a prototype -&gt; create a new instance.                Object prototypeInstance = null;                try {                    beforePrototypeCreation(beanName);                    prototypeInstance = createBean(beanName, mbd, args);                }                finally {                    afterPrototypeCreation(beanName);                }                //该方法是FactoryBean接口的调用入口                bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);            }      //其他作用域，如自定义作用域            else {                String scopeName = mbd.getScope();                final Scope scope = this.scopes.get(scopeName);                if (scope == null) {                    throw new IllegalStateException(&quot;No Scope registered for scope name &#39;&quot; + scopeName + &quot;&#39;&quot;);                }                try {                    Object scopedInstance = scope.get(beanName, () -&gt; {                        beforePrototypeCreation(beanName);                        try {                            return createBean(beanName, mbd, args);                        }                        finally {                            afterPrototypeCreation(beanName);                        }                    });                    //改方法是FactoryBean接口的调用入口                    bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd);                }                catch (IllegalStateException ex) {                    throw new BeanCreationException(beanName,                            &quot;Scope &#39;&quot; + scopeName + &quot;&#39; is not active for the current thread; consider &quot; +                            &quot;defining a scoped proxy for this bean if you intend to refer to it from a singleton&quot;,                            ex);                }            }        }        catch (BeansException ex) {            cleanupAfterBeanCreationFailure(beanName);            throw ex;        }    }    // Check if required type matches the type of the actual bean instance.    if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) {        try {            T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType);            if (convertedBean == null) {                throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());            }            return convertedBean;        }        catch (TypeMismatchException ex) {            if (logger.isTraceEnabled()) {                logger.trace(&quot;Failed to convert bean &#39;&quot; + name + &quot;&#39; to required type &#39;&quot; +                        ClassUtils.getQualifiedName(requiredType) + &quot;&#39;&quot;, ex);            }            throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());        }    }    return (T) bean;}</code></pre><h3 id="自定义作用域的实现"><a href="#自定义作用域的实现" class="headerlink" title="自定义作用域的实现"></a>自定义作用域的实现</h3><p>spring在完成BeanDefinition的实例化及IOC、DI后，会调用BeanFactoryPostProcessor接口的postProcessBeanFactory()方法并将beanFactory传递进去，我们可以在这个方法中调用beanFactory的regtsterScope()方法将自定义作用域添加到spring容器中。</p><pre><code class="java">@Componentpublic class ThreadScopeRegistry implements BeanDefinitionRegistryPostProcessor {    private BeanDefinitionRegistry beanDefinitionRegistry;    @Override    public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException {        this.beanDefinitionRegistry = registry;    }    @Override    public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException {        beanFactory.registerScope(&quot;refresh&quot;,new ThreadScope());    }}</code></pre><p>在创建实例时会调用到Scope对象的get()方法， 并向get()方法中传递beanName跟创建方法factory.getObject()。所以我们可以在Scope中精准的控制bean对象的作用域。比如创建一个线程间共享的作用域。</p><pre><code class="java">public class ThreadScope implements Scope {    private ThreadLocal local = new ThreadLocal();    @Override    public Object get(String name, ObjectFactory&lt;?&gt; objectFactory) {        if (local.get()!=null) {            return local.get();        }        Object bean = objectFactory.getObject();        local.set(bean);        return bean;    }}</code></pre><h3 id="spring的作用域"><a href="#spring的作用域" class="headerlink" title="spring的作用域"></a>spring的作用域</h3><p>singleton：spring的默认作用域，在spring容器中仅存在一个Bean实例，在启动时会实例化并放入一级缓存中，之后都是从一级缓存中获取。</p><p>prototype：多实例每次getBean()操作时都会重新创建。启动时不会初始化，只有在getBean()时才会实例化，而且在实例话时不会放入一级缓存，但会放入singletonsCurrentlyInCreation容器，阻断循环依赖。</p><p>request：每次http请求都创建一个实例，仅在web容器中存在。如果以xml文件的方式启动会直接报错。原理就是将创建后的Bean实例放在request中。</p><p>session：与request基本相同，不同的是Bean实例会放在Session中。</p><h2 id="基于注解的启动方式解析"><a href="#基于注解的启动方式解析" class="headerlink" title="基于注解的启动方式解析"></a>基于注解的启动方式解析</h2><h3 id="AnnotationConfigApplicaitonContext类解析"><a href="#AnnotationConfigApplicaitonContext类解析" class="headerlink" title="AnnotationConfigApplicaitonContext类解析"></a>AnnotationConfigApplicaitonContext类解析</h3><p>其构造函数中会创建一个AnnotatedBeanDefinitionReader对象，然后将annotatedClasses对象交给register()方法完成解析</p><pre><code class="java">    public AnnotationConfigApplicationContext(Class&lt;?&gt;... annotatedClasses) {        this();        register(annotatedClasses);        refresh();    }</code></pre><h4 id="register-方法"><a href="#register-方法" class="headerlink" title="register()方法"></a>register()方法</h4><p>register()方法会调用到AnnotatedBeanDefinitionReader的register()方法循环annotatedClasses并调用registerBean()方法进行BeanDefinition的注册。</p><p>doRegisterBean()是registerBean()的主要方法。doRegisterBean()方法首会创建一个BeanDefinition对象，然后将收集annotatedClass的信息并包装为Metadata对象，之后使用AnnotationConfigUtils.processCommonDefinitionAnnotations()对Metadata对象的注解和处理并设置到BeanDefinition对象中，之后将BeanDefinition对象封装为BeanDefinitionHolder并注册。</p><pre><code class="java">    &lt;T&gt; void doRegisterBean(Class&lt;T&gt; annotatedClass, @Nullable Supplier&lt;T&gt; instanceSupplier, @Nullable String name,            @Nullable Class&lt;? extends Annotation&gt;[] qualifiers, BeanDefinitionCustomizer... definitionCustomizers) {        AnnotatedGenericBeanDefinition abd = new AnnotatedGenericBeanDefinition(annotatedClass);        if (this.conditionEvaluator.shouldSkip(abd.getMetadata())) {            return;        }        abd.setInstanceSupplier(instanceSupplier);        ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(abd);        abd.setScope(scopeMetadata.getScopeName());        String beanName = (name != null ? name : this.beanNameGenerator.generateBeanName(abd, this.registry));    //对注解进行收集        AnnotationConfigUtils.processCommonDefinitionAnnotations(abd);        if (qualifiers != null) {            for (Class&lt;? extends Annotation&gt; qualifier : qualifiers) {                if (Primary.class == qualifier) {                    abd.setPrimary(true);                }                else if (Lazy.class == qualifier) {                    abd.setLazyInit(true);                }                else {                    abd.addQualifier(new AutowireCandidateQualifier(qualifier));                }            }        }        for (BeanDefinitionCustomizer customizer : definitionCustomizers) {            customizer.customize(abd);        }    //封装并创建BeanDefinitionHolder对象        BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(abd, beanName);        definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry);        BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, this.registry);    }</code></pre><h5 id="processCommonDefinitionAnnotations-方法"><a href="#processCommonDefinitionAnnotations-方法" class="headerlink" title="processCommonDefinitionAnnotations()方法"></a>processCommonDefinitionAnnotations()方法</h5><p>该方法会对注解进行收集并放到BeanDefinition中。</p><pre><code class="java">static void processCommonDefinitionAnnotations(AnnotatedBeanDefinition abd, AnnotatedTypeMetadata metadata) {   //对@Lazy注解支持   AnnotationAttributes lazy = attributesFor(metadata, Lazy.class);   if (lazy != null) {      abd.setLazyInit(lazy.getBoolean(&quot;value&quot;));   }   else if (abd.getMetadata() != metadata) {      lazy = attributesFor(abd.getMetadata(), Lazy.class);      if (lazy != null) {         abd.setLazyInit(lazy.getBoolean(&quot;value&quot;));      }   }   if (metadata.isAnnotated(Primary.class.getName())) {      abd.setPrimary(true);   }   //对@DependsOn注解支持   AnnotationAttributes dependsOn = attributesFor(metadata, DependsOn.class);   if (dependsOn != null) {      abd.setDependsOn(dependsOn.getStringArray(&quot;value&quot;));   }   AnnotationAttributes role = attributesFor(metadata, Role.class);   if (role != null) {      abd.setRole(role.getNumber(&quot;value&quot;).intValue());   }   AnnotationAttributes description = attributesFor(metadata, Description.class);   if (description != null) {      abd.setDescription(description.getString(&quot;value&quot;));   }}</code></pre><h3 id="AnnotatedBeanDefinitionReader解析"><a href="#AnnotatedBeanDefinitionReader解析" class="headerlink" title="AnnotatedBeanDefinitionReader解析"></a>AnnotatedBeanDefinitionReader解析</h3><p>其构造函数中会调用AnnotationConfigUtils.registerAnnotationConfigProcessors()方法。</p><pre><code class="java">    public AnnotatedBeanDefinitionReader(BeanDefinitionRegistry registry, Environment environment) {        Assert.notNull(registry, &quot;BeanDefinitionRegistry must not be null&quot;);        Assert.notNull(environment, &quot;Environment must not be null&quot;);        this.registry = registry;        this.conditionEvaluator = new ConditionEvaluator(registry, environment, null);        AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry);    }</code></pre><h4 id="registerAnnotationConfigProcessors-方法"><a href="#registerAnnotationConfigProcessors-方法" class="headerlink" title="registerAnnotationConfigProcessors()方法"></a>registerAnnotationConfigProcessors()方法</h4><p>此方法会创建一些BeanDefinitionRegistryPostProcessor类，用于在Bean实例化之前对BeanDefinition进行操作。BeanDefinitionRegistryPostProcessor类继承了BeanFactoryPostProcessor类，在spring会在实例化Bean之前创建BeanFactoryPostProcessor对象，并调用postProcessBeanDefinitionRegistry()方法。</p><pre><code class="java">    public static Set&lt;BeanDefinitionHolder&gt; registerAnnotationConfigProcessors(            BeanDefinitionRegistry registry, @Nullable Object source) {        DefaultListableBeanFactory beanFactory = unwrapDefaultListableBeanFactory(registry);        if (beanFactory != null) {            if (!(beanFactory.getDependencyComparator() instanceof AnnotationAwareOrderComparator)) {                beanFactory.setDependencyComparator(AnnotationAwareOrderComparator.INSTANCE);            }            if (!(beanFactory.getAutowireCandidateResolver() instanceof ContextAnnotationAutowireCandidateResolver)) {                beanFactory.setAutowireCandidateResolver(new ContextAnnotationAutowireCandidateResolver());            }        }        Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;&gt;(8);        if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) {      // 重点关注这行代码中的ConfigurationClassPostProcessor类            RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class);            def.setSource(source);            beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME));        }        if (!registry.containsBeanDefinition(AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) {            RootBeanDefinition def = new RootBeanDefinition(AutowiredAnnotationBeanPostProcessor.class);            def.setSource(source);            beanDefs.add(registerPostProcessor(registry, def, AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME));        }        // Check for JSR-250 support, and if present add the CommonAnnotationBeanPostProcessor.        if (jsr250Present &amp;&amp; !registry.containsBeanDefinition(COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)) {            RootBeanDefinition def = new RootBeanDefinition(CommonAnnotationBeanPostProcessor.class);            def.setSource(source);            beanDefs.add(registerPostProcessor(registry, def, COMMON_ANNOTATION_PROCESSOR_BEAN_NAME));        }        // Check for JPA support, and if present add the PersistenceAnnotationBeanPostProcessor.        if (jpaPresent &amp;&amp; !registry.containsBeanDefinition(PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)) {            RootBeanDefinition def = new RootBeanDefinition();            try {                def.setBeanClass(ClassUtils.forName(PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME,                        AnnotationConfigUtils.class.getClassLoader()));            }            catch (ClassNotFoundException ex) {                throw new IllegalStateException(                        &quot;Cannot load optional framework class: &quot; + PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, ex);            }            def.setSource(source);            beanDefs.add(registerPostProcessor(registry, def, PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME));        }        if (!registry.containsBeanDefinition(EVENT_LISTENER_PROCESSOR_BEAN_NAME)) {            RootBeanDefinition def = new RootBeanDefinition(EventListenerMethodProcessor.class);            def.setSource(source);            beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_PROCESSOR_BEAN_NAME));        }        if (!registry.containsBeanDefinition(EVENT_LISTENER_FACTORY_BEAN_NAME)) {            RootBeanDefinition def = new RootBeanDefinition(DefaultEventListenerFactory.class);            def.setSource(source);            beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_FACTORY_BEAN_NAME));        }        return beanDefs;  }</code></pre><h3 id="ConfigurationClassPostProcessor类解析"><a href="#ConfigurationClassPostProcessor类解析" class="headerlink" title="ConfigurationClassPostProcessor类解析"></a>ConfigurationClassPostProcessor类解析</h3><p>ConfigurationClassPostProcessor类是registerAnnotationConfigProcessors()方法注册的BeanDefinitionRegistryPostProcessor之一。</p><h4 id="processConfigBeanDefinitions-方法"><a href="#processConfigBeanDefinitions-方法" class="headerlink" title="processConfigBeanDefinitions()方法"></a>processConfigBeanDefinitions()方法</h4><p>该方法首先会调用ConfigurationClassUtils.checkConfigurationClassCandidate()方法将具有某些注解的BeanDefination对象放入configCandidates容器中，然后对configCandidates容器进行排序，再使用parse()方法对注解进行处理，最后使用loadBeanDefinitions()完成注册。</p><pre><code class="java">    public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) {        List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;&gt;();        String[] candidateNames = registry.getBeanDefinitionNames();        for (String beanName : candidateNames) {            BeanDefinition beanDef = registry.getBeanDefinition(beanName);            if (ConfigurationClassUtils.isFullConfigurationClass(beanDef) ||                    ConfigurationClassUtils.isLiteConfigurationClass(beanDef)) {                if (logger.isDebugEnabled()) {                    logger.debug(&quot;Bean definition has already been processed as a configuration class: &quot; + beanDef);                }            }            //判断是类上或方法上的注解，            else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) {                configCandidates.add(new BeanDefinitionHolder(beanDef, beanName));            }        }        // Return immediately if no @Configuration classes were found        if (configCandidates.isEmpty()) {            return;        }    //排序        // Sort by previously determined @Order value, if applicable        configCandidates.sort((bd1, bd2) -&gt; {            int i1 = ConfigurationClassUtils.getOrder(bd1.getBeanDefinition());            int i2 = ConfigurationClassUtils.getOrder(bd2.getBeanDefinition());            return Integer.compare(i1, i2);        });        // Detect any custom bean name generation strategy supplied through the enclosing application context        SingletonBeanRegistry sbr = null;        if (registry instanceof SingletonBeanRegistry) {            sbr = (SingletonBeanRegistry) registry;            if (!this.localBeanNameGeneratorSet) {                BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(CONFIGURATION_BEAN_NAME_GENERATOR);                if (generator != null) {                    this.componentScanBeanNameGenerator = generator;                    this.importBeanNameGenerator = generator;                }            }        }        if (this.environment == null) {            this.environment = new StandardEnvironment();        }        //这个类很重要，@ComponentScan @Configuration支持        // Parse each @Configuration class        ConfigurationClassParser parser = new ConfigurationClassParser(                this.metadataReaderFactory, this.problemReporter, this.environment,                this.resourceLoader, this.componentScanBeanNameGenerator, registry);        Set&lt;BeanDefinitionHolder&gt; candidates = new LinkedHashSet&lt;&gt;(configCandidates);        Set&lt;ConfigurationClass&gt; alreadyParsed = new HashSet&lt;&gt;(configCandidates.size());        do {            parser.parse(candidates);            parser.validate();            Set&lt;ConfigurationClass&gt; configClasses = new LinkedHashSet&lt;&gt;(parser.getConfigurationClasses());            configClasses.removeAll(alreadyParsed);            // Read the model and create bean definitions based on its content            if (this.reader == null) {                this.reader = new ConfigurationClassBeanDefinitionReader(                        registry, this.sourceExtractor, this.resourceLoader, this.environment,                        this.importBeanNameGenerator, parser.getImportRegistry());            }            //设置beanDefinition的属性值,重点看，具体执行 import importSource @Bean的逻辑            this.reader.loadBeanDefinitions(configClasses);            alreadyParsed.addAll(configClasses);            candidates.clear();            if (registry.getBeanDefinitionCount() &gt; candidateNames.length) {                String[] newCandidateNames = registry.getBeanDefinitionNames();                Set&lt;String&gt; oldCandidateNames = new HashSet&lt;&gt;(Arrays.asList(candidateNames));                Set&lt;String&gt; alreadyParsedClasses = new HashSet&lt;&gt;();                for (ConfigurationClass configurationClass : alreadyParsed) {                    alreadyParsedClasses.add(configurationClass.getMetadata().getClassName());                }                for (String candidateName : newCandidateNames) {                    if (!oldCandidateNames.contains(candidateName)) {                        BeanDefinition bd = registry.getBeanDefinition(candidateName);                        if (ConfigurationClassUtils.checkConfigurationClassCandidate(bd, this.metadataReaderFactory) &amp;&amp;                                !alreadyParsedClasses.contains(bd.getBeanClassName())) {                            candidates.add(new BeanDefinitionHolder(bd, candidateName));                        }                    }                }                candidateNames = newCandidateNames;            }        }        while (!candidates.isEmpty());        // Register the ImportRegistry as a bean in order to support ImportAware @Configuration classes        if (sbr != null &amp;&amp; !sbr.containsSingleton(IMPORT_REGISTRY_BEAN_NAME)) {            sbr.registerSingleton(IMPORT_REGISTRY_BEAN_NAME, parser.getImportRegistry());        }        if (this.metadataReaderFactory instanceof CachingMetadataReaderFactory) {            // Clear cache in externally provided MetadataReaderFactory; this is a no-op            // for a shared cache since it&#39;ll be cleared by the ApplicationContext.            ((CachingMetadataReaderFactory) this.metadataReaderFactory).clearCache();        }    }</code></pre><h5 id="checkConfigurationClassCandidate-方法"><a href="#checkConfigurationClassCandidate-方法" class="headerlink" title="checkConfigurationClassCandidate()方法"></a>checkConfigurationClassCandidate()方法</h5><p>该方法会检查类上是否有@Component、@ComponentScan、@Import、@ImportResource、@Configuration注解或者方法上是否有@Bean注解，如果有会对用于排序的order属性进行设置。</p><pre><code class="java">    public static boolean checkConfigurationClassCandidate(            BeanDefinition beanDef, MetadataReaderFactory metadataReaderFactory) {        String className = beanDef.getBeanClassName();        if (className == null || beanDef.getFactoryMethodName() != null) {            return false;        }        AnnotationMetadata metadata;        if (beanDef instanceof AnnotatedBeanDefinition &amp;&amp;                className.equals(((AnnotatedBeanDefinition) beanDef).getMetadata().getClassName())) {            // Can reuse the pre-parsed metadata from the given BeanDefinition...            metadata = ((AnnotatedBeanDefinition) beanDef).getMetadata();        }        else if (beanDef instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) beanDef).hasBeanClass()) {            // Check already loaded Class if present...            // since we possibly can&#39;t even load the class file for this Class.            Class&lt;?&gt; beanClass = ((AbstractBeanDefinition) beanDef).getBeanClass();            metadata = new StandardAnnotationMetadata(beanClass, true);        }        else {            try {                MetadataReader metadataReader = metadataReaderFactory.getMetadataReader(className);                metadata = metadataReader.getAnnotationMetadata();            }            catch (IOException ex) {                if (logger.isDebugEnabled()) {                    logger.debug(&quot;Could not find class file for introspecting configuration annotations: &quot; +                            className, ex);                }                return false;            }        }        //判断是否有@Component、@ComponentScan、@Import、@ImportResource、@Configuration注解        if (isFullConfigurationCandidate(metadata)) {            beanDef.setAttribute(CONFIGURATION_CLASS_ATTRIBUTE, CONFIGURATION_CLASS_FULL);        }        //判断是否有@Component注解，或者类上面没注解（xml配置实例化）方法上面有@Bean注解        else if (isLiteConfigurationCandidate(metadata)) {            beanDef.setAttribute(CONFIGURATION_CLASS_ATTRIBUTE, CONFIGURATION_CLASS_LITE);        }        else {            return false;        }        // It&#39;s a full or lite configuration candidate... Let&#39;s determine the order value, if any.    //设置order属性        Integer order = getOrder(metadata);        if (order != null) {            beanDef.setAttribute(ORDER_ATTRIBUTE, order);        }        return true;    }</code></pre><h5 id="parse-方法"><a href="#parse-方法" class="headerlink" title="parse()方法"></a>parse()方法</h5><p>parse()方法最终会调用doProcessConfigurationClass()方法对注解进行处理。此处分析的为componentScanParser中的doProcessConfigurationClass()方法，该方法会使用parse()方法解析某些有特定注解的类，然后对@Import注解进行处理，最后调用scanner.doScan()方法完成包扫描。@Import注解用于引用一个类，该类会交由spring初始化及管理，常用于引入扫描路径之外的类。</p><pre><code class="java">    protected final SourceClass doProcessConfigurationClass(ConfigurationClass configClass, SourceClass sourceClass)            throws IOException {        if (configClass.getMetadata().isAnnotated(Component.class.getName())) {            // Recursively process any member (nested) classes first            processMemberClasses(configClass, sourceClass);        }        // Process any @PropertySource annotations        for (AnnotationAttributes propertySource : AnnotationConfigUtils.attributesForRepeatable(                sourceClass.getMetadata(), PropertySources.class,                org.springframework.context.annotation.PropertySource.class)) {            if (this.environment instanceof ConfigurableEnvironment) {                processPropertySource(propertySource);            }            else {                logger.info(&quot;Ignoring @PropertySource annotation on [&quot; + sourceClass.getMetadata().getClassName() +                        &quot;]. Reason: Environment must implement ConfigurableEnvironment&quot;);            }        }        // Process any @ComponentScan annotations        Set&lt;AnnotationAttributes&gt; componentScans = AnnotationConfigUtils.attributesForRepeatable(                sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class);        if (!componentScans.isEmpty() &amp;&amp;                !this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) {            for (AnnotationAttributes componentScan : componentScans) {                // The config class is annotated with @ComponentScan -&gt; perform the scan immediately        //重点看这个方法                Set&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions =                        this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName());                // Check the set of scanned definitions for any further config classes and parse recursively if needed                for (BeanDefinitionHolder holder : scannedBeanDefinitions) {                    BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition();                    if (bdCand == null) {                        bdCand = holder.getBeanDefinition();                    }          //对特定注解进行扫描                    if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) {                        parse(bdCand.getBeanClassName(), holder.getBeanName());                    }                }            }        }    //用于处理@import注解        // Process any @Import annotations        processImports(configClass, sourceClass, getImports(sourceClass), true);        // Process any @ImportResource annotations        AnnotationAttributes importResource =                AnnotationConfigUtils.attributesFor(sourceClass.getMetadata(), ImportResource.class);        if (importResource != null) {            String[] resources = importResource.getStringArray(&quot;locations&quot;);            Class&lt;? extends BeanDefinitionReader&gt; readerClass = importResource.getClass(&quot;reader&quot;);            for (String resource : resources) {                String resolvedResource = this.environment.resolveRequiredPlaceholders(resource);                configClass.addImportedResource(resolvedResource, readerClass);            }        }        // Process individual @Bean methods        Set&lt;MethodMetadata&gt; beanMethods = retrieveBeanMethodMetadata(sourceClass);        for (MethodMetadata methodMetadata : beanMethods) {            configClass.addBeanMethod(new BeanMethod(methodMetadata, configClass));        }        // Process default methods on interfaces        processInterfaces(configClass, sourceClass);        // Process superclass, if any        if (sourceClass.getMetadata().hasSuperClass()) {            String superclass = sourceClass.getMetadata().getSuperClassName();            if (superclass != null &amp;&amp; !superclass.startsWith(&quot;java&quot;) &amp;&amp;                    !this.knownSuperclasses.containsKey(superclass)) {                this.knownSuperclasses.put(superclass, configClass);                // Superclass found, return its annotation metadata and recurse                return sourceClass.getSuperClass();            }        }        // No superclass -&gt; processing is complete        return null;  }</code></pre><h5 id="loadBeanDefinitions"><a href="#loadBeanDefinitions" class="headerlink" title="loadBeanDefinitions()"></a>loadBeanDefinitions()</h5><p>loadBeanDefinitions最终会调用loadBeanDefinitionsForConfigurationClass()方法完成对@Bean，@Import，@ImportSource注解的处理。@ImportSources注解会引入一个xml文件，loadBeanDefinitionsFromImportedResources()方法会调用loadBeanDefinitions()方法解析xml文件，这个方法在spring以xml文件的方式启动时调用的相同。</p><pre><code class="java">    private void loadBeanDefinitionsForConfigurationClass(            ConfigurationClass configClass, TrackedConditionEvaluator trackedConditionEvaluator) {        if (trackedConditionEvaluator.shouldSkip(configClass)) {            String beanName = configClass.getBeanName();            if (StringUtils.hasLength(beanName) &amp;&amp; this.registry.containsBeanDefinition(beanName)) {                this.registry.removeBeanDefinition(beanName);            }            this.importRegistry.removeImportingClass(configClass.getMetadata().getClassName());            return;        }        if (configClass.isImported()) {            registerBeanDefinitionForImportedConfigurationClass(configClass);        }        for (BeanMethod beanMethod : configClass.getBeanMethods()) {            //@Bean标签的处理            loadBeanDefinitionsForBeanMethod(beanMethod);        }        //@ImportSources注解处理        loadBeanDefinitionsFromImportedResources(configClass.getImportedResources());        //@Import注解处理        loadBeanDefinitionsFromRegistrars(configClass.getImportBeanDefinitionRegistrars());    }</code></pre>]]></content>
    
    
    <categories>
      
      <category>Spring源码解析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码解析</tag>
      
      <tag>spring</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>spring实例化bean的过程</title>
    <link href="/2020/04/15/spring%E5%AE%9E%E4%BE%8B%E5%8C%96bean%E7%9A%84%E8%BF%87%E7%A8%8B/"/>
    <url>/2020/04/15/spring%E5%AE%9E%E4%BE%8B%E5%8C%96bean%E7%9A%84%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="DeanDefinition简介"><a href="#DeanDefinition简介" class="headerlink" title="DeanDefinition简介"></a>DeanDefinition简介</h2><p>BeanDefinition在spring中贯穿始终，spring要根据BeanDefiniton对象来实例化bean。在实例化之前，需要解析bean标签并封装成BeanDefiniton对象。</p><h3 id="BeanDefinition实现类"><a href="#BeanDefinition实现类" class="headerlink" title="BeanDefinition实现类"></a>BeanDefinition实现类</h3><ul><li>ChildBeanDefinition：ChildBeanDefinitio可以继承parent bean definition的设置，对RootBeanDefinition 有一定的依赖关系。 ChildBeanDefinition可以继承父类的构造参数值，属性值并可以重写父类的方法，同时也可以增加新的属性或者方法。若指定初始化方法，销毁方法或者静态工厂方法，ChildBeanDefinition将重写相应父类的设置。</li><li>RootBeanDefinition：RootBeanDefinition是一个可合并的bean definition，即在spring beanFactory运行期间，可以返回一个特定的bean。</li><li>GenericBeanDefinition：从spring 2.5以后了提供的更好的注册bean definition类，用来替代ChildBeanDefinition跟RootBeanDefinition。标准BeanDefinition，除了具有指定类、可选的构造参数值和属性参数这些其它BeanDefinition一样的特性外，它还具有通过parenetName属性来动态设置parent bean definition，而非硬编码作为root bean definition。 </li></ul><h3 id="BeanDefinition中的属性"><a href="#BeanDefinition中的属性" class="headerlink" title="BeanDefinition中的属性"></a>BeanDefinition中的属性</h3><img src="/2020/04/15/spring%E5%AE%9E%E4%BE%8B%E5%8C%96bean%E7%9A%84%E8%BF%87%E7%A8%8B/pic1.png" srcset="/img/loading.gif" class=""><ul><li><p>id：Bean 的唯一标识名。它必须是合法的 XMLID，在整个 XML 文档中唯一。</p></li><li><p>name：用来为id创建一个或多个别名。它可以是任意的字母符合。多个别名之间用逗号或空格分开。</p></li><li><p>class：用来定义类的全限定名(包名+类名)。只有子类 Bean 不用定义该属性。</p></li><li><p>parent：子类Bean 定义它所引用它的父类Bean。这时前面的class 属性失效。子类Bean会继承父类Bean的所有属性，子类Bean也可以覆盖父类 Bean 的属性。注意:子类 Bean 和父类 Bean 是同一 个 Java 类。</p></li><li><p>abstract(默认为”false”)：用来定义Bean是否为抽象Bean。它表示这个Bean将不会被实例化，一般用于父类 Bean，因为父类Bean主要是供子类Bean继承使用。</p></li><li><p>lazy-init(默认为“default”)：用来定义这个Bean是否实现懒初始化。如果为“true”，它将在BeanFactory 启动时初始化所有的SingletonBean。反之，如果为“false”，它只在Bean请求时才开始创建SingletonBean。</p></li><li><p>autowire：(自动装配，默认为“default”：它定义了Bean的自动装载方式。 </p><ul><li><p>“no”：不使用自动装配功能。</p></li><li><p>“byName”：通过 Bean 的属性名实现自动装配。</p></li><li><p>“byType”：通过 Bean 的类型实现自动装配。</p></li><li><p>“constructor”：类似于 byType，但它是用于构造函数的参数的自动组装。</p></li><li><p>“autodetect”：通过 Bean 类的反省机制(introspection)决定是使用“constructor”还是使用“byType”。</p></li></ul></li><li><p>depends-on(依赖对象)：这个Bean在初始化时依赖的对象，这个对象会在这个Bean初始化之前创建。</p></li><li><p>init-method：用来定义Bean的初始化方法，它会在Bean组装之后调用。它必须是一个无参数的方法。</p></li><li><p>destroy-method：用来定义Bean的销毁方法，它在BeanFactory关闭时调用。同样，它也必须是一个无参数的方法。它只能应用于 singletonBean。</p></li><li><p>factory-method：定义创建该Bean对象的工厂方法。它用于下面的“factory-bean”，表示 这个Bean是通过工厂方法创建。此时，“class”属性失效。</p></li><li><p>factory-bean：定义创建该Bean对象的工厂类。如果使用了“factory-bean”则“class”属性失效。</p></li><li><p>autowire-candidate：采用xml格式配置bean时，将&lt;bean/&gt;元素的autowire-candidate属性设置为 false，这样容器在查找自动装配对象时，将不考虑该bean，即它不会被考虑作为其它bean自动装配的候选者，但是该bean本身还是可以使用自动装配来注入其它bean的。</p></li><li><p>MutablePropertyValues：用于封装&lt;property&gt;标签的信息，其实类里面就是有一个list，list里面是PropertyValue对象，PropertyValue就是一个name和value属性，用于封装&lt;property&gt;标签的名称和值信息</p></li><li><p>ConstructorArgumentValues：用于封装&lt;constructor-arg&gt;\标签的信息，其实类里面就是有一个map，map中用构造函数的参数顺序作为key，值作为value存储到map中</p></li><li><p>MethodOverrides：用于封装lookup-method和replaced-method标签的信息，同样的类里面有一个Set对象添加LookupOverride对象和ReplaceOverride对象</p></li></ul><h2 id="invokeBeanFactoryPostProcessors-方法"><a href="#invokeBeanFactoryPostProcessors-方法" class="headerlink" title="invokeBeanFactoryPostProcessors()方法"></a>invokeBeanFactoryPostProcessors()方法</h2><p>invokeBeanFactoryPostProcessors()方法在spring的核心方法refresh()中调用，主要用于处理BeanFactoryPostProcessor接口，是针对BeanFactory的扩展，主要用在bean实例化之前，读取bean的定义，完成对BeanDefinition的修改。</p><p>该方法会实例化和调用所有的BeanFactoryPostProcessor（包括子类BeanDefinitionRegistryPostProcessor），并调用postProcessBeanDefinitionRegistry()方法。</p><p>postProcessBeanDefinitionRegistry()方法的入参为BeanDefinitionRegistry对象，通过这个对象可以完成对所有BeanDefinition对象的增删改查。</p><p>在执行过程中会对实现排序接口的BeanFactoryPostProcessor进行排序，然后按照顺序进行调用。</p><p>调用顺序为: </p><ol><li>实现PriorityOrdered排序接口</li><li>实现Ordered排序接口</li><li>没有实现接口的调用</li></ol><pre><code class="java">    public static void invokeBeanFactoryPostProcessors(            ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) {        // Invoke BeanDefinitionRegistryPostProcessors first, if any.        Set&lt;String&gt; processedBeans = new HashSet&lt;&gt;();        if (beanFactory instanceof BeanDefinitionRegistry) {            BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory;            List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new ArrayList&lt;&gt;();            List&lt;BeanDefinitionRegistryPostProcessor&gt; registryProcessors = new ArrayList&lt;&gt;();            for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) {                if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) {                    BeanDefinitionRegistryPostProcessor registryProcessor =                            (BeanDefinitionRegistryPostProcessor) postProcessor;                    registryProcessor.postProcessBeanDefinitionRegistry(registry);                    registryProcessors.add(registryProcessor);                }                else {                    regularPostProcessors.add(postProcessor);                }            }            // Do not initialize FactoryBeans here: We need to leave all regular beans            // uninitialized to let the bean factory post-processors apply to them!            // Separate between BeanDefinitionRegistryPostProcessors that implement            // PriorityOrdered, Ordered, and the rest.            List&lt;BeanDefinitionRegistryPostProcessor&gt; currentRegistryProcessors = new ArrayList&lt;&gt;();            //获取实现了BeanDefinitionRegistryPostProcessor接口的所有类的BeanDefinition对象的beanName            // First, invoke the BeanDefinitionRegistryPostProcessors that implement PriorityOrdered.            String[] postProcessorNames =                    beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);            for (String ppName : postProcessorNames) {                //判断是否实现了排序接口 PriorityOrdered                if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) {                    currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));                    processedBeans.add(ppName);                }            }            //排序            sortPostProcessors(currentRegistryProcessors, beanFactory);            registryProcessors.addAll(currentRegistryProcessors);            //调用过程            invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);            currentRegistryProcessors.clear();            // Next, invoke the BeanDefinitionRegistryPostProcessors that implement Ordered.            postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);            for (String ppName : postProcessorNames) {                //判断是否是实现的Ordered接口                if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) {          //完成实例化                    currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));                    processedBeans.add(ppName);                }            }            sortPostProcessors(currentRegistryProcessors, beanFactory);            registryProcessors.addAll(currentRegistryProcessors);            invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);            currentRegistryProcessors.clear();            //没实现排序接口的调用            // Finally, invoke all other BeanDefinitionRegistryPostProcessors until no further ones appear.            boolean reiterate = true;            while (reiterate) {                reiterate = false;                postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);                for (String ppName : postProcessorNames) {                    if (!processedBeans.contains(ppName)) {                        currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));                        processedBeans.add(ppName);                        reiterate = true;                    }                }                sortPostProcessors(currentRegistryProcessors, beanFactory);                registryProcessors.addAll(currentRegistryProcessors);                //                invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);                currentRegistryProcessors.clear();            }            //调用postProcessBeanFactory方法            // Now, invoke the postProcessBeanFactory callback of all processors handled so far.            invokeBeanFactoryPostProcessors(registryProcessors, beanFactory);            invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory);        }        else {            // Invoke factory processors registered with the context instance.            invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory);        }        //获取实现了BeanFactoryPostProcessor接口的类，获取beanDefinition的名称        // Do not initialize FactoryBeans here: We need to leave all regular beans        // uninitialized to let the bean factory post-processors apply to them!        String[] postProcessorNames =                beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false);        // Separate between BeanFactoryPostProcessors that implement PriorityOrdered,        // Ordered, and the rest.        List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;();        List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;();        List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;();        for (String ppName : postProcessorNames) {            if (processedBeans.contains(ppName)) {                // skip - already processed in first phase above            }            //实现了PriorityOrdered接口的            else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) {                priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class));            }            //实现了Ordered接口的            else if (beanFactory.isTypeMatch(ppName, Ordered.class)) {                orderedPostProcessorNames.add(ppName);            }            else {                //没实现接口的                nonOrderedPostProcessorNames.add(ppName);            }        }        //排序        // First, invoke the BeanFactoryPostProcessors that implement PriorityOrdered.        sortPostProcessors(priorityOrderedPostProcessors, beanFactory);        //调用        invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory);        // Next, invoke the BeanFactoryPostProcessors that implement Ordered.        List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;();        for (String postProcessorName : orderedPostProcessorNames) {            orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));        }        sortPostProcessors(orderedPostProcessors, beanFactory);        invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory);        // Finally, invoke all other BeanFactoryPostProcessors.        List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;();        for (String postProcessorName : nonOrderedPostProcessorNames) {            nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));        }        invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory);        // Clear cached merged bean definitions since the post-processors might have        // modified the original metadata, e.g. replacing placeholders in values...        beanFactory.clearMetadataCache();    }</code></pre><h2 id="registerBeanPostProcessors-方法"><a href="#registerBeanPostProcessors-方法" class="headerlink" title="registerBeanPostProcessors()方法"></a>registerBeanPostProcessors()方法</h2><p>registerBeanPostProcessors方法主要用于处理BeanPostProcessor接口，会实例化所有的BeanPostProcessor，将所有实现了BeanPostProcessor接口的类加载到BeanFactory中。BeanPostProcessor接口用于在BeanDefination初始化过程中对Bean进行一些操作。</p><p>调用顺序与invokeBeanFactoryPostProcessors()方法相同。</p><pre><code class="java">    public static void registerBeanPostProcessors(            ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) {        //拿到工程里面所有实现了BeanPostProcessor接口的类，获取到BeanDefinition的名称        String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false);        // Register BeanPostProcessorChecker that logs an info message when        // a bean is created during BeanPostProcessor instantiation, i.e. when        // a bean is not eligible for getting processed by all BeanPostProcessors.        int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length;        beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount));        // Separate between BeanPostProcessors that implement PriorityOrdered,        // Ordered, and the rest.        List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;();        List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;&gt;();        List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;();        List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;();        //提前实例化BeanPostProcessor类型的bean，然后bean进行排序        for (String ppName : postProcessorNames) {            if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) {                //getBean是实例化方法，后面我们在讲bean实例化过程是会着重讲到                BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);                priorityOrderedPostProcessors.add(pp);                //判断类型是否是MergedBeanDefinitionPostProcessor，如果是则代码是内部使用的                if (pp instanceof MergedBeanDefinitionPostProcessor) {                    internalPostProcessors.add(pp);                }            }            else if (beanFactory.isTypeMatch(ppName, Ordered.class)) {                orderedPostProcessorNames.add(ppName);            }            else {                nonOrderedPostProcessorNames.add(ppName);            }        }        // First, register the BeanPostProcessors that implement PriorityOrdered.        sortPostProcessors(priorityOrderedPostProcessors, beanFactory);        //注册到BeanFactory中        registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors);        // Next, register the BeanPostProcessors that implement Ordered.        List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;();        for (String ppName : orderedPostProcessorNames) {            BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);            orderedPostProcessors.add(pp);            if (pp instanceof MergedBeanDefinitionPostProcessor) {                internalPostProcessors.add(pp);            }        }        sortPostProcessors(orderedPostProcessors, beanFactory);        registerBeanPostProcessors(beanFactory, orderedPostProcessors);        // Now, register all regular BeanPostProcessors.        List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;();        for (String ppName : nonOrderedPostProcessorNames) {            BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);            nonOrderedPostProcessors.add(pp);            if (pp instanceof MergedBeanDefinitionPostProcessor) {                internalPostProcessors.add(pp);            }        }        registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors);        // Finally, re-register all internal BeanPostProcessors.        sortPostProcessors(internalPostProcessors, beanFactory);        registerBeanPostProcessors(beanFactory, internalPostProcessors);        // Re-register post-processor for detecting inner beans as ApplicationListeners,        // moving it to the end of the processor chain (for picking up proxies etc).        beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));    }</code></pre><h2 id="finishBeanFactoryInitialization-方法"><a href="#finishBeanFactoryInitialization-方法" class="headerlink" title="finishBeanFactoryInitialization()方法"></a>finishBeanFactoryInitialization()方法</h2><p>这个方法是spring中最重要的方法，包括bean实例化过程、ioc、注解支持、BeanPostProcessor的执行、Aop的入口。</p><ol><li><p>preInstantiateSingletons()是他的主要方法，完成对bean的实例化。该方法会遍历beanDefinitionNames，首先会将父子BeanDefinition合并，然后将具有某些特征的BeanDefinition通过getBean()方法实例化。</p><pre><code class="java">    public void preInstantiateSingletons() throws BeansException {        if (logger.isTraceEnabled()) {            logger.trace(&quot;Pre-instantiating singletons in &quot; + this);        }        // Iterate over a copy to allow for init methods which in turn register new bean definitions.        // While this may not be part of the regular factory bootstrap, it does otherwise work fine.        //xml解析时，讲过，把所有beanName都缓存到beanDefinitionNames了        List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames);        // Trigger initialization of all non-lazy singleton beans...        for (String beanName : beanNames) {            //把父BeanDefinition里面的属性拿到子BeanDefinition中      //在解析xml时父子标签会被解析为两个BeanDefinition但只会实例化一个对象            RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName);            //如果不是抽象的，单例的，非懒加载的就实例化            if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) {                //判断bean是否实现了FactoryBean接口，这里可以不看                if (isFactoryBean(beanName)) {                    Object bean = getBean(FACTORY_BEAN_PREFIX + beanName);                    if (bean instanceof FactoryBean) {                        final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) bean;                        boolean isEagerInit;                        if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) {                            isEagerInit = AccessController.doPrivileged((PrivilegedAction&lt;Boolean&gt;)                                            ((SmartFactoryBean&lt;?&gt;) factory)::isEagerInit,                                    getAccessControlContext());                        }                        else {                            isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp;                                    ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit());                        }                        if (isEagerInit) {                            getBean(beanName);                        }                    }                }                else {                    //主要从这里进入，看看实例化过程                    getBean(beanName);                }            }        }        // Trigger post-initialization callback for all applicable beans...        for (String beanName : beanNames) {            Object singletonInstance = getSingleton(beanName);            if (singletonInstance instanceof SmartInitializingSingleton) {                final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance;                if (System.getSecurityManager() != null) {                    AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; {                        smartSingleton.afterSingletonsInstantiated();                        return null;                    }, getAccessControlContext());                }                else {                    smartSingleton.afterSingletonsInstantiated();                }            }        }    }</code></pre></li><li><p>getBean()是实例化的核心方法，doGetBean()方法是getBean()方法的主要方法。该方法首先会尝试从缓存中获取实例，如果没有再进行类的实例化，此时缓存中一般是没有实例的。在类实例化之前会判断类上是否有@Dependon注解，如果有就先实例化@Dependon注解中的类。类的实例化是通过getSingleton()方法实现的。getObjectForBeanInstance()方法用于对BeanFactory接口的支持，之后会进行单独分析。</p><pre><code class="java">protected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType,            @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException {        final String beanName = transformedBeanName(name);        Object bean;        //从缓存中拿实例        // Eagerly check singleton cache for manually registered singletons.        Object sharedInstance = getSingleton(beanName);        //如果缓存里面能拿到实例        if (sharedInstance != null &amp;&amp; args == null) {            if (logger.isTraceEnabled()) {                if (isSingletonCurrentlyInCreation(beanName)) {                    logger.trace(&quot;Returning eagerly cached instance of singleton bean &#39;&quot; + beanName +                            &quot;&#39; that is not fully initialized yet - a consequence of a circular reference&quot;);                }                else {                    logger.trace(&quot;Returning cached instance of singleton bean &#39;&quot; + beanName + &quot;&#39;&quot;);                }            }            //改方法是FactoryBean接口的调用入口            bean = getObjectForBeanInstance(sharedInstance, name, beanName, null);        }        else {            //如果singletonObjects缓存里面没有，则走下来            // Fail if we&#39;re already creating this bean instance:            // We&#39;re assumably within a circular reference.            //如果是scope 是Prototype的，校验是否有出现循环依赖，如果有则直接报错            if (isPrototypeCurrentlyInCreation(beanName)) {                throw new BeanCurrentlyInCreationException(beanName);            }            // Check if bean definition exists in this factory.            BeanFactory parentBeanFactory = getParentBeanFactory();            if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) {                // Not found -&gt; check parent.                String nameToLookup = originalBeanName(name);                if (parentBeanFactory instanceof AbstractBeanFactory) {                    return ((AbstractBeanFactory) parentBeanFactory).doGetBean(                            nameToLookup, requiredType, args, typeCheckOnly);                }                else if (args != null) {                    // Delegation to parent with explicit args.                    return (T) parentBeanFactory.getBean(nameToLookup, args);                }                else if (requiredType != null) {                    // No args -&gt; delegate to standard getBean method.                    return parentBeanFactory.getBean(nameToLookup, requiredType);                }                else {                    return (T) parentBeanFactory.getBean(nameToLookup);                }            }            if (!typeCheckOnly) {                markBeanAsCreated(beanName);            }            try {                //父子BeanDefinition合并                final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);                checkMergedBeanDefinition(mbd, beanName, args);                //获取依赖对象属性，依赖对象要先实例化                // Guarantee initialization of beans that the current bean depends on.                String[] dependsOn = mbd.getDependsOn();                if (dependsOn != null) {                    for (String dep : dependsOn) {                        if (isDependent(beanName, dep)) {                            throw new BeanCreationException(mbd.getResourceDescription(), beanName,                                    &quot;Circular depends-on relationship between &#39;&quot; + beanName + &quot;&#39; and &#39;&quot; + dep + &quot;&#39;&quot;);                        }                        registerDependentBean(dep, beanName);                        try {                            //实例化                            getBean(dep);                    }                        catch (NoSuchBeanDefinitionException ex) {                            throw new BeanCreationException(mbd.getResourceDescription(), beanName,                                    &quot;&#39;&quot; + beanName + &quot;&#39; depends on missing bean &#39;&quot; + dep + &quot;&#39;&quot;, ex);                        }                    }                }                //着重看，大部分是单例的情况                // Create bean instance.                if (mbd.isSingleton()) {                    sharedInstance = getSingleton(beanName, () -&gt; {                        try {                            return createBean(beanName, mbd, args);                        }                        catch (BeansException ex) {                            // Explicitly remove instance from singleton cache: It might have been put there                            // eagerly by the creation process, to allow for circular reference resolution.                            // Also remove any beans that received a temporary reference to the bean.                            destroySingleton(beanName);                            throw ex;                        }                    });                    //该方法是FactoryBean接口的调用入口                    bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);                }                else if (mbd.isPrototype()) {                    // It&#39;s a prototype -&gt; create a new instance.                    Object prototypeInstance = null;                    try {                        beforePrototypeCreation(beanName);                        prototypeInstance = createBean(beanName, mbd, args);                    }                    finally {                        afterPrototypeCreation(beanName);                    }                    //该方法是FactoryBean接口的调用入口                    bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);                }                else {                    String scopeName = mbd.getScope();                    final Scope scope = this.scopes.get(scopeName);                    if (scope == null) {                        throw new IllegalStateException(&quot;No Scope registered for scope name &#39;&quot; + scopeName + &quot;&#39;&quot;);                    }                    try {                        Object scopedInstance = scope.get(beanName, () -&gt; {                            beforePrototypeCreation(beanName);                            try {                                return createBean(beanName, mbd, args);                            }                            finally {                                afterPrototypeCreation(beanName);                            }                        });                        //改方法是FactoryBean接口的调用入口                        bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd);                    }                    catch (IllegalStateException ex) {                        throw new BeanCreationException(beanName,                                &quot;Scope &#39;&quot; + scopeName + &quot;&#39; is not active for the current thread; consider &quot; +                                &quot;defining a scoped proxy for this bean if you intend to refer to it from a singleton&quot;,                                ex);                    }                }            }            catch (BeansException ex) {                cleanupAfterBeanCreationFailure(beanName);                throw ex;            }        }        // Check if required type matches the type of the actual bean instance.        if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) {            try {                T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType);                if (convertedBean == null) {                    throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());                }                return convertedBean;            }            catch (TypeMismatchException ex) {                if (logger.isTraceEnabled()) {                    logger.trace(&quot;Failed to convert bean &#39;&quot; + name + &quot;&#39; to required type &#39;&quot; +                            ClassUtils.getQualifiedName(requiredType) + &quot;&#39;&quot;, ex);                }                throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());            }        }        return (T) bean;    }</code></pre></li><li><p>getSingleton()方法在创建前会将beanName添加到singletonsCurrentlyInCreation容器中，该容器中存储着正在实例化的beanName，然后调用传入的singletonFactory的getObject()方法创建实例，创建完成后再从容器中删除，并放入一级缓存中。getObject()方法会调用上层传入的方法createBean()。</p><pre><code class="java">    public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) {        Assert.notNull(beanName, &quot;Bean name must not be null&quot;);        synchronized (this.singletonObjects) {            //如果缓存中有，则直接返回            Object singletonObject = this.singletonObjects.get(beanName);            if (singletonObject == null) {                if (this.singletonsCurrentlyInDestruction) {                    throw new BeanCreationNotAllowedException(beanName,                            &quot;Singleton bean creation not allowed while singletons of this factory are in destruction &quot; +                            &quot;(Do not request a bean from a BeanFactory in a destroy method implementation!)&quot;);                }                if (logger.isDebugEnabled()) {                    logger.debug(&quot;Creating shared instance of singleton bean &#39;&quot; + beanName + &quot;&#39;&quot;);                }                //把beanName添加到singletonsCurrentlyInCreation Set容器中，在这个集合里面的bean都是正在实例化的bean                beforeSingletonCreation(beanName);                boolean newSingleton = false;                boolean recordSuppressedExceptions = (this.suppressedExceptions == null);                if (recordSuppressedExceptions) {                    this.suppressedExceptions = new LinkedHashSet&lt;&gt;();                }        //调用上层传入的方法创建实例                try {                    singletonObject = singletonFactory.getObject();                    newSingleton = true;                }                catch (IllegalStateException ex) {                    // Has the singleton object implicitly appeared in the meantime -&gt;                    // if yes, proceed with it since the exception indicates that state.                    singletonObject = this.singletonObjects.get(beanName);                    if (singletonObject == null) {                        throw ex;                    }                }                catch (BeanCreationException ex) {                    if (recordSuppressedExceptions) {                        for (Exception suppressedException : this.suppressedExceptions) {                            ex.addRelatedCause(suppressedException);                        }                    }                    throw ex;                }                finally {                    if (recordSuppressedExceptions) {                        this.suppressedExceptions = null;                    }                    //bean创建完成后singletonsCurrentlyInCreation要删除该bean                    afterSingletonCreation(beanName);                }                if (newSingleton) {                    //创建对象成功时，把对象缓存到singletonObjects缓存中,bean创建完成时放入一级缓存                    addSingleton(beanName, singletonObject);                }            }            return singletonObject;        }</code></pre></li><li><p>doCreateBean()是createBean()的主要方法。此方法中首先会通过createBeanInstance()方法创建实例，然后调用applyMergedBeanDefinitionPostProcessors()方法完成注解的装配，收集。addSingletonFactory()方法用于解决循环依赖的问题，之后会进行分析。populateBean()方法用于完成applyMergedBeanDefinitionPostProcessors(方法装配的注解进行处理，主要完成IOC、DI等工作。initializeBean()方法用于完成实例化后的一些操作。</p><pre><code class="java">    protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args)            throws BeanCreationException {        // Instantiate the bean.        BeanWrapper instanceWrapper = null;        if (mbd.isSingleton()) {            instanceWrapper = this.factoryBeanInstanceCache.remove(beanName);        }        if (instanceWrapper == null) {            //创建实例 重点看 重要程度：5            instanceWrapper = createBeanInstance(beanName, mbd, args);        }        final Object bean = instanceWrapper.getWrappedInstance();        Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass();        if (beanType != NullBean.class) {            mbd.resolvedTargetType = beanType;        }        // Allow post-processors to modify the merged bean definition.        synchronized (mbd.postProcessingLock) {            if (!mbd.postProcessed) {                try {                    //CommonAnnotationBeanPostProcessor  支持了@PostConstruct，@PreDestroy,@Resource注解                    //AutowiredAnnotationBeanPostProcessor 支持 @Autowired,@Value注解                    //BeanPostProcessor接口的典型运用，这里要理解这个接口                    //对类中注解的装配过程                    //重要程度5，必须看                    applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName);                }                catch (Throwable ex) {                    throw new BeanCreationException(mbd.getResourceDescription(), beanName,                            &quot;Post-processing of merged bean definition failed&quot;, ex);                }                mbd.postProcessed = true;            }        }        // Eagerly cache singletons to be able to resolve circular references        // even when triggered by lifecycle interfaces like BeanFactoryAware.        //是否    单例bean提前暴露        boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp;                isSingletonCurrentlyInCreation(beanName));        if (earlySingletonExposure) {            if (logger.isTraceEnabled()) {                logger.trace(&quot;Eagerly caching bean &#39;&quot; + beanName +                        &quot;&#39; to allow for resolving potential circular references&quot;);            }            //这里着重理解，对理解循环依赖帮助非常大，重要程度 5   添加三级缓存            addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));        }        // Initialize the bean instance.        Object exposedObject = bean;        try {            //ioc di，依赖注入的核心方法，该方法必须看，重要程度：5            populateBean(beanName, mbd, instanceWrapper);            //bean 实例化+ioc依赖注入完以后的调用，非常重要，重要程度：5            exposedObject = initializeBean(beanName, exposedObject, mbd);        }        catch (Throwable ex) {            if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) {                throw (BeanCreationException) ex;            }            else {                throw new BeanCreationException(                        mbd.getResourceDescription(), beanName, &quot;Initialization of bean failed&quot;, ex);            }        }        if (earlySingletonExposure) {            Object earlySingletonReference = getSingleton(beanName, false);            if (earlySingletonReference != null) {                if (exposedObject == bean) {                    exposedObject = earlySingletonReference;                }                else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) {                    String[] dependentBeans = getDependentBeans(beanName);                    Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;&gt;(dependentBeans.length);                    for (String dependentBean : dependentBeans) {                        if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) {                            actualDependentBeans.add(dependentBean);                        }                    }                    if (!actualDependentBeans.isEmpty()) {                        throw new BeanCurrentlyInCreationException(beanName,                                &quot;Bean with name &#39;&quot; + beanName + &quot;&#39; has been injected into other beans [&quot; +                                StringUtils.collectionToCommaDelimitedString(actualDependentBeans) +                                &quot;] in its raw version as part of a circular reference, but has eventually been &quot; +                                &quot;wrapped. This means that said other beans do not use the final version of the &quot; +                                &quot;bean. This is often the result of over-eager type matching - consider using &quot; +                                &quot;&#39;getBeanNamesOfType&#39; with the &#39;allowEagerInit&#39; flag turned off, for example.&quot;);                    }                }            }        }        // Register bean as disposable.        try {            //注册bean销毁时的类DisposableBeanAdapter            registerDisposableBeanIfNecessary(beanName, bean, mbd);        }        catch (BeanDefinitionValidationException ex) {            throw new BeanCreationException(                    mbd.getResourceDescription(), beanName, &quot;Invalid destruction signature&quot;, ex);        }        return exposedObject;    }</code></pre></li></ol><h3 id="createBeanInstance-方法"><a href="#createBeanInstance-方法" class="headerlink" title="createBeanInstance()方法"></a>createBeanInstance()方法</h3><ol><li><p>createBeanInstance()方法，首先会通过反射拿到Class对象，然后会检查是否有FactoryMethodName属性，如果有则调用instantiateUsingFactoryMethod()方法创建后返回，如果没有会使用determineConstructorsFromBeanPostProcessors()方法扫描有Autowired注解的构造函数，如果有则使用autowireConstructor()方法创建对象并返回，无参构造直接使用反射调用构造函数创建实例并包装为BeanWrapperImpl返回。</p><pre><code class="java">    protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) {        // Make sure bean class is actually resolved at this point.        //反射拿到Class对象        Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName);        if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) {            throw new BeanCreationException(mbd.getResourceDescription(), beanName,                    &quot;Bean class isn&#39;t public, and non-public access not allowed: &quot; + beanClass.getName());        }        Supplier&lt;?&gt; instanceSupplier = mbd.getInstanceSupplier();        if (instanceSupplier != null) {            return obtainFromSupplier(instanceSupplier, beanName);        }        //如果有FactoryMethodName属性        if (mbd.getFactoryMethodName() != null) {            return instantiateUsingFactoryMethod(beanName, mbd, args);        }        // Shortcut when re-creating the same bean...        boolean resolved = false;        boolean autowireNecessary = false;        if (args == null) {            synchronized (mbd.constructorArgumentLock) {                if (mbd.resolvedConstructorOrFactoryMethod != null) {                    resolved = true;                    autowireNecessary = mbd.constructorArgumentsResolved;                }            }        }        if (resolved) {            if (autowireNecessary) {                return autowireConstructor(beanName, mbd, null, null);            }            else {                return instantiateBean(beanName, mbd);            }        }        // Candidate constructors for autowiring?        //寻找当前正在实例化的bean中有@Autowired注解的构造函数        Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName);        if (ctors != null || mbd.getResolvedAutowireMode() == AUTOWIRE_CONSTRUCTOR ||                mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) {            //如果ctors不为空，就说明构造函数上有@Autowired注解            return autowireConstructor(beanName, mbd, ctors, args);        }        // Preferred constructors for default construction?        ctors = mbd.getPreferredConstructors();        if (ctors != null) {            return autowireConstructor(beanName, mbd, ctors, null);        }        //无参构造函数的实例化,大部分的实例是采用的无参构造函数的方式实例化        // No special handling: simply use no-arg constructor.        return instantiateBean(beanName, mbd);    }</code></pre></li><li><p>instantiateUsingFactoryMethod()方法是通过反射调用类中的factoryMethod方法创建对象，然后将对象包装为BeanWrapperImpl对象。BeanWrapperImpl对象中包含对实例的引用，以及一些编辑器和类型转换器，这个对象不需要深究，了解即可。@Bean注解其实就是把方法名称设置到BeanDefinition的factoryMethod属性中。该方法里面的参数解析过程不需要了解。</p><pre><code class="java">    public BeanWrapper instantiateUsingFactoryMethod(            String beanName, RootBeanDefinition mbd, @Nullable Object[] explicitArgs) {        BeanWrapperImpl bw = new BeanWrapperImpl();        this.beanFactory.initBeanWrapper(bw);        Object factoryBean;        Class&lt;?&gt; factoryClass;        boolean isStatic;        String factoryBeanName = mbd.getFactoryBeanName();        if (factoryBeanName != null) {            if (factoryBeanName.equals(beanName)) {                throw new BeanDefinitionStoreException(mbd.getResourceDescription(), beanName,                        &quot;factory-bean reference points back to the same bean definition&quot;);            }            factoryBean = this.beanFactory.getBean(factoryBeanName);            if (mbd.isSingleton() &amp;&amp; this.beanFactory.containsSingleton(beanName)) {                throw new ImplicitlyAppearedSingletonException();            }            factoryClass = factoryBean.getClass();            isStatic = false;        }        else {            // It&#39;s a static factory method on the bean class.            if (!mbd.hasBeanClass()) {                throw new BeanDefinitionStoreException(mbd.getResourceDescription(), beanName,                        &quot;bean definition declares neither a bean class nor a factory-bean reference&quot;);            }            factoryBean = null;            factoryClass = mbd.getBeanClass();            isStatic = true;        }        Method factoryMethodToUse = null;        ArgumentsHolder argsHolderToUse = null;        Object[] argsToUse = null;        if (explicitArgs != null) {            argsToUse = explicitArgs;        }        else {            Object[] argsToResolve = null;            synchronized (mbd.constructorArgumentLock) {                factoryMethodToUse = (Method) mbd.resolvedConstructorOrFactoryMethod;                if (factoryMethodToUse != null &amp;&amp; mbd.constructorArgumentsResolved) {                    // Found a cached factory method...                    argsToUse = mbd.resolvedConstructorArguments;                    if (argsToUse == null) {                        argsToResolve = mbd.preparedConstructorArguments;                    }                }            }            if (argsToResolve != null) {                argsToUse = resolvePreparedArguments(beanName, mbd, bw, factoryMethodToUse, argsToResolve, true);            }        }        if (factoryMethodToUse == null || argsToUse == null) {            // Need to determine the factory method...            // Try all methods with this name to see if they match the given arguments.            factoryClass = ClassUtils.getUserClass(factoryClass);            Method[] rawCandidates = getCandidateMethods(factoryClass, mbd);            List&lt;Method&gt; candidateList = new ArrayList&lt;&gt;();            for (Method candidate : rawCandidates) {                if (Modifier.isStatic(candidate.getModifiers()) == isStatic &amp;&amp; mbd.isFactoryMethod(candidate)) {                    candidateList.add(candidate);                }            }            if (candidateList.size() == 1 &amp;&amp; explicitArgs == null &amp;&amp; !mbd.hasConstructorArgumentValues()) {                Method uniqueCandidate = candidateList.get(0);                if (uniqueCandidate.getParameterCount() == 0) {                    mbd.factoryMethodToIntrospect = uniqueCandidate;                    synchronized (mbd.constructorArgumentLock) {                        mbd.resolvedConstructorOrFactoryMethod = uniqueCandidate;                        mbd.constructorArgumentsResolved = true;                        mbd.resolvedConstructorArguments = EMPTY_ARGS;                    }                    bw.setBeanInstance(instantiate(beanName, mbd, factoryBean, uniqueCandidate, EMPTY_ARGS));                    return bw;                }            }            Method[] candidates = candidateList.toArray(new Method[0]);            AutowireUtils.sortFactoryMethods(candidates);            ConstructorArgumentValues resolvedValues = null;            boolean autowiring = (mbd.getResolvedAutowireMode() == AutowireCapableBeanFactory.AUTOWIRE_CONSTRUCTOR);            int minTypeDiffWeight = Integer.MAX_VALUE;            Set&lt;Method&gt; ambiguousFactoryMethods = null;            int minNrOfArgs;            if (explicitArgs != null) {                minNrOfArgs = explicitArgs.length;            }            else {                // We don&#39;t have arguments passed in programmatically, so we need to resolve the                // arguments specified in the constructor arguments held in the bean definition.                if (mbd.hasConstructorArgumentValues()) {                    ConstructorArgumentValues cargs = mbd.getConstructorArgumentValues();                    resolvedValues = new ConstructorArgumentValues();                    minNrOfArgs = resolveConstructorArguments(beanName, mbd, bw, cargs, resolvedValues);                }                else {                    minNrOfArgs = 0;                }            }            LinkedList&lt;UnsatisfiedDependencyException&gt; causes = null;            for (Method candidate : candidates) {                Class&lt;?&gt;[] paramTypes = candidate.getParameterTypes();                if (paramTypes.length &gt;= minNrOfArgs) {                    ArgumentsHolder argsHolder;                    if (explicitArgs != null) {                        // Explicit arguments given -&gt; arguments length must match exactly.                        if (paramTypes.length != explicitArgs.length) {                            continue;                        }                        argsHolder = new ArgumentsHolder(explicitArgs);                    }                    else {                        // Resolved constructor arguments: type conversion and/or autowiring necessary.                        try {                            String[] paramNames = null;                            ParameterNameDiscoverer pnd = this.beanFactory.getParameterNameDiscoverer();                            if (pnd != null) {                                paramNames = pnd.getParameterNames(candidate);                            }                            argsHolder = createArgumentArray(beanName, mbd, resolvedValues, bw,                                    paramTypes, paramNames, candidate, autowiring, candidates.length == 1);                        }                        catch (UnsatisfiedDependencyException ex) {                            if (logger.isTraceEnabled()) {                                logger.trace(&quot;Ignoring factory method [&quot; + candidate + &quot;] of bean &#39;&quot; + beanName + &quot;&#39;: &quot; + ex);                            }                            // Swallow and try next overloaded factory method.                            if (causes == null) {                                causes = new LinkedList&lt;&gt;();                            }                            causes.add(ex);                            continue;                        }                    }                    int typeDiffWeight = (mbd.isLenientConstructorResolution() ?                            argsHolder.getTypeDifferenceWeight(paramTypes) : argsHolder.getAssignabilityWeight(paramTypes));                    // Choose this factory method if it represents the closest match.                    if (typeDiffWeight &lt; minTypeDiffWeight) {                        factoryMethodToUse = candidate;                        argsHolderToUse = argsHolder;                        argsToUse = argsHolder.arguments;                        minTypeDiffWeight = typeDiffWeight;                        ambiguousFactoryMethods = null;                    }                    // Find out about ambiguity: In case of the same type difference weight                    // for methods with the same number of parameters, collect such candidates                    // and eventually raise an ambiguity exception.                    // However, only perform that check in non-lenient constructor resolution mode,                    // and explicitly ignore overridden methods (with the same parameter signature).                    else if (factoryMethodToUse != null &amp;&amp; typeDiffWeight == minTypeDiffWeight &amp;&amp;                            !mbd.isLenientConstructorResolution() &amp;&amp;                            paramTypes.length == factoryMethodToUse.getParameterCount() &amp;&amp;                            !Arrays.equals(paramTypes, factoryMethodToUse.getParameterTypes())) {                        if (ambiguousFactoryMethods == null) {                            ambiguousFactoryMethods = new LinkedHashSet&lt;&gt;();                            ambiguousFactoryMethods.add(factoryMethodToUse);                        }                        ambiguousFactoryMethods.add(candidate);                    }                }            }            if (factoryMethodToUse == null) {                if (causes != null) {                    UnsatisfiedDependencyException ex = causes.removeLast();                    for (Exception cause : causes) {                        this.beanFactory.onSuppressedException(cause);                    }                    throw ex;                }                List&lt;String&gt; argTypes = new ArrayList&lt;&gt;(minNrOfArgs);                if (explicitArgs != null) {                    for (Object arg : explicitArgs) {                        argTypes.add(arg != null ? arg.getClass().getSimpleName() : &quot;null&quot;);                    }                }                else if (resolvedValues != null) {                    Set&lt;ValueHolder&gt; valueHolders = new LinkedHashSet&lt;&gt;(resolvedValues.getArgumentCount());                    valueHolders.addAll(resolvedValues.getIndexedArgumentValues().values());                    valueHolders.addAll(resolvedValues.getGenericArgumentValues());                    for (ValueHolder value : valueHolders) {                        String argType = (value.getType() != null ? ClassUtils.getShortName(value.getType()) :                                (value.getValue() != null ? value.getValue().getClass().getSimpleName() : &quot;null&quot;));                        argTypes.add(argType);                    }                }                String argDesc = StringUtils.collectionToCommaDelimitedString(argTypes);                throw new BeanCreationException(mbd.getResourceDescription(), beanName,                        &quot;No matching factory method found: &quot; +                        (mbd.getFactoryBeanName() != null ?                            &quot;factory bean &#39;&quot; + mbd.getFactoryBeanName() + &quot;&#39;; &quot; : &quot;&quot;) +                        &quot;factory method &#39;&quot; + mbd.getFactoryMethodName() + &quot;(&quot; + argDesc + &quot;)&#39;. &quot; +                        &quot;Check that a method with the specified name &quot; +                        (minNrOfArgs &gt; 0 ? &quot;and arguments &quot; : &quot;&quot;) +                        &quot;exists and that it is &quot; +                        (isStatic ? &quot;static&quot; : &quot;non-static&quot;) + &quot;.&quot;);            }            else if (void.class == factoryMethodToUse.getReturnType()) {                throw new BeanCreationException(mbd.getResourceDescription(), beanName,                        &quot;Invalid factory method &#39;&quot; + mbd.getFactoryMethodName() +                        &quot;&#39;: needs to have a non-void return type!&quot;);            }            else if (ambiguousFactoryMethods != null) {                throw new BeanCreationException(mbd.getResourceDescription(), beanName,                        &quot;Ambiguous factory method matches found in bean &#39;&quot; + beanName + &quot;&#39; &quot; +                        &quot;(hint: specify index/type/name arguments for simple parameters to avoid type ambiguities): &quot; +                        ambiguousFactoryMethods);            }            if (explicitArgs == null &amp;&amp; argsHolderToUse != null) {                mbd.factoryMethodToIntrospect = factoryMethodToUse;                argsHolderToUse.storeCache(mbd, factoryMethodToUse);            }        }        Assert.state(argsToUse != null, &quot;Unresolved factory method arguments&quot;);        bw.setBeanInstance(instantiate(beanName, mbd, factoryBean, factoryMethodToUse, argsToUse));        return bw;    }</code></pre></li><li><p>determineConstructorsFromBeanPostProcessors()首先会获取所有的BeanPostProcessor，然后调用determineCandidateConstructors()方法获取带@Autowired注解的构造函数。该方法是BeanPostProcessor接口类的首次应用，最终会掉到AutowiredAnnotationBeanPostProcessor类的方法，在方法中会扫描有注解的构造函数并返回。</p><pre><code class="java">    protected Constructor&lt;?&gt;[] determineConstructorsFromBeanPostProcessors(@Nullable Class&lt;?&gt; beanClass, String beanName)            throws BeansException {        if (beanClass != null &amp;&amp; hasInstantiationAwareBeanPostProcessors()) {            //获取所有的BeanPostProcessors            for (BeanPostProcessor bp : getBeanPostProcessors()) {                if (bp instanceof SmartInstantiationAwareBeanPostProcessor) {                    SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp;                    //找到合适的构造函数                    Constructor&lt;?&gt;[] ctors = ibp.determineCandidateConstructors(beanClass, beanName);                    if (ctors != null) {                        return ctors;                    }                }            }        }        return null;    }</code></pre></li><li><p>AutowiredAnnotationBeanPostProcessor中的determineCandidateConstructors()方法，该方法会返回有@Autowired注解的构造函数。该方法首先会扫描所有方法，处理有@Lookup注解的方法，然后拿到所有的构造函数并使用findAutowiredAnnotation()方法对@Autowired跟@Value注解进行扫描，返回有@Autowired的构造函数。</p><pre><code class="java">    public Constructor&lt;?&gt;[] determineCandidateConstructors(Class&lt;?&gt; beanClass, final String beanName)            throws BeanCreationException {        // Let&#39;s check for lookup methods here..        if (!this.lookupMethodsChecked.contains(beanName)) {            try {                //拿到所有方法，循环回调lambda中的内容                ReflectionUtils.doWithMethods(beanClass, method -&gt; {                    //对注解@Lookup的支持，该注解用于替代方法返回值                    Lookup lookup = method.getAnnotation(Lookup.class);                    if (lookup != null) {                        Assert.state(this.beanFactory != null, &quot;No BeanFactory available&quot;);                        LookupOverride override = new LookupOverride(method, lookup.value());                        try {                            RootBeanDefinition mbd = (RootBeanDefinition) this.beanFactory.getMergedBeanDefinition(beanName);                            mbd.getMethodOverrides().addOverride(override);                        }                        catch (NoSuchBeanDefinitionException ex) {                            throw new BeanCreationException(beanName,                                    &quot;Cannot apply @Lookup to beans without corresponding bean definition&quot;);                        }                    }                });            }            catch (IllegalStateException ex) {                throw new BeanCreationException(beanName, &quot;Lookup method resolution failed&quot;, ex);            }            this.lookupMethodsChecked.add(beanName);        }        // Quick check on the concurrent map first, with minimal locking.        Constructor&lt;?&gt;[] candidateConstructors = this.candidateConstructorsCache.get(beanClass);        if (candidateConstructors == null) {            // Fully synchronized resolution now...            synchronized (this.candidateConstructorsCache) {                candidateConstructors = this.candidateConstructorsCache.get(beanClass);                if (candidateConstructors == null) {                    Constructor&lt;?&gt;[] rawCandidates;                    try {                        //获取bean对应的所有构造器                        rawCandidates = beanClass.getDeclaredConstructors();                    }                    catch (Throwable ex) {                        throw new BeanCreationException(beanName,                                &quot;Resolution of declared constructors on bean Class [&quot; + beanClass.getName() +                                &quot;] from ClassLoader [&quot; + beanClass.getClassLoader() + &quot;] failed&quot;, ex);                    }                    List&lt;Constructor&lt;?&gt;&gt; candidates = new ArrayList&lt;&gt;(rawCandidates.length);                    Constructor&lt;?&gt; requiredConstructor = null;                    Constructor&lt;?&gt; defaultConstructor = null;                    Constructor&lt;?&gt; primaryConstructor = BeanUtils.findPrimaryConstructor(beanClass);                    int nonSyntheticConstructors = 0;                    for (Constructor&lt;?&gt; candidate : rawCandidates) {                        if (!candidate.isSynthetic()) {                            nonSyntheticConstructors++;                        }                        else if (primaryConstructor != null) {                            continue;                        }                        //获取到构造函数上的@Autowired注解信息,这个方法可以不看                        AnnotationAttributes ann = findAutowiredAnnotation(candidate);                        if (ann == null) {                            Class&lt;?&gt; userClass = ClassUtils.getUserClass(beanClass);                            if (userClass != beanClass) {                                try {                                    Constructor&lt;?&gt; superCtor =                                            userClass.getDeclaredConstructor(candidate.getParameterTypes());                                    ann = findAutowiredAnnotation(superCtor);                                }                                catch (NoSuchMethodException ex) {                                    // Simply proceed, no equivalent superclass constructor found...                                }                            }                        }                        if (ann != null) {                            if (requiredConstructor != null) {                                throw new BeanCreationException(beanName,                                        &quot;Invalid autowire-marked constructor: &quot; + candidate +                                        &quot;. Found constructor with &#39;required&#39; Autowired annotation already: &quot; +                                        requiredConstructor);                            }                            //获取到@Autowired里面的required方法的值                            boolean required = determineRequiredStatus(ann);                            if (required) {                                if (!candidates.isEmpty()) {                                    throw new BeanCreationException(beanName,                                            &quot;Invalid autowire-marked constructors: &quot; + candidates +                                            &quot;. Found constructor with &#39;required&#39; Autowired annotation: &quot; +                                            candidate);                                }                                requiredConstructor = candidate;                            }                            candidates.add(candidate);                        }                        else if (candidate.getParameterCount() == 0) {                            defaultConstructor = candidate;                        }                    }                    if (!candidates.isEmpty()) {                        // Add default constructor to list of optional constructors, as fallback.                        if (requiredConstructor == null) {                            if (defaultConstructor != null) {                                candidates.add(defaultConstructor);                            }                            else if (candidates.size() == 1 &amp;&amp; logger.isInfoEnabled()) {                                logger.info(&quot;Inconsistent constructor declaration on bean with name &#39;&quot; + beanName +                                        &quot;&#39;: single autowire-marked constructor flagged as optional - &quot; +                                        &quot;this constructor is effectively required since there is no &quot; +                                        &quot;default constructor to fall back to: &quot; + candidates.get(0));                            }                        }                        candidateConstructors = candidates.toArray(new Constructor&lt;?&gt;[0]);                    }                    else if (rawCandidates.length == 1 &amp;&amp; rawCandidates[0].getParameterCount() &gt; 0) {                        candidateConstructors = new Constructor&lt;?&gt;[] {rawCandidates[0]};                    }                    else if (nonSyntheticConstructors == 2 &amp;&amp; primaryConstructor != null &amp;&amp;                            defaultConstructor != null &amp;&amp; !primaryConstructor.equals(defaultConstructor)) {                        candidateConstructors = new Constructor&lt;?&gt;[] {primaryConstructor, defaultConstructor};                    }                    else if (nonSyntheticConstructors == 1 &amp;&amp; primaryConstructor != null) {                        candidateConstructors = new Constructor&lt;?&gt;[] {primaryConstructor};                    }                    else {                        candidateConstructors = new Constructor&lt;?&gt;[0];                    }                    this.candidateConstructorsCache.put(beanClass, candidateConstructors);                }            }        }        return (candidateConstructors.length &gt; 0 ? candidateConstructors : null);    }</code></pre></li><li><p>autowireConstructor()方法中会获取@Autowired的参数，过程中会触发getBean()方法，此时的getBean()方法可能是从缓存中获取。获取到参数后使用反射创建实例并包装为BeanWrapperImpl后返回。</p><pre><code class="java">public BeanWrapper autowireConstructor(String beanName, RootBeanDefinition mbd,            @Nullable Constructor&lt;?&gt;[] chosenCtors, @Nullable Object[] explicitArgs) {        BeanWrapperImpl bw = new BeanWrapperImpl();        //忽略可以不看，设置类型转换器，注册自定义编辑器        this.beanFactory.initBeanWrapper(bw);        Constructor&lt;?&gt; constructorToUse = null;        ArgumentsHolder argsHolderToUse = null;        Object[] argsToUse = null;        if (explicitArgs != null) {            argsToUse = explicitArgs;        }        else {            Object[] argsToResolve = null;            synchronized (mbd.constructorArgumentLock) {                constructorToUse = (Constructor&lt;?&gt;) mbd.resolvedConstructorOrFactoryMethod;                if (constructorToUse != null &amp;&amp; mbd.constructorArgumentsResolved) {                    // Found a cached constructor...                    argsToUse = mbd.resolvedConstructorArguments;                    if (argsToUse == null) {                        argsToResolve = mbd.preparedConstructorArguments;                    }                }            }            if (argsToResolve != null) {                argsToUse = resolvePreparedArguments(beanName, mbd, bw, constructorToUse, argsToResolve, true);            }        }        if (constructorToUse == null || argsToUse == null) {            // Take specified constructors, if any.            Constructor&lt;?&gt;[] candidates = chosenCtors;            if (candidates == null) {                Class&lt;?&gt; beanClass = mbd.getBeanClass();                try {                    candidates = (mbd.isNonPublicAccessAllowed() ?                            beanClass.getDeclaredConstructors() : beanClass.getConstructors());                }                catch (Throwable ex) {                    throw new BeanCreationException(mbd.getResourceDescription(), beanName,                            &quot;Resolution of declared constructors on bean Class [&quot; + beanClass.getName() +                            &quot;] from ClassLoader [&quot; + beanClass.getClassLoader() + &quot;] failed&quot;, ex);                }            }            //mbd.hasConstructorArgumentValues()这个是false的，因为是@Autowired的构造函数，不是&lt;constructor-arg&gt;标签            if (candidates.length == 1 &amp;&amp; explicitArgs == null &amp;&amp; !mbd.hasConstructorArgumentValues()) {                Constructor&lt;?&gt; uniqueCandidate = candidates[0];                //如果是无参构造函数                if (uniqueCandidate.getParameterCount() == 0) {                    synchronized (mbd.constructorArgumentLock) {                        mbd.resolvedConstructorOrFactoryMethod = uniqueCandidate;                        mbd.constructorArgumentsResolved = true;                        mbd.resolvedConstructorArguments = EMPTY_ARGS;                    }                    bw.setBeanInstance(instantiate(beanName, mbd, uniqueCandidate, EMPTY_ARGS));                    return bw;                }            }            // Need to resolve the constructor.            boolean autowiring = (chosenCtors != null ||                    mbd.getResolvedAutowireMode() == AutowireCapableBeanFactory.AUTOWIRE_CONSTRUCTOR);            ConstructorArgumentValues resolvedValues = null;            int minNrOfArgs;            if (explicitArgs != null) {                minNrOfArgs = explicitArgs.length;            }            else {                ConstructorArgumentValues cargs = mbd.getConstructorArgumentValues();                resolvedValues = new ConstructorArgumentValues();                minNrOfArgs = resolveConstructorArguments(beanName, mbd, bw, cargs, resolvedValues);            }            AutowireUtils.sortConstructors(candidates);            int minTypeDiffWeight = Integer.MAX_VALUE;            Set&lt;Constructor&lt;?&gt;&gt; ambiguousConstructors = null;            LinkedList&lt;UnsatisfiedDependencyException&gt; causes = null;            for (Constructor&lt;?&gt; candidate : candidates) {                //获取到构造函数的参数类型                Class&lt;?&gt;[] paramTypes = candidate.getParameterTypes();                if (constructorToUse != null &amp;&amp; argsToUse != null &amp;&amp; argsToUse.length &gt; paramTypes.length) {                    // Already found greedy constructor that can be satisfied -&gt;                    // do not look any further, there are only less greedy constructors left.                    break;                }                if (paramTypes.length &lt; minNrOfArgs) {                    continue;                }                ArgumentsHolder argsHolder;                if (resolvedValues != null) {                    try {                        String[] paramNames = ConstructorPropertiesChecker.evaluate(candidate, paramTypes.length);                        if (paramNames == null) {                            ParameterNameDiscoverer pnd = this.beanFactory.getParameterNameDiscoverer();                            if (pnd != null) {                                //获取构造函数中参数的名称                                paramNames = pnd.getParameterNames(candidate);                            }                        }                        //获取到参数的值，建议不要看，比较深，主流程弄懂后再去细细打磨                        argsHolder = createArgumentArray(beanName, mbd, resolvedValues, bw, paramTypes, paramNames,                                getUserDeclaredConstructor(candidate), autowiring, candidates.length == 1);                    }                    catch (UnsatisfiedDependencyException ex) {                        if (logger.isTraceEnabled()) {                            logger.trace(&quot;Ignoring constructor [&quot; + candidate + &quot;] of bean &#39;&quot; + beanName + &quot;&#39;: &quot; + ex);                        }                        // Swallow and try next constructor.                        if (causes == null) {                            causes = new LinkedList&lt;&gt;();                        }                        causes.add(ex);                        continue;                    }                }                else {                    // Explicit arguments given -&gt; arguments length must match exactly.                    if (paramTypes.length != explicitArgs.length) {                        continue;                    }                    argsHolder = new ArgumentsHolder(explicitArgs);                }                int typeDiffWeight = (mbd.isLenientConstructorResolution() ?                        argsHolder.getTypeDifferenceWeight(paramTypes) : argsHolder.getAssignabilityWeight(paramTypes));                // Choose this constructor if it represents the closest match.                if (typeDiffWeight &lt; minTypeDiffWeight) {                    constructorToUse = candidate;                    argsHolderToUse = argsHolder;                    argsToUse = argsHolder.arguments;                    minTypeDiffWeight = typeDiffWeight;                    ambiguousConstructors = null;                }                else if (constructorToUse != null &amp;&amp; typeDiffWeight == minTypeDiffWeight) {                    if (ambiguousConstructors == null) {                        ambiguousConstructors = new LinkedHashSet&lt;&gt;();                        ambiguousConstructors.add(constructorToUse);                    }                    ambiguousConstructors.add(candidate);                }            }            if (constructorToUse == null) {                if (causes != null) {                    UnsatisfiedDependencyException ex = causes.removeLast();                    for (Exception cause : causes) {                        this.beanFactory.onSuppressedException(cause);                    }                    throw ex;                }                throw new BeanCreationException(mbd.getResourceDescription(), beanName,                        &quot;Could not resolve matching constructor &quot; +                        &quot;(hint: specify index/type/name arguments for simple parameters to avoid type ambiguities)&quot;);            }            else if (ambiguousConstructors != null &amp;&amp; !mbd.isLenientConstructorResolution()) {                throw new BeanCreationException(mbd.getResourceDescription(), beanName,                        &quot;Ambiguous constructor matches found in bean &#39;&quot; + beanName + &quot;&#39; &quot; +                        &quot;(hint: specify index/type/name arguments for simple parameters to avoid type ambiguities): &quot; +                        ambiguousConstructors);            }            if (explicitArgs == null &amp;&amp; argsHolderToUse != null) {                argsHolderToUse.storeCache(mbd, constructorToUse);            }        }        Assert.state(argsToUse != null, &quot;Unresolved constructor arguments&quot;);        //有参构造函数的实例化，反射实例化        bw.setBeanInstance(instantiate(beanName, mbd, constructorToUse, argsToUse));        return bw;    }</code></pre></li></ol><h3 id="applyMergedBeanDefinitionPostProcessors-方法"><a href="#applyMergedBeanDefinitionPostProcessors-方法" class="headerlink" title="applyMergedBeanDefinitionPostProcessors()方法"></a>applyMergedBeanDefinitionPostProcessors()方法</h3><ol><li><p>applyMergedBeanDefinitionPostProcessors()方法会拿到所有的BeanPostProcessor接口，然后调用MergedBeanDefinitionPostProcessor接口的postProcessMergedBeanDefinition()方法完成注解的收集。</p><pre><code class="java">    protected void applyMergedBeanDefinitionPostProcessors(RootBeanDefinition mbd, Class&lt;?&gt; beanType, String beanName) {        for (BeanPostProcessor bp : getBeanPostProcessors()) {            if (bp instanceof MergedBeanDefinitionPostProcessor) {                MergedBeanDefinitionPostProcessor bdp = (MergedBeanDefinitionPostProcessor) bp;                bdp.postProcessMergedBeanDefinition(mbd, beanType, beanName);            }        }    }</code></pre></li><li><p>CommonAnnotationBeanPostProcessor的postProcessMergedBeanDefinition()方法会调用InitDestroyAnnotationBeanPostProcessor的postProcessMergedBeanDefinition()方法完成@postConstruct跟@PreDestory()注解的扫描，然后调用findResourceMetadata()扫描@Resource注解。</p><pre><code>    public void postProcessMergedBeanDefinition(RootBeanDefinition beanDefinition, Class&lt;?&gt; beanType, String beanName) {        //扫描@PostConstruct @PreDestroy        super.postProcessMergedBeanDefinition(beanDefinition, beanType, beanName);        //扫描@Resource,扫描属性和方法上面是否有@Resource注解，如果有则收集起来封装成对象        InjectionMetadata metadata = findResourceMetadata(beanName, beanType, null);        metadata.checkConfigMembers(beanDefinition);    }</code></pre></li><li><p>InitDestroyAnnotationBeanPostProcessor的postProcessMergedBeanDefinition()方法会调用findLifecycleMetadata()方法，然后再次封装其返回的LifecycleMetadata对象。buildLifecycleMetadata()是findLifecycleMetadata()的核心方法，会循环判断类中的所有方法是否有@postConstruct跟@PreDestory()注解，如果有就将这个方法放到容器中，最后包装为LifecycleMetadata并返回。</p><pre><code class="java">    private LifecycleMetadata buildLifecycleMetadata(final Class&lt;?&gt; clazz) {        List&lt;LifecycleElement&gt; initMethods = new ArrayList&lt;&gt;();        List&lt;LifecycleElement&gt; destroyMethods = new ArrayList&lt;&gt;();        Class&lt;?&gt; targetClass = clazz;        do {            final List&lt;LifecycleElement&gt; currInitMethods = new ArrayList&lt;&gt;();            final List&lt;LifecycleElement&gt; currDestroyMethods = new ArrayList&lt;&gt;();            ReflectionUtils.doWithLocalMethods(targetClass, method -&gt; {                if (this.initAnnotationType != null &amp;&amp; method.isAnnotationPresent(this.initAnnotationType)) {                    LifecycleElement element = new LifecycleElement(method);                    currInitMethods.add(element);                    if (logger.isTraceEnabled()) {                        logger.trace(&quot;Found init method on class [&quot; + clazz.getName() + &quot;]: &quot; + method);                    }                }                if (this.destroyAnnotationType != null &amp;&amp; method.isAnnotationPresent(this.destroyAnnotationType)) {                    currDestroyMethods.add(new LifecycleElement(method));                    if (logger.isTraceEnabled()) {                        logger.trace(&quot;Found destroy method on class [&quot; + clazz.getName() + &quot;]: &quot; + method);                    }                }            });            initMethods.addAll(0, currInitMethods);            destroyMethods.addAll(currDestroyMethods);            targetClass = targetClass.getSuperclass();        }        while (targetClass != null &amp;&amp; targetClass != Object.class);        return new LifecycleMetadata(clazz, initMethods, destroyMethods);    }</code></pre></li><li><p>findResourceMetadata()方法会调用buildResourceMetadata()方法获取包装后的InjectionMetadata，放入缓存后返回。</p><pre><code class="java">    private InjectionMetadata findResourceMetadata(String beanName, final Class&lt;?&gt; clazz, @Nullable PropertyValues pvs) {        // Fall back to class name as cache key, for backwards compatibility with custom callers.        String cacheKey = (StringUtils.hasLength(beanName) ? beanName : clazz.getName());        // Quick check on the concurrent map first, with minimal locking.        InjectionMetadata metadata = this.injectionMetadataCache.get(cacheKey);        if (InjectionMetadata.needsRefresh(metadata, clazz)) {            synchronized (this.injectionMetadataCache) {                metadata = this.injectionMetadataCache.get(cacheKey);                if (InjectionMetadata.needsRefresh(metadata, clazz)) {                    if (metadata != null) {                        metadata.clear(pvs);                    }                    //主要看这个方法                    metadata = buildResourceMetadata(clazz);                    this.injectionMetadataCache.put(cacheKey, metadata);                }            }        }        return metadata;    }</code></pre></li><li><p>buildResourceMetadata()方法会去获取类上的所有属性，然后循环调用lambda中的内容放到容器中，最后封装为InjectionMetadata对象后返回。</p><pre><code class="java">    private InjectionMetadata buildResourceMetadata(final Class&lt;?&gt; clazz) {        List&lt;InjectionMetadata.InjectedElement&gt; elements = new ArrayList&lt;&gt;();        Class&lt;?&gt; targetClass = clazz;        do {            final List&lt;InjectionMetadata.InjectedElement&gt; currElements = new ArrayList&lt;&gt;();            ReflectionUtils.doWithLocalFields(targetClass, field -&gt; {                if (webServiceRefClass != null &amp;&amp; field.isAnnotationPresent(webServiceRefClass)) {                    if (Modifier.isStatic(field.getModifiers())) {                        throw new IllegalStateException(&quot;@WebServiceRef annotation is not supported on static fields&quot;);                    }                    currElements.add(new WebServiceRefElement(field, field, null));                }                else if (ejbRefClass != null &amp;&amp; field.isAnnotationPresent(ejbRefClass)) {                    if (Modifier.isStatic(field.getModifiers())) {                        throw new IllegalStateException(&quot;@EJB annotation is not supported on static fields&quot;);                    }                    currElements.add(new EjbRefElement(field, field, null));                }                else if (field.isAnnotationPresent(Resource.class)) {                    if (Modifier.isStatic(field.getModifiers())) {                        throw new IllegalStateException(&quot;@Resource annotation is not supported on static fields&quot;);                    }                    if (!this.ignoredResourceTypes.contains(field.getType().getName())) {                        currElements.add(new ResourceElement(field, field, null));                    }                }            });            ReflectionUtils.doWithLocalMethods(targetClass, method -&gt; {                Method bridgedMethod = BridgeMethodResolver.findBridgedMethod(method);                if (!BridgeMethodResolver.isVisibilityBridgeMethodPair(method, bridgedMethod)) {                    return;                }                if (method.equals(ClassUtils.getMostSpecificMethod(method, clazz))) {                    if (webServiceRefClass != null &amp;&amp; bridgedMethod.isAnnotationPresent(webServiceRefClass)) {                        if (Modifier.isStatic(method.getModifiers())) {                            throw new IllegalStateException(&quot;@WebServiceRef annotation is not supported on static methods&quot;);                        }                        if (method.getParameterCount() != 1) {                            throw new IllegalStateException(&quot;@WebServiceRef annotation requires a single-arg method: &quot; + method);                        }                        PropertyDescriptor pd = BeanUtils.findPropertyForMethod(bridgedMethod, clazz);                        currElements.add(new WebServiceRefElement(method, bridgedMethod, pd));                    }                    else if (ejbRefClass != null &amp;&amp; bridgedMethod.isAnnotationPresent(ejbRefClass)) {                        if (Modifier.isStatic(method.getModifiers())) {                            throw new IllegalStateException(&quot;@EJB annotation is not supported on static methods&quot;);                        }                        if (method.getParameterCount() != 1) {                            throw new IllegalStateException(&quot;@EJB annotation requires a single-arg method: &quot; + method);                        }                        PropertyDescriptor pd = BeanUtils.findPropertyForMethod(bridgedMethod, clazz);                        currElements.add(new EjbRefElement(method, bridgedMethod, pd));                    }                    else if (bridgedMethod.isAnnotationPresent(Resource.class)) {                        if (Modifier.isStatic(method.getModifiers())) {                            throw new IllegalStateException(&quot;@Resource annotation is not supported on static methods&quot;);                        }                        Class&lt;?&gt;[] paramTypes = method.getParameterTypes();                        if (paramTypes.length != 1) {                            throw new IllegalStateException(&quot;@Resource annotation requires a single-arg method: &quot; + method);                        }                        if (!this.ignoredResourceTypes.contains(paramTypes[0].getName())) {                            PropertyDescriptor pd = BeanUtils.findPropertyForMethod(bridgedMethod, clazz);                            currElements.add(new ResourceElement(method, bridgedMethod, pd));                        }                    }                }            });            elements.addAll(0, currElements);            targetClass = targetClass.getSuperclass();        }        while (targetClass != null &amp;&amp; targetClass != Object.class);        return new InjectionMetadata(clazz, elements);    }</code></pre></li></ol><p>注：其他类型的BeanPostProcessor收集过程与InitDestroyAnnotationBeanPostProcessor基本相同，只是扫描的注解不同，此处不在赘述。</p><h3 id="populateBean-方法"><a href="#populateBean-方法" class="headerlink" title="populateBean()方法"></a>populateBean()方法</h3><ol><li><p>依赖注入的核心方法，主要方法为postProcessProperties()，依据applyMergedBeanDefinitionPostProcessors收集的注解进行依赖注入。</p><pre><code class="java">    protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) {        if (bw == null) {            if (mbd.hasPropertyValues()) {                throw new BeanCreationException(                        mbd.getResourceDescription(), beanName, &quot;Cannot apply property values to null instance&quot;);            }            else {                // Skip property population phase for null instance.                return;            }        }        // Give any InstantiationAwareBeanPostProcessors the opportunity to modify the        // state of the bean before properties are set. This can be used, for example,        // to support styles of field injection.        boolean continueWithPropertyPopulation = true;        //这里很有意思，写接口可以让所有类都不能依赖注入        if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) {            for (BeanPostProcessor bp : getBeanPostProcessors()) {                if (bp instanceof InstantiationAwareBeanPostProcessor) {                    InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;                    if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) {                        //是否需要DI，依赖注入                        continueWithPropertyPopulation = false;                        break;                    }                }            }        }        if (!continueWithPropertyPopulation) {            return;        }        PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null);        if (mbd.getResolvedAutowireMode() == AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == AUTOWIRE_BY_TYPE) {            MutablePropertyValues newPvs = new MutablePropertyValues(pvs);            // Add property values based on autowire by name if applicable.            if (mbd.getResolvedAutowireMode() == AUTOWIRE_BY_NAME) {                autowireByName(beanName, mbd, bw, newPvs);            }            // Add property values based on autowire by type if applicable.            if (mbd.getResolvedAutowireMode() == AUTOWIRE_BY_TYPE) {                autowireByType(beanName, mbd, bw, newPvs);            }            pvs = newPvs;        }        boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors();        boolean needsDepCheck = (mbd.getDependencyCheck() != AbstractBeanDefinition.DEPENDENCY_CHECK_NONE);        PropertyDescriptor[] filteredPds = null;        //重点看这个if代码块，重要程度 5        if (hasInstAwareBpps) {            if (pvs == null) {                pvs = mbd.getPropertyValues();            }            for (BeanPostProcessor bp : getBeanPostProcessors()) {                if (bp instanceof InstantiationAwareBeanPostProcessor) {                    InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;                    //依赖注入过程，@Autowired的支持                    PropertyValues pvsToUse = ibp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName);                    if (pvsToUse == null) {                        if (filteredPds == null) {                            filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching);                        }                        //老版本用这个完成依赖注入过程，@Autowired的支持                        pvsToUse = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName);                        if (pvsToUse == null) {                            return;                        }                    }                    pvs = pvsToUse;                }            }        }        if (needsDepCheck) {            if (filteredPds == null) {                filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching);            }            checkDependencies(beanName, mbd, filteredPds, pvs);        }        //这个方法很鸡肋了，建议不看，是老版本用&lt;property name=&quot;username&quot; value=&quot;Jack&quot;/&gt;        //标签做依赖注入的代码实现，复杂且无用        if (pvs != null) {            applyPropertyValues(beanName, mbd, bw, pvs);        }    }</code></pre></li><li><p>AutowiredAnnotationBeanPostProcessor的postProcessProperties()方法。该方法首先从缓存中获取之前收集好的所有InjectionMetadata对象，然后调用循环调用inject()方法进行注入。</p><pre><code class="java">    public PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName) {    // 从缓存中获取InjectionMetadata对象        InjectionMetadata metadata = findAutowiringMetadata(beanName, bean.getClass(), pvs);        try {            metadata.inject(bean, beanName, pvs);        }        catch (BeanCreationException ex) {            throw ex;        }        catch (Throwable ex) {            throw new BeanCreationException(beanName, &quot;Injection of autowired dependencies failed&quot;, ex);        }        return pvs;    }</code></pre></li><li><p>此处为inject()方法，先从spring容器中拿到参数对应的值，这时可能会触发实例化，然后通过反射完成对象的注入。</p><pre><code class="java">        protected void inject(Object bean, @Nullable String beanName, @Nullable PropertyValues pvs) throws Throwable {            Field field = (Field) this.member;            Object value;            if (this.cached) {                value = resolvedCachedArgument(beanName, this.cachedFieldValue);            }            else {                DependencyDescriptor desc = new DependencyDescriptor(field, this.required);                desc.setContainingClass(bean.getClass());                Set&lt;String&gt; autowiredBeanNames = new LinkedHashSet&lt;&gt;(1);                Assert.state(beanFactory != null, &quot;No BeanFactory available&quot;);                TypeConverter typeConverter = beanFactory.getTypeConverter();                try {                    value = beanFactory.resolveDependency(desc, beanName, autowiredBeanNames, typeConverter);                }                catch (BeansException ex) {                    throw new UnsatisfiedDependencyException(null, beanName, new InjectionPoint(field), ex);                }                synchronized (this) {                    if (!this.cached) {                        if (value != null || this.required) {                            this.cachedFieldValue = desc;                            registerDependentBeans(beanName, autowiredBeanNames);                            if (autowiredBeanNames.size() == 1) {                                String autowiredBeanName = autowiredBeanNames.iterator().next();                                if (beanFactory.containsBean(autowiredBeanName) &amp;&amp;                                        beanFactory.isTypeMatch(autowiredBeanName, field.getType())) {                                    this.cachedFieldValue = new ShortcutDependencyDescriptor(                                            desc, autowiredBeanName, field.getType());                                }                            }                        }                        else {                            this.cachedFieldValue = null;                        }                        this.cached = true;                    }                }            }            if (value != null) {                ReflectionUtils.makeAccessible(field);                field.set(bean, value);            }        }    }</code></pre></li></ol><p>注：其他类的postProcessProperties与此处基本相同。</p><h3 id="initializeBean-方法"><a href="#initializeBean-方法" class="headerlink" title="initializeBean()方法"></a>initializeBean()方法</h3><ol><li><p>initializeBean()方法是BeanDefinition实例化完成后的操作。首先会使用applyBeanPostProcessorsBeforeInitialization()方法对@PostConstruct，Aware接口进行调用，然后使用invokeInitMethods()接口，完成对InitializingBean接口的afterPropertiesSet()方法、BeanDefination中init-method对应方法的调用。这些注解在applyMergedBeanDefinitionPostProcessors()方法中已经被收集并封装为Metadata对象。applyBeanPostProcessorsAfterInitialization()方法是aop入口类，在之后会有详细分析。</p><pre><code class="java">    protected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) {        if (System.getSecurityManager() != null) {            AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; {                invokeAwareMethods(beanName, bean);                return null;            }, getAccessControlContext());        }        else {            //调用Aware方法            invokeAwareMethods(beanName, bean);        }        Object wrappedBean = bean;        if (mbd == null || !mbd.isSynthetic()) {            //对类中某些特殊方法的调用，比如@PostConstruct，Aware接口，非常重要 重要程度 ：5            wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName);        }        try {            //InitializingBean接口，afterPropertiesSet，init-method属性调用,非常重要，重要程度：5            invokeInitMethods(beanName, wrappedBean, mbd);        }        catch (Throwable ex) {            throw new BeanCreationException(                    (mbd != null ? mbd.getResourceDescription() : null),                    beanName, &quot;Invocation of init method failed&quot;, ex);        }        if (mbd == null || !mbd.isSynthetic()) {            wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);        }        return wrappedBean;    }</code></pre></li><li><p>applyBeanPostProcessorsBeforeInitialization()方法</p><pre><code class="java">    @Override    public Object applyBeanPostProcessorsBeforeInitialization(Object existingBean, String beanName)            throws BeansException {        Object result = existingBean;        /*        * 着重看几个        * 1、ApplicationContextAwareProcessor  对某个Aware接口方法的调用        * 2、InitDestroyAnnotationBeanPostProcessor  @PostConstruct注解方法的调用        *        * 3、ImportAwareBeanPostProcessor  对ImportAware类型实例setImportMetadata调用        * 这个对理解springboot有很大帮助。 这里暂时不需要深入看        * */        for (BeanPostProcessor processor : getBeanPostProcessors()) {            Object current = processor.postProcessBeforeInitialization(result, beanName);            if (current == null) {                return result;            }            result = current;        }        return result;    }</code></pre></li><li><p>InitDestroyAnnotationBeanPostProcessor的postProcessBeforeInitialization()方法会通过反射调用metadata中的方法，此处被调用的方法不能有任何参数。</p><pre><code class="java">    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {        LifecycleMetadata metadata = findLifecycleMetadata(bean.getClass());        try {            //调用@PostConstruct注解的方法            metadata.invokeInitMethods(bean, beanName);        }        catch (InvocationTargetException ex) {            throw new BeanCreationException(beanName, &quot;Invocation of init method failed&quot;, ex.getTargetException());        }        catch (Throwable ex) {            throw new BeanCreationException(beanName, &quot;Failed to invoke init method&quot;, ex);        }        return bean;    }</code></pre></li><li><p>invokeInitMethods()方法首先会判断bean是否实现了InitializingBean接口，如果是就直接通过反射调用该接口的afterPropertiesSet()方法。然后会通过invokeCustomInitMethod()方法调用initMethod()方法方法。如果要在Bean实例化之后去做一些事情可以实现InitializingBean接口，比如缓存预热，注册到注册中心等，Mybatis中xml的解析也是用了该接口。</p><pre><code class="java">    protected void invokeInitMethods(String beanName, final Object bean, @Nullable RootBeanDefinition mbd)            throws Throwable {        boolean isInitializingBean = (bean instanceof InitializingBean);        if (isInitializingBean &amp;&amp; (mbd == null || !mbd.isExternallyManagedInitMethod(&quot;afterPropertiesSet&quot;))) {            if (logger.isTraceEnabled()) {                logger.trace(&quot;Invoking afterPropertiesSet() on bean with name &#39;&quot; + beanName + &quot;&#39;&quot;);            }            if (System.getSecurityManager() != null) {                try {                    AccessController.doPrivileged((PrivilegedExceptionAction&lt;Object&gt;) () -&gt; {                        ((InitializingBean) bean).afterPropertiesSet();                        return null;                    }, getAccessControlContext());                }                catch (PrivilegedActionException pae) {                    throw pae.getException();                }            }            else {                ((InitializingBean) bean).afterPropertiesSet();            }        }        if (mbd != null &amp;&amp; bean.getClass() != NullBean.class) {            String initMethodName = mbd.getInitMethodName();            if (StringUtils.hasLength(initMethodName) &amp;&amp;                    !(isInitializingBean &amp;&amp; &quot;afterPropertiesSet&quot;.equals(initMethodName)) &amp;&amp;                    !mbd.isExternallyManagedInitMethod(initMethodName)) {                invokeCustomInitMethod(beanName, bean, mbd);            }        }    }</code></pre></li></ol><h3 id="registerDisposableBeanIfNecessary-方法"><a href="#registerDisposableBeanIfNecessary-方法" class="headerlink" title="registerDisposableBeanIfNecessary()方法"></a>registerDisposableBeanIfNecessary()方法</h3><p>该方法首先会将需要销毁的Bean包装为DisposableBeanAdapter对象，然后通过registerDisposableBean()方法放入disposableBeans容器中。</p><pre><code class="java">    protected void registerDisposableBeanIfNecessary(String beanName, Object bean, RootBeanDefinition mbd) {        AccessControlContext acc = (System.getSecurityManager() != null ? getAccessControlContext() : null);        if (!mbd.isPrototype() &amp;&amp; requiresDestruction(bean, mbd)) {            if (mbd.isSingleton()) {                // Register a DisposableBean implementation that performs all destruction                // work for the given bean: DestructionAwareBeanPostProcessors,                // DisposableBean interface, custom destroy method.                registerDisposableBean(beanName,                        new DisposableBeanAdapter(bean, beanName, mbd, getBeanPostProcessors(), acc));            }            else {                // A bean with a custom scope...                Scope scope = this.scopes.get(mbd.getScope());                if (scope == null) {                    throw new IllegalStateException(&quot;No Scope registered for scope name &#39;&quot; + mbd.getScope() + &quot;&#39;&quot;);                }                scope.registerDestructionCallback(beanName,                        new DisposableBeanAdapter(bean, beanName, mbd, getBeanPostProcessors(), acc));            }        }    }</code></pre><p>DisposableBeanAdapter的构造方法。该方法首先会拿到类的destory-method属性，然后通过filterPostProcessors()方法获取到DestructionAwareBeanPostProcessor类型的BeanPostProcessor。</p><pre><code class="java">    public DisposableBeanAdapter(Object bean, String beanName, RootBeanDefinition beanDefinition,            List&lt;BeanPostProcessor&gt; postProcessors, @Nullable AccessControlContext acc) {        Assert.notNull(bean, &quot;Disposable bean must not be null&quot;);        this.bean = bean;        this.beanName = beanName;        this.invokeDisposableBean =                (this.bean instanceof DisposableBean &amp;&amp; !beanDefinition.isExternallyManagedDestroyMethod(&quot;destroy&quot;));        this.nonPublicAccessAllowed = beanDefinition.isNonPublicAccessAllowed();        this.acc = acc;        String destroyMethodName = inferDestroyMethodIfNecessary(bean, beanDefinition);        if (destroyMethodName != null &amp;&amp; !(this.invokeDisposableBean &amp;&amp; &quot;destroy&quot;.equals(destroyMethodName)) &amp;&amp;                !beanDefinition.isExternallyManagedDestroyMethod(destroyMethodName)) {            this.destroyMethodName = destroyMethodName;            this.destroyMethod = determineDestroyMethod(destroyMethodName);            if (this.destroyMethod == null) {                if (beanDefinition.isEnforceDestroyMethod()) {                    throw new BeanDefinitionValidationException(&quot;Could not find a destroy method named &#39;&quot; +                            destroyMethodName + &quot;&#39; on bean with name &#39;&quot; + beanName + &quot;&#39;&quot;);                }            }            else {                Class&lt;?&gt;[] paramTypes = this.destroyMethod.getParameterTypes();                if (paramTypes.length &gt; 1) {                    throw new BeanDefinitionValidationException(&quot;Method &#39;&quot; + destroyMethodName + &quot;&#39; of bean &#39;&quot; +                            beanName + &quot;&#39; has more than one parameter - not supported as destroy method&quot;);                }                else if (paramTypes.length == 1 &amp;&amp; boolean.class != paramTypes[0]) {                    throw new BeanDefinitionValidationException(&quot;Method &#39;&quot; + destroyMethodName + &quot;&#39; of bean &#39;&quot; +                            beanName + &quot;&#39; has a non-boolean parameter - not supported as destroy method&quot;);                }            }        }        this.beanPostProcessors = filterPostProcessors(postProcessors, bean);    }</code></pre><p>destory()方法首先会调用BeanPostProcessor接口的postProcessBeforeDestruction()方法，然后调用DisposableBean接口的distory()方法，再通过反射调用destory-method属性设置的方法。这个方法一般由tomcat中servlet规范中的ContextLoaderListener.contextDestroyed()方法触发。</p><pre><code class="java">    public void destroy() {        if (!CollectionUtils.isEmpty(this.beanPostProcessors)) {            for (DestructionAwareBeanPostProcessor processor : this.beanPostProcessors) {                processor.postProcessBeforeDestruction(this.bean, this.beanName);            }        }        if (this.invokeDisposableBean) {            if (logger.isTraceEnabled()) {                logger.trace(&quot;Invoking destroy() on bean with name &#39;&quot; + this.beanName + &quot;&#39;&quot;);            }            try {                if (System.getSecurityManager() != null) {                    AccessController.doPrivileged((PrivilegedExceptionAction&lt;Object&gt;) () -&gt; {                        ((DisposableBean) this.bean).destroy();                        return null;                    }, this.acc);                }                else {                    ((DisposableBean) this.bean).destroy();                }            }            catch (Throwable ex) {                String msg = &quot;Invocation of destroy method failed on bean with name &#39;&quot; + this.beanName + &quot;&#39;&quot;;                if (logger.isDebugEnabled()) {                    logger.info(msg, ex);                }                else {                    logger.info(msg + &quot;: &quot; + ex);                }            }        }        if (this.destroyMethod != null) {            invokeCustomDestroyMethod(this.destroyMethod);        }        else if (this.destroyMethodName != null) {            Method methodToCall = determineDestroyMethod(this.destroyMethodName);            if (methodToCall != null) {                invokeCustomDestroyMethod(methodToCall);            }        }    }</code></pre><h2 id="单实例循环依赖"><a href="#单实例循环依赖" class="headerlink" title="单实例循环依赖"></a>单实例循环依赖</h2><p><a href="https://www.processon.com/view/link/5df9ce52e4b0c4255ea1a84f" target="_blank" rel="noopener">循环依赖流程图</a></p><p>单例实例无参构造函数的循环依赖是可以解决的，但如果是参构造函数@Autowired 的方式造成的循环依赖会直接报错，多例的循环依赖也是直接报错。</p><p>doGetBean()方法的再分析。在调用doGetBean()方法获取实例时，在该方法中会尝试通过getSingleton(beanName)方法从缓存中获取实例，如果没有会通过getSingleton()的重载方法创建实例。</p><pre><code class="java">    protected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType,            @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException {        final String beanName = transformedBeanName(name);        Object bean;        //从缓存中拿实例        // Eagerly check singleton cache for manually registered singletons.        Object sharedInstance = getSingleton(beanName);        //如果缓存里面能拿到实例        if (sharedInstance != null &amp;&amp; args == null) {            if (logger.isTraceEnabled()) {                if (isSingletonCurrentlyInCreation(beanName)) {                    logger.trace(&quot;Returning eagerly cached instance of singleton bean &#39;&quot; + beanName +                            &quot;&#39; that is not fully initialized yet - a consequence of a circular reference&quot;);                }                else {                    logger.trace(&quot;Returning cached instance of singleton bean &#39;&quot; + beanName + &quot;&#39;&quot;);                }            }            //改方法是FactoryBean接口的调用入口            bean = getObjectForBeanInstance(sharedInstance, name, beanName, null);        }        else {            //如果singletonObjects缓存里面没有，则走下来            // Fail if we&#39;re already creating this bean instance:            // We&#39;re assumably within a circular reference.            //如果是scope 是Prototype的，校验是否有出现循环依赖，如果有则直接报错            if (isPrototypeCurrentlyInCreation(beanName)) {                throw new BeanCurrentlyInCreationException(beanName);            }            // Check if bean definition exists in this factory.            BeanFactory parentBeanFactory = getParentBeanFactory();            if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) {                // Not found -&gt; check parent.                String nameToLookup = originalBeanName(name);                if (parentBeanFactory instanceof AbstractBeanFactory) {                    return ((AbstractBeanFactory) parentBeanFactory).doGetBean(                            nameToLookup, requiredType, args, typeCheckOnly);                }                else if (args != null) {                    // Delegation to parent with explicit args.                    return (T) parentBeanFactory.getBean(nameToLookup, args);                }                else if (requiredType != null) {                    // No args -&gt; delegate to standard getBean method.                    return parentBeanFactory.getBean(nameToLookup, requiredType);                }                else {                    return (T) parentBeanFactory.getBean(nameToLookup);                }            }            if (!typeCheckOnly) {                markBeanAsCreated(beanName);            }            try {                //父子BeanDefinition合并                final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);                checkMergedBeanDefinition(mbd, beanName, args);                //获取依赖对象属性，依赖对象要先实例化                // Guarantee initialization of beans that the current bean depends on.                String[] dependsOn = mbd.getDependsOn();                if (dependsOn != null) {                    for (String dep : dependsOn) {                        if (isDependent(beanName, dep)) {                            throw new BeanCreationException(mbd.getResourceDescription(), beanName,                                    &quot;Circular depends-on relationship between &#39;&quot; + beanName + &quot;&#39; and &#39;&quot; + dep + &quot;&#39;&quot;);                        }                        registerDependentBean(dep, beanName);                        try {                            //实例化                            getBean(dep);                    }                        catch (NoSuchBeanDefinitionException ex) {                            throw new BeanCreationException(mbd.getResourceDescription(), beanName,                                    &quot;&#39;&quot; + beanName + &quot;&#39; depends on missing bean &#39;&quot; + dep + &quot;&#39;&quot;, ex);                        }                    }                }                //着重看，大部分是单例的情况                // Create bean instance.                if (mbd.isSingleton()) {                    sharedInstance = getSingleton(beanName, () -&gt; {                        try {                            return createBean(beanName, mbd, args);                        }                        catch (BeansException ex) {                            // Explicitly remove instance from singleton cache: It might have been put there                            // eagerly by the creation process, to allow for circular reference resolution.                            // Also remove any beans that received a temporary reference to the bean.                            destroySingleton(beanName);                            throw ex;                        }                    });                    //该方法是FactoryBean接口的调用入口                    bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);                }                else if (mbd.isPrototype()) {                    // It&#39;s a prototype -&gt; create a new instance.                    Object prototypeInstance = null;                    try {                        beforePrototypeCreation(beanName);                        prototypeInstance = createBean(beanName, mbd, args);                    }                    finally {                        afterPrototypeCreation(beanName);                    }                    //该方法是FactoryBean接口的调用入口                    bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);                }                else {                    String scopeName = mbd.getScope();                    final Scope scope = this.scopes.get(scopeName);                    if (scope == null) {                        throw new IllegalStateException(&quot;No Scope registered for scope name &#39;&quot; + scopeName + &quot;&#39;&quot;);                    }                    try {                        Object scopedInstance = scope.get(beanName, () -&gt; {                            beforePrototypeCreation(beanName);                            try {                                return createBean(beanName, mbd, args);                            }                            finally {                                afterPrototypeCreation(beanName);                            }                        });                        //该方法是FactoryBean接口的调用入口                        bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd);                    }                    catch (IllegalStateException ex) {                        throw new BeanCreationException(beanName,                                &quot;Scope &#39;&quot; + scopeName + &quot;&#39; is not active for the current thread; consider &quot; +                                &quot;defining a scoped proxy for this bean if you intend to refer to it from a singleton&quot;,                                ex);                    }                }            }            catch (BeansException ex) {                cleanupAfterBeanCreationFailure(beanName);                throw ex;            }        }        // Check if required type matches the type of the actual bean instance.        if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) {            try {                T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType);                if (convertedBean == null) {                    throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());                }                return convertedBean;            }            catch (TypeMismatchException ex) {                if (logger.isTraceEnabled()) {                    logger.trace(&quot;Failed to convert bean &#39;&quot; + name + &quot;&#39; to required type &#39;&quot; +                            ClassUtils.getQualifiedName(requiredType) + &quot;&#39;&quot;, ex);                }                throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass());            }        }        return (T) bean;    }</code></pre><p>getSingleton()方法，该方法用于从缓存中获取实例，会按照一级缓存、二级缓存、三级缓存的顺序获取，再从三级缓存中获取实例后，会将实例放到二级缓存并删除三级缓存。一级缓存中的bean是完成实例化，IOC、DI注入的，三级缓存中时仅仅执行完构造方法，还没有对属性进行赋值操作的bean，二级缓存中的bean与三级缓存相同，二级缓存存在的意义是为了提升效率。</p><pre><code class="java">    protected Object getSingleton(String beanName, boolean allowEarlyReference) {        //根据beanName从缓存中拿实例        //先从一级缓存拿        Object singletonObject = this.singletonObjects.get(beanName);        //如果bean还正在创建，还没创建完成，其实就是堆内存有了，属性还没有DI依赖注入        if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) {            synchronized (this.singletonObjects) {                //从二级缓存中拿                singletonObject = this.earlySingletonObjects.get(beanName);                //如果还拿不到，并且允许bean提前暴露                if (singletonObject == null &amp;&amp; allowEarlyReference) {                    //从三级缓存中拿到对象工厂                    ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName);                    if (singletonFactory != null) {                        //从工厂中拿到对象                        singletonObject = singletonFactory.getObject();                        //升级到二级缓存                        this.earlySingletonObjects.put(beanName, singletonObject);                        //删除三级缓存                        this.singletonFactories.remove(beanName);                    }                }            }        }        return singletonObject;    }</code></pre><p>重载的getSingleton()方法，该方法在创建Bean之前会将beanName添加到singletonsCurrentlyInCreation容器中，如果容器中已有该beanName会直接报错，然后通过singletonFactory.getObject()方法创建实例，如果有返回值，就表示实例已经完成创建，再从容器中删除beanName，创建完成后调用addSingleton()方法放入一级缓存。</p><pre><code class="java">    public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) {        Assert.notNull(beanName, &quot;Bean name must not be null&quot;);        synchronized (this.singletonObjects) {            //如果缓存中有，则直接返回            Object singletonObject = this.singletonObjects.get(beanName);            if (singletonObject == null) {                if (this.singletonsCurrentlyInDestruction) {                    throw new BeanCreationNotAllowedException(beanName,                            &quot;Singleton bean creation not allowed while singletons of this factory are in destruction &quot; +                            &quot;(Do not request a bean from a BeanFactory in a destroy method implementation!)&quot;);                }                if (logger.isDebugEnabled()) {                    logger.debug(&quot;Creating shared instance of singleton bean &#39;&quot; + beanName + &quot;&#39;&quot;);                }                //把beanName添加到singletonsCurrentlyInCreation Set容器中，在这个集合里面的bean都是正在实例化的bean                beforeSingletonCreation(beanName);                boolean newSingleton = false;                boolean recordSuppressedExceptions = (this.suppressedExceptions == null);                if (recordSuppressedExceptions) {                    this.suppressedExceptions = new LinkedHashSet&lt;&gt;();                }                try {                    singletonObject = singletonFactory.getObject();                    newSingleton = true;                }                catch (IllegalStateException ex) {                    // Has the singleton object implicitly appeared in the meantime -&gt;                    // if yes, proceed with it since the exception indicates that state.                    singletonObject = this.singletonObjects.get(beanName);                    if (singletonObject == null) {                        throw ex;                    }                }                catch (BeanCreationException ex) {                    if (recordSuppressedExceptions) {                        for (Exception suppressedException : this.suppressedExceptions) {                            ex.addRelatedCause(suppressedException);                        }                    }                    throw ex;                }                finally {                    if (recordSuppressedExceptions) {                        this.suppressedExceptions = null;                    }                    //bean创建完成后singletonsCurrentlyInCreation要删除该bean                    afterSingletonCreation(beanName);                }                if (newSingleton) {                    //创建对象成功时，把对象缓存到singletonObjects缓存中,bean创建完成时放入一级缓存                    addSingleton(beanName, singletonObject);                }            }            return singletonObject;        }</code></pre><p>addSington()方法，该方法在实例创建后会将实例放入一级缓存，并删除二级、三级缓存中的实例。</p><pre><code class="java">    protected void addSingleton(String beanName, Object singletonObject) {        synchronized (this.singletonObjects) {            //一级缓存            this.singletonObjects.put(beanName, singletonObject);            //三级缓存            this.singletonFactories.remove(beanName);            //二级缓存            this.earlySingletonObjects.remove(beanName);            this.registeredSingletons.add(beanName);        }    }</code></pre><p>singletonFactory.getObject()方法会回调到doCreateBean()方法，该方法完成实例的构造函数后创建实例后，会判断类是否需要提前暴露，如果需要会调用addSingletonFactory()方法将正在创建的bean添加到三级缓存，注意此时注解装配已经完成，但对注解的IOC、DI等操作还未开始。addSingletonFactory()方法会调用到getEarlyBeanReference()方法获取完成实例化的bean。判断bean是否正在创建的方法为判断beanName在singletonsCurrentlyInCreation中是否存在。</p><pre><code class="java">    protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args)            throws BeanCreationException {        // Instantiate the bean.        BeanWrapper instanceWrapper = null;        if (mbd.isSingleton()) {            instanceWrapper = this.factoryBeanInstanceCache.remove(beanName);        }        if (instanceWrapper == null) {            //创建实例 重点看 重要程度：5            instanceWrapper = createBeanInstance(beanName, mbd, args);        }        final Object bean = instanceWrapper.getWrappedInstance();        Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass();        if (beanType != NullBean.class) {            mbd.resolvedTargetType = beanType;        }        // Allow post-processors to modify the merged bean definition.        synchronized (mbd.postProcessingLock) {            if (!mbd.postProcessed) {                try {                    //CommonAnnotationBeanPostProcessor  支持了@PostConstruct，@PreDestroy,@Resource注解                    //AutowiredAnnotationBeanPostProcessor 支持 @Autowired,@Value注解                    //BeanPostProcessor接口的典型运用，这里要理解这个接口                    //对类中注解的装配过程                    //重要程度5，必须看                    applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName);                }                catch (Throwable ex) {                    throw new BeanCreationException(mbd.getResourceDescription(), beanName,                            &quot;Post-processing of merged bean definition failed&quot;, ex);                }                mbd.postProcessed = true;            }        }        // Eagerly cache singletons to be able to resolve circular references        // even when triggered by lifecycle interfaces like BeanFactoryAware.        //是否    单例bean提前暴露        boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp;                isSingletonCurrentlyInCreation(beanName));        if (earlySingletonExposure) {            if (logger.isTraceEnabled()) {                logger.trace(&quot;Eagerly caching bean &#39;&quot; + beanName +                        &quot;&#39; to allow for resolving potential circular references&quot;);            }            //这里着重理解，对理解循环依赖帮助非常大，重要程度 5   添加三级缓存            addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));        }        // Initialize the bean instance.        Object exposedObject = bean;        try {            //ioc di，依赖注入的核心方法，该方法必须看，重要程度：5            populateBean(beanName, mbd, instanceWrapper);            //bean 实例化+ioc依赖注入完以后的调用，非常重要，重要程度：5            exposedObject = initializeBean(beanName, exposedObject, mbd);        }        catch (Throwable ex) {            if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) {                throw (BeanCreationException) ex;            }            else {                throw new BeanCreationException(                        mbd.getResourceDescription(), beanName, &quot;Initialization of bean failed&quot;, ex);            }        }        if (earlySingletonExposure) {            Object earlySingletonReference = getSingleton(beanName, false);            if (earlySingletonReference != null) {                if (exposedObject == bean) {                    exposedObject = earlySingletonReference;                }                else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) {                    String[] dependentBeans = getDependentBeans(beanName);                    Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;&gt;(dependentBeans.length);                    for (String dependentBean : dependentBeans) {                        if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) {                            actualDependentBeans.add(dependentBean);                        }                    }                    if (!actualDependentBeans.isEmpty()) {                        throw new BeanCurrentlyInCreationException(beanName,                                &quot;Bean with name &#39;&quot; + beanName + &quot;&#39; has been injected into other beans [&quot; +                                StringUtils.collectionToCommaDelimitedString(actualDependentBeans) +                                &quot;] in its raw version as part of a circular reference, but has eventually been &quot; +                                &quot;wrapped. This means that said other beans do not use the final version of the &quot; +                                &quot;bean. This is often the result of over-eager type matching - consider using &quot; +                                &quot;&#39;getBeanNamesOfType&#39; with the &#39;allowEagerInit&#39; flag turned off, for example.&quot;);                    }                }            }        }        // Register bean as disposable.        try {            //注册bean销毁时的类DisposableBeanAdapter            registerDisposableBeanIfNecessary(beanName, bean, mbd);        }        catch (BeanDefinitionValidationException ex) {            throw new BeanCreationException(                    mbd.getResourceDescription(), beanName, &quot;Invalid destruction signature&quot;, ex);        }        return exposedObject;    }</code></pre><p>getEarlyBeanReference()会将刚执行完构造函数，还没有进行属性设置的类返回。</p><pre><code class="java">    protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) {        Object exposedObject = bean;        if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) {            for (BeanPostProcessor bp : getBeanPostProcessors()) {                if (bp instanceof SmartInstantiationAwareBeanPostProcessor) {                    SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp;                    exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName);                }            }        }        return exposedObject;    }</code></pre><p>循环依赖步骤:</p><ol><li>A类无参构造函数实例化后，设置三级缓存。</li><li>A类进行依赖注入，调用B类的getBean()操作。</li><li>B类无参构造函数实例化后，设置三级缓存。</li><li>B类依赖注入，再次触发了A类getBean()操作。</li><li>B类拿到了A的三级缓存中的实例并注入。</li><li>B类的实例化完成，由于B类的初始化是A类调用getBean()完成的，B类完成实例化后会返回给A类。</li><li>A类获取到B类，完成依赖注入。</li></ol><p>看完上面的流程后，对于有参构造函数中的@Autowired造成的循环依赖直接报错的原因就显而易见了。如果A类在执行有@Autowired注解的构造函数时需要注入B类，B类的构造函数中也使用@Autowired要求注入A类，那么在调用A的构造函数时会触发B类的初始化。而要处理B类构造函数的@Autowired就需要获取A的实例，就会再次触发A类的getBean()，但此时A的构造函数还没有完成，通过三级缓存是拿不到A类的，所以会再次触发getSingleton往singletonsCurrentlyInCreation中放入beanName，但由于在上面执行A的构造函数之前就已经往singletonsCurrentlyInCreation放入了A类的beanName，此时再次放入会直接报错。</p><h2 id="FactoryBean接口"><a href="#FactoryBean接口" class="headerlink" title="FactoryBean接口"></a>FactoryBean接口</h2><p>该接口主要是在BeanFactory完成实例化后，创建交给Spring管理的、可以用于@Autowired注解的对象。注意此时根据beanName获取的是BeanFactory接口创建的实例，如果要获取BeanFactory接口的实例需要在BeanName前加上&amp;符号。</p><p>getObjectForBeanInstance()方法用于对该接口的支持，如果beanName不是以&amp;开头，并且beanInstance是FactoryBean类型，就会从缓存里面拿FactoryBean类型的实例，然后调用getObjectFromFactoryBean()方法创建实例。</p><pre><code class="java">    protected Object getObjectForBeanInstance(            Object beanInstance, String name, String beanName, @Nullable RootBeanDefinition mbd) {        // Don&#39;t let calling code try to dereference the factory if the bean isn&#39;t a factory.        if (BeanFactoryUtils.isFactoryDereference(name)) {            if (beanInstance instanceof NullBean) {                return beanInstance;            }            if (!(beanInstance instanceof FactoryBean)) {                throw new BeanIsNotAFactoryException(transformedBeanName(name), beanInstance.getClass());            }        }        // Now we have the bean instance, which may be a normal bean or a FactoryBean.        // If it&#39;s a FactoryBean, we use it to create a bean instance, unless the        // caller actually wants a reference to the factory.        //如果实例不是FactoryBean类型的，或者name是以&amp;号开头的，则直接返回实例        if (!(beanInstance instanceof FactoryBean) || BeanFactoryUtils.isFactoryDereference(name)) {            return beanInstance;        }        //如果代码能走下来，则说明 beanName不是以&amp;开头，并且beanInstance是FactoryBean类型的        Object object = null;        if (mbd == null) {            //从缓存里面拿FactoryBean类型的实例            object = getCachedObjectForFactoryBean(beanName);        }        if (object == null) {            // Return bean instance from factory.            FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) beanInstance;            // Caches object obtained from FactoryBean if it is a singleton.            if (mbd == null &amp;&amp; containsBeanDefinition(beanName)) {                mbd = getMergedLocalBeanDefinition(beanName);            }            boolean synthetic = (mbd != null &amp;&amp; mbd.isSynthetic());            //重点看            object = getObjectFromFactoryBean(factory, beanName, !synthetic);        }        return object;    }</code></pre><p>getObjectFromFactoryBean()方法会调用FactoryBean接口的getObject()方法获取实例，然后将创建的对象会放入factoryBeanObjectCache容器中，而不是一级缓存的容器。</p><pre><code class="java">    protected Object getObjectFromFactoryBean(FactoryBean&lt;?&gt; factory, String beanName, boolean shouldPostProcess) {        if (factory.isSingleton() &amp;&amp; containsSingleton(beanName)) {            synchronized (getSingletonMutex()) {                Object object = this.factoryBeanObjectCache.get(beanName);                if (object == null) {                    //调用getObject方法                    object = doGetObjectFromFactoryBean(factory, beanName);                    // Only post-process and store if not put there already during getObject() call above                    // (e.g. because of circular reference processing triggered by custom getBean calls)                    Object alreadyThere = this.factoryBeanObjectCache.get(beanName);                    if (alreadyThere != null) {                        object = alreadyThere;                    }                    else {                        if (shouldPostProcess) {                            if (isSingletonCurrentlyInCreation(beanName)) {                                // Temporarily return non-post-processed object, not storing it yet..                                return object;                            }                            beforeSingletonCreation(beanName);                            try {                                object = postProcessObjectFromFactoryBean(object, beanName);                            }                            catch (Throwable ex) {                                throw new BeanCreationException(beanName,                                        &quot;Post-processing of FactoryBean&#39;s singleton object failed&quot;, ex);                            }                            finally {                                afterSingletonCreation(beanName);                            }                        }                        if (containsSingleton(beanName)) {                            //把实例缓存到factoryBeanObjectCache map中，这个是单独缓存FactoryBean类型实例的map                            this.factoryBeanObjectCache.put(beanName, object);                        }                    }                }                return object;            }        }        else {            Object object = doGetObjectFromFactoryBean(factory, beanName);            if (shouldPostProcess) {                try {                    object = postProcessObjectFromFactoryBean(object, beanName);                }                catch (Throwable ex) {                    throw new BeanCreationException(beanName, &quot;Post-processing of FactoryBean&#39;s object failed&quot;, ex);                }            }            return object;        }    }</code></pre><h2 id="BeanPostProcessor接口"><a href="#BeanPostProcessor接口" class="headerlink" title="BeanPostProcessor接口"></a>BeanPostProcessor接口</h2><p>BeanPostProcessor接口类型实例是针对某种特定功能的埋点，在这个点会根据接口类型来过滤掉不关注这个点的其他类，只有真正关注的类才会在这个点进行相应的功能实现。在使用时通常会拿到所有的BeanPostProcessor接口，然后循环根据BeanPostProcessor接口的类型进行过滤，或者直接调用对应的方法，如果该BeanPostProcessor接口不关注这个点，对应的方法中就没有相应的实现。</p><h3 id="获取有-Autowired注解的构造函数埋点"><a href="#获取有-Autowired注解的构造函数埋点" class="headerlink" title="获取有@Autowired注解的构造函数埋点"></a>获取有@Autowired注解的构造函数埋点</h3><p>doCreateBean()初始化Bean实例时，用于创建Bean实例的createBeanInstance()方法中，会调用determineConstructorsFromBeanPostProcessors()方法获得有@Autowired注解的构造方法。</p><pre><code>        // Candidate constructors for autowiring?        //寻找当前正在实例化的bean中有@Autowired注解的构造函数        Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName);        if (ctors != null || mbd.getResolvedAutowireMode() == AUTOWIRE_CONSTRUCTOR ||                mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) {            //如果ctors不为空，就说明构造函数上有@Autowired注解            return autowireConstructor(beanName, mbd, ctors, args);        }</code></pre><p>这里过滤的接口类型是SmartInstantiationAwareBeanPostProcessor，调用的方法是determineCandidateConstructors()。</p><pre><code class="java">    protected Constructor&lt;?&gt;[] determineConstructorsFromBeanPostProcessors(@Nullable Class&lt;?&gt; beanClass, String beanName)            throws BeansException {        if (beanClass != null &amp;&amp; hasInstantiationAwareBeanPostProcessors()) {            //获取所有的BeanPostProcessors            for (BeanPostProcessor bp : getBeanPostProcessors()) {                if (bp instanceof SmartInstantiationAwareBeanPostProcessor) {                    SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp;                    //找到合适的构造函数                    Constructor&lt;?&gt;[] ctors = ibp.determineCandidateConstructors(beanClass, beanName);                    if (ctors != null) {                        return ctors;                    }                }            }        }        return null;    }</code></pre><h3 id="收集-Resource、-Autowired、-Value-PostConstruct、-PreDestroy注解的方法和属性埋点"><a href="#收集-Resource、-Autowired、-Value-PostConstruct、-PreDestroy注解的方法和属性埋点" class="headerlink" title="收集@Resource、@Autowired、@Value@PostConstruct、@PreDestroy注解的方法和属性埋点"></a>收集@Resource、@Autowired、@Value@PostConstruct、@PreDestroy注解的方法和属性埋点</h3><p>doCreateBean()进行注解的装配时，会使用applyMergedBeanDefinitionPostProcessors()方法。</p><pre><code class="java">        synchronized (mbd.postProcessingLock) {            if (!mbd.postProcessed) {                try {                    //CommonAnnotationBeanPostProcessor  支持了@PostConstruct，@PreDestroy,@Resource注解                    //AutowiredAnnotationBeanPostProcessor 支持 @Autowired,@Value注解                    //BeanPostProcessor接口的典型运用，这里要理解这个接口                    //对类中注解的装配过程                    //重要程度5，必须看                    applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName);                }                catch (Throwable ex) {                    throw new BeanCreationException(mbd.getResourceDescription(), beanName,                            &quot;Post-processing of merged bean definition failed&quot;, ex);                }                mbd.postProcessed = true;            }        }</code></pre><p>过滤的接口类型是MergedBeanDefinitionPostProcessor，调用的方法是postProcessMergedBeanDefinition()。</p><pre><code class="java">    protected void applyMergedBeanDefinitionPostProcessors(RootBeanDefinition mbd, Class&lt;?&gt; beanType, String beanName) {        for (BeanPostProcessor bp : getBeanPostProcessors()) {            if (bp instanceof MergedBeanDefinitionPostProcessor) {                MergedBeanDefinitionPostProcessor bdp = (MergedBeanDefinitionPostProcessor) bp;                bdp.postProcessMergedBeanDefinition(mbd, beanType, beanName);            }        }    }</code></pre><h3 id="循环依赖解决中bean的提前暴露埋点"><a href="#循环依赖解决中bean的提前暴露埋点" class="headerlink" title="循环依赖解决中bean的提前暴露埋点"></a>循环依赖解决中bean的提前暴露埋点</h3><p>doCreateBean()对Bean进行提前暴露时，会调用getEarlyBeanReference()方法获取到Bean实例。</p><pre><code class="java">        //是否    单例bean提前暴露        boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp;                isSingletonCurrentlyInCreation(beanName));        if (earlySingletonExposure) {            if (logger.isTraceEnabled()) {                logger.trace(&quot;Eagerly caching bean &#39;&quot; + beanName +                        &quot;&#39; to allow for resolving potential circular references&quot;);            }            //这里着重理解，对理解循环依赖帮助非常大，重要程度 5   添加三级缓存            addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));        }</code></pre><p>过滤的接口类型是SmartInstantiationAwareBeanPostProcessor，调用的方法是determineCandidateConstructors()。</p><pre><code class="java">    protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) {        Object exposedObject = bean;        if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) {            for (BeanPostProcessor bp : getBeanPostProcessors()) {                if (bp instanceof SmartInstantiationAwareBeanPostProcessor) {                    SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp;                    exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName);                }            }        }        return exposedObject;    }</code></pre><h3 id="阻止依赖注入埋点"><a href="#阻止依赖注入埋点" class="headerlink" title="阻止依赖注入埋点"></a>阻止依赖注入埋点</h3><p>位于doCreateBean()进行依赖注入时，populateBean()方法中。</p><p>过滤的接口类型是InstantiationAwareBeanPostProcessor，调用的方法是postProcessAfterInstantiation。</p><pre><code class="java">        //这里写接口可以让所有类都不能依赖注入        if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) {            for (BeanPostProcessor bp : getBeanPostProcessors()) {                if (bp instanceof InstantiationAwareBeanPostProcessor) {                    InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;                    if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) {                        //是否需要DI，依赖注入                        continueWithPropertyPopulation = false;                        break;                    }                }            }        }</code></pre><h3 id="IOC-DI-依赖注入埋点"><a href="#IOC-DI-依赖注入埋点" class="headerlink" title="IOC/DI 依赖注入埋点"></a>IOC/DI 依赖注入埋点</h3><p>位于doCreateBean()进行依赖注入时，populateBean()方法中。</p><p>过滤的接口类型是InstantiationAwareBeanPostProcessor，调用的方法是postProcessProperties。</p><pre><code class="java">        //重点看这个if代码块，重要程度 5        if (hasInstAwareBpps) {            if (pvs == null) {                pvs = mbd.getPropertyValues();            }            for (BeanPostProcessor bp : getBeanPostProcessors()) {                if (bp instanceof InstantiationAwareBeanPostProcessor) {                    InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp;                    //依赖注入过程，@Autowired的支持                    PropertyValues pvsToUse = ibp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName);                    if (pvsToUse == null) {                        if (filteredPds == null) {                            filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching);                        }                        //老版本用这个完成依赖注入过程，@Autowired的支持                        pvsToUse = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName);                        if (pvsToUse == null) {                            return;                        }                    }                    pvs = pvsToUse;                }            }    }</code></pre><h3 id="Bean销毁的埋点"><a href="#Bean销毁的埋点" class="headerlink" title="Bean销毁的埋点"></a>Bean销毁的埋点</h3><p>位于doGreateBean().registerDisposableBeanIfNecessary()方法中调用DisposableBeanAdapter的构造函数时。用于寻找DestructionAwareBeanPostProcessor类型的BeanPostProcessor。</p><pre><code class="java">    private List&lt;DestructionAwareBeanPostProcessor&gt; filterPostProcessors(List&lt;BeanPostProcessor&gt; processors, Object bean) {        List&lt;DestructionAwareBeanPostProcessor&gt; filteredPostProcessors = null;        if (!CollectionUtils.isEmpty(processors)) {            filteredPostProcessors = new ArrayList&lt;&gt;(processors.size());            for (BeanPostProcessor processor : processors) {                if (processor instanceof DestructionAwareBeanPostProcessor) {                    DestructionAwareBeanPostProcessor dabpp = (DestructionAwareBeanPostProcessor) processor;                    if (dabpp.requiresDestruction(bean)) {                        filteredPostProcessors.add(dabpp);                    }                }            }        }        return filteredPostProcessors;    }</code></pre>]]></content>
    
    
    <categories>
      
      <category>Spring源码解析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码解析</tag>
      
      <tag>spring</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>spring程序入口和xml解析</title>
    <link href="/2020/04/13/spring%E7%A8%8B%E5%BA%8F%E5%85%A5%E5%8F%A3%E5%92%8Cxml%E8%A7%A3%E6%9E%90/"/>
    <url>/2020/04/13/spring%E7%A8%8B%E5%BA%8F%E5%85%A5%E5%8F%A3%E5%92%8Cxml%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h2 id="Spring的历史"><a href="#Spring的历史" class="headerlink" title="Spring的历史"></a>Spring的历史</h2><ul><li><p>2002年10月，Rod Johnso发布《Expert One-on-One J2EE 设计和开发》一书</p></li><li><p>2004 年 3 月，Spring1.0 发布</p><p>2003 年 6 月，Spring Framework 第一次以 Apache 2.0 许可证下发布 0.9 版 本，2004 年 3 月，Spring1.0 正式发布。对于 Spring1.0，其源码只有一个包，在该包中包含了 aop、beans、context、 core、jdbc、orm 等。对于此时的版本，Spring1.0 仅支持 XML 配置的方式。</p></li><li><p>2006 年 10 月，Spring2.0 发布<br>对于 2.0，Spring 主要增加了对注解的支持，实现了基于注解的配置。</p><p>在 2007 年 11 月，发布 Spring2.5，该版本具备的特性有：</p><ul><li><p>添加可扩展的 XML 配置功能，用于简化 XML 配置，</p></li><li><p>支持 Java5</p></li><li><p>添加额外的 IOC 容器扩展点，支持动态语言(如 groovy，aop 增强功能和新 的 bean 范围 )</p></li></ul></li><li><p>2009 年 12 月，Spring3.0 发布</p><p>Spring3.0 主要具有的特性有: </p><ul><li>模块重组系统</li><li>支持 Spring 表达式语言(Spring Expression)</li><li>基于 Java 的 Bean 配置(JavaConfig) 支持嵌入式数据库:HSQL、H2 等 支持 REST</li><li>支持 Java6</li></ul></li><li><p>2013 年 12 月，发布 Spring4.0</p><p>对于 Spring4.0 是 Spring 版本历史上的一重大升级。其特性为: </p><ul><li>全面支持 Java8支持 Lambda 表达式。</li><li>支持 Java8 的时间和日期 API</li><li>支持重复注解</li><li>支持 Java8 的 Optional</li><li>核心容器增强</li><li>增加泛型依赖注入</li><li>增加 Map 依赖注入</li><li>增加 List 依赖注入</li><li>支持 lazy 注解配置懒加载</li><li>支持 Condition 条件注解</li><li>CGLIB 动态代理增强</li><li>支持基于 GroovyDSL 定义 Bean</li><li>Web 增强</li><li>增强 SpringMVC，基于 Servlet3.0 开发</li><li>提供 RestController 注解</li><li>提供 AsyncRestTemplate 支持客户端的异步无阻塞请求</li><li>增加对 WebSocket 的支持</li></ul></li><li><p>2017 年 9 月，Spring5.0 发布</p><p>Spring5.0 特性如下：</p><ul><li>升级到 Java8、JavaEE7</li><li>废弃低版本，将 Java8、JavaEE 7 作为最低版本要求 兼容 Java9、兼容 JavaEE8</li><li>反应式编程模型，增加 WebFlux 模块</li><li>升级 SpringMVC，增加对最新的 API(Jackson 等)的支持 增加函数式编程模式</li><li>重构源码，部分功能使用 Lambda 表达式实现</li></ul></li></ul><h2 id="Spring的子项目"><a href="#Spring的子项目" class="headerlink" title="Spring的子项目"></a>Spring的子项目</h2><ul><li>Spring IO Platform : Spring IO 是可集成的、构建现代化应用的版本平台。Spring IO 是模块化的、企业级的分布式系统，包括一系列依赖，是的开发者仅能对自己所需的部分进行完全的部署控制。</li><li>Spring Boot:Spring 应用快速开发工具，用来简化 Spring 应用开发过程。 </li><li>Spring XD:Spring XD(eXtreme Date，极限数据)是 Pivotal 的大数据产品。它结合了 Spring Boot 和 Grails，组成 Spring IO 平台的执行部分。</li><li>Spring Data:Spring Data 是为了简化构建基于 Spring 框架应用的数据访问实现，包括非关系数据库、Map-Reduce 框架、云数据服务等;另外，也包含对关 系数据库的访问支持。</li><li>Spring Integration:Spring Integration 为企业数据集成提供了各种适配器，可以通过这些适配器来转换各种消息格式，并帮助 Spring 应用完成与企业应用系统的集成。</li><li>Spring Batch:Spring Batch 是一个轻量级的完整批处理框架，旨在帮助应用开发者构建一个健壮、高效的企业级批处理应用(这些应用的特点是不需要与用 户交互，重复的操作量大，对于大容量的批量数据处理而言，这些操作往往要求 较高的可靠性)</li><li>Spring Security:Spring Security 是一个能够为基于 Spring 的企业应用系统提 供声明式的安全访问控制解决方案的安全框架。它提供了一组可以在 Spring 应用 上下文配置的 bean，充分利用 Ioc 和 AOP 功能，为应用系统提供声明式的安全 访问控制功能。</li><li>Spring Hateoas:Spring Hateoas 是一个用户支持实现超文本驱动的 REST Web 服务的开发库，是 Hateoas 的实现。Hateoas(Hypermedia as the engine of application state)是 REST 架构风格中最复杂的约束，也是构建成熟 REST 服务的核 心。它的重要性在于打破了客户端和服务器之间严格的契约，是的客户端可以更加智能和自适应。</li><li>Spring Social:Spring Social 是 Spring 框架的扩展，用来方便开发 Web 社交应用程序，可通过该项目来创建与各种社交网站的交互，如 Facebook，LinkedIn、 Twitter 等。</li><li>Spring AMQP:Spring AMQP 是基于 Spring 框架的 AMQP 消息解决方案，提供 模版化的发送和接收消息的抽象层，提供基于消息驱动的 POJO。这个项目支持 Java和.NET连个版本。Spring Source旗下的Rabbit MQ就是一个开源的基于AMQP 的消息服务器。</li><li>Spring for Android:Spring for Android 为 Android 终端开发应用提供 Spring 的 支持，它提供了一个在 Android 应用环境中工作、基于 Java的REST 客户端。</li><li>Spring Mobile:Spring Mobile 是基于 Spring MVC 构建的，为移动端的服务器 应用开发提供支持。</li><li>Spring Web Flow:Spring Web Flow(SWF)一个建立在 Spring MVC 基础上的 Web 页面流引擎。</li><li>Spring Web Service:Spring Web Service 是基于 Spring 框架的 Web 服务框架， 主要侧重于基于文档驱动的 Web 服务，提供 SOAP 服务开发，允许通过多种方 式创建 Web 服务。</li><li>Spring LDAP:Spring LDAP 是一个用户操作 LDAP 的 Java 框架，类似 Spring JDBC 提供了 JdbcTemplate 方式来操作数据库。这个框架提供了一个 LdapTemplate 操 作模版，可帮助开发人员简化 looking up、closing contexts、encoding/decoding、 filters 等操作。</li><li>Spring Session: Spring Session 致力于提供一个公共基础设施会话，支持从任意环境中访问一个会话，在 Web 环境下支持独立于容器的集群会话，支持可插拔策略来确定 Session ID，WebSocket 活跃的时候可以简单地保持 HttpSession。</li><li>Spring Shell: Spring Shell 提供交互式的 Shell，用户可以简单的基于 Spring 的编程模型来开发命令。</li></ul><h2 id="Spring容器的加载方式"><a href="#Spring容器的加载方式" class="headerlink" title="Spring容器的加载方式"></a>Spring容器的加载方式</h2><ul><li><p>类路径获取配置文件<br>ApplicationContext applicationContext= new ClassPathXmlApplicationContext(“spring.xml”);</p></li><li><p>文件系统路径获取配置文件【绝对路径】<br>ApplicationContext applicationContext = new FileSystemXmlApplicationContext(“E:\idea\public\springdemo\src\main\resou rces\spring.xml”);</p></li><li><p>无配置文件加载容器 ApplicationContext applicationContext = new<br>AnnotationConfigApplicationContext(“com.xx.jack”);</p></li><li><p>springboot 加载容器 ApplicationContext applicationContext = new<br>EmbeddedWebApplicationContext();</p></li></ul><h2 id="Spring容器加载的核心方法"><a href="#Spring容器加载的核心方法" class="headerlink" title="Spring容器加载的核心方法"></a>Spring容器加载的核心方法</h2><p>AbstractApplicationContext.refresh()方法</p><p>refresh()方法是spring容器启动过程中的核心方法，spring容器要加载必须执行该方法。</p><pre><code class="java">    @Override    public void refresh() throws BeansException, IllegalStateException {        synchronized (this.startupShutdownMonitor) {            //为容器初始化做准备，重要程度：0            //Prepare this context for refreshing.            prepareRefresh();            /**            * 重要程度：5            * 1、创建BeanFactory对象            * 2、xml解析            *     传统标签解析：bean、import等            *     自定义标签解析 如：&lt;context:component-scan base-package=&quot;com.xiangxue.jack&quot;/&gt;            *     自定义标签解析流程：            *         a、根据当前解析标签的头信息找到对应的namespaceUri            *         b、加载spring所以jar中的spring.handlers文件。并建立映射关系            *         c、根据namespaceUri从映射关系中找到对应的实现了NamespaceHandler接口的类            *         d、调用类的init方法，init方法是注册了各种自定义标签的解析类            *         e、根据namespaceUri找到对应的解析类，然后调用paser方法完成标签解析            *            * 3、把解析出来的xml标签封装成BeanDefinition对象            * */            // Tell the subclass to refresh the internal bean factory.            ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();            /*            * 给beanFactory设置一些属性值，可以不看            * */            // Prepare the bean factory for use in this context.            prepareBeanFactory(beanFactory);            try {                //TODO                // Allows post-processing of the bean factory in context subclasses.                postProcessBeanFactory(beanFactory);                /*                * BeanDefinitionRegistryPostProcessor                * BeanFactoryPostProcessor                * 完成对这两个接口的调用                * */                // Invoke factory processors registered as beans in the context.                invokeBeanFactoryPostProcessors(beanFactory);                /*                * 把实现了BeanPostProcessor接口的类实例化，并且加入到BeanFactory中                * */                // Register bean processors that intercept bean creation.                registerBeanPostProcessors(beanFactory);                /*                * 国际化,重要程度2                * */                // Initialize message source for this context.                initMessageSource();                //初始化事件管理类                // Initialize event multicaster for this context.                initApplicationEventMulticaster();                //这个方法着重理解模板设计模式，因为在springboot中，这个方法是用来做内嵌tomcat启动的                // Initialize other special beans in specific context subclasses.                onRefresh();                /*                * 往事件管理类中注册事件类                * */                // Check for listener beans and register them.                registerListeners();                /*                * 这个方法是spring中最重要的方法，没有之一                * 所以这个方法一定要理解要具体看                * 1、bean实例化过程                * 2、ioc                * 3、注解支持                * 4、BeanPostProcessor的执行                * 5、Aop的入口                *                * */                // Instantiate all remaining (non-lazy-init) singletons.                finishBeanFactoryInitialization(beanFactory);                // Last step: publish corresponding event.                finishRefresh();            }            catch (BeansException ex) {                if (logger.isWarnEnabled()) {                    logger.warn(&quot;Exception encountered during context initialization - &quot; +                            &quot;cancelling refresh attempt: &quot; + ex);                }                // Destroy already created singletons to avoid dangling resources.                destroyBeans();                // Reset &#39;active&#39; flag.                cancelRefresh(ex);                // Propagate exception to caller.                throw ex;            }            finally {                // Reset common introspection caches in Spring&#39;s core, since we                // might not ever need metadata for singleton beans anymore...                resetCommonCaches();            }        }    }</code></pre><h2 id="设计模式1-模版设计模式"><a href="#设计模式1-模版设计模式" class="headerlink" title="设计模式1-模版设计模式"></a>设计模式1-模版设计模式</h2><p>spring源码中大量使用了模版设计模式，是使用的最多的设计模式。</p><p>模版设计模式一般有两种类，抽象的父类，以及具体实现的子类。父类中实现逻辑中不变的部分，将可变的行为定义为抽象方法交给子类实现，但方法的执行顺序由父类决定。</p><p>创建一个抽象模版结构</p><pre><code class="java">public abstract class AblstractClass {    //模板方法用来控制子类的顺序 要想有人生必须按老爸的人生顺序来      //声明final不让子类覆盖这个方法，防止改变人生顺序    public final void 人生(){        学习();        工作();        爱情();    }    //家里穷更得用工学习    public void 学习(){        System.out.println(&quot;每天晚上趴在邻居窗上学习&quot;);    }    //工作必须稳定    public void 工作(){               System.out.println(&quot;从一而终&quot;);    }    //恋爱自由  让儿子自由恋去    public abstract void 爱情();}</code></pre><p>创建一个具体模版</p><pre><code class="java">public class ConcreteClass extends AblstractClass {    //儿子不认可父亲的学习方法  考高分影响同学关系    @Override    public void 学习() {        System.out.println(&quot;60分万岁...&quot;);    }    //父亲给我爱情自由  一定好好谈恋爱    @Override    public void 爱情() {        System.out.println(&quot;肤白貌美大长腿...&quot;);    }}</code></pre><p>具体的调用</p><pre><code class="java">public class TestMain {    public static void main(String[] args) {         ConcreteClass cs  = new ConcreteClass();         cs.人生();    }}</code></pre><h2 id="xml解析"><a href="#xml解析" class="headerlink" title="xml解析"></a>xml解析</h2><p>ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();</p><p>该方法主要进行xml解析工作，流程如下：</p><ol><li><p>创建XmlBeanDefinitionReader对象</p><pre><code class="java">        XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory);</code></pre></li><li><p>通过Reader对象加载配置文件</p><pre><code class="java">    protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException {        Resource[] configResources = getConfigResources();        if (configResources != null) {            reader.loadBeanDefinitions(configResources);        }        //获取需要加载的xml配置文件        String[] configLocations = getConfigLocations();        if (configLocations != null) {            reader.loadBeanDefinitions(configLocations);        }    }</code></pre></li><li><p>根据加载的配置文件把配置文件封装成document对象</p><pre><code class="java">    protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource)            throws BeanDefinitionStoreException {        try {            //把inputSource 封装成Document文件对象，这是jdk的API            Document doc = doLoadDocument(inputSource, resource);            //主要看这个方法，根据解析出来的document对象，拿到里面的标签元素封装成BeanDefinition            int count = registerBeanDefinitions(doc, resource);            if (logger.isDebugEnabled()) {                logger.debug(&quot;Loaded &quot; + count + &quot; bean definitions from &quot; + resource);            }            return count;        }</code></pre></li><li><p>创建BeanDefinitionDocumentReader对象，DocumentReader负责对document对象解析</p><pre><code class="java">    public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException {        //又来一记委托模式，BeanDefinitionDocumentReader委托这个类进行document的解析        BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader();        int countBefore = getRegistry().getBeanDefinitionCount();        //主要看这个方法，createReaderContext(resource) XmlReaderContext上下文，封装了XmlBeanDefinitionReader对象        documentReader.registerBeanDefinitions(doc, createReaderContext(resource));        return getRegistry().getBeanDefinitionCount() - countBefore;    }</code></pre></li><li><p>parseDefaultElement(ele,delegate);负责常规标签的解析，delegate.parseCustomElement(ele)负责自定义标签的解析</p><pre><code>    protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) {        if (delegate.isDefaultNamespace(root)) {            NodeList nl = root.getChildNodes();            for (int i = 0; i &lt; nl.getLength(); i++) {                Node node = nl.item(i);                if (node instanceof Element) {                    Element ele = (Element) node;                    if (delegate.isDefaultNamespace(ele)) {                        //默认标签解析                        parseDefaultElement(ele, delegate);                    }                    else {                        //自定义标签解析                        delegate.parseCustomElement(ele);                    }                }            }        }        else {            delegate.parseCustomElement(root);        }    }</code></pre></li><li><p>最终解析的标签封装成BeanDefinition并缓存到容器中。</p></li><li><p>xml流程分析</p></li></ol><img src="/2020/04/13/spring%E7%A8%8B%E5%BA%8F%E5%85%A5%E5%8F%A3%E5%92%8Cxml%E8%A7%A3%E6%9E%90/pic1.png" srcset="/img/loading.gif" class=""><h2 id="自定义标签解析"><a href="#自定义标签解析" class="headerlink" title="自定义标签解析"></a>自定义标签解析</h2><ol><li><p>首先获取自定义标签头的namespace命名空间，例如：<code>http://www.springframework.org/schema/context</code>，然后通过namespace获取到NamespaceHandler处理类，之后再使用NamespaceHandler中的解析类解析标签获得BeanDefinition对象。</p><pre><code class="java">    public BeanDefinition parseCustomElement(Element ele, @Nullable BeanDefinition containingBd) {      // 获取自定义标签的命名空间        String namespaceUri = getNamespaceURI(ele);        if (namespaceUri == null) {            return null;        }    // 这里有SPI服务发现的思想，根据配置文件获取namespaceUri对应的处理类        NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri);        if (handler == null) {            error(&quot;Unable to locate Spring NamespaceHandler for XML schema namespace [&quot; + namespaceUri + &quot;]&quot;, ele);            return null;        }        return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd));    }</code></pre></li><li><p>获取namespace与NamespaceHandler实例的映射关系，然后通过反射创建实例，并调用NamespaceHandler的init()方法完成解析类的注册。</p><pre><code class="java">    public NamespaceHandler resolve(String namespaceUri) {        //获取spring中所有jar包里面的 &quot;META-INF/spring.handlers&quot;文件，并且建立映射关系        Map&lt;String, Object&gt; handlerMappings = getHandlerMappings();        //根据namespaceUri：http://www.springframework.org/schema/p，获取到这个命名空间的处理类        Object handlerOrClassName = handlerMappings.get(namespaceUri);        if (handlerOrClassName == null) {            return null;        }        else if (handlerOrClassName instanceof NamespaceHandler) {            return (NamespaceHandler) handlerOrClassName;        }        else {            String className = (String) handlerOrClassName;            try {                Class&lt;?&gt; handlerClass = ClassUtils.forName(className, this.classLoader);                if (!NamespaceHandler.class.isAssignableFrom(handlerClass)) {                    throw new FatalBeanException(&quot;Class [&quot; + className + &quot;] for namespace [&quot; + namespaceUri +                            &quot;] does not implement the [&quot; + NamespaceHandler.class.getName() + &quot;] interface&quot;);                }                NamespaceHandler namespaceHandler = (NamespaceHandler) BeanUtils.instantiateClass(handlerClass);                //调用处理类的init方法，在init方法中完成标签元素解析类的注册                namespaceHandler.init();                handlerMappings.put(namespaceUri, namespaceHandler);                return namespaceHandler;            }            catch (ClassNotFoundException ex) {                throw new FatalBeanException(&quot;Could not find NamespaceHandler class [&quot; + className +                        &quot;] for namespace [&quot; + namespaceUri + &quot;]&quot;, ex);            }            catch (LinkageError err) {                throw new FatalBeanException(&quot;Unresolvable class definition for NamespaceHandler class [&quot; +                        className + &quot;] for namespace [&quot; + namespaceUri + &quot;]&quot;, err);            }        }    }</code></pre></li><li><p>获取namespace跟NamespaceHandler映射关系的详细过程。spring在jar包的META-INF/spring.handlers文件中，已经保存了NamespaceUri和NamepsaceHandler之间的映射。此处会加载spring.handlers中的所有内容并保存在map中。</p><pre><code class="java">    private Map&lt;String, Object&gt; getHandlerMappings() {        Map&lt;String, Object&gt; handlerMappings = this.handlerMappings;        if (handlerMappings == null) {            synchronized (this) {                handlerMappings = this.handlerMappings;                if (handlerMappings == null) {                    if (logger.isTraceEnabled()) {                        logger.trace(&quot;Loading NamespaceHandler mappings from [&quot; + this.handlerMappingsLocation + &quot;]&quot;);                    }                    try {                        //加载&quot;META-INF/spring.handlers&quot;文件过程                        Properties mappings =                                PropertiesLoaderUtils.loadAllProperties(this.handlerMappingsLocation, this.classLoader);                        if (logger.isTraceEnabled()) {                            logger.trace(&quot;Loaded NamespaceHandler mappings: &quot; + mappings);                        }                        //所有&quot;META-INF/spring.handlers&quot;文件里面的内容建立映射关系                        handlerMappings = new ConcurrentHashMap&lt;&gt;(mappings.size());                        CollectionUtils.mergePropertiesIntoMap(mappings, handlerMappings);                        this.handlerMappings = handlerMappings;                    }                    catch (IOException ex) {                        throw new IllegalStateException(                                &quot;Unable to load NamespaceHandler mappings from location [&quot; + this.handlerMappingsLocation + &quot;]&quot;, ex);                    }                }            }        }        return handlerMappings;    }</code></pre></li></ol><h2 id="默认标签的解析"><a href="#默认标签的解析" class="headerlink" title="默认标签的解析"></a>默认标签的解析</h2><ol><li><p>默认标签分为四种，import、alias、bean、beans，这里主要看bean标签的解析。</p><pre><code class="java">    private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) {        //import标签解析  重要程度 1 ，可看可不看        if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) {            importBeanDefinitionResource(ele);        }        //alias标签解析 别名标签  重要程度 1 ，可看可不看        else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) {            processAliasRegistration(ele);        }        //bean标签，重要程度  5，必须看        else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) {            processBeanDefinition(ele, delegate);        }        else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) {            // recurse            doRegisterBeanDefinitions(ele);        }    }</code></pre></li><li><p>先调用parseBeanDefinitionElement(ele)方法首先解析节点属性封装为BeanDefinitionHolder对象，之后再解析BeanDefinitionHolder对象中的自定义属性，并使用装饰者模式将解析后的属性设置到BeanDefinitionHolder中，然后对BeanDefinitionHolder进行注册。</p><pre><code class="java">    protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) {        //重点看这个方法，重要程度 5 ，解析ele，封装成BeanDefinition        BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele);        if (bdHolder != null) {            //该方法功能不重要，设计模式重点看一下，装饰者设计模式，加上SPI设计思想            bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder);            try {                //完成document到BeanDefinition对象转换后，对BeanDefinition对象进行缓存注册                // Register the final decorated instance.                //注册过程，重要程度5                BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry());            }            catch (BeanDefinitionStoreException ex) {                getReaderContext().error(&quot;Failed to register bean definition with name &#39;&quot; +                        bdHolder.getBeanName() + &quot;&#39;&quot;, ele, ex);            }            // Send registration event.            getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder));        }    }</code></pre></li><li><p>初次解析标签的过程。这里解析完成后会返回到上层方法，上层方法会将BeanDefinition、beanname、aliases（别名）封装为BeanDefinitionHolder并返回。</p><pre><code class="java">    public AbstractBeanDefinition parseBeanDefinitionElement(            Element ele, String beanName, @Nullable BeanDefinition containingBean) {        this.parseState.push(new BeanEntry(beanName));        String className = null;        if (ele.hasAttribute(CLASS_ATTRIBUTE)) {            className = ele.getAttribute(CLASS_ATTRIBUTE).trim();        }        String parent = null;        if (ele.hasAttribute(PARENT_ATTRIBUTE)) {            parent = ele.getAttribute(PARENT_ATTRIBUTE);        }        try {            //创建GenericBeanDefinition对象            AbstractBeanDefinition bd = createBeanDefinition(className, parent);            //解析bean标签的属性，并把解析出来的属性设置到BeanDefinition对象中            parseBeanDefinitionAttributes(ele, beanName, containingBean, bd);            bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT));            //解析bean中的meta标签            parseMetaElements(ele, bd);            //解析bean中的lookup-method标签  重要程度：2，可看可不看            parseLookupOverrideSubElements(ele, bd.getMethodOverrides());            //解析bean中的replaced-method标签  重要程度：2，可看可不看            parseReplacedMethodSubElements(ele, bd.getMethodOverrides());            //解析bean中的constructor-arg标签  重要程度：2，可看可不看            parseConstructorArgElements(ele, bd);            //解析bean中的property标签  重要程度：2，可看可不看            parsePropertyElements(ele, bd);            //可以不看，用不到            parseQualifierElements(ele, bd);            bd.setResource(this.readerContext.getResource());            bd.setSource(extractSource(ele));            return bd;        }</code></pre></li><li><p>对标签中的自定义属性再次进行解析，此处用到的SPI思想跟装饰者模式，通过SPI思想获取处理类的方式与自定义标签解析中的方式相同，此处不再赘述。</p><pre><code class="java">    public BeanDefinitionHolder decorateIfRequired(            Node node, BeanDefinitionHolder originalDef, @Nullable BeanDefinition containingBd) {        //根据node获取到node的命名空间，形如：http://www.springframework.org/schema/p        String namespaceUri = getNamespaceURI(node);        if (namespaceUri != null &amp;&amp; !isDefaultNamespace(namespaceUri)) {            //这里有SPI服务发现的思想，根据配置文件获取namespaceUri对应的处理类            NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri);            if (handler != null) {                //调用NamespaceHandler处理类的decorate方法，开始具体装饰过程，并返回装饰完的对象                BeanDefinitionHolder decorated =                        handler.decorate(node, originalDef, new ParserContext(this.readerContext, this, containingBd));                if (decorated != null) {                    return decorated;                }            }            else if (namespaceUri.startsWith(&quot;http://www.springframework.org/&quot;)) {                error(&quot;Unable to locate Spring NamespaceHandler for XML schema namespace [&quot; + namespaceUri + &quot;]&quot;, node);            }            else {                // A custom namespace, not to be handled by Spring - maybe &quot;xml:...&quot;.                if (logger.isDebugEnabled()) {                    logger.debug(&quot;No Spring NamespaceHandler found for XML schema namespace [&quot; + namespaceUri + &quot;]&quot;);                }            }        }        return originalDef;    }</code></pre></li><li><p>注册过程，此处完成完成BeanDefinition的注册后会将beanname与aliases建立联系。</p><pre><code class="java">    public static void registerBeanDefinition(            BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry)            throws BeanDefinitionStoreException {        // Register bean definition under primary name.        String beanName = definitionHolder.getBeanName();        //完成BeanDefinition的注册，重点看，重要程度 5        registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition());        //建立别名和 id的映射，这样就可以根据别名获取到id        // Register aliases for bean name, if any.        String[] aliases = definitionHolder.getAliases();        if (aliases != null) {            for (String alias : aliases) {                registry.registerAlias(beanName, alias);            }        }    }</code></pre></li><li><p>BeanDefinition的注册详细过程。将beanname与beanDefinition缓存到map中、beanName放到beanDefinitionNames中，之后将通过beanDefinitionNames实例化bean</p><pre><code class="java">    public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition)            throws BeanDefinitionStoreException {        Assert.hasText(beanName, &quot;Bean name must not be empty&quot;);        Assert.notNull(beanDefinition, &quot;BeanDefinition must not be null&quot;);        if (beanDefinition instanceof AbstractBeanDefinition) {            try {                ((AbstractBeanDefinition) beanDefinition).validate();            }            catch (BeanDefinitionValidationException ex) {                throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName,                        &quot;Validation of bean definition failed&quot;, ex);            }        }        //先判断BeanDefinition是否已经注册        BeanDefinition existingDefinition = this.beanDefinitionMap.get(beanName);        if (existingDefinition != null) {            if (!isAllowBeanDefinitionOverriding()) {                throw new BeanDefinitionOverrideException(beanName, beanDefinition, existingDefinition);            }            else if (existingDefinition.getRole() &lt; beanDefinition.getRole()) {                // e.g. was ROLE_APPLICATION, now overriding with ROLE_SUPPORT or ROLE_INFRASTRUCTURE                if (logger.isInfoEnabled()) {                    logger.info(&quot;Overriding user-defined bean definition for bean &#39;&quot; + beanName +                            &quot;&#39; with a framework-generated bean definition: replacing [&quot; +                            existingDefinition + &quot;] with [&quot; + beanDefinition + &quot;]&quot;);                }            }            else if (!beanDefinition.equals(existingDefinition)) {                if (logger.isDebugEnabled()) {                    logger.debug(&quot;Overriding bean definition for bean &#39;&quot; + beanName +                            &quot;&#39; with a different definition: replacing [&quot; + existingDefinition +                            &quot;] with [&quot; + beanDefinition + &quot;]&quot;);                }            }            else {                if (logger.isTraceEnabled()) {                    logger.trace(&quot;Overriding bean definition for bean &#39;&quot; + beanName +                            &quot;&#39; with an equivalent definition: replacing [&quot; + existingDefinition +                            &quot;] with [&quot; + beanDefinition + &quot;]&quot;);                }            }            this.beanDefinitionMap.put(beanName, beanDefinition);        }        else {            if (hasBeanCreationStarted()) {                // Cannot modify startup-time collection elements anymore (for stable iteration)                synchronized (this.beanDefinitionMap) {                    this.beanDefinitionMap.put(beanName, beanDefinition);                    List&lt;String&gt; updatedDefinitions = new ArrayList&lt;&gt;(this.beanDefinitionNames.size() + 1);                    updatedDefinitions.addAll(this.beanDefinitionNames);                    updatedDefinitions.add(beanName);                    this.beanDefinitionNames = updatedDefinitions;                    if (this.manualSingletonNames.contains(beanName)) {                        Set&lt;String&gt; updatedSingletons = new LinkedHashSet&lt;&gt;(this.manualSingletonNames);                        updatedSingletons.remove(beanName);                        this.manualSingletonNames = updatedSingletons;                    }                }            }            else {                //把beanDefinition缓存到map中                // Still in startup registration phase                this.beanDefinitionMap.put(beanName, beanDefinition);                //把beanName放到beanDefinitionNames list中                this.beanDefinitionNames.add(beanName);                this.manualSingletonNames.remove(beanName);            }            this.frozenBeanDefinitionNames = null;        }        if (existingDefinition != null || containsSingleton(beanName)) {            resetBeanDefinition(beanName);        }    }</code></pre></li></ol><h2 id="设计模式2-委托模式"><a href="#设计模式2-委托模式" class="headerlink" title="设计模式2-委托模式"></a>设计模式2-委托模式</h2><p>不属于23种设计模式之一，是面向对象设计模式中常用的一种模式，可以理解为静态代理和策略模式的一种特殊的组合。简单来说就是接受请求的对象将请求委托给另一个对象来处理，在spring中比较常见。</p><pre><code class="java">public interface Company{    void product();}</code></pre><pre><code class="java">public class Sum implements Company{  @Override  public void product(){    System.out.println(&quot;sum product&quot;);  }}</code></pre><pre><code class="java">public class Boss implemets Company{    Sun sun = new Sun();    @Override    public void product(){        sun.product();    }}</code></pre><h2 id="设计模式3-装饰模式"><a href="#设计模式3-装饰模式" class="headerlink" title="设计模式3-装饰模式"></a>设计模式3-装饰模式</h2><p>装饰模式通过创建一个包装对象，包装对象中通常持有真实对象的引用，通常与装饰对象有相同的接口，提供与真实对象相同的交互方式。装饰对象在接收请求时会将请求转发给真实对象，并在转发前后增加一些附加功能。这样就可以在不改变真实对象的前提下，动态扩展真实对象的功能。</p><p>创建装饰的公共接口</p><pre><code class="java">public interface Person {    void desc();}</code></pre><p>创建被装饰类</p><pre><code class="java">public class FeiZhai implements Person {    @Override    public void desc() {        System.out.println(&quot;这是一个快乐肥宅&quot;);    }}</code></pre><p>创建装饰器</p><pre><code class="java">public class Decorator implements Person {    Person person;    public PersonDecorator(Person person) {        this.person = person;    }    @Override    public void desc() {        person.desc();    }}</code></pre><p>创建装饰子类：</p><pre><code class="java">public class DecoratorDnfPlayer extends PersonDecorator {    public HighPerson(Person person) {        super(person);    }    @Override    public void desc() {        super.desc();        System.out.println(&quot;DNF玩家，八百万勇士之一！！！&quot;);    }}</code></pre><p>具体使用</p><pre><code class="java">public class DecorationTest {    @Test    public void test(){        System.out.println(&quot;创建一个肥宅&quot;);        Person person = new FeiZhai();        person.desc();        System.out.println(&quot;使用装饰器，装饰肥宅&quot;);        person = new DecoratorDnfPlayer(persion);        person.desc();    }}</code></pre><h2 id="设计模式4策略模式"><a href="#设计模式4策略模式" class="headerlink" title="设计模式4策略模式"></a>设计模式4策略模式</h2><p>简单来说就是创建不同的处理逻辑，然后根据条件去选择处理逻辑。当代码中出现大量的if时，为了避免修改核心代码，以及增加拓展性就经常需要使用策略模式。</p><p>比如，有省份不同省份做不同处理的需求时：</p><p>先创建一个接口</p><pre><code class="java">public interface Province {    public boolean support(String flag);    public String handler();}</code></pre><p>湖北的处理策略</p><pre><code class="java">@Componentpublic class HN implements Province{    private static String flag = &quot;HN&quot;;    @Override    public boolean support(String flag) {        return HN.flag.equalsIgnoreCase(flag);    }    @Override    public String handler() {        System.out.println(&quot;======HN处理类处理&quot;);        return null;    }}</code></pre><p>湖南的处理策略</p><pre><code class="java">@Componentpublic class HN implements Province{    private static String flag = &quot;HN&quot;;    @Override    public boolean support(String flag) {        return HN.flag.equalsIgnoreCase(flag);    }    @Override    public String handler() {        System.out.println(&quot;======HN处理类处理&quot;);        return null;    }}</code></pre><p>具体的使用</p><pre><code class="java">public void test1() {    String flag = &quot;CQ&quot;;    Map&lt;String, Province&gt; beansOfType = applicationContext.getBeansOfType(Province.class);    beansOfType.forEach((k,v) -&gt; {        if(v.support(flag)) {            v.handler();        }    });}</code></pre><h2 id="设计模式5建造者模式"><a href="#设计模式5建造者模式" class="headerlink" title="设计模式5建造者模式"></a>设计模式5建造者模式</h2><p>当类的属性过于复杂时，使用构造方法或set()方法设置会让代码变的混乱，这时就可以通过建造者模式对类进行装配。</p><pre><code class="java">public class BuilderClass {    private final int servingSize;    private final int servings;    private final int calories;    private final int fat;    private final int sodium;    private final int carbohydrate;    public static class Builder {        // 必要参数        private final int servingSize;        private final int servings;        // 可选参数        private int calories = 0;        private int fat = 0;        private int carbohydrate = 0;        private int sodium = 0;        public Builder(int servingSize, int servings) {            this.servingSize = servingSize;            this.servings = servings;        }        public Builder calories(int val) {            calories = val;            return this;        }        public Builder fat(int val) {            fat = val;            return this;        }        public Builder carbohydrate(int val) {            carbohydrate = val;            return this;        }        public Builder sodium(int val) {            sodium = val;            return this;        }        public BuilderClass build() {            return new BuilderClass(this);        }    }    private BuilderClass(Builder builder) {        servingSize = builder.servingSize;        servings = builder.servings;        calories = builder.calories;        fat = builder.fat;        sodium = builder.sodium;        carbohydrate = builder.carbohydrate;    }    public static void main(String[] args) {        BuilderClass cocaCola = new BuilderClass.Builder(240, 8)                .calories(100).sodium(35).carbohydrate(27).build();    }}</code></pre><h2 id="component-scan标签的解析"><a href="#component-scan标签的解析" class="headerlink" title="component-scan标签的解析"></a>component-scan标签的解析</h2><ol><li><p>context属于自定义标签，所以需要先通过namespace命名空间在spring.handlers文件中获取到对应的NamepsaceHandler处理类之后再调用init()方法注册BeanDefinitionParser解析类，然后再获取scan对应的BeanDefinitionParser解析类进行解析。</p><pre><code>http\://www.springframework.org/schema/context=org.springframework.context.config.ContextNamespaceHandlerhttp\://www.springframework.org/schema/jee=org.springframework.ejb.config.JeeNamespaceHandlerhttp\://www.springframework.org/schema/lang=org.springframework.scripting.config.LangNamespaceHandlerhttp\://www.springframework.org/schema/task=org.springframework.scheduling.config.TaskNamespaceHandlerhttp\://www.springframework.org/schema/cache=org.springframework.cache.config.CacheNamespaceHandler</code></pre></li><li><p>调用ContextNamespaceHandler的init()方法注册BeanDefinitionParser解析类。</p><pre><code class="java">    @Override    public void init() {        registerBeanDefinitionParser(&quot;property-placeholder&quot;, new PropertyPlaceholderBeanDefinitionParser());        registerBeanDefinitionParser(&quot;property-override&quot;, new PropertyOverrideBeanDefinitionParser());        registerBeanDefinitionParser(&quot;annotation-config&quot;, new AnnotationConfigBeanDefinitionParser());        registerBeanDefinitionParser(&quot;component-scan&quot;, new ComponentScanBeanDefinitionParser());        registerBeanDefinitionParser(&quot;load-time-weaver&quot;, new LoadTimeWeaverBeanDefinitionParser());        registerBeanDefinitionParser(&quot;spring-configured&quot;, new SpringConfiguredBeanDefinitionParser());        registerBeanDefinitionParser(&quot;mbean-export&quot;, new MBeanExportBeanDefinitionParser());        registerBeanDefinitionParser(&quot;mbean-server&quot;, new MBeanServerBeanDefinitionParser());    }</code></pre></li><li><p>BeanDefinitionParser的parser()方法中的逻辑。在这里将创建扫描器对基础包路径下的类进行扫描，并创建为BeanDefiniton对象，然后通过registerComponents()方法注册BeanPostProcessor。BeanPostProcessor主要是支撑类中其他注解的功能，如@Autowired、@PostConstruct、@PreDestory等。</p><pre><code class="java">    public BeanDefinition parse(Element element, ParserContext parserContext) {        //获取basePackage属性        String basePackage = element.getAttribute(BASE_PACKAGE_ATTRIBUTE);        basePackage = parserContext.getReaderContext().getEnvironment().resolvePlaceholders(basePackage);        //可以用逗号分开        String[] basePackages = StringUtils.tokenizeToStringArray(basePackage,                ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS);        //创建注解扫描器        // Actually scan for bean definitions and register them.        ClassPathBeanDefinitionScanner scanner = configureScanner(parserContext, element);        //扫描并把扫描的类封装成beanDefinition对象  核心方法，重要程度 5        Set&lt;BeanDefinitionHolder&gt; beanDefinitions = scanner.doScan(basePackages);    //注册BeanPostProcessor        registerComponents(parserContext.getReaderContext(), beanDefinitions, element);        return null;    }</code></pre></li><li><p>doScan()方法中会扫描到有注解的类并封装成BeanDefinitionHolder对象。在通过findCandidateComponents()获取到BeanDefinition之后，会根据ScopeMetadata对BeanDefinitionHolder的属性再次进行设置，并创建BeanDefinitionHolder对象，最后注册BeanDefinitonHolder。注册过程与默认实例化中相同，此处不再赘述。</p><pre><code class="java">    protected Set&lt;BeanDefinitionHolder&gt; doScan(String... basePackages) {        Assert.notEmpty(basePackages, &quot;At least one base package must be specified&quot;);        Set&lt;BeanDefinitionHolder&gt; beanDefinitions = new LinkedHashSet&lt;&gt;();        for (String basePackage : basePackages) {            //扫描到有注解的类并封装成BeanDefinition对象            Set&lt;BeanDefinition&gt; candidates = findCandidateComponents(basePackage);            for (BeanDefinition candidate : candidates) {                ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(candidate);                candidate.setScope(scopeMetadata.getScopeName());                String beanName = this.beanNameGenerator.generateBeanName(candidate, this.registry);                if (candidate instanceof AbstractBeanDefinition) {                    postProcessBeanDefinition((AbstractBeanDefinition) candidate, beanName);                }                if (candidate instanceof AnnotatedBeanDefinition) {                    //支持了@Lazy @DependOn注解                    AnnotationConfigUtils.processCommonDefinitionAnnotations((AnnotatedBeanDefinition) candidate);                }                if (checkCandidate(beanName, candidate)) {                    BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(candidate, beanName);                    //这里不看                    definitionHolder =                            AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry);                    beanDefinitions.add(definitionHolder);                    //BeanDefinition注册                    registerBeanDefinition(definitionHolder, this.registry);                }            }        }        return beanDefinitions;    }</code></pre></li><li><p>findCandidateComponents()会递寻找包路径下文件，然后将文件封装为MetadataReader对象，之后再根据MetadataReader中的类注解判断是否进行实例化。进行处理并封装为BeanDefinition。MetadataReader中持有一个ClassMetadata，ClassMetadata对象中几乎包括类的所有信息。</p><pre><code class="java">    private Set&lt;BeanDefinition&gt; scanCandidateComponents(String basePackage) {        Set&lt;BeanDefinition&gt; candidates = new LinkedHashSet&lt;&gt;();        try {            String packageSearchPath = ResourcePatternResolver.CLASSPATH_ALL_URL_PREFIX +                    resolveBasePackage(basePackage) + &#39;/&#39; + this.resourcePattern;            //这里递归寻找文件            Resource[] resources = getResourcePatternResolver().getResources(packageSearchPath);            boolean traceEnabled = logger.isTraceEnabled();            boolean debugEnabled = logger.isDebugEnabled();            for (Resource resource : resources) {                if (traceEnabled) {                    logger.trace(&quot;Scanning &quot; + resource);                }                if (resource.isReadable()) {                    try {                        //将文件信息包装为类基本信息的对象                        MetadataReader metadataReader = getMetadataReaderFactory().getMetadataReader(resource);                        //如果类上面有includeFilters中的注解                        if (isCandidateComponent(metadataReader)) {                            ScannedGenericBeanDefinition sbd = new ScannedGenericBeanDefinition(metadataReader);                            sbd.setResource(resource);                            sbd.setSource(resource);                            if (isCandidateComponent(sbd)) {                                if (debugEnabled) {                                    logger.debug(&quot;Identified candidate component class: &quot; + resource);                                }                                candidates.add(sbd);                            }                            else {                                if (debugEnabled) {                                    logger.debug(&quot;Ignored because not a concrete top-level class: &quot; + resource);                                }                            }                        }                        else {                            if (traceEnabled) {                                logger.trace(&quot;Ignored because not matching any filter: &quot; + resource);                            }                        }                    }                    catch (Throwable ex) {                        throw new BeanDefinitionStoreException(                                &quot;Failed to read candidate component class: &quot; + resource, ex);                    }                }                else {                    if (traceEnabled) {                        logger.trace(&quot;Ignored because not readable: &quot; + resource);                    }                }            }        }        catch (IOException ex) {            throw new BeanDefinitionStoreException(&quot;I/O failure during classpath scanning&quot;, ex);        }        return candidates;    }</code></pre></li><li><p>递归寻找文件的主要方法</p><pre><code class="java">    protected void doRetrieveMatchingFiles(String fullPattern, File dir, Set&lt;File&gt; result) throws IOException {        if (logger.isTraceEnabled()) {            logger.trace(&quot;Searching directory [&quot; + dir.getAbsolutePath() +                    &quot;] for files matching pattern [&quot; + fullPattern + &quot;]&quot;);        }        for (File content : listDirectory(dir)) {            String currPath = StringUtils.replace(content.getAbsolutePath(), File.separator, &quot;/&quot;);            //如果是一个文件夹，则递归            if (content.isDirectory() &amp;&amp; getPathMatcher().matchStart(fullPattern, currPath + &quot;/&quot;)) {                if (!content.canRead()) {                    if (logger.isDebugEnabled()) {                        logger.debug(&quot;Skipping subdirectory [&quot; + dir.getAbsolutePath() +                                &quot;] because the application is not allowed to read the directory&quot;);                    }                }                else {                    doRetrieveMatchingFiles(fullPattern, content, result);                }            }            //如果是一个文件，则加入到容器            if (getPathMatcher().match(fullPattern, currPath)) {                result.add(content);            }        }    }</code></pre></li><li><p>注册BeanPostProcessor过程</p><pre><code class="java">    public static Set&lt;BeanDefinitionHolder&gt; registerAnnotationConfigProcessors(            BeanDefinitionRegistry registry, @Nullable Object source) {        DefaultListableBeanFactory beanFactory = unwrapDefaultListableBeanFactory(registry);        if (beanFactory != null) {            if (!(beanFactory.getDependencyComparator() instanceof AnnotationAwareOrderComparator)) {                beanFactory.setDependencyComparator(AnnotationAwareOrderComparator.INSTANCE);            }            if (!(beanFactory.getAutowireCandidateResolver() instanceof ContextAnnotationAutowireCandidateResolver)) {                beanFactory.setAutowireCandidateResolver(new ContextAnnotationAutowireCandidateResolver());            }        }        Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;&gt;(8);        if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) {            RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class);            def.setSource(source);            beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME));        }        if (!registry.containsBeanDefinition(AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) {            RootBeanDefinition def = new RootBeanDefinition(AutowiredAnnotationBeanPostProcessor.class);            def.setSource(source);            beanDefs.add(registerPostProcessor(registry, def, AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME));        }        // Check for JSR-250 support, and if present add the CommonAnnotationBeanPostProcessor.        if (jsr250Present &amp;&amp; !registry.containsBeanDefinition(COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)) {            RootBeanDefinition def = new RootBeanDefinition(CommonAnnotationBeanPostProcessor.class);            def.setSource(source);            beanDefs.add(registerPostProcessor(registry, def, COMMON_ANNOTATION_PROCESSOR_BEAN_NAME));        }        // Check for JPA support, and if present add the PersistenceAnnotationBeanPostProcessor.        if (jpaPresent &amp;&amp; !registry.containsBeanDefinition(PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)) {            RootBeanDefinition def = new RootBeanDefinition();            try {                def.setBeanClass(ClassUtils.forName(PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME,                        AnnotationConfigUtils.class.getClassLoader()));            }            catch (ClassNotFoundException ex) {                throw new IllegalStateException(                        &quot;Cannot load optional framework class: &quot; + PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, ex);            }            def.setSource(source);            beanDefs.add(registerPostProcessor(registry, def, PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME));        }        if (!registry.containsBeanDefinition(EVENT_LISTENER_PROCESSOR_BEAN_NAME)) {            RootBeanDefinition def = new RootBeanDefinition(EventListenerMethodProcessor.class);            def.setSource(source);            beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_PROCESSOR_BEAN_NAME));        }        if (!registry.containsBeanDefinition(EVENT_LISTENER_FACTORY_BEAN_NAME)) {            RootBeanDefinition def = new RootBeanDefinition(DefaultEventListenerFactory.class);            def.setSource(source);            beanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_FACTORY_BEAN_NAME));        }        return beanDefs;    }</code></pre></li></ol><h2 id="简单上手"><a href="#简单上手" class="headerlink" title="简单上手"></a>简单上手</h2><h3 id="使用自定义标签连接redis"><a href="#使用自定义标签连接redis" class="headerlink" title="使用自定义标签连接redis"></a>使用自定义标签连接redis</h3><ol><li>创建自定义标签约束文件myMags.xsd，位置为在resources/META-INF/</li></ol><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;xsd:schema xmlns=&quot;http://www.test.com/schema/mytags&quot;            xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; targetNamespace=&quot;http://www.test.com/schema/mytags&quot;            elementFormDefault=&quot;qualified&quot; attributeFormDefault=&quot;unqualified&quot;&gt;    &lt;xsd:element name=&quot;redis&quot;&gt;        &lt;xsd:complexType&gt;            &lt;xsd:attribute name=&quot;id&quot; type=&quot;xsd:string&quot;&gt;&lt;/xsd:attribute&gt;            &lt;xsd:attribute name=&quot;ip&quot; type=&quot;xsd:string&quot;&gt;&lt;/xsd:attribute&gt;            &lt;xsd:attribute name=&quot;port&quot; type=&quot;xsd:string&quot;&gt;&lt;/xsd:attribute&gt;        &lt;/xsd:complexType&gt;    &lt;/xsd:element&gt;&lt;/xsd:schema&gt;</code></pre><ol start="2"><li>在相同位置为xsd文件创建映射文件spring.schemas</li></ol><pre><code class="scheme">http\://www.test.com/schema/mytags.xsd=META-INF/myTags.xsd</code></pre><ol start="3"><li>在相同位置下创建spring.handlers文件</li></ol><pre><code>http\://www.test.com/schema/mytags=org.example.tag.TagsNamespaceHandler</code></pre><ol start="4"><li>创建RedisBeanDefinitionParser类</li></ol><pre><code class="java">public class RedisBeanDefinitionParser extends AbstractSingleBeanDefinitionParser {    @Override    protected Class&lt;?&gt; getBeanClass(Element element) {        return Jedis.class;    }    @Override    protected void doParse(Element element, BeanDefinitionBuilder builder) {        String ip = element.getAttribute(&quot;ip&quot;);        String port = element.getAttribute(&quot;port&quot;);        builder.addConstructorArgValue(ip);        builder.addConstructorArgValue(Integer.parseInt(port));    }}</code></pre><ol start="5"><li>创建TagsNamespaceHandler类</li></ol><pre><code class="java">public class TagsNamespaceHandler extends NamespaceHandlerSupport {    @Override    public void init() {        this.registerBeanDefinitionParser(&quot;redis&quot;,new RedisBeanDefinitionParser());    }    @Override    public BeanDefinitionHolder decorate(Node node, BeanDefinitionHolder definition, ParserContext parserContext) {        return super.decorate(node, definition, parserContext);    }}</code></pre><ol start="6"><li>在spring.xml中使用自定义标签</li></ol><pre><code class="xml">&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:my=&quot;http://www.test.com/schema/mytags&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans       http://www.springframework.org/schema/beans/spring-beans.xsd       http://www.test.com/schema/mytags       http://www.test.com/schema/mytags.xsd&quot;       default-lazy-init=&quot;false&quot;&gt;    &lt;!--自定义标签--&gt;    &lt;my:redis id=&quot;redis&quot; ip=&quot;localhost&quot; port=&quot;6379&quot;/&gt;&lt;/beans&gt;</code></pre><ol start="7"><li>测试类</li></ol><pre><code class="java">@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = {&quot;classpath:spring.xml&quot;})public class MyTest {    @Autowired    private Jedis jedis;    @Test    public void myTag() {        jedis.set(&quot;tag&quot;,&quot;test&quot;);        System.out.println(jedis.get(&quot;tag&quot;));    }}</code></pre><h3 id="使用自定义注解创建Bean对象"><a href="#使用自定义注解创建Bean对象" class="headerlink" title="使用自定义注解创建Bean对象"></a>使用自定义注解创建Bean对象</h3><ol><li>创建MyBeanDefinitionRegistryPostProcessor</li></ol><pre><code class="java">public class MyBeanDefinitionRegistryPostProcessor implements BeanDefinitionRegistryPostProcessor {    @Override    public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException {        GenericBeanDefinition genericBeanDefinition = new GenericBeanDefinition();        genericBeanDefinition.setBeanClass(BeanClass.class);        MutablePropertyValues propertyValues = genericBeanDefinition.getPropertyValues();        propertyValues.addPropertyValue(&quot;username&quot;,&quot;test&quot;);        registry.registerBeanDefinition(&quot;beanClass&quot;,genericBeanDefinition);        ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(registry);        scanner.addIncludeFilter(new AnnotationTypeFilter(MyService.class));        scanner.scan(&quot;org.example.beanDefinition&quot;);    }    @Override    public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException {    }}</code></pre><ol start="2"><li>创建BeanClass</li></ol><pre><code class="java">public class BeanClass {    private String username;    public String getUsername() {        return username;    }    public void setUsername(String username) {        this.username = username;    }}</code></pre><ol start="3"><li>创建</li></ol><pre><code class="java">@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface MyService {ßß    String value() default &quot;&quot;;}</code></pre><ol start="4"><li>测试类</li></ol><pre><code class="java">@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = {&quot;classpath:spring.xml&quot;})public class MyTest {    @Autowired    private Jedis jedis;    @Test    public void myTag() {        jedis.set(&quot;tag&quot;,&quot;test&quot;);        System.out.println(jedis.get(&quot;tag&quot;));    }    @Autowired    private BeanClass beanClass;    @Test    public void beanDefinition(){        System.out.println(beanClass.getUsername());    }}</code></pre>]]></content>
    
    
    <categories>
      
      <category>Spring源码解析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码解析</tag>
      
      <tag>spring</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL的索引与执行计划</title>
    <link href="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/"/>
    <url>/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/</url>
    
    <content type="html"><![CDATA[<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。可以得到索引的本质：<strong>索引是数据结构</strong>。</p><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic1.png" srcset="/img/loading.gif" class=""><p>MySQL默认存储引擎InnoDB只显示支持B-Tree（从技术上来说是B+Tree），在创建创建主键索引时会新增一个节点，当通过主键来查询内容的时候，首先去查索引库快速的定位索引的具体位置。</p><h4 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h4><p>二分查找法（binary search） 也称为折半查找法，用来查找一组有序的记录数组中的某一记录。</p><p>其基本思想是：将记录按有序化（递增或递减）排列，在查找过程中采用跳跃式方式查找，即先以有序数列的中点位置作为比较对象，如果要找的元素值小于该中点元素，则将待查序列缩小为左半部分，否则为右半部分。通过一次比较，将查找区间缩小一半。</p><h4 id="二叉树-Binary-Tree"><a href="#二叉树-Binary-Tree" class="headerlink" title="二叉树(Binary Tree)"></a>二叉树(Binary Tree)</h4><p>每个节点至多只有二棵子树； </p><ul><li><p>二叉树的子树有左右之分，次序不能颠倒； </p></li><li><p>一棵深度为k，且有2的k-1次方个节点，称为满二叉树(Full Tree)； </p></li><li><p>一棵深度为k，且跟节点到k-1层的节点树都达到最大，第k层的所有节点都连续集中在最左边，此时为完全二叉树（Complete Tree）</p></li></ul><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic2.png" srcset="/img/loading.gif" class=""><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic3.png" srcset="/img/loading.gif" class=""><h4 id="平衡二叉树（AVL-树）"><a href="#平衡二叉树（AVL-树）" class="headerlink" title="平衡二叉树（AVL-树）"></a>平衡二叉树（AVL-树）</h4><ul><li>左子树和右子树的高度差绝对值不超过1</li><li>左子树和右子树都是平衡二叉树</li></ul><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic4.png" srcset="/img/loading.gif" class=""><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic5.png" srcset="/img/loading.gif" class=""><h5 id="平衡二叉树的遍历"><a href="#平衡二叉树的遍历" class="headerlink" title="平衡二叉树的遍历"></a>平衡二叉树的遍历</h5><ul><li>前序 ：6 ,3, 2, 5,7, 8（ROOT节点在开头, 中-左-右 顺序）</li><li>中序 ：2, 3, 5, 6,7, 8（中序遍历即为升序，左-中-右 顺序）</li><li>后序 ：2, 5, 3, 8,7, 6 （ROOT节点在结尾，左-右-中 顺序）</li></ul><h5 id="平衡二叉树的旋转"><a href="#平衡二叉树的旋转" class="headerlink" title="平衡二叉树的旋转"></a>平衡二叉树的旋转</h5><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic6.png" srcset="/img/loading.gif" class=""><p>需要通过旋转（左旋，右旋）来维护平衡二叉树的平衡，在添加和删除的时候需要有额外的开销。</p><h4 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h4><h5 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h5><ul><li><p>数据只存储在叶子节点上，非叶子节点只保存索引信息；</p><ul><li>非叶子节点（索引节点）存储的只是一个Flag，不保存实际数据记录； </li><li>索引节点指示该节点的左子树比这个Flag小，而右子树大于等于这个Flag；</li></ul></li><li><p>叶子节点本身按照数据的升序排序进行链接（串联起来）；</p><ul><li>叶子节点中的数据在物理存储上是无序的，仅仅是在逻辑上有序（通过指针串在一起）；</li></ul></li></ul><h5 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h5><ul><li>在块设备上，通过B+树可以有效的存储数据； </li><li>所有记录都存储在叶子节点上，非叶子(non-leaf)存储索引(keys)信息； </li><li>B+树含有非常高的扇出（fanout），通常超过100，在查找一个记录时，可以有效的减少IO操作； </li></ul><h5 id="扇出"><a href="#扇出" class="headerlink" title="扇出"></a>扇出</h5><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic7.png" srcset="/img/loading.gif" class=""><p>扇出是每个索引节点(Non-LeafPage)指向每个叶子节点(LeafPage)的指针，扇出数 = 索引节点(Non-LeafPage)可存储的最大关键字个数 + 1。图例中的索引节点（Non-LeafPage）最大可以存放4个关键字，但实际使用了3个；</p><ul><li>该 B+ 树高度为 2</li><li>每叶子页（LeafPage）4条记录</li><li>扇出数为5 ，</li><li>叶子节点(LeafPage)由小到大（有序）串联在一起</li></ul><h5 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h5><p>B+树的插入必须保证插入后叶子节点中的记录依然排序。 </p><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic8.png" srcset="/img/loading.gif" class=""><h3 id="索引的分类"><a href="#索引的分类" class="headerlink" title="索引的分类"></a>索引的分类</h3><ul><li><p>普通索引：即一个索引只包含单个列，一个表可以有多个单列索引</p></li><li><p>唯一索引：索引列的值必须唯一，但允许有空值</p></li><li><p>复合索引：即一个索引包含多个列</p></li><li><p>聚簇索引（聚集索引）：并不是一种单独的索引类型，而是一种数据存储方式。将数据存储与索引存储在一起，找到索引也就找到了数据。聚簇索引是唯一的，InnoDB通过聚簇索引保存数据，非聚簇索引一定存储有聚簇索引的列值。</p></li><li><p>非聚簇索引：将数据存储与索引分开存储的结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因。</p></li></ul><h3 id="索引的使用"><a href="#索引的使用" class="headerlink" title="索引的使用"></a>索引的使用</h3><p><strong>查看索引</strong></p><pre><code>SHOW INDEX FROM table_name;</code></pre><p><strong>创建索引</strong></p><pre><code>CREATE [UNIQUE ] INDEX indexName ON mytable(columnname(length));ALTER TABLE 表名 ADD [UNIQUE ] INDEX [indexName] ON (columnname(length));</code></pre><p><strong>删除索引</strong></p><pre><code>DROP INDEX [indexName] ON mytable;</code></pre><h2 id="执行计划"><a href="#执行计划" class="headerlink" title="执行计划"></a>执行计划</h2><p>使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的，分析你的查询语句或是表结构的性能瓶颈。</p><p>执行计划的语法比较简单，只要在SQL查询前加上EXPLAIN关键字就行。</p><p>比如：EXPLAIN select * from table1;</p><h3 id="执行计划详解"><a href="#执行计划详解" class="headerlink" title="执行计划详解"></a>执行计划详解</h3><p>通过执行计划的结果可以分析出以下内容：</p><ul><li>表的读取顺序</li><li>数据读取操作的操作类型</li><li>哪些索引可以使用</li><li>哪些索引被实际使用</li><li>表之间的引用</li><li>每张表有多少行被优化器查询</li></ul><p>通过EXPLAIN关键分析的结果由以下列组成，接下来挨个分析每一个列</p>{% asset_img pic9.png %}<h4 id="id"><a href="#id" class="headerlink" title="id"></a>id</h4><p>描述select查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序</p><p>根据ID的数值结果可以分成一下三种情况</p><ul><li>id相同：执行顺序由上至下</li><li>id不同：如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行</li><li>id相同不同：同时存在</li></ul><h4 id="select-type"><a href="#select-type" class="headerlink" title="select_type"></a>select_type</h4><p>查询类型，主要是用于区别普通查询，联合查询，自查询等的复杂查询</p><table><thead><tr><th>类型</th><th>描述</th></tr></thead><tbody><tr><td>SIMPLE</td><td>简单的select查询，查询中不包含子查询或者UNION</td></tr><tr><td>PRIMARY</td><td>查询中包含任何复杂的子部分，则最外层查询被标记为PRIMARY</td></tr><tr><td>SUBQUERY</td><td>在SELECT或者WHERE列表中包含的子查询</td></tr><tr><td>DERIVED</td><td>在FROM列表中包含的子查询被标记为DERIVED（衍生），MySQL会递归执行这些子查询，把结果放在临时表里。</td></tr><tr><td>UNION</td><td>若第二个SELECT出现在UNION之后，则标记为UNION；若UNION包含在FROM子句的子查询中，外层的SELECT被标记为DEIRIVED</td></tr><tr><td>UNION RESULT</td><td>从UNION表获取结果的SELECT</td></tr></tbody></table><h4 id="table"><a href="#table" class="headerlink" title="table"></a>table</h4><p>所关联的表</p><h4 id="type"><a href="#type" class="headerlink" title="type"></a>type</h4><p>type显示的是访问类型，是较为重要的一个指标，结果值从最好到最坏依次是：</p><p>system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL </p><p>常用的：</p><p>system&gt;const&gt;eq_ref&gt;ref&gt;range&gt;index&gt;ALL</p><p>一般来说，得保证查询至少达到range级别，最好能达到ref。</p><ul><li><p><strong>system</strong>：表只有一行记录（等于系统表），这是const类型的特例，平时不会出现，可以忽略不计</p></li><li><p><strong>const</strong>：表示通过索引一次就找到了，const用于比较primary key 或者 unique索引。因为只需匹配一行数据，所有很快。如果将主键置于where列表中，mysql就能将该查询转换为一个const </p></li><li><p><strong>eq_ref</strong>： 唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描。</p></li><li><p><strong>ref</strong>：非唯一性索引扫描，返回匹配某个单独值的所有行。本质是也是一种索引访问，它返回所有匹配某个单独值的行，然而他可能会找到多个符合条件的行，所以它应该属于查找和扫描的混合体 。</p></li><li><p><strong>range</strong>：只检索给定范围的行，使用一个索引来选择行。key列显示使用了那个索引。一般就是在where语句中出现了bettween、&lt;、&gt;、in等的查询。这种索引列上的范围扫描比全索引扫描要好。只需要开始于某个点，结束于另一个点，不用扫描全部索引 </p></li><li><p><strong>index</strong>：Full Index Scan，index与ALL区别为index类型只遍历索引树。这通常为ALL块，应为索引文件通常比数据文件小。（Index与ALL虽然都是读全表，但index是从索引中读取，而ALL是从硬盘读取） </p></li><li><p><strong>ALL</strong>：Full Table Scan，遍历全表以找到匹配的行</p></li></ul><h4 id="possible-keys与key"><a href="#possible-keys与key" class="headerlink" title="possible_keys与key"></a>possible_keys与key</h4><p>possible_keys：可能使用的索引。</p><p>key：实际使用的索引，如果为NULL，则没事用索引。</p><h4 id="key-len"><a href="#key-len" class="headerlink" title="key_len"></a>key_len</h4><p>Key_len表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。在不损失精确性的情况下，长度越短越好。如果充分用了索引key_len会比没有充分用到索引要长。key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的。</p><ul><li>根据这个值，就可以判断索引使用情况，特别是在组合索引的时候，判断所有的索引字段是否都被查询用到。</li><li>char和varchar跟字符编码也有密切的联系。</li><li>latin1占用1个字节，gbk占用2个字节，utf8占用3个字节。（不同字符编码占用的存储空间不同）</li></ul><h5 id="字符类型key-len计算"><a href="#字符类型key-len计算" class="headerlink" title="字符类型key_len计算"></a>字符类型key_len计算</h5><p>变长字段（varchar）需要额外的2个字节（VARCHAR值保存时只保存需要的字符数，另加一个字节来记录长度（如果列声明的长度超过255，则使用两个字节），所以VARCAHR索引长度计算时候要加2），固定长度字段（char）不需要额外的字节。 </p><p>而如果允许为NULL都需要1个字节的额外空间，所以索引字段最好不要允许为NULL，因为允许为NULL会让统计更加复杂并且需要额外的存储空间。</p><p>复合索引有最左前缀的特性，如果复合索引能全部使用上，则是复合索引字段的索引长度之和，这也可以用来判定复合索引是否部分使用，还是全部使用。</p><h5 id="整数-浮点数-时间类型的索引长度"><a href="#整数-浮点数-时间类型的索引长度" class="headerlink" title="整数/浮点数/时间类型的索引长度"></a>整数/浮点数/时间类型的索引长度</h5><p>整数/浮点数/时间类型的索引长度等于字段本身的字段长度，如果为NULL就等于字段本身的长度+1。</p><p>datetime类型在5.6中字段长度是5个字节，datetime类型在5.5中字段长度是8个字节。</p><h4 id="ref"><a href="#ref" class="headerlink" title="ref"></a>ref</h4><p>显示索引的哪一列被使用了，如果可能的话，是一个常数。哪些列或常量被用于查找索引列上的值</p><h4 id="rows"><a href="#rows" class="headerlink" title="rows"></a>rows</h4><p>根据表统计信息及索引选用情况，大致估算出找到所需的记录所需要读取的行数</p><h4 id="extra"><a href="#extra" class="headerlink" title="extra"></a>extra</h4><p>包含不适合在其他列中显示但十分重要的额外信息。</p><p>Using filesort：文件排序，表示MySQL中无法利用索引完成的排序。当查询的排序规则与复合索引顺序不同时，MySQL会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。。</p><p>Using temporary：表示使用了临时表保存中间结果，常见于排序order by和分组查询group by。</p><p>Using index：表示使用了覆盖索引。覆盖索引表示在获取查询结果时只需要遍历索引树，不需要从硬盘中读取。</p><p>Using where：表示使用了where或者on过滤。</p><p>Using join buffer：表示使用了连接缓存，连接缓存的大小可以使用<code>show VARIABLES like &#39;%join_buffer_size%&#39;</code></p><p>Impossible where：where子句的值总是false，不能用来获取任何元组。</p><h2 id="SQL优化策略"><a href="#SQL优化策略" class="headerlink" title="SQL优化策略"></a>SQL优化策略</h2><p><strong>尽量全值匹配</strong>：如果使用复合索引，应使where条件中尽量包含复合索引的全部列。</p><p><strong>最佳左前缀法则</strong>：复合索引在使用时要遵守最左前缀法则，即查询条件应从从索引最左侧的列开始并且不跳过索引中间的列。</p><p><strong>不在索引列上做任何操作</strong>：索引列上做任何操作（计数、函数、类型转换）会导致索引失效而转向全表扫描。</p><p><strong>进行范围条件查询的列放最后</strong>：如果对复合索引中的列进行范围查询，而且该列处于复合索引的中间位置，会导致符合索引后面的索引列全部失效。</p><p><strong>尽量使用覆盖索引</strong>：尽量使用覆盖索引(只访问索引的查询(索引列和查询列一致))，减少select *</p><p><strong>不等于要慎用</strong>：mysql 在使用不等于（!= 或者&lt;&gt;）的时候会导致索引失效会导致全表扫描，解决方式为使用覆盖索引</p><p><strong>NULL、NOT NULL会影响索引</strong>：在列不允许为空的情况下，使用IS NULL或IS NOT NULL会导致索引失效，在列允许为空的情况下IS NOT NULL会导致索引失效，使用覆盖索引也可以解决这个问题。</p><p><strong>慎用LIKE查询</strong>：如果LIKE以通配符开头（’%abc…’）会导致索引失效变成全表扫描的操作，同样使用覆盖索引也可以解决这个问题。</p><p><strong>字符类型加引号</strong>：字符串不加单引号索引失效。</p><p><strong>OR改为UNION效率高</strong>：OR会导致索引失效，解决方式为使用UNION改写SQL。</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><table><thead><tr><th>where语句</th><th>使用到的索引</th></tr></thead><tbody><tr><td>where a = 3</td><td>a</td></tr><tr><td>where a = 3 and b = 5</td><td>a,b</td></tr><tr><td>where a = 3 and b = 5 and c = 4</td><td>a,b,c</td></tr><tr><td>where b = 3 或者 where b = 3 and c = 4 或者 where c = 5</td><td>空</td></tr><tr><td>where a = 3 and c = 5</td><td>a</td></tr><tr><td>where a = 3 and b &gt;4 and c = 5</td><td>a,b</td></tr><tr><td>where a = 3 and b like ‘kk%’ and c = 4</td><td>a,b,c</td></tr><tr><td>where a = 3 and b like ‘%kk’ and c = 4</td><td>a</td></tr><tr><td>where a = 3 and b like ‘%kk%’ and c = 4</td><td>a</td></tr><tr><td>where a = 3 and b like ‘k%kk%’ and c = 4</td><td>a,b,c</td></tr></tbody></table><h3 id="记忆总结"><a href="#记忆总结" class="headerlink" title="记忆总结"></a>记忆总结</h3><ul><li><p>全值匹配我最爱，最左前缀要遵守；</p></li><li><p>带头大哥不能死，中间兄弟不能断；</p></li><li><p>索引列上少计算，范围之后全失效；</p></li><li><p>LIKE百分写最右，覆盖索引不写*；</p></li><li><p>不等空值还有OR，索引影响要注意；</p></li><li><p>VARCHAR引号不可丢， SQL优化有诀窍。</p></li></ul><h3 id="数据的迁移"><a href="#数据的迁移" class="headerlink" title="数据的迁移"></a>数据的迁移</h3><p>使用前需要确认MySQL是否允许允许导入导出。</p><pre><code>show VARIABLES like &#39;secure_file_priv&#39;</code></pre><ul><li><p>secure_file_priv为NULL时，表示限制MySQL不允许导入或导出。</p></li><li><p>secure_file_priv为/tmp时，表示限制MySQL只能在/tmp目录中执行导入导出，其他目录不能执行。</p></li><li><p>secure_file_priv没有值时，表示不限制MySQL在任意目录的导入导出。</p></li></ul><p>修改方法为将<code>source_file_priv=&#39;&#39;</code>添加到my.cnf文件中。</p><pre><code>select * into OUTFILE &#39;D:\\product.txt&#39; from product_info    -- 将表中的数据迁移到product.txt文件中load data INFILE &#39;D:\\product.txt&#39; into table product_info    -- 将product.txt文件中的数据导入到表中</code></pre>]]></content>
    
    
    <categories>
      
      <category>MySQL进阶</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL的慢查询</title>
    <link href="/2020/04/02/MySQL%E7%9A%84%E6%85%A2%E6%9F%A5%E8%AF%A2/"/>
    <url>/2020/04/02/MySQL%E7%9A%84%E6%85%A2%E6%9F%A5%E8%AF%A2/</url>
    
    <content type="html"><![CDATA[<h2 id="慢查询的配置"><a href="#慢查询的配置" class="headerlink" title="慢查询的配置"></a>慢查询的配置</h2><p>慢查询日志是指MySQL记录所有执行超过long_query_time参数设定的时间阈值的SQL语句的日志。该日志能为SQL语句的优化带来很好的帮助。默认情况下，慢查询日志是关闭的，要使用慢查询日志功能，首先要开启慢查询日志功能。</p><h3 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h3><ul><li>slow_query_log 启动停止技术慢查询日志</li><li>slow_query_log_file 指定慢查询日志得存储路径及文件（默认和数据文件放一起）</li><li>long_query_time 指定记录慢查询日志SQL执行时间得伐值（单位:秒，默认10秒）</li><li>log_queries_not_using_indexes 是否记录未使用索引的SQL</li><li>log_output 日志存放的地方[TABLE][FILE][FILE,TABLE]</li></ul><p>通过下面命令查看下上面的配置：</p><pre><code>show VARIABLES like &#39;%slow_query_log%&#39;show VARIABLES like &#39;%slow_query_log_file%&#39;show VARIABLES like &#39;%long_query_time%&#39;show VARIABLES like &#39;%log_queries_not_using_indexes%&#39;show VARIABLES like &#39;%log_output%&#39;</code></pre><p>通过下面命令设置上面的配置：</p><pre><code>set global long_query_time=5;  -- 默认10秒，这里设置为5秒set GLOBAL slow_query_log = 1; -- 开启慢查询日志set global log_output=&#39;FILE,TABLE&#39; -- 记录在表跟文件中，项目开发中日志只能记录在日志文件中，不能记表中</code></pre><p>设置完成后在datadir中就可以看到慢查询语句，数据库的datadir查看方式为<code>show VARIABLES like &#39;datadir&#39;</code></p><h2 id="慢查询解读"><a href="#慢查询解读" class="headerlink" title="慢查询解读"></a>慢查询解读</h2><pre><code># User@Host: root[root] @ localhost [127.0.0.1]  Id:   10    -- 用户名 、用户的IP信息、线程ID号# Query_time: 0.001042    -- 执行花费的时间【单位：毫秒】# Lock_time:0.000000    -- 执行获得锁的时间# Rows_sent: 2    -- 获得的结果行数# Rows_examined: 2    -- 扫描的数据行数SET timestamp=1535462721;    -- 这SQL执行的具体时间SELECT * FROM mvarchive LIMIT O, 1000;    -- 具体的SQL语句</code></pre><h2 id="慢查询分析"><a href="#慢查询分析" class="headerlink" title="慢查询分析"></a>慢查询分析</h2><p>慢查询的日志记录非常多，要从里面找寻一条查询慢的日志并不是很容易的事情，一般来说都需要一些工具辅助才能快速定位到需要优化的SQL语句，下面介绍两个慢查询辅助工具。</p><h3 id="mysql-dumpslow"><a href="#mysql-dumpslow" class="headerlink" title="mysql dumpslow"></a>mysql dumpslow</h3><p>常用的慢查询日志分析工具，汇总除查询条件外其他完全相同的SQL，并将分析结果按照参数中所指定的顺序输出。</p><p>使用方法：</p><pre><code>mysqldumpslow -s r -t 10 slow-mysql.log-s 排序规则，可选参数[c,t,l,r,at,al,ar]   c:总次数   t:总时间   l:锁的时间   r:总数据行   at,al,ar:平均数[例如：at = 总时间/总次数]-t 选取条数</code></pre><h3 id="pt-query-digest"><a href="#pt-query-digest" class="headerlink" title="pt_query_digest"></a>pt_query_digest</h3><p>是用于分析mysql慢查询的一个工具，与mysqldumpshow工具相比，py-query_digest 工具的分析结果更具体，更完善。但可能因为某些原因如权限不足等，无法在服务器上记录查询。</p><h4 id="安装方式"><a href="#安装方式" class="headerlink" title="安装方式"></a>安装方式</h4><pre><code>安装依赖工具：yum install perl-DBIyum install perl-DBD-MySQLyum install perl-Time-HiResyum install perl-IO-Socket-SSLyum install perl-Digest-MD5下载pt-query-disgest、授权、将其放到/usr/bin下：wget percona.com/get/pt-query-digestchmod u+x pt-query-digestmv /usr/src/pt-query-digest /usr/bin/perl ./pt-query-digest  --explain h=127.0.0.1,u=root,p=root1234%  /usr/local/mysql/data/mysql-slow.log</code></pre><h4 id="语法与重要选项"><a href="#语法与重要选项" class="headerlink" title="语法与重要选项"></a>语法与重要选项</h4><pre><code>pt-query-digest [OPTIONS] [FILES] [DSN]--create-review-table  当使用--review参数把分析结果输出到表中时，如果没有表就自动创建。--create-history-table  当使用--history参数把分析结果输出到表中时，如果没有表就自动创建。--filter  对输入的慢查询按指定的字符串进行匹配过滤后再进行分析--limit限制输出结果百分比或数量，默认值是20,即将最慢的20条语句输出，如果是50%则按总响应时间占比从大到小排序，输出到总和达到50%位置截止。--host  mysql服务器地址--user  mysql用户名--password  mysql用户密码--history 将分析结果保存到表中，分析结果比较详细，下次再使用--history时，如果存在相同的语句，且查询所在的时间区间和历史表中的不同，则会记录到数据表中，可以通过查询同一CHECKSUM来比较某类型查询的历史变化。--review 将分析结果保存到表中，这个分析只是对查询条件进行参数化，一个类型的查询一条记录，比较简单。当下次使用--review时，如果存在相同的语句分析，就不会记录到数据表中。--output 分析结果输出类型，值可以是report(标准分析报告)、slowlog(Mysql slow log)、json、json-anon，一般使用report，以便于阅读。--since 从什么时间开始分析，值为字符串，可以是指定的某个”yyyy-mm-dd [hh:mm:ss]”格式的时间点，也可以是简单的一个时间值：s(秒)、h(小时)、m(分钟)、d(天)，如12h就表示从12小时前开始统计。--until 截止时间，配合—since可以分析一段时间内的慢查询。</code></pre><h4 id="用法示例"><a href="#用法示例" class="headerlink" title="用法示例"></a>用法示例</h4><p>直接分析慢查询文件:</p><pre><code class="bash">#分析slow.log日志，并将分析报告输入到slow_report.log中shell&gt; pt-query-digest  slow.log &gt; slow_report.log</code></pre><p>分析最近12小时内的查询：</p><pre><code class="bash">shell&gt; pt-query-digest  --since=12h  slow.log &gt; slow_report2.log</code></pre><p>分析指定时间范围内的查询：</p><pre><code class="bash">pt-query-digest slow.log --since &#39;2014-04-17 09:30:00&#39; --until &#39;2014-04-17 10:00:00&#39; &gt; slow_report3.log</code></pre><p>分析指含有select语句的慢查询</p><pre><code class="bash">shell&gt; pt-query-digest--filter &#39;$event-&gt;{fingerprint} =~ m/^select/i&#39; slow.log&gt; slow_report4.log</code></pre><p>针对某个用户的慢查询</p><pre><code class="bash">shell&gt; pt-query-digest--filter &#39;($event-&gt;{user} || &quot;&quot;) =~ m/^root/i&#39; slow.log&gt; slow_report5.log</code></pre><p>查询所有所有的全表扫描或full join的慢查询</p><pre><code class="bash">  pt-query-digest--filter &#39;(($event-&gt;{Full_scan} || &quot;&quot;) eq &quot;yes&quot;) ||(($event-&gt;{Full_join} || &quot;&quot;) eq &quot;yes&quot;)&#39; slow.log&gt; slow_report6.log</code></pre><p>把查询保存到query_review表</p><pre><code class="bash">pt-query-digest  --user=root –password=abc123 --review  h=localhost,D=test,t=query_review--create-review-table  slow.log</code></pre><p>把查询保存到query_history表</p><pre><code class="bash">pt-query-digest  --user=root –password=abc123 --review  h=localhost,D=test,t=query_ history--create-review-table  slow.log_20140401pt-query-digest  --user=root –password=abc123--review  h=localhost,D=test,t=query_history--create-review-table  slow.log_20140402</code></pre><p>通过tcpdump抓取mysql的tcp协议数据，然后再分析</p><pre><code class="bash">tcpdump -s 65535 -x -nn -q -tttt -i any -c 1000 port 3306 &gt; mysql.tcp.txtpt-query-digest --type tcpdump mysql.tcp.txt&gt; slow_report9.log</code></pre><p>分析binlog</p><pre><code class="bash">mysqlbinlog mysql-bin.000093 &gt; mysql-bin000093.sqlpt-query-digest  --type=binlog  mysql-bin000093.sql &gt; slow_report10.log</code></pre><p>分析general log</p><pre><code class="bash">pt-query-digest  --type=genlog  localhost.log &gt; slow_report11.log</code></pre><h4 id="报告参数说明"><a href="#报告参数说明" class="headerlink" title="报告参数说明"></a>报告参数说明</h4>{% asset_img pic1.png %}<h5 id="第一部分：总体统计结果"><a href="#第一部分：总体统计结果" class="headerlink" title="第一部分：总体统计结果"></a>第一部分：总体统计结果</h5><ul><li>Overall：总共有多少条查询</li><li>Time range：查询执行的时间范围</li><li>unique：唯一查询数量，即对查询条件进行参数化以后，总共有多少个不同的查询</li><li>total：总计 min：最小 max：最大 avg：平均</li><li>95%：把所有值从小到大排列，位置位于95%的那个数，这个数一般最具有参考价值</li><li>median：中位数，把所有值从小到大排列，位置位于中间那个数</li></ul><pre><code># 该工具执行日志分析的用户时间，系统时间，物理内存占用大小，虚拟内存占用大小# 340ms user time, 140ms system time, 23.99M rss, 203.11M vsz# 工具执行时间# Current date: Fri Nov 25 02:37:18 2016# 运行分析工具的主机名# Hostname: localhost.localdomain# 被分析的文件名# Files: slow.log# 语句总数量，唯一的语句数量，QPS，并发数# Overall: 2 total, 2 unique, 0.01 QPS, 0.01x concurrency # 日志记录的时间范围# Time range: 2016-11-22 06:06:18 to 06:11:40# 属性    总计  最小 最大 平均 95% 标准 中等# Attribute   total  min  max  avg  95% stddev median# ============  ======= ======= ======= ======= ======= ======= =======# 语句执行时间# Exec time    3s 640ms  2s  1s  2s 999ms  1s# 锁占用时间# Lock time   1ms  0  1ms 723us  1ms  1ms 723us# 发送到客户端的行数# Rows sent    5  1  4 2.50  4 2.12 2.50# select语句扫描行数# Rows examine  186.17k  0 186.17k 93.09k 186.17k 131.64k 93.09k# 查询的字符数# Query size   455  15  440 227.50  440 300.52 227.50</code></pre><h5 id="第二部分：查询分组统计结果"><a href="#第二部分：查询分组统计结果" class="headerlink" title="第二部分：查询分组统计结果"></a>第二部分：查询分组统计结果</h5><ul><li>Rank：所有语句的排名，默认按查询时间降序排列，通过–order-by指定</li><li>Query ID：语句的ID，（去掉多余空格和文本字符，计算hash值）</li><li>Response：总的响应时间</li><li>time：该查询在本次分析中总的时间占比</li><li>calls：执行次数，即本次分析总共有多少条这种类型的查询语句</li><li>R/Call：平均每次执行的响应时间</li><li>V/M：响应时间Variance-to-mean的比率</li><li>Item：查询对象</li></ul><pre><code># Profile# Rank Query ID   Response time Calls R/Call V/M Item# ==== ================== ============= ===== ====== ===== ===============# 1 0xF9A57DD5A41825CA 2.0529 76.2%  1 2.0529 0.00 SELECT# 2 0x4194D8F83F4F9365 0.6401 23.8%  1 0.6401 0.00 SELECT wx_member_base</code></pre><h5 id="第三部分：每一种查询的详细统计结果"><a href="#第三部分：每一种查询的详细统计结果" class="headerlink" title="第三部分：每一种查询的详细统计结果"></a>第三部分：每一种查询的详细统计结果</h5><p>由下面查询的详细统计结果，最上面的表格列出了执行次数、最大、最小、平均、95%等各项目的统计。</p><ul><li>ID：查询的ID号，和上图的Query ID对应</li><li>Databases：数据库名</li><li>Users：各个用户执行的次数（占比）</li><li>Query_time distribution ：查询时间分布, 长短体现区间占比，本例中1s-10s之间查询数量是10s以上的两倍。</li><li>Tables：查询中涉及到的表</li><li>Explain：SQL语句</li></ul><pre><code># Query 1: 0 QPS, 0x concurrency, ID 0xF9A57DD5A41825CA at byte 802 # This item is included in the report because it matches --limit.# Scores: V/M = 0.00# Time range: all events occurred at 2016-11-22 06:11:40# Attribute pct total  min  max  avg  95% stddev median# ============ === ======= ======= ======= ======= ======= ======= =======# Count   50  1# Exec time  76  2s  2s  2s  2s  2s  0  2s# Lock time  0  0  0  0  0  0  0  0# Rows sent  20  1  1  1  1  1  0  1# Rows examine 0  0  0  0  0  0  0  0# Query size  3  15  15  15  15  15  0  15# String:# Databases test# Hosts  192.168.8.1# Users  mysql# Query_time distribution# 1us# 10us# 100us# 1ms# 10ms# 100ms# 1s ################################################################# 10s+# EXPLAIN /*!50100 PARTITIONS*/select sleep(2)\G</code></pre>]]></content>
    
    
    <categories>
      
      <category>MySQL进阶</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL的业务设计</title>
    <link href="/2020/04/01/MySQL%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%AE%BE%E8%AE%A1/"/>
    <url>/2020/04/01/MySQL%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%AE%BE%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<h2 id="逻辑设计"><a href="#逻辑设计" class="headerlink" title="逻辑设计"></a>逻辑设计</h2><h3 id="数据库设计的三大范式"><a href="#数据库设计的三大范式" class="headerlink" title="数据库设计的三大范式"></a>数据库设计的三大范式</h3><h4 id="一、要求每一列属性值都不可再分，确保每一列的原子性"><a href="#一、要求每一列属性值都不可再分，确保每一列的原子性" class="headerlink" title="一、要求每一列属性值都不可再分，确保每一列的原子性"></a>一、要求每一列属性值都不可再分，确保每一列的原子性</h4><img src="/2020/04/01/MySQL%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%AE%BE%E8%AE%A1/pic1.png" srcset="/img/loading.gif" class=""><p>这张表的name-age列具有name跟age两个属性，不符合第一个范式，这时候就需要对name-age列进行拆分。</p><img src="/2020/04/01/MySQL%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%AE%BE%E8%AE%A1/pic2.png" srcset="/img/loading.gif" class=""><h4 id="二、必须满足第一范式，并且所有非主属性都完全依赖于主键即不允许有第二主键。"><a href="#二、必须满足第一范式，并且所有非主属性都完全依赖于主键即不允许有第二主键。" class="headerlink" title="二、必须满足第一范式，并且所有非主属性都完全依赖于主键即不允许有第二主键。"></a>二、必须满足第一范式，并且所有非主属性都完全依赖于主键即不允许有第二主键。</h4><img src="/2020/04/01/MySQL%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%AE%BE%E8%AE%A1/pic3.png" srcset="/img/loading.gif" class=""><p>一个订单有多个产品，所以订单的主键为订单ID和产品ID组成的联合主键，这样的设计不符合第二范式，而且产品ID和订单ID没有强关联，所以需要把订单表进行拆分为订单表与订单与商品的中间表</p><img src="/2020/04/01/MySQL%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%AE%BE%E8%AE%A1/pic4.png" srcset="/img/loading.gif" class=""><h4 id="三、必须满足第二范式，并且数据不能存在传递关系，即每个属性都跟主键有直接关系而不是间接关系。"><a href="#三、必须满足第二范式，并且数据不能存在传递关系，即每个属性都跟主键有直接关系而不是间接关系。" class="headerlink" title="三、必须满足第二范式，并且数据不能存在传递关系，即每个属性都跟主键有直接关系而不是间接关系。"></a>三、必须满足第二范式，并且数据不能存在传递关系，即每个属性都跟主键有直接关系而不是间接关系。</h4><img src="/2020/04/01/MySQL%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%AE%BE%E8%AE%A1/pic5.png" srcset="/img/loading.gif" class=""><p>此时，如果客户编号发生改变，用户姓名也会改变，这样不符合第三大范式，应该把客户姓名这一列删除</p><h3 id="反范式设计"><a href="#反范式设计" class="headerlink" title="反范式设计"></a>反范式设计</h3><p>范式设计是为了尽可能的降低数据的冗余，完全符合范式化的设计有时并不能得到良好得SQL查询性能。反范式化是针对范式化而言得，是为了性能而适当得对数据库设计范式得要求进行违反，允许存在少量得冗余，换句话来说反范式化就是使用空间来换取时间。</p><h2 id="物理设计"><a href="#物理设计" class="headerlink" title="物理设计"></a>物理设计</h2><h3 id="命名规范"><a href="#命名规范" class="headerlink" title="命名规范"></a>命名规范</h3><ul><li>可读性原则：使用下划线来格式化的库对象名字以获得良好的可读性</li><li>表意性原则：对象的名字应该能够描述它所表示的对象，对于存储过程，存储过程应该能够体现存储过程的功能。</li><li>长名原则：尽可能少使用或者不使用缩写</li></ul><h3 id="存储引擎的选择"><a href="#存储引擎的选择" class="headerlink" title="存储引擎的选择"></a>存储引擎的选择</h3><table><thead><tr><th><strong>功 能</strong></th><th><strong>MYISAM</strong></th><th><strong>Memory</strong></th><th><strong>InnoDB</strong></th><th><strong>Archive</strong></th></tr></thead><tbody><tr><td>存储限制</td><td>256TB</td><td>RAM</td><td>64TB</td><td>None</td></tr><tr><td>支持事物</td><td>No</td><td>No</td><td>Yes</td><td>No</td></tr><tr><td>支持全文索引</td><td>Yes</td><td>No</td><td>No</td><td>No</td></tr><tr><td>支持数索引</td><td>Yes</td><td>Yes</td><td>Yes</td><td>No</td></tr><tr><td>支持哈希索引</td><td>No</td><td>Yes</td><td>No</td><td>No</td></tr><tr><td>支持数据缓存</td><td>No</td><td>N/A</td><td>Yes</td><td>No</td></tr><tr><td>支持外键</td><td>No</td><td>No</td><td>Yes</td><td>No</td></tr></tbody></table><p>如果要提供提交、回滚、崩溃恢复能力的事物安全（ACID兼容）能力，并要求实现并发控制，InnoDB是一个好的选择。</p><p>如果数据表主要用来插入和查询记录，则MyISAM引擎能提供较高的处理效率。</p><p>如果只是临时存放数据，数据量不大，并且不需要较高的数据安全性，可以选择将数据保存在内存中的Memory引擎，MySQL中使用该引擎作为临时表，存放查询的中间结果。</p><p>如果只有INSERT和SELECT操作，可以选择Archive，Archive支持高并发的插入操作，但是本身不是事务安全的。Archive非常适合存储归档数据，如记录日志信息可以使用Archive。</p><p>使用哪一种引擎需要灵活选择，<strong>一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求</strong>，使用合适的存储引擎，将会提高整个数据库的性能</p><h3 id="数据类型选择"><a href="#数据类型选择" class="headerlink" title="数据类型选择"></a>数据类型选择</h3><p>选择原则</p><ul><li><p><strong>更小的通常更好</strong>：一般情况下选择可以正确存储数据的最小数据类型。越小的数据类型通常更快，占用磁盘，内存和CPU缓存更小。</p></li><li><p><strong>简单就好</strong>：简单的数据类型的操作通常需要更少的CPU周期。例如：整型比字符操作代价要小得多，因为字符集和校对规则(排序规则)使字符比整型比较更加复杂。</p></li><li><p><strong>尽量避免NULL</strong>:尽量制定列为NOT NULL，除非真的需要NULL类型的值。因为可能为NULL列使得索引，索引统计和值比较都更复杂。可为NULL的列会使用更多的存储空间，在MySQL里也需要特殊处理。</p></li></ul><p>当一个列可以选择多种数据类型时</p><ul><li>优先考虑数字类型</li><li>其次是日期、时间类型</li><li>最后是字符类型</li><li>对于相同级别的数据类型，应该优先选择占用空间小的数据类型</li></ul>]]></content>
    
    
    <categories>
      
      <category>MySQL进阶</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL中的锁和事务</title>
    <link href="/2020/03/31/MySQL%E4%B8%AD%E7%9A%84%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/"/>
    <url>/2020/03/31/MySQL%E4%B8%AD%E7%9A%84%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<h2 id="锁的简介"><a href="#锁的简介" class="headerlink" title="锁的简介"></a>锁的简介</h2><h3 id="锁的类型"><a href="#锁的类型" class="headerlink" title="锁的类型"></a>锁的类型</h3><ul><li>表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。</li><li>行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。</li><li>页面锁（gap锁，间隙锁）：开销界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。</li></ul><h3 id="锁的选择"><a href="#锁的选择" class="headerlink" title="锁的选择"></a>锁的选择</h3><p>从锁的角度来说，表级锁更适合以查询为主，只有少量按索引条件更新数据的应用，行级锁更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用。锁的使用需要根据具体应用的特点来确定，不能一概而论。</p><h2 id="MyISAM锁"><a href="#MyISAM锁" class="headerlink" title="MyISAM锁"></a>MyISAM锁</h2><p>MyISAM引擎只支持表锁，表锁又分为表共享读锁（Table Read Lock）和表独占写锁（Table Write Lock）。</p><p>读锁的语法为：<code>lock table 表名 read</code>，写锁的语法为：<code>lock table 表名write</code>，解锁语法为：<code>unlock tables;</code></p><p>当使用读锁锁住MyISAM表时，当前会话对这张表的写操作以及对其他表（如果给这张表起别名MySQL会认为这张表不是被锁住的表）的读写操作都会报错，其他会话对这张表的写操作会被阻塞，对这张表的读操作以及其他表的操作不会被影响，也可以使用读锁锁住这张表，但写锁会被阻塞。</p><p>当使用写锁锁住MyISAM表时，对其他表的读写操作都会报错，其他会话对这张表的读写操作以及对这张表的锁操作会被阻塞，对其他表的操作不会被影响。</p><h2 id="InnnoDB锁"><a href="#InnnoDB锁" class="headerlink" title="InnnoDB锁"></a>InnnoDB锁</h2><p>InnoDB支持多种锁粒度，默认使用行锁，锁粒度最小，锁冲突发生的概率最低，支持的并发度也最高，但系统消耗成本也相对较高。共享锁与排他锁是InnoDB实现的两种标准的行锁。</p><p>InnoDB有三种锁算法——记录锁、gap间隙锁、还有结合了记录锁与间隙锁的next-key锁，InnoDB对于行的查询加锁是使用的是next-key locking这种算法，一定程度上解决了幻读问题。</p><p>共享锁和拍他锁的关系为：</p><ul><li><p>当一个事务对某几行上共享锁时，允许其他事务对这几行进行读操作，但不允许其进行写操作，也不允许其他事务给这几行上排它锁，但允许上读锁。</p></li><li><p>当一个事务对某几个上排它锁时，不允许其他事务写，但允许读。更不允许其他事务给这几行上任何锁。包括写锁。 </p></li></ul><p>共享锁的语法：<code>lock in share mode</code>，例如： <code>select * from 表 where 条件 lock in share mode;</code></p><p>排它锁的写法：<code>for update</code>，例如：<code>select * from 表 where 条件 for update;</code></p><p>注意：</p><ol><li><p>两个事务不能锁同一条数据。</p></li><li><p>insert、delete、update在事务中都会自动默认加上排它锁。</p></li><li><p>行锁必须有索引才能实现，否则会自动锁全表，那么就不是行锁了。</p></li></ol><h2 id="锁的等待问题"><a href="#锁的等待问题" class="headerlink" title="锁的等待问题"></a>锁的等待问题</h2><p>实际开发过程中，你的同事在debug程序的时候可能会锁住一部分数据库的数据，而这个时候再操作这部分数据就可能会超时，这就是锁等待问题的一个体现。</p><p>通过下面这个语句可以查看数据库中锁的情况。</p><pre><code>select * from information_schema.INNODB_LOCKS;</code></pre><p>如果数据库版本为5.7可以通过下面这个指令获取pid，之后使用最下面的kill命令，退出阻塞的SQL</p><pre><code>select * from sys.innodb_lock_waits</code></pre><p>如果不是5.7版本，可以通过下面这条语句来查看阻塞的SQL的线程号</p><pre><code>SELECT  r.trx_id waiting_trx_id,  r.trx_mysql_thread_id waiting_thread,  r.trx_query waiting_query,  b.trx_id blocking_trx_id,  b.trx_mysql_thread_id blocking_threadFROM  information_schema.innodb_lock_waits wINNER JOIN  information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_idINNER JOIN  information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id;</code></pre><p>得到线程号后就可以通过<code>kill [线程号]</code>这样来退出阻塞的线程。</p><p>不过如果你的同事在进行比较重要的调试，强行kill掉他的SQL可能会影响同事间的关系，如果不是迫不得已这种做法还是少用比较好。</p><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>现在的很多软件都是多用户，多程序，多线程的，对同一个表可能同时有很多人在用，为保持数据的一致性，所以提出了事务的概念，目前只有InnoDB引擎支持事务。</p><h3 id="ACID特性"><a href="#ACID特性" class="headerlink" title="ACID特性"></a>ACID特性</h3><p>事务应该具有4个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为ACID特性。</p><ul><li>原子性（atomicity）：一个事务必须被视为一个不可分割的最小单元，整个事务中的所有操作要么全部提交成功，要么全部失败，对于一个事务来说，不可能只执行其中的一部分操作</li><li>一致性（consistency）：一致性是指事务将数据库从一种一致性转换到另外一种一致性状态，在事务开始之前和事务结束之后数据库中数据的完整性没有被破坏。</li><li>持久性（durability）：一旦事务提交，则其所做的修改就会永久保存到数据库中。此时即使系统崩溃，已经提交的修改数据也不会丢失，如果单纯依靠是数据库，持久性并不能完全解决。</li><li>隔离性（isolation）：一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。</li></ul><h3 id="并发问题"><a href="#并发问题" class="headerlink" title="并发问题"></a>并发问题</h3><p>数据库中共有四种隔离级别：未提交读（READ UNCOMMITED）、已提交读 （READ COMMITED）、可重复读（REPEATABLE READ）、可串行化（SERIALIZABLE）。MySQL默认的事务隔离级别为repeatable-read可以通过<code>show VARIABLES LIKE &#39;%tx_isolation%&#39;;</code>查看数据库目前的隔离级别。</p><p>事务并发引发的问题总共有三种：</p><ul><li><p>脏读：如果在事务B更新数据时，被事务A读取了更新的数据，然后B回滚操作，那么A读取到的数据是脏数据。</p></li><li><p>不可重复读：事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。</p></li><li><p>幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。</p></li></ul><p>不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表</p><p>与隔离级别的对应关系</p><table><thead><tr><th>事务隔离级别</th><th>脏读</th><th>不可重复读</th><th>幻读</th></tr></thead><tbody><tr><td>未提交读（READ UNCOMMITED）</td><td>是</td><td>是</td><td>是</td></tr><tr><td>已提交读 （READ COMMITED）</td><td>否</td><td>是</td><td>是</td></tr><tr><td>可重复读（REPEATABLE READ）</td><td>否</td><td>否</td><td>是</td></tr><tr><td>可串行化（SERIALIZABLE）</td><td>否</td><td>否</td><td>否</td></tr></tbody></table><h3 id="间隙锁（Gap-Lock）"><a href="#间隙锁（Gap-Lock）" class="headerlink" title="间隙锁（Gap Lock）"></a>间隙锁（Gap Lock）</h3><p>间隙锁（Gap Lock）是InnoDB在可重复读提交下为了解决幻读问题时引入的锁机制，间隙锁是一个在索引记录之间的间隙上的锁。</p><p>当使用唯一索引来搜索唯一行的语句时，不需要间隙锁定。如下面语句的id列有唯一索引，此时只会对id值为10的行使用记录锁。</p><pre><code>select * from t where id = 10 for update;// 注意：普通查询是快照读，不需要加锁</code></pre><p>如果上面语句中id列没有建立索引或者是非唯一索引时，则语句会产生间隙锁。</p><p>如果搜索条件里有多个查询条件(即使每个列都有唯一索引)，也是会有间隙锁的。</p><p>需要注意的是，当id列上没有索引时，SQL会走聚簇索引的全表扫描进行过滤，由于过滤是在MySQL Server层面进行的。因此每条记录（无论是否满足条件）都会被加上锁。但是，为了效率考量，MySQL做了优化，对于不满足条件的记录，会在判断后<strong>放锁</strong>，最终持有的，是满足条件的记录上的锁。但是不满足条件的记录上的加锁/放锁动作是不会省略的。所以在没有索引时，不满足条件的数据行会有加锁又放锁的耗时过程。</p><h3 id="事务的使用"><a href="#事务的使用" class="headerlink" title="事务的使用"></a>事务的使用</h3><ul><li><p>开启事务：begin、START TRANSACTION（推荐）、begin work </p></li><li><p>事务回滚：rollback</p></li><li><p>事务提交：commit</p></li><li><p>设置还原点：savepoint [变量名]</p></li><li><p>回退到还原点：rollback to savepoint [变量名]</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>MySQL进阶</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL架构与存储引擎</title>
    <link href="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"/>
    <url>/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/</url>
    
    <content type="html"><![CDATA[<h2 id="MySQL逻辑架构"><a href="#MySQL逻辑架构" class="headerlink" title="MySQL逻辑架构"></a>MySQL逻辑架构</h2><img src="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/pic1.png" srcset="/img/loading.gif" class=""><h3 id="连接层"><a href="#连接层" class="headerlink" title="连接层"></a>连接层</h3><img src="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/pic2.png" srcset="/img/loading.gif" class=""><p>当MySQL启动（MySQL服务器就是一个进程），等待客户端连接，每一个客户端连接请求，服务器都会新建一个线程处理（如果是线程池的话，则是分配一个空的线程），每个线程独立，拥有各自的内存处理空间。</p><p>show VARIABLES like ‘%max_connections%’</p><img src="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/pic3.png" srcset="/img/loading.gif" class=""><p>连接到服务器，服务器需要对其进行验证，也就是用户名、IP、密码验证，一旦连接成功，还需要验证是否具有执行某个特定的查询权限。</p><h3 id="处理层"><a href="#处理层" class="headerlink" title="处理层"></a>处理层</h3><img src="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/pic4.png" srcset="/img/loading.gif" class=""><p>这一层主要功能有：SQL语句的解析、优化，缓存的查询，MySQL内置函数的实现，跨存储引擎功能（所谓跨存储引擎就是说每个引擎都需提供的功能（引擎需对外提供接口）），例如：存储过程、触发器、视图等。</p><pre><code>show variables like &#39;%query_cache_type%&#39;</code></pre><p>大概步骤为：</p><ol><li><p>如果是查询语句（select语句），首先会查询缓存是否已有相应结果，有则返回结果，无则进行下一步（如果不是查询语句，同样调到下一步）</p></li><li><p>解析查询，创建一个内部数据结构（解析树），这个解析树主要用来SQL语句的语义与语法解析；</p></li><li><p>优化：优化SQL语句，例如重写查询，决定表的读取顺序，以及选择需要的索引等。这一阶段用户是可以查询的，查询服务器优化器是如何进行优化的，便于用户重构查询和修改相关配置，达到最优化。这一阶段还涉及到存储引擎，优化器会询问存储引擎，比如某个操作的开销信息、是否对特定索引有查询优化等。</p></li></ol><h4 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h4><pre><code>show variables like  &#39;%query_cache_type%&#39;  -- 查看缓存类型，默认不开启show variables like  &#39;%query_cache_size%&#39;  -- 查看缓存空间大小，默认值1M</code></pre><p>query_cache_type只能在my.cnf文件中修改，使用set修改会报错，缓存只有在两次SQL连接的数据库、协议版本、字符集等因素完全一致时才会起作用。</p><p>具体配置方法：</p><ol><li><p>将query_cache_size设置为具体的大小，具体大小是多少取决于查询的实际情况，但最好设置为1024的倍数，参考值32M。</p></li><li><p>增加一行：query_cache_type=1</p></li><li><p>保存文件后重启MySQL服务。</p></li></ol><p>如：</p><pre><code>query_cache_size=128M query_cache_type=1</code></pre><h4 id="解析查询顺序"><a href="#解析查询顺序" class="headerlink" title="解析查询顺序"></a>解析查询顺序</h4><img src="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/pic5.png" srcset="/img/loading.gif" class=""><h4 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h4><p>SQL编辑器会对SQL语句进行优化，例如重写查询，决定表的读取顺序，以及选择需要的索引等。这一阶段还涉及到存储引擎，优化器会询问存储引擎，比如某个操作的开销信息、是否对特定索引有查询优化等。</p><h3 id="逻辑架构"><a href="#逻辑架构" class="headerlink" title="逻辑架构"></a>逻辑架构</h3><img src="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/pic6.png" srcset="/img/loading.gif" class=""><p>在mysql中schema与oracle schemas其实是不一样的，oracle中schemas的概念可理解为 “多个表（数据库对象）的集合，但在mysql中schema与database等价，只是为了兼容其他数据库，所以也提出了这个。如果通过sql语句删除schema，database也会被删除。</p><h3 id="物理存储结构"><a href="#物理存储结构" class="headerlink" title="物理存储结构"></a>物理存储结构</h3><p>mysql的数据文件都存放在dtadir中，其查看方式为<code>show VARIABLES like &#39;datadir&#39;</code>。当创建一个数据库时，datadir中也会新增一个同名目录，用户建立的表都会在这个目录中，表文件跟具体的存储引擎相关，但都有个后缀为frm的文件用来存放表结构。</p><p>frm文件可以通过安装mysql utilities工具来查看</p><pre><code>tar -zxvf mysql-utilities-1.6.5.tar.gz cd mysql-utilities-1.6.5python ./setup.py buildpython ./setup.py install</code></pre><p>通过以上步骤安装mysql utilities之后，运行以下命令就可以看到表结构</p><pre><code>mysqlfrm --diagnostic /usr/local/mysql/data/mall/account.frm </code></pre><h2 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h2><p>存储引擎是数据库的核心，对于mysql来说，存储引擎是以插件的形式运行的。MySQL允许在一个数据库中使用不同的存储引擎，综合实际需求选择存储引擎可以提升数据库的性能。可以通过<code>show engines;</code>查看数据库的支持的引擎，<code>show variables like &#39;%storage_engine%&#39;;</code>可以查看当前默认的存储引擎。</p><h3 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h3><p>使用这个存储引擎，每个MyISAM在磁盘上存储成三个文件。</p><ol><li><p>frm文件：存储表的定义数据</p></li><li><p>MYD文件：存放表具体记录的数据</p></li><li><p>MYI文件：存储索引</p></li></ol><p>frm和MYI可以存放在不同的目录下。MYI文件用来存储索引，但仅保存记录所在页的指针，索引的结构是B+树结构。这种索引跟数据分开存储的表也被称为堆表。</p><p>MyISAM支持表压缩，但是压缩之后的表就无法进行新增操作，需要再进行解压缩。</p><pre><code>myisampack -b -f /usr/local/mysql/data/mall/testmysam.MYI  -- 压缩myisamchk -r -f /usr/local/mysql/data/mall/testmysam.MYI  -- 解压缩</code></pre><p>MyISAM是不支持事务的，所以他的存储速度相比InnorDB也更快，如果读写操作允许有错误数据，只追求速度的话，可以选择这个存储引擎。不过由于现在innodb越来越强大，MyISAM已经停止维护，绝大多数场景下已经不适合MyISAM。</p><h3 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h3><p>InnoDB是默认的数据库存储引擎，他的主要特点有：</p><ul><li><p>可以通过自动增长列，方法是auto_increment。</p></li><li><p>支持事务。默认的事务隔离级别为可重复度，通过MVCC（并发版本控制）来实现的。</p></li><li><p>使用的锁粒度为行级锁，可以支持更高的并发；</p></li><li><p>支持外键约束；外键约束其实降低了表的查询速度，但是增加了表之间的耦合度。</p></li><li><p>配合一些热备工具可以支持在线热备份；</p></li><li><p>在InnoDB中存在着缓冲管理，通过缓冲池，将索引和数据全部缓存起来，加快查询的速度；</p></li><li><p>对于InnoDB类型的表，其数据的物理组织形式是聚簇表。所有的数据按照主键来组织。数据和索引放在一块，都位于B+数的叶子节点上；</p></li></ul><p>InnoDB的存储表和索引也有下面两种形式：</p><ul><li><p>使用共享表空间存储：所有的表和索引存放在同一个表空间中。</p></li><li><p>使用多表空间存储：表结构放在frm文件，数据和索引放在IBD文件中。分区表的话，每个分区对应单独的IBD文件，分区表的定义可以查看我的其他文章。使用分区表的好处在于提升查询效率。</p></li></ul><p>对于InnoDB来说，最大的特点在于支持事务。但是这是以损失效率来换取的。</p><h3 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h3><p>将数据存在内存，为了提高数据的访问速度，每一个表实际上和一个磁盘文件关联。文件是frm。</p><ul><li><p>支持的数据类型有限制，比如：不支持TEXT和BLOB类型，对于字符串类型的数据，只支持固定长度的行，VARCHAR会被自动存储为CHAR类型；</p></li><li><p>支持的锁粒度为表级锁。所以，在访问量比较大时，表级锁会成为MEMORY存储引擎的瓶颈；</p></li><li><p>由于数据是存放在内存中，一旦服务器出现故障，数据都会丢失；</p></li><li><p>查询的时候，如果有用到临时表，而且临时表中有BLOB，TEXT类型的字段，那么这个临时表就会转化为MyISAM类型的表，性能会急剧降低；</p></li><li><p>默认使用hash索引。</p></li><li><p>果一个内部表很大，会转化为磁盘表。</p></li></ul><img src="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/pic7.png" srcset="/img/loading.gif" class=""><h3 id="CSV"><a href="#CSV" class="headerlink" title="CSV"></a>CSV</h3><p> CSV引擎类似Oracle的外部表。它将数据存储在“逗号分隔值（CSV）文件”中，但不支持在这种文件上建立相关索引，所有列也不允许为NULL。这种引擎支持从数据库中拷入/拷出CSV文件，比如从电子表格软件输出一个CSV文件，将其存放在MySQL服务器的数据目录中，服务器执行刷新表操作后（<code>flush table</code>），就能够马上读取相关的CSV文件。同样，如果写数据库到一个CSV表，外部程序也可以立刻读取它。在实现某种类型的日志记录时，CSV表作为一种数据交换格式，特别有用。</p><h3 id="Archive"><a href="#Archive" class="headerlink" title="Archive"></a>Archive</h3><p> 从archive单词的解释我们大概可以明白这个存储引擎的用途，这个存储引擎基本上用于数据归档；它的压缩比非常的高，存储空间大概是innodb的10-15分之一所以它用来存储历史数据非常的适合，由于它不支持索引同时也不能缓存索引和数据，所以它不适合作为并发访问表的存储引擎。Archivec存储引擎使用行锁来实现高并发插入操作，但是它不支持事务，而且只允许在自增id列上加索引，其设计目标只是提供高速的插入和压缩功能。</p><h3 id="Ferderated"><a href="#Ferderated" class="headerlink" title="Ferderated"></a>Ferderated</h3><p>Ferderated引擎将数据存储在远程MySQL上，本地只存储表结构和连接信息，相当于提供了一个远程访问MySQL服务器上表的方法。通常使用在统计分析和数据查询中，在游戏行业使用的比较多。</p><p>在MySQL中默认是禁止的，需要在my.ini配置文件中增加federated参数来启用。可以通过<code>show ENGINES</code>查看已经开启的引擎。具体使用如下</p><pre><code>CREATE TABLE `local_fed` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c1` varchar(10) NOT NULL DEFAULT &#39;&#39;, `c2` char(10) NOT NULL DEFAULT &#39;&#39;, PRIMARY KEY (`id`)) ENGINE=federated CONNECTION =&#39;mysql://root:root1234%@127.0.0.1:3306/remote/remote_fed&#39;</code></pre>]]></content>
    
    
    <categories>
      
      <category>MySQL进阶</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL基础</title>
    <link href="/2020/03/25/MySQL%E5%9F%BA%E7%A1%80/"/>
    <url>/2020/03/25/MySQL%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h2 id="MySQL安装"><a href="#MySQL安装" class="headerlink" title="MySQL安装"></a>MySQL安装</h2><p>Linux 使用的版本是centos 7，为方便起见先把防火墙关闭，配置好网络，在安装部分，会分成两部分首先会进行单实例安装，也就是一台服务器上就装一个mysql，接下来就多实例安装，在一个服务器上安装2个甚至多个mysql。</p><h3 id="单实例的安装"><a href="#单实例的安装" class="headerlink" title="单实例的安装"></a>单实例的安装</h3><ol><li><p>解压：将mysql-5.7.9-linux-glibc2.5-x86_64.tar.gz解压到/usr/local/目录下</p><pre><code>cp /soft/mysql-5.7.9-linux-glibc2.5-x86_64.tar.gz  /usr/local/tar -zxvf mysql-5.7.9-linux-glibc2.5-x86_64.tar.gz </code></pre></li><li><p>之后的步骤可以根据解压后目录中的INSTALL-BINARY文件来</p><pre><code>shell&gt; groupadd mysqlshell&gt; useradd -r -g mysql mysqlshell&gt; cd /usr/localshell&gt; tar zxvf /path/to/mysql-VERSION-OS.tar.gzshell&gt; ln -s full-path-to-mysql-VERSION-OS mysqlshell&gt; cd mysqlshell&gt; mkdir mysql-filesshell&gt; chmod 770 mysql-filesshell&gt; chown -R mysql .shell&gt; chgrp -R mysql .shell&gt; bin/mysqld --initialize --user=mysql     # MySQL 5.7.6 and up //这一步会出现数据库密码注意保存shell&gt; bin/mysql_ssl_rsa_setup              # MySQL 5.7.6 and upshell&gt; chown -R root .shell&gt; chown -R mysql data mysql-files //在此之前需要手动创建data目录shell&gt; bin/mysqld_safe --user=mysql &amp; //如果此时报错可以删除etc下的my.cnf文件之后再从bin/mysqld --initialize --user=mysql开始重新执行# Next command is optionalshell&gt; cp support-files/mysql.server /etc/init.d/mysql.server //可选项</code></pre></li><li><p>配置环境变量：</p><p>在<code>/etc/profile</code>中添加<code>export PATH=/usr/local/mysql/bin:$PATH</code></p><p>保存后输入<code>source /etc/profile</code>命令使配置生效</p></li><li><p>配置开启启动</p><p><code>chkconfig mysql.server on</code></p><p><code>chkconfig --list</code></p></li><li><p>登录、修改密码、允许远程登录</p><p><code>mysql -uroot  -p&#39;使用第二步中保存的密码&#39;</code></p><p>成功进入后：</p><p><code>set password = &#39;新密码&#39;;</code></p><p>允许远程登陆</p><p><code>GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;密码&#39;</code></p><p>刷新权限</p><p><code>flush privileges;</code></p></li></ol><h3 id="多实例的安装"><a href="#多实例的安装" class="headerlink" title="多实例的安装"></a>多实例的安装</h3><p>在mysql中已经考虑到了多实例安装的情况。也有相应的脚本命令的支持。</p><p>比如现在装两个mysql端口分别为3307、3308</p><ol><li><p>新建 /etc/my.cnf 配置如下</p><pre><code>[mysqld]sql_mode = &quot;STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER&quot;[mysqld_multi]mysqld = /usr/local/mysql/bin/mysqld_safemysqladmin = /usr/local/mysql/bin/mysqladminlog = /var/log/mysqld_multi.log[mysqld1] server-id = 11socket = /tmp/mysql.sock1port = 3307datadir = /data1user = mysqlperformance_schema = offinnodb_buffer_pool_size = 32Mskip_name_resolve = 1log_error = error.logpid-file = /data1/mysql.pid1[mysqld2]server-id = 12socket = /tmp/mysql.sock2port = 3308datadir = /data2user = mysqlperformance_schema = offinnodb_buffer_pool_size = 32Mskip_name_resolve = 1log_error = error.logpid-file = /data2/mysql.pid2</code></pre></li><li><p>创建2个数据目录</p><pre><code>mkdir /data1mkdir /data2</code></pre></li><li><p>初始化MySQL</p><pre><code>chown mysql.mysql /data{1..2}mysqld --initialize --user=mysql --datadir=/data1mysqld --initialize --user=mysql --datadir=/data2cp /usr/local/mysql/support-files/mysqld_multi.server /etc/init.d/mysqld_multid</code></pre></li><li><p>安装perl环境</p><pre><code>yum -y install perl perl-devel</code></pre></li><li><p>查看状态</p><pre><code>mysqld_multi report</code></pre></li><li><p>启动</p><pre><code>mysqld_multi start</code></pre></li><li><p>修改密码，允许远程连接</p><pre><code>mysql -u root -S /tmp/mysql.sock1 -p -P3307mysql -u root -S /tmp/mysql.sock2 -p -P3308set password = &#39;root1234%&#39;;GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;root1234%&#39;;flush privileges;  </code></pre></li></ol><h2 id="MySQL权限"><a href="#MySQL权限" class="headerlink" title="MySQL权限"></a>MySQL权限</h2><p>MySQL的权限简单的理解就是MySQK允许你做权限以内的事情，不可以越界。比如只允许你执行select操作，那么你就不能执行update操作。只允许你从某台机器上连接mysql，那么你就不能从除那台机器以外的其他机器连接mysql。</p><h3 id="简单使用"><a href="#简单使用" class="headerlink" title="简单使用"></a>简单使用</h3><pre><code>grant SELECT on mall.* TO &#39;dev&#39;@&#39;192.168.244.%&#39; IDENTIFIED BY &#39;123&#39; WITH GRANT OPTION;</code></pre><p>以上语可以创建一个拥有mall中所有表进行select操作，用户名为dev，密码为123，允许在网段192.168.0.*连接的用户。</p><pre><code>show grants for &#39;dev&#39;@&#39;192.168.244.%&#39;</code></pre><p>这条命令可以输出刚才创建的dev用户的权限</p><h3 id="用户标识"><a href="#用户标识" class="headerlink" title="用户标识"></a>用户标识</h3><p>在MySQL中的权限不是单纯的赋予给用户的，而是赋予给”用户+IP”的。</p><p>比如dev用户是否能登陆，用什么密码登陆，并且能访问什么数据库等都需要加上IP，这样才算一个完整的用户标识，换句话说 ‘dev’@’192.168.0.168’ 、‘dev’@’127.0.0.1’与‘dev’@’localhost’ 这3个是完全不同的用户标识（哪怕你本机的ip就是192.168.0.168）。</p><h3 id="用户权限所涉及的表"><a href="#用户权限所涉及的表" class="headerlink" title="用户权限所涉及的表"></a>用户权限所涉及的表</h3><p>在mysql库中中存在4个控制权限的表，<code>分别为user表，db表，tables_priv表，columns_priv表</code></p><ul><li>user：存储用户标识</li><li>db：用户对数据库的权限</li><li>table_priv：用户对表的权限</li><li>column_priv：用户对某一列的权限</li></ul><p>MySQL的权限粒度甚至可以细化到某一列上。</p><pre><code>grant select(id,name) on mall.account to &#39;dev&#39;@&#39;192.168.244.%&#39;;</code></pre><p>这条语句可以将mall数据库中account表的id跟name的查询条件给‘dev’@’192.168.244.%’用户，但如果用户之前拥有更高的权限，会以之前权限为准，所以要想生效就需要移除‘dev’@’192.168.244.%’用户之前的权限。</p><pre><code>revoke select on mail.* from &#39;dev&#39;@&#39;192.168.244.%&#39;;</code></pre><p>此时再使用‘dev’@’192.168.244.%’用户查看表account时可能会报错，此时可以用过以下语句查看是否设置成功。</p><pre><code>select id,name from account;</code></pre><h2 id="MySQL的角色"><a href="#MySQL的角色" class="headerlink" title="MySQL的角色"></a>MySQL的角色</h2><p> MySql基于”用户+IP”的这种授权模式在设置给多个用户设置相同权限时会比较繁琐。所以MySQL官方在5.7之后推出“Role Like”功能来实现类似角色的功能，更加方便管理多个同样权限的账户。</p><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><ol><li><p>检查是否开启角色功能</p><pre><code>show variables like &quot;%proxy%&quot;</code></pre></li><li><p><code>check_proxy_users</code>，<code>mysql_native_password_proxy_users</code>这两个变量需要设置成true</p><pre><code>set GLOBAL check_proxy_users =1;set GLOBAL mysql_native_password_proxy_users = 1;</code></pre></li></ol><h3 id="简单使用-1"><a href="#简单使用-1" class="headerlink" title="简单使用"></a>简单使用</h3><ol><li><p>创建一个dev_role用户</p><pre><code>create USER &#39;dev_role&#39;</code></pre></li><li><p>在创建两个用户</p><pre><code>create USER &#39;test1&#39;create USER &#39;test2&#39;</code></pre></li><li><p>把两个用户加到组里面</p><pre><code>grant proxy on &#39;dev_role&#39; to &#39;test1&#39;grant proxy on &#39;dev_role&#39; to &#39;test2&#39;</code></pre></li><li><p>如果是远程连接需要给远程连接的ROOTGRANT权限</p><pre><code>GRANT PROXY ON &#39;&#39;@&#39;&#39; TO &#39;root&#39;@&#39;%&#39; WITH GRANT OPTION;</code></pre></li><li><p>给<code>dev_role</code>设置权限</p><pre><code>grant select(id,name) on mall.account to &#39;dev_role&#39;</code></pre></li></ol><h2 id="MySQL的数据类型"><a href="#MySQL的数据类型" class="headerlink" title="MySQL的数据类型"></a>MySQL的数据类型</h2><h3 id="int类型"><a href="#int类型" class="headerlink" title="int类型"></a>int类型</h3><table><thead><tr><th><strong>类型</strong></th><th><strong>字节</strong></th><th><strong>最小值</strong>（有符号/无符号）</th><th><strong>最大值</strong>（有符号/无符号）</th></tr></thead><tbody><tr><td>TINYINT</td><td>1</td><td>-128 / 0</td><td>127 / 255</td></tr><tr><td>SMALLINT</td><td>2</td><td>-32768 / 0</td><td>32767/65535</td></tr><tr><td>MEDIUMINT</td><td>3</td><td>-8388608 / 0</td><td>8388607/16777215</td></tr><tr><td>INT</td><td>4</td><td>-2147483648 / 0</td><td>2147483647/4294967295</td></tr><tr><td>BIGINT</td><td>8</td><td>-9223372036854775808 / 0</td><td>9223372036854775807/18446744073709551615</td></tr></tbody></table><p>注：</p><ul><li>项目中通常使用有符号的BIGINT。</li><li>int(N)中N是指显示宽度，并不是最大存储长度，如果开启zerofill（填充0），在数据长度未达到N时会在左侧填充数字0至N（可视化工具中可能会将左侧的0屏蔽）。</li><li>自动增长只能用于主键，且只有主键类型为NULL时会触发。</li></ul><h3 id="字符类型"><a href="#字符类型" class="headerlink" title="字符类型"></a>字符类型</h3><table><thead><tr><th>类型</th><th>说明</th><th>N的含义</th><th>是否有字符集</th><th>最大长度</th></tr></thead><tbody><tr><td>CHAR(N)</td><td>定长字符</td><td>字符</td><td>是</td><td>255</td></tr><tr><td>VARCHAR(N)</td><td>变长字符</td><td>字符</td><td>是</td><td>16384</td></tr><tr><td>BINARY(N)</td><td>定长二进制字节</td><td>字节</td><td>否</td><td>255</td></tr><tr><td>VARBINARY(N)</td><td>变长二进制字节</td><td>字节</td><td>否</td><td>16384</td></tr><tr><td>TINYBLOB(N)</td><td>二进制大对象</td><td>字节</td><td>否</td><td>256</td></tr><tr><td>BLOB(N)</td><td>二进制大对象</td><td>字节</td><td>否</td><td>16K</td></tr><tr><td>MEDIUMBLOB(N)</td><td>二进制大对象</td><td>字节</td><td>否</td><td>16M</td></tr><tr><td>LONGBLOB(N)</td><td>二进制大对象</td><td>字节</td><td>否</td><td>4G</td></tr><tr><td>TINYTEXT(N)</td><td>大对象</td><td>字节</td><td>是</td><td>256</td></tr><tr><td>TEXT(N)</td><td>大对象</td><td>字节</td><td>是</td><td>16K</td></tr><tr><td>MEDIUMTEXT(N)</td><td>大对象</td><td>字节</td><td>是</td><td>16M</td></tr><tr><td>LONGTEXT(N)</td><td>大对象</td><td>字节</td><td>是</td><td>4G</td></tr></tbody></table><p>注：</p><ul><li>排序规则中_ci为不区分大小写比较，_cs为区分大小写比较，_bin为使用二进制编码比较。</li><li>utf8_unicode_ci和utf8_general_ci对中、英文来说没有实质的差别。utf8_general_ci校对速度快，但准确度稍差，utf8_unicode_ci准确度高，但校对速度稍慢。如果你的应用有德语、法语或者俄语，请一定使用utf8_unicode_ci，其余情况下utf8_general_ci就够了。</li><li>除char，varchar中的N表示字符长度外，其余类型中的N均表示字节长度。</li></ul><h3 id="时间类型"><a href="#时间类型" class="headerlink" title="时间类型"></a>时间类型</h3><table><thead><tr><th>日期类型</th><th>占用空间</th><th>表示范围</th></tr></thead><tbody><tr><td>DATETIME</td><td>8</td><td>1000-01-01 00:00:00 ~ 9999-12-31 23:59:59</td></tr><tr><td>DATE</td><td>3</td><td>1000-01-01 ~ 9999-12-31</td></tr><tr><td>TIMESTAMP</td><td>4</td><td>1970-01-01 00:00:00UTC ~ 2038-01-19 03:14:07UTC</td></tr><tr><td>YEAR</td><td>1</td><td>YEAR(2):1970-2070, YEAR(4):1901-2155</td></tr><tr><td>TIME</td><td>3</td><td>-838:59:59 ~ 838:59:59</td></tr></tbody></table><p>注：datetime与timestamp区别在于，再修改时区后timestamp会相应的变化，datetime不会。</p><h3 id="JSON类型"><a href="#JSON类型" class="headerlink" title="JSON类型"></a>JSON类型</h3><p>MySQK5.7开始引入JSON数据类型用来保存JSON类型的数据，与varchar的区别在于</p><ul><li>MySQL提供了一组操作JSON数据的内置函数。</li></ul><ul><li>JSON数据类型会自动校验数据是否为JSON格式，如果不是JSON格式数据，则会报错。</li><li>存储在JSON列中的JSON数据被转换成内部的存储格式，允许快速读取。</li><li>可以修改特定的键值</li></ul><h3 id="相关的内置函数"><a href="#相关的内置函数" class="headerlink" title="相关的内置函数"></a>相关的内置函数</h3><ul><li><p>json_type：显示当前JSON字符串的类型，如<code>select json_type(&#39;[&quot;test1&quot;,&quot;test2&quot;,&quot;test3&quot;]&#39;);</code>输出结果为：<code>ARRAY</code></p></li><li><p>json_array：将数组对象转为JSON数组，如<code>select json_array(1,now(),&quot;test&quot;);</code>输出结果为：<code>[1, &quot;2020-03-29 20:44:41.000000&quot;, &quot;test1&quot;]</code></p></li><li><p>json_object：将对象转为JSON格式数据，如<code>select json_object(&quot;name&quot;, &quot;enjoy&quot;, &quot;email&quot;, &quot;enjoy.com&quot;, &quot;age&quot;,35);</code>输出结果为：<code>{&quot;age&quot;: 35, &quot;name&quot;: &quot;enjoy&quot;, &quot;email&quot;: &quot;enjoy.com&quot;}</code></p></li><li><p>json_extract：可以提取JSON格式中的属性，如<code>select json_extract(&#39;[10, 20, [30, 40]]&#39;, &#39;$[1]&#39;);</code>输出结果为：<code>20</code></p></li><li><p>json_insert：向JSON中插入数据，如果已存在则不会修改，如</p><pre><code> set @json = &#39;{ &quot;a&quot;: 1, &quot;b&quot;: [2, 3]}&#39;; select json_insert(@json, &#39;$.a&#39;, 10, &#39;$.c&#39;, &#39;[true, false]&#39;);</code></pre><p>输出结果为：<code>{&quot;a&quot;: 1, &quot;b&quot;: [2, 3], &quot;c&quot;: &quot;[true, false]&quot;}</code></p></li><li><p>json_merge：合并数据并返回，如<code>select json_merge(&#39;{&quot;name&quot;: &quot;enjoy&quot;}&#39;, &#39;{&quot;id&quot;: 47}&#39;);</code>输出结果为：<code>{&quot;id&quot;: 47, &quot;name&quot;: &quot;enjoy&quot;}</code></p></li></ul><p><a href="https://dev.mysql.com/doc/refman/5.7/en/json-function-reference.html" target="_blank" rel="noopener">其他函数</a></p><h3 id="JSON类型的索引"><a href="#JSON类型的索引" class="headerlink" title="JSON类型的索引"></a>JSON类型的索引</h3><p>由于JSON类型数据本身无法直接创建索引，所以将要建立索引的JSON数据中的字段，重新生成虚拟字段（Virtual Columns）之后，再对该字段进行索引。</p><pre><code>create table test( data json, gen_col varchar(10) generated always as (data-&gt;&gt;&#39;$.name&#39;),  index idx (gen_col) );</code></pre><p>上面的语句将为test表中data字段中的name属性创建名为gen_col的虚拟字段，再为gen_col创建名为idx的索引。</p>]]></content>
    
    
    <categories>
      
      <category>MySQL进阶</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>编写高效优雅的Java代码</title>
    <link href="/2020/03/24/%E7%BC%96%E5%86%99%E9%AB%98%E6%95%88%E4%BC%98%E9%9B%85%E7%9A%84Java%E4%BB%A3%E7%A0%81/"/>
    <url>/2020/03/24/%E7%BC%96%E5%86%99%E9%AB%98%E6%95%88%E4%BC%98%E9%9B%85%E7%9A%84Java%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<h3 id="避免过多的构造器参数"><a href="#避免过多的构造器参数" class="headerlink" title="避免过多的构造器参数"></a>避免过多的构造器参数</h3><p>如果参数过多，会导致构造方法非常复杂、拓展性差、难以理解。</p><p>可以使用get()、set()方法对非必须的属性进行设置，构造方法中只包含必须的属性，将原本的一行代码转为多行代码。</p><p>还可以使用建造者模式，一般有</p><ol><li>抽象建造者：一般来说是个接口，包含1）建造方法，建造部件的方法（不止一个），2）返回产品的方法</li><li>具体建造者</li><li>导演者，调用具体的建造者，创建产品对象</li><li>产品，需要建造的复杂对象</li></ol><p>使用时需要创建导演者和具体建造者，并把具体建造者交给导演者，然后通知导演者操纵建造者进行产品的创建。在实际的应用过程中，有时会省略抽象建造者和导演者。建造者模式的代码易于阅读和编写，相对于上一种方式更加安全。</p><pre><code>/** * 建造者模式（简单版） */public class BoxBuilder {    //required必须参数    private  final String name;//礼盒名称    private  final int price;//礼盒价格    //optional可选参数    private   int zz;//粽子    private   int xyd;//咸鸭蛋    private   int ldg;//绿豆糕    private   int yb;//月饼    private   int jg;//坚果    //具体建造者    public static class Builder{        //required必须参数        private  final String name;//礼盒名称        private  final int price;//礼盒价格        //optional可选参数        private   int zz;//粽子        private   int xyd;//咸鸭蛋        private   int ldg;//绿豆糕        private   int yb;//月饼        private   int jg;//坚果        //构造方法        public Builder(String name, int price) {            super();            this.name = name;            this.price = price;        }        //建造方法        public BoxBuilder builder(){            return new BoxBuilder(this);        }        public Builder zz(int value){            this.zz=value;            return this;        }        public Builder xyd(int value){            this.xyd=value;            return this;        }        //......    }    private BoxBuilder (Builder builder){        name = builder.name;        price =builder.price;        zz =builder.zz;        xyd =builder.xyd;        ldg=builder.ldg;        yb=builder.yb;        jg=builder.jg;    }    public static void main(String[] args) {        BoxBuilder box1 = new Builder(&quot;端午节礼盒1&quot;,120)                .zz(8)                .xyd(4)                .builder();    }}</code></pre><h3 id="类构造器私有化"><a href="#类构造器私有化" class="headerlink" title="类构造器私有化"></a>类构造器私有化</h3><p>一些不需要实例化的类比如工具类，这些类是不应该提供具体实例的，此时可以将构造函数私有化，防止使用者new出实例。</p><h4 id="不要创建不必要的对象"><a href="#不要创建不必要的对象" class="headerlink" title="不要创建不必要的对象"></a>不要创建不必要的对象</h4><ol><li><p>避免无意中创建的对象，如自动装箱，<code>String a = new String(&quot;a&quot;)</code>等</p></li><li><p>尽量重用不可变的对象，以及不会被修改的对象。</p></li><li><p>使用静态工厂替代构造方法可以避免过多的创建对象。</p></li><li><p>通过维护对象池（pool）来避免创建对象并不是一种好的做法，除非是重量级的对象，比如数据库的连接等。</p></li></ol><h3 id="避免使用终结方法"><a href="#避免使用终结方法" class="headerlink" title="避免使用终结方法"></a>避免使用终结方法</h3><p>jdk不能保证finalizer方法何时执行，也不能保证一定会执行，如果需要释放资源可以使用try/finally。</p><h3 id="使类和成员的可访问性最小化"><a href="#使类和成员的可访问性最小化" class="headerlink" title="使类和成员的可访问性最小化"></a>使类和成员的可访问性最小化</h3><p>模块对外部其他模块来说，隐藏其内部数据和其他实现细节–封装</p><p>编写程序和设计架构，最重要的目标之一就是模块之间的解耦。使类和成员的可访问性最小化无疑是有效的途径之一。让每个类或成员尽可能的不可访问，即使用尽可能低的实现细节，避免公开公共类的成员，在仔细设计类公共方法之后，让所有成员设计为私有的。 只有当同一个包中的其他类真的需要访问成员时，再去修改私有修饰符，从而使成员包成为包级私有的。</p><p>对于成员(属性、方法、嵌套类和嵌套接口)，有四种可能的访问级别，在这里，按照可访问性从小到大列出：</p><ul><li><p>private：该成员只能在声明它的顶级类内访问。</p></li><li><p>package-private：成员可以从被声明的包中的任何类中访问。从技术上讲，如果没有指定访问修饰符(接口成员除外，它默认是公共的)，这是默认访问级别。</p></li><li><p>protected：成员可以从被声明的类的子类中访问(受一些限制，JLS，6.6.2)，以及它声明的包中的任何类。</p></li><li><p>public：该成员可以从任何地方被访问。</p></li></ul><h3 id="使可变性最小"><a href="#使可变性最小" class="headerlink" title="使可变性最小"></a>使可变性最小</h3><p>不可变类只是其实例不能被修改的类。每个实例中包含的所有信息都必须在创建该实例的时候就提供，并在对象的整个生命周期内固定不变。Java平台类库中包含许多不可变的类，其中有String、基本类型的包装类、BigInteger和BigDecimal。存在不可变的类有许多理由：不可变的类比可变的泪更加易于设计、实现和使用。他们不容易出错，且更加安全。</p><p>为了使类成为不可变，要遵循下面五条规则：</p><ul><li><p>不要提供任何会修改对象状态的方法。</p></li><li><p>保证类不会被扩展。为了防止子类化，一般做法是使这个类成为final的 。</p></li><li><p>使所有的域都是final的。一是为了表明意图，二是为了在多线程间确保对对象使用正确的行为。</p></li><li><p>使所有的域都成为私有的。这样可以防止客户端获得访问被域引用的可变对象的权限，并防止客户端直接修改这些对象。</p></li><li><p>确保对于任何可变组件的互斥访问。如果类具有指向可变对象的域，则必须确保该类的使用者无法获得指向这些对象的引用。并且，永远不要对使用者提供的对象引用来初始化这样的域，也不要从任何方法中返回该对象引用。</p></li></ul><h3 id="复合优先于继承"><a href="#复合优先于继承" class="headerlink" title="复合优先于继承"></a>复合优先于继承</h3><p>你永远不知道你的用户是如何使用你写的产品，同样使用继承拓展一个其他人的类也是危险的。父类的具体实现很容易影响子类的正确性。尽量不使用继承扩展现有的类，而是在新类中引用现有的类，这种设计称为复合（Composition）。</p><h3 id="接口优于抽象类"><a href="#接口优于抽象类" class="headerlink" title="接口优于抽象类"></a>接口优于抽象类</h3><p>由于Java只允许单继承的，当发生业务变化需要新增业务方法时，使用抽象类有可能导致不需要变化的其他子类也不得不实现新增的业务方法，如果使用接口，只需要在实现中增加新创建的接口即可。</p><p>JDK源码通常声明一个抽象的骨架类实现接口，骨架类类实现通用的方法，实际业务类可以同时实现接口又继承骨架类，也可以只实现接口。如HashSet实现了Set接口 但是继承AbstractSet类，而AbstractSet本身也实现了Set接口。其他如Map，List都是这样的设计的。</p><h3 id="慎用可变参数"><a href="#慎用可变参数" class="headerlink" title="慎用可变参数"></a>慎用可变参数</h3><p>在定义参数数目不定的方法时，可变参数方法是一种很方便的方式，但是他们不应该被过渡滥用。如果使用不当，会产生混乱的结果。</p><p>可变参数的机制原理：</p><ol><li><p>创建一个array[]，它的size就是所传参数的个数；</p></li><li><p>将参数放入到array[]中；</p></li><li><p>将array[]传给方法。</p></li></ol><p>可变参数方法是允许传入0个参数或者null的，而且编译时正常但会在运行时失败。可变参数方法的每次调用都会进行一次数组分配和初始化，对系统性能有一定影响。</p><h3 id="返回空的数组或集合，不要返回null"><a href="#返回空的数组或集合，不要返回null" class="headerlink" title="返回空的数组或集合，不要返回null"></a>返回空的数组或集合，不要返回null</h3><p>如果方法的结果返回null，会导致开发者的要单独处理为null的情况。这样的方法比较难以使用，更容易出错，并且没有性能优势。而返回零长度，调用方可以统一处理，如使用foreach即可。</p><p>JDK提供的空集合：<code>Collections.emptyList()</code>、<code>Collections.emptySet()</code>、<code>Collections.emptyMap</code></p><h3 id="优先使用标准的异常"><a href="#优先使用标准的异常" class="headerlink" title="优先使用标准的异常"></a>优先使用标准的异常</h3><p>代码重用是值得提倡的，这是一条通用的规则，异常也不例外。Java平台类库提供了一组基本的未受检的异常，他们满足了绝大多数API的异常抛出需要。</p><p>常用的异常：</p><ul><li><p>IllegalArgumentException：调用者传递的参数不合适</p></li><li><p>IllegalStateException：接收的对象状态不对，</p></li><li><p>NullPointerException：对象为空</p></li><li><p>UnsupportedOperationException：不支持的操作</p></li><li><p>ConcurrentModificationExccetion：禁止并发修改时，监测到对象的并发修改</p></li></ul><p>重用现有的异常有多方面的好处。其中最主要的好处是使代码更加易于学习和使用，现有异常大多是是开发者已知的，他们的可读性会更好。还有就是异常类越少，意味着需要加载的类越少，装载这些类的时间开销也越少。</p><h3 id="用枚举代替int常量"><a href="#用枚举代替int常量" class="headerlink" title="用枚举代替int常量"></a>用枚举代替int常量</h3><p>针对int常量以下不足： </p><ol><li>在类型安全方面，使用相同的常量值的两个常量，编译器并不能检测出错误； </li><li>因为int常量是编译时常量，被编译到使用它们class文件中。若常量发生变化，相关类必须重新编译，否则它们的行为就不确定； </li><li>想要描述常量是比较困难的。</li></ol><p>枚举高级用法：</p><ul><li><p>枚举常量与数据关联：枚举常量可以与数据相关，可以在其构造方法中加入逻辑代码，然后在枚举中提供新的属性以存放和返回结果信息。</p></li><li><p>枚举常量与行为关联：枚举常量还可以与行为关联，如实现四则运算</p><pre><code>public enum Operation {  PLUS(&quot;+&quot;) {    @Override    double apply(double x, double y) {      return x + y;    }  },  MINUS(&quot;-&quot;) {    @Override    double apply(double x, double y) {      return x - y;    }  },  TIMES(&quot;*&quot;) {    @Override    double apply(double x, double y) {      return x * y;    }  },  DIVIDE(&quot;/&quot;) {    @Override    double apply(double x, double y) {      return x / y;    }  };  private String symbol;  Operation(String symbol) {    this.symbol = symbol;  }  @Override  public String toString() {    return symbol;  }  abstract double apply(double x, double y);}</code></pre></li><li><p>枚举策略模式：以下代码是计算工人工资。平时工作8小时，超过8小时，以加班工资方式另外计算，如果是双休日，都按照加班方式处理工资。</p><pre><code>public enum PayRoll {  MONDY(PayType.WEEKDAY),  TUESDAY(PayType.WEEKDAY),  WEDNESDAY(PayType.WEEKDAY),  THURSDAY(PayType.WEEKDAY),  FRIDAY(PayType.WEEKDAY),  SATURDAY(PayType.WEEKEND),  SUNDAY(PayType.WEEKEND);  private final PayType payType;  PayRoll(PayType payType) {    this.payType = payType;  }  double pay(double hoursWorked, double payRate) {    return payType.pay(hoursWorked, payRate);  }  private enum PayType {    WEEKDAY {      @Override      double overtimePay(double hoursWorked, double payRate) {        double overtime = hoursWorked - HOURS_PER_SHIFT;        return overtime &lt;= 0 ? 0 : overtime * payRate / 2;      }    },    WEEKEND {      @Override      double overtimePay(double hoursWorked, double payRate) {        return hoursWorked * payRate / 2;      }    };    private static final int HOURS_PER_SHIFT = 8;    abstract double overtimePay(double hoursWorked, double payRate);    double pay(double hoursWorked, double payRate) {      double basePay = hoursWorked * payRate;      return basePay + overtimePay(hoursWorked, payRate);    }  }}</code></pre></li></ul><h3 id="将局部变量的作用域最小化"><a href="#将局部变量的作用域最小化" class="headerlink" title="将局部变量的作用域最小化"></a>将局部变量的作用域最小化</h3><p>将局部变量的作用域最小化，可以增强代码的可读性和可维护性，并降低出错的可能性。</p><ul><li>使一个局部变量的作用域最小化，最有力的技术是在第一次使用它的地方声明。如果变量在使用之前进行声明，这只会造成混乱————对于试图理解程序功能的读者来说，这又多了一种只会分散他们注意力的因素。等到用到该变量的时候，读者可能已经记不起该变量的类型或者初始值了。</li><li>尽量使局部变量的声明都包含一个初始化表达式，如果初始化条件不满足，就需要推迟声明。</li><li>使方法体尽可能小而集中 ，如果把两个操作（activity）合并到同一个方法中，与其中一个操作相关的局部变量就有可能会出现在执行另一个操作的代码范围之内。此时可以把这个方法分成两个，每个方法各执行一个操作。</li></ul><h3 id="精确计算，避免使用float和double"><a href="#精确计算，避免使用float和double" class="headerlink" title="精确计算，避免使用float和double"></a>精确计算，避免使用float和double</h3><p>float和double主要为了科学计算和工程计算而设计，执行二进制浮点运算，这是为了在广泛的数值范围上提供较为精确的快速近似计算而精心设计的。然而，它们没有提供完全精确的结果，所以不适合用于需要精确结果的场合，尤其是货币计算。</p><p>可以使用BigDecimal来解决这个问题，BigDecimal还提供了八种舍入模式来让开发者完全控制舍入，然而使用BigDecimal有两个缺点：与使用基本运算类型相比，这样做很不方便，而且很慢。</p><p>除了使用BigDecimal之外，还有一种办法是使用int或者long，到底选用int或者long，到底选用int或者long要取决于所涉及数值的大小，同时要自己处理十进制小数点。</p><h3 id="当心字符串连接的性能"><a href="#当心字符串连接的性能" class="headerlink" title="当心字符串连接的性能"></a>当心字符串连接的性能</h3><p>在存在大量字符串拼接或者大型字符串拼接的时候，尽量使用StringBuilder和StringBuffer，不要使用字符串连接操作符来合并多个字符串，除非性能无关紧要。</p><h3 id="控制方法的大小"><a href="#控制方法的大小" class="headerlink" title="控制方法的大小"></a>控制方法的大小</h3><p>尽量将方法长度控制的尽量小，方法复杂度&gt;=代码行数^2，当代码超过10行以上时，方法的复杂度就会大幅攀升，超过500行的代码可维护性就会大打折扣。</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>JVM</tag>
      
      <tag>Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入了解性能优化</title>
    <link href="/2020/03/23/%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    <url>/2020/03/23/%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="虚拟机优化技术-逃逸分析"><a href="#虚拟机优化技术-逃逸分析" class="headerlink" title="虚拟机优化技术-逃逸分析"></a>虚拟机优化技术-逃逸分析</h2><p>逃逸分析（Escape Analysis）是目前JVM中比较前沿的优化技术，它不是直接的优化手段而是为其他优化手段提供依据的分析技术，逃逸分析的基本行为就是分析对象动态作用域。简单来讲就是，Java Hotspot 虚拟机可以分析新创建对象的使用范围，并决定是否在 Java 堆上分配内存的一项技术。</p><p><strong>相关的JVM参数：</strong></p><ul><li><p>-XX:+DoEscapeAnalysis：启用逃逸分析(默认打开)</p></li><li><p>-XX:-DoEscapeAnalysis：关闭逃逸分析</p></li><li><p>-XX:+PrintEscapeAnalysis：显示分析结果</p></li><li><p>-XX:+EliminateAllocations：标量替换(默认打开) </p></li><li><p>-XX:+UseTLAB 本地线程分配缓冲(默认打开) </p></li></ul><p>开启逃逸分析创建的对象可以在栈上分配，对象的生命周期就跟随线程，不需要进行垃圾回收，在频繁的调用方法的情况下可以得到很大的性能提高。但由于线程私有的分配缓冲比较小，约为Eden的百分之一，所以大对象的分配还是会在堆中进行。</p><p>使用了逃逸分析时对象在栈上分配：</p><img src="/2020/03/23/%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic1.png" srcset="/img/loading.gif" class=""><p>没有使用逃逸分析时对象都在堆上分配（触发频次GC，加重负担）：</p><img src="/2020/03/23/%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic2.png" srcset="/img/loading.gif" class=""><h2 id="常用的性能评价-测试指标"><a href="#常用的性能评价-测试指标" class="headerlink" title="常用的性能评价/测试指标"></a>常用的性能评价/测试指标</h2><p>一个web应用不是一个孤立的个体，它是一个系统的部分，系统中的每一部分都会影响整个系统的性能</p><p><strong>响应时间</strong></p><p>提交请求和返回该请求的响应之间使用的时间，一般比较关注平均响应时间。</p><p>常用操作的响应时间列表：</p><table><thead><tr><th>操作</th><th>响应时间</th></tr></thead><tbody><tr><td>打开一个站点</td><td>几秒</td></tr><tr><td>数据库查询一条记录（有索引）</td><td>十几毫秒</td></tr><tr><td>机械磁盘一次寻址定位</td><td>4毫秒</td></tr><tr><td>从机械磁盘顺序读取1M数据</td><td>2毫秒</td></tr><tr><td>从SSD磁盘顺序读取1M数据</td><td>0.3毫秒</td></tr><tr><td>从远程分布式换成Redis读取一个数据</td><td>0.5毫秒</td></tr><tr><td>从内存读取1M数据</td><td>十几微妙</td></tr><tr><td>Java程序本地方法调用</td><td>几微妙</td></tr><tr><td>网络传输2Kb数据</td><td>1微妙</td></tr></tbody></table><p><strong>并发数</strong></p><p>同一时刻，对服务器有实际交互的请求数。</p><p>和网站在线用户数的关联：1000个同时在线用户数，可以估计并发数在5%到15%之间，也就是同时并发数在50~150之间。</p><p><strong>吞吐量</strong></p><p>对单位时间内完成的工作量（请求）的量度</p><p><strong>关系</strong></p><p>系统吞吐量和系统并发数以及响应时间的关系：</p><p>吞吐量可以理解为单位时间内响应请求的次数，并发数是同一时刻的请求数。</p><p>响应时间是车速。</p><p>当请求数很少时，响应速度比较快，但是单位时间的响应也比较少，所以吞吐量也比较少，。随着请求数的增多，响应速度会收到影响，但是吞吐量会增加的很快；请求数的继续增加，响应速度影响比较大，单位时间内完成的请求次数会受到影响，会进一步影响到吞吐量；</p><p>如果请求数继续增加，导致系统资源耗尽，系统将会无法完成响应。</p><h2 id="常用的性能优化手段"><a href="#常用的性能优化手段" class="headerlink" title="常用的性能优化手段"></a>常用的性能优化手段</h2><p><strong>避免过早优化</strong></p><p>项目初期，我们应该着重于编写清晰，直接，易读和易理解高效优雅的代码，真正的优化应该留到以后，等到性能分析表明优化措施有巨大的收益时再进行。</p><p><strong>不应该把大量的时间耗费在小的性能改进上，过早考虑优化是所有噩梦的根源。</strong></p><p><strong>进行系统性能测试</strong></p><p>所有的性能调优，都有应该建立在性能测试的基础上，直觉很重要，但是要用数据说话，可以推测，但是要通过测试求证。</p><p><strong>寻找系统瓶颈，分而治之，逐步优化</strong></p><p>性能测试后，对整个请求经历的各个环节进行分析，排查出现性能瓶颈的地方，定位问题，分析影响性能的的主要因素，如内存、磁盘IO、网络、CPU、代码问题、架构设计、系统资源等。</p><h3 id="前端优化常用手段（了解即可）"><a href="#前端优化常用手段（了解即可）" class="headerlink" title="前端优化常用手段（了解即可）"></a>前端优化常用手段（了解即可）</h3><ul><li><p><strong>合并请求</strong></p><p>合并CSS，Js，图片请求，使用http中的keep-alive减少连接消耗（http1.1中默认开启，包括nginx）</p></li><li><p><strong>使用客户端缓冲</strong></p><p>将静态资源文件（css、图标等）缓存在浏览器中，可以通过Cache-Control（相对时间）和Expires设置相关的属性，如果文件发生了变化，需要更新，则通过改变文件名来解决。</p></li><li><p><strong>启用压缩</strong></p><p>使用压缩可以减少网络传输量，但也会给浏览器和服务器带来性能的压力，需要权衡使用。</p></li><li><p><strong>资源文件加载顺序</strong></p><p>css放在页面前，js放在页面后，JS只要加载后就会立刻执行，有些JS可能执行时间比较长影响css加载速度，浏览器在加载完CSS才会对页面进行渲染。</p></li><li><p><strong>减少Cookie传输</strong></p><p>cookie包含在每次的请求和响应中，因此哪些数据写入cookie需要慎重考虑（静态资源不需要放入cookie）</p></li><li><p><strong>友好的提示（非技术手段）</strong></p><p>有时候在给用户一个提示，就能收到良好的效果。</p></li><li><p><strong>CDN加速</strong></p><p>CDN，又称内容分发网络，本质是一个缓存，而且是将数据缓存在用户最近的地方。无法自行实现CDN的时候，可以根据经济实力考虑商用CDN服务。</p></li><li><p><strong>反向代理缓存（动静分离）</strong></p><p>将静态资源文件缓存在反向代理服务器上，一般是Nginx。</p></li><li><p><strong>WEB组件分离</strong></p><p>将js，css和图片文件放在不同的域名下。可以提高浏览器在下载web组件的并发数。因为浏览器在下载同一个域名的的数据存在并发数限制。</p></li></ul><h3 id="应用服务性能优化"><a href="#应用服务性能优化" class="headerlink" title="应用服务性能优化"></a>应用服务性能优化</h3><h4 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h4><p>网站性能优化第一定律：优先考虑使用缓存优化性能</p><h5 id="缓存的基本原理和本质"><a href="#缓存的基本原理和本质" class="headerlink" title="缓存的基本原理和本质"></a>缓存的基本原理和本质</h5><p>缓存是将数据存在访问速度较高的介质中，减少数据访问的时间，同时避免重复计算。</p><h5 id="合理使用缓存的准则"><a href="#合理使用缓存的准则" class="headerlink" title="合理使用缓存的准则"></a>合理使用缓存的准则</h5><ul><li><p>频繁修改的数据，尽量不要缓存，读写比2:1以上才有缓存的价值。</p></li><li><p>缓存一定是热点数据。</p></li><li><p>应用能够容忍一定时间的数据不一致。</p></li><li><p>缓存可用性问题，一般通过热备或者集群来解决。 </p></li></ul><h5 id="分布式缓存"><a href="#分布式缓存" class="headerlink" title="分布式缓存"></a>分布式缓存</h5><p>以集群的方式提供缓存服务，有两种实现；</p><ol><li><p>需要更新同步的分布式缓存，所有的服务器保存相同的缓存数据，带来的问题就是，缓存的数据量受限制，其次，数据要在所有的机器上同步，代价很大。</p></li><li><p>每台机器只缓存一部分数据，然后通过一定的算法选择缓存服务器。常见的余数hash算法存在当有服务器上下线的时候，大量缓存数据重建的问题。所以提出了一致性哈希算法。</p></li></ol><h5 id="哈希一致性"><a href="#哈希一致性" class="headerlink" title="哈希一致性"></a>哈希一致性</h5><ol><li><p>首先求出服务器（节点）的哈希值，并将其配置到0～2的32次方的圆（continuum）上。</p></li><li><p>然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。</p></li><li><p>然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过232仍然找不到服务器，就会保存到第一台服务器上。</p></li></ol><p>哈希一致性算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。</p><h5 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h5><p>一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题，此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器ip或主机名的后面增加编号来实现。例如，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点：同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。</p><h5 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h5><p>可以很好的将用户的请求分配到多个机器处理，对总体性能有很大的提升</p><h4 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h4><h5 id="同步和异步、阻塞和非阻塞"><a href="#同步和异步、阻塞和非阻塞" class="headerlink" title="同步和异步、阻塞和非阻塞"></a>同步和异步、阻塞和非阻塞</h5><p><strong>同步和异步关注的是结果消息的通信机制</strong></p><p><strong>同步</strong>：同步的意思就是调用方需要主动等待结果的返回</p><p><strong>异步</strong>：异步的意思就是不需要主动等待结果的返回，而是通过其他手段比如，状态通知，回调函数等。</p><p><strong>阻塞和非阻塞主要关注的是等待结果返回的调用方的状态</strong></p><p><strong>阻塞</strong>：是指结果返回之前，当前线程被挂起，不做任何事</p><p><strong>非阻塞</strong>：是指结果在返回之前，线程可以做一些其他事，不会被挂起。</p><p><strong>同步阻塞</strong>：同步阻塞基本也是编程中最常见的模型，比如说同步队列的take()方法，如果队列中没有元素，当前线程会一直阻塞直到获取到元素，BIO也属于同步阻塞。</p><p><strong>同步非阻塞</strong>：同步非阻塞在编程中可以抽象为一个轮询模式，比如说同步队列的poll()方法，如果队列中没有元素会返回null，此时我们可以执行其他的逻辑，在此期间会不断调用poll()方法直到不为null，jdk里的NIO就属于 同步非阻塞。</p><p><strong>异步阻塞</strong>：异步阻塞这个编程里面用的较少，如果在线程池中提交有返回值的任务之后，马上调用future.get()，此时线程会马上被阻塞，直到任务之行结束。所以这个模式有点憨，与同步阻塞的效果相同，但还需要调用资源开辟线程。</p><p><strong>异步非阻塞</strong>：例如jdk提供的CompletableFuture，它采用了观察者设计模式，可以完成异步非阻塞的计算，弥补了future阻塞式获取结果的不足，jdk里的AIO就属于异步。</p><h5 id="常见异步的手段"><a href="#常见异步的手段" class="headerlink" title="常见异步的手段"></a>常见异步的手段</h5><ul><li><p>Servlet异步</p></li><li><p>多线程</p></li><li><p>消息队列</p></li></ul><h4 id="代码优化"><a href="#代码优化" class="headerlink" title="代码优化"></a>代码优化</h4><p>一个应用的性能归根结底取决于代码是如何编写的。</p><ul><li><p><strong>选择合适的数据结构</strong></p><p>比如ArrayList和LinkedList的选择，LinkedList在进行add()操作时不需要进行扩容，而ArrayList内部是数组实现，数据量较大时会进行扩容，扩容时的数据复制会比较耗费时间。</p></li><li><p><strong>选择更优的算法</strong></p></li><li><p><strong>编写更少的代码</strong></p></li><li><p><strong>并发编程</strong></p></li><li><p><strong>资源的复用</strong></p><p>目的是减少开销很大的系统资源的创建和销毁，比如数据库连接，网络通信连接，线程资源等等。</p></li><li><p><strong>单例模式</strong></p><p>Spring中的bean</p></li><li><p><strong>池化技术</strong></p></li></ul><h4 id="存储性能优化"><a href="#存储性能优化" class="headerlink" title="存储性能优化"></a>存储性能优化</h4><ul><li><p><strong>尽量使用SSD</strong></p></li><li><p><strong>定时清理数据或者按数据的性质分开存放</strong></p></li><li><p><strong>结果集处理</strong></p><p>用setFetchSize控制jdbc每次从数据库中返回多少数据。</p></li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>调优是个很复杂、很细致的过程，要根据实际情况调整，不同的机器、不同的应用、不同的性能要求调优的手段都是不同的。也没有一个放之四海而皆准的配置或者公式。King老师也无法告诉大家全部与性能相关的知识，即使是jvm参数也是如此，再比如说性能有关的操作系统工具，和操作系统本身相关的所谓大页机制，都需要大家平时去积累，去观察，去实践。</p><p>king老师在这个专题上告诉大家的除了各种java虚拟机基础知识、内部原理，也告诉大家一个性能优化的一个基本思路和着手的方向。</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>JVM</tag>
      
      <tag>Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JVM性能优化</title>
    <link href="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    <url>/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="内存溢出"><a href="#内存溢出" class="headerlink" title="内存溢出"></a>内存溢出</h2><p>程序在申请内存时，没有足够的内存空间就会发生内存溢出。</p><p>内存溢出的几种方式：</p><ul><li><p><strong>栈溢出</strong>：方法死循环递归调用即线程内的栈空间不足：<strong>StackOverflowError</strong>，不断建立线程即JVM栈空间不足：<strong>StackOutOfMemoryError</strong></p></li><li><p><strong>堆溢出</strong>：不断创建对象导致垃圾回收线程占用了超过98%的资源，但是回收效率小于2%时：<strong>OutOfMemoryError</strong>:GC overhead limit exceeded，分配对象大于最大堆的大小：<strong>OutOfMemoryError</strong>:Java heap space</p></li><li><p><strong>方法区溢出</strong>：由于方法区GC效率低，动态语言、CGLB、JSP、OSGI会加载在方法区，如果方法区大小不足，会造成方法区溢出。</p></li><li><p><strong>直接内存溢出</strong>：分配的本机直接内存（NIO使用的就是本机直接内存）大小大于JVM对直接内存的限制：<strong>OutOfMemoryError</strong>:Direct buffer memory</p></li></ul><h2 id="内存泄漏"><a href="#内存泄漏" class="headerlink" title="内存泄漏"></a>内存泄漏</h2><p>程序在申请内存后不再使用，但由于与GC Roots仍存在关联，在垃圾回收时无法释放已申请的内存空间，导致内存长期被占用。</p><p>内存泄露的几种原因：</p><ul><li><p><strong>长生命周期的对象持有短生命周期对象的引用</strong>：例如将ArrayList设置为静态变量，则容器中的对象在程序结束之前将不能被释放，从而造成内存泄漏</p></li><li><p><strong>连接未关闭</strong>：如数据库连接、网络连接和IO连接等，只有连接被关闭后，垃圾回收器才会回收对应的对象。</p></li><li><p><strong>变量作用域不合理</strong>：例如：变量的定义的作用范围大于其使用范围、没有及时地把对象设置为null等</p></li><li><p><strong>内部类持有外部类</strong>：Java的非静态内部类的创建方式，会隐式地持有外部类的引用，而且默认情况下这个引用是强引用，如果内部类的生命周期长于外部类的生命周期，程序很容易就产生内存泄漏（主观上垃圾回收器会回收掉外部类的实例，但由于内部类持有外部类的引用，实际上外部类并没有被回收）</p><p>解决方法：内部类尽量定义为静态，或者在内部类的内部显式持有一个外部类的软引用(或弱引用)，并通过构造方法的方式传递进来，在内部类的使用过程中，先判断一下外部类是否被回收；</p></li><li><p><strong>Hash值改变</strong>：在集合中，如果修改了对象中的参与计算哈希值的字段，会导致无法从集合中单独删除当前对象，造成内存泄露</p></li></ul><h2 id="内存泄漏和内存溢出辨析"><a href="#内存泄漏和内存溢出辨析" class="headerlink" title="内存泄漏和内存溢出辨析"></a>内存泄漏和内存溢出辨析</h2><ul><li><p><strong>产生原因</strong>：内存溢出是由于内存空间不足导致，而且内存泄漏是由于应该释放的对象没有释放，导致可使用内存的缩小。</p></li><li><p><strong>如何避免：</strong>内存溢出可以通过检查代码问题以及调整虚拟机参数设置足够的空间来解决，内存泄漏一定是代码的问题，所以只能通过检查代码问题来解决，很多情况下内存溢出是内存泄漏导致的。</p></li></ul><h2 id="MAT"><a href="#MAT" class="headerlink" title="MAT"></a>MAT</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>MAT是Eclipse Memory Analyzer的简称，是一个快速且功能丰富的Java堆分析器，可以用于查找内存泄露以及查看内存消耗情况。使用Memory Analyzer分析具有数亿个对象的高效堆转储，快速计算对象的保留大小，查看谁阻止垃圾收集器收集对象，运行报告以自动提取泄漏嫌疑者。可以在<a href="http://www.eclipse.org/mat/下载并使用MAT。" target="_blank" rel="noopener">http://www.eclipse.org/mat/下载并使用MAT。</a></p><h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><p>模拟内存溢出错误并导出dump文件</p><pre><code>public class OOMTest {    public static void main(String[] args) {        List&lt;Object&gt; list = new LinkedList&lt;&gt;();        int i = 0;        while (true) {            i++;            if (i % 10000 == 0) {                System.out.println(&quot;i=&quot; + i);            }            list.add(new Object());        }    }}</code></pre><p>加入vm参数-Xms30m -Xmx30m  -XX:+PrintGCDetails -XX:+HeapDumpOnOutOfMemoryError</p><p>栈溢出时会在项目目录下生成*.hprof文件</p><p>使用MAT打开文件 File-&gt;Open Heap Dump-&gt;Leak Suspects Report-&gt;Finash</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic1.png" srcset="/img/loading.gif" class=""><p>在<strong>Problem Supect</strong>中显示主线程占用了97.88%的空间，点击Details后可以看到更加具体的分析。</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic2.png" srcset="/img/loading.gif" class=""><p>其中</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic3.png" srcset="/img/loading.gif" class=""><p><strong>浅堆</strong>（Shallow Heap）：分配一个对象所消耗的内存</p><p><strong>深堆</strong>（Retained Heap）：深堆大小是对象直接或间接引用到的所有对象的浅堆大小之，即GC回收时真实可回收的内存大小。</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic4.png" srcset="/img/loading.gif" class=""><p>例如：对象A引用了C和D，对象B引用了E。那么对象A的浅堆大小只是A本身，而如果A被回收，那么C和D都会被回收(可达性分析算法)，所以A的深堆大小为A+C+D之和，同时由于对象E还可以通过对象B访问到，因此不在对象A的深堆范围内。</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic5.png" srcset="/img/loading.gif" class=""><p><strong>incoming</strong>：当前对象引用的对象</p><p><strong>outgoing</strong>：当前对象在哪些对象中被引用</p><h2 id="JVM工具"><a href="#JVM工具" class="headerlink" title="JVM工具"></a>JVM工具</h2><h3 id="命令行工具"><a href="#命令行工具" class="headerlink" title="命令行工具"></a>命令行工具</h3><ul><li><p><strong>jps</strong></p><p>列出当前机器上正在运行的虚拟机进程，JPS从操作系统的临时目录上去找。</p><p>-q:仅仅显示进程号</p><p>-m:输出主函数传入的参数</p><p>-l:输出应用程序主类完整package名称或jar完整名称</p><p>-v:列出jvm参数</p></li><li><p><strong>jstat</strong></p><p>是用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据，在没有GUI图形界面，只提供了纯文本控制台环境的服务器上，它将是运行期定位虚拟机性能问题的首选工具。</p><p>例如：jstat-gc 13616 250 10:每250毫秒查询一次进程13616垃圾收集状况，一共查询10次</p><p>-class (类加载器) </p><p>-compiler (JIT) </p><p>-gc (GC堆状态) </p><p>-gccapacity (各区大小) </p><p>-gccause (最近一次GC统计和原因) </p><p>-gcnew (新区统计)</p><p>-gcnewcapacity (新区大小)</p><p>-gcold (老区统计)</p><p>-gcoldcapacity (老区大小)</p><p>-gcpermcapacity (永久区大小)</p><p>-gcutil (GC统计汇总)</p><p>-printcompilation (HotSpot编译统计)</p></li><li><p><strong>jinfo</strong> </p><p>查看和修改虚拟机的参数。</p><p>jinfo –sysprops 可以查看由System.getProperties()取得的参数</p><p>jinfo –flag 未被显式指定的参数的系统默认值</p><p>jinfo –flags（注意s）显示虚拟机的参数</p><p>jinfo –flag +[参数] 增加参数</p><p>由于虚拟机的限制，只有输入java -XX:+PrintFlagsFinal –version命令后，查询结果最后一列为manageable的参数可以增加。</p><p>jinfo –flag -[参数] 去除参数</p></li><li><p><strong>jmap</strong></p><p>用于生成堆转储快照（一般称为heapdump或dump文件）。jmap的作用并不仅仅是为了获取dump文件，它还可以查询finalize执行队列、Java堆和永久代的详细信息，如空间使用率、当前用的是哪种收集器等。和jinfo命令一样，jmap有不少功能在Windows平台下都是受限的，除了生成dump文件的-dump选项和用于查看每个类的实例、空间占用统计的-histo选项在所有操作系统都提供之外，其余选项都只能在Linux/Solaris下使用。</p><p>jmap -dump:live,format=b,file=heap.bin &lt;pid&gt;</p><p>Sun JDK提供jhat（JVM Heap Analysis Tool）命令与jmap搭配使用，来分析jmap生成的堆转储快照。</p></li><li><p><strong>jhat</strong></p><p>jhat dump文件名</p><p>使用jhat可以在服务器上生成堆转储文件分析（一般不推荐，毕竟占用服务器的资源，比如一个文件就有1个G）</p><p>后屏幕显示“Server is ready.”的提示后，用户在浏览器中键入<a href="http://localhost:7000/就可以访问详情。" target="_blank" rel="noopener">http://localhost:7000/就可以访问详情。</a></p></li><li><p><strong>jstack</strong></p><p>（Stack Trace for Java）命令用于生成虚拟机当前时刻的线程快照。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等都是导致线程长时间停顿的常见原因。</p><p>在代码中可以用java.lang.Thread类的getAllStackTraces（）方法用于获取虚拟机中所有线程的StackTraceElement对象。使用这个方法可以通过简单的几行代码就完成jstack的大部分功能，在实际项目中不妨调用这个方法做个管理员页面，可以随时使用浏览器来查看线程堆栈。</p></li></ul><h3 id="可视化工具"><a href="#可视化工具" class="headerlink" title="可视化工具"></a>可视化工具</h3><p>JMX（Java Management Extensions，即Java管理扩展）是一个为应用程序、设备、系统等<a href="https://baike.baidu.com/item/%E6%A4%8D%E5%85%A5/7958584" target="_blank" rel="noopener">植入</a>管理功能的框架。JMX可以跨越一系列异构操作系统平台、<a href="https://baike.baidu.com/item/%E7%B3%BB%E7%BB%9F%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/6842760" target="_blank" rel="noopener">系统体系结构</a>和<a href="https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE/332131" target="_blank" rel="noopener">网络传输协议</a>，灵活的开发无缝集成的系统、网络和服务管理应用。</p><p><strong>远程连接生产环境需要在启动参数中增加：</strong></p><p>-Djava.rmi.server.hostname=…..</p><p>-Dcom.sun.management.jmxremote</p><p>-Dcom.sun.management.jmxremote.port=8888</p><p>-Dcom.sun.management.jmxremote.authenticate=false</p><p>-Dcom.sun.management.jmxremote.ssl=false</p><h4 id="Jconsole"><a href="#Jconsole" class="headerlink" title="Jconsole"></a>Jconsole</h4><p>java监视与管理控制台</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic7.png" srcset="/img/loading.gif" class=""><h4 id="Jvisualvm"><a href="#Jvisualvm" class="headerlink" title="Jvisualvm"></a>Jvisualvm</h4><p>多合一故障处理工具，一般来说用于本机调试用，如果需要用于生产环境必须启用远程连接</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic6.png" srcset="/img/loading.gif" class=""><p>插件中心地址</p><p><a href="https://visualvm.github.io/archive/uc/8u40/updates.xml.gz" target="_blank" rel="noopener">https://visualvm.github.io</a></p><p>但是注意版本问题，不同的JDK所带的visualvm是不一样的，下载插件时需要下对应的版本。</p><h2 id="GC调优"><a href="#GC调优" class="headerlink" title="GC调优"></a>GC调优</h2><p>JVM调优并不能显著的提高系统性能，主要提升的是系统稳定性。如果系统出现了频繁的垃圾回收，这时候系统是不稳定的，所以需要进行JVM调优，调整垃圾回收的频次。</p><h3 id="GC调优原则"><a href="#GC调优原则" class="headerlink" title="GC调优原则"></a>GC调优原则</h3><ol><li>大多数的java应用不需要GC调优</li><li>大多数需要GC调优的情况是由于代码问题引起的</li><li>优化GC参数是最后的手段</li></ol><h3 id="GC调优指标"><a href="#GC调优指标" class="headerlink" title="GC调优指标"></a>GC调优指标</h3><ul><li><p><strong>GC的时间</strong></p><p>参考性指标：</p><ul><li>Minor GC执行时间在50ms内</li><li>Full GC执行时间在1000ms内</li></ul></li><li><p><strong>GC的频率</strong></p><p>参考性指标：</p><ul><li>Minor GC执行大于10秒一次</li><li>Full GC执行频率大于10分钟1次</li></ul></li></ul><p>即：如果满足下面的指标，则一般不需要进行GC调优</p><ul><li><p>Minor GC执行时间不到50ms；</p></li><li><p>Minor GC执行不频繁，约10秒一次；</p></li><li><p>Full GC执行时间不到1s</p></li><li><p>Full GC执行频率不算频繁，不低于10分钟1次；</p></li></ul><h3 id="GC调优步骤"><a href="#GC调优步骤" class="headerlink" title="GC调优步骤"></a>GC调优步骤</h3><ol><li><p><strong>监控GC的状态：使用各种JVM工具</strong>，查看当前日志，分析当前JVM参数设置，并且分析当前堆内存快照和GC日志，根据实际的各区域内存划分和GC执行时间，决定是否进行优化。</p></li><li><p><strong>分析结果，判断是否需要优化</strong>：如果各项参数设置合理，系统没有超时日志出现，GC频率不高，GC耗时不高，那么没有必要进行GC优化；如果GC时间超过1-3秒，或者频繁GC，则必须优化；</p></li><li><p><strong>调整GC类型和内存分配</strong>：如果内存分配过大或过小，或者采用的GC收集器比较慢，则应该优先调整这些参数，并且先找1台或几台机器进行beta，然后比较优化过的机器和没有优化的机器的性能对比，并有针对性的做出最后选择；</p></li><li><p><strong>不断的分析和调整</strong>：通过不断的试验和试错，分析并找到最合适的参数</p></li><li><p><strong>全面应用参数</strong>：如果找到了最合适的参数，则将这些参数应用到所有服务器，并进行后续跟踪。</p></li></ol><h3 id="GC调优实战"><a href="#GC调优实战" class="headerlink" title="GC调优实战"></a>GC调优实战</h3><h4 id="如何阅读GC日志"><a href="#如何阅读GC日志" class="headerlink" title="如何阅读GC日志"></a>如何阅读GC日志</h4><p>主要关注MinorGC和FullGC 的回收效率（回收前大小和回收比较）、回收的时间。</p><p>以参数<strong>-Xms5m -Xmx5m -XX:+PrintGCDetails -XX:+UseSerialGC</strong>为例：</p><p>[DefNew: 1855K-&gt;1855K(1856K), 0.0000148 secs][Tenured: 2815K-&gt;4095K(4096K), 0.0134819 secs] 4671K</p><p>DefNew指明了收集器类型，而且说明了收集发生在新生代。</p><p>1855K-&gt;1855K(1856K)表示，回收前 新生代占用1855K，回收后占用1855K，新生代大小1856K。</p><p>0.0000148 secs 表明新生代回收耗时。</p><p>Tenured表明收集发生在老年代</p><p>2815K-&gt;4095K(4096K), 0.0134819 secs：含义同新生代</p><p>最后的4671K指明堆的大小。</p><p>收集器参数变为<strong>-XX:+UseParNewGC</strong>，日志变为：</p><p>[ParNew: 1856K-&gt;1856K(1856K), 0.0000107 secs][Tenured: 2890K-&gt;4095K(4096K), 0.0121148 secs]</p><p>收集器参数变为-<strong>XX:+ UseParallelGC或UseParallelOldGC</strong>，日志变为：</p><p>[PSYoungGen: 1024K-&gt;1022K(1536K)] [ParOldGen: 3783K-&gt;3782K(4096K)] 4807K-&gt;4804K(5632K),</p><p>当收集器参数变为：<strong>-XX:+UseConcMarkSweepGC</strong>、<strong>-XX:+UseG1GC</strong>时，CMS收集器和G1收集器会有明显的相关字样</p><h4 id="项目启动时的GC优化"><a href="#项目启动时的GC优化" class="headerlink" title="项目启动时的GC优化"></a>项目启动时的GC优化</h4><ol><li>开启日志分析 -XX:+PrintGCDetails 发现有7次Minor GC，2次Full GC，执行FullGC的原因是Metaspace空间不足。</li><li>调整Metadata空间-XX:MetaspaceSize=64m，调整后FullGC不再出现。</li><li>调整堆空间-Xms500m，调整后Minor GC次数减少至4次</li><li>继续调整堆空间-Xms1000m，调整后Minor GC减少至2次</li><li>调整新生代空间-Xmn900m，调整后Minor GC减少至1次</li><li>继续调整新生代空间-Xms2000m -Xmn1800m，调整后Minor GC次数没有变化，这次的调整时没有意义的，反而会造成资源浪费。</li></ol><h4 id="项目运行GC优化"><a href="#项目运行GC优化" class="headerlink" title="项目运行GC优化"></a>项目运行GC优化</h4><p>使用jmeter同时访问三个接口，index、time、noblemetal</p><p>使用40个线程，循环2500次进行压力测试，观察并发的变化</p><p>使用单线程GC -XX:+UseSerialGC</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic8.png" srcset="/img/loading.gif" class=""><p>使用多线程GC -XX:+UseParNewGC</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic9.png" srcset="/img/loading.gif" class=""><p>可以看到吞吐量有一定的上升</p><p>使用CMS -XX:+UseConcMarkSweepGC</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic10.png" srcset="/img/loading.gif" class=""><p>CMS采用了并发收集，所以STW的时间较小，吞吐量较单线程GC有一定提高，最大请求时间有明显的下降。</p><p>使用G1 -XX:+UseG1GC</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic11.png" srcset="/img/loading.gif" class=""><p>此时的吞吐量是最大的，最大请求时间有明显的下降。</p><h4 id="推荐策略"><a href="#推荐策略" class="headerlink" title="推荐策略"></a>推荐策略</h4><h5 id="堆空间的设置"><a href="#堆空间的设置" class="headerlink" title="堆空间的设置"></a>堆空间的设置</h5><p>可以将新生代尽可能的设置的大一些，减少MinorGC的次数。如果新生代设置的过小会导致对象直接进入老年代，如果此时老年代满了，会触发FullGC.。</p><h5 id="垃圾收集器的选择"><a href="#垃圾收集器的选择" class="headerlink" title="垃圾收集器的选择"></a>垃圾收集器的选择</h5><p>响应时间优先的应用：老年代尽量使用并发收集器，大小需要小心设置一般要考虑并发会话率和会话持续时间等一些参数。如果堆设置小了,可能会造成内存碎片，高回收频率以及应用暂停而使用传统的标记清除方式。如果堆大了，则需要较长的收集时间。最优化的方案,一般需要参考以下数据获得：</p><ul><li>并发垃圾收集信息</li><li>持久代并发收集次数</li><li>传统GC信息</li><li>新生代和老年代回收上的时间比例。</li></ul><p>吞吐量优先的应用：一般吞吐量优先的应用都有一个很大的新生代和一个较小的老年代。这样可以尽可能回收掉大部分短期对象，减少中期的对象，而老年代可以尽量存放长期存活对象。</p><p>GC调优是个很复杂、很细致的过程，要根据实际情况调整，不同的机器、不同的应用、不同的性能要求调优的手段都是不同的，king老师也无法告诉大家全部，即使是jvm参数也是如此，比如说性能有关的操作系统工具，和操作系统本身相关的所谓大页机制，都需要大家平时去积累，去观察，去实践，king老师在这个专题上告诉大家的除了各种java虚拟机基础知识和内部原理，也告诉大家一个性能优化的一个基本思路和着手的方向。</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>JVM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JVM的执行子系统</title>
    <link href="/2020/03/12/JVM%E7%9A%84%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F/"/>
    <url>/2020/03/12/JVM%E7%9A%84%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="Class文件结构"><a href="#Class文件结构" class="headerlink" title="Class文件结构"></a>Class文件结构</h2><h3 id="Jvm的无关性"><a href="#Jvm的无关性" class="headerlink" title="Jvm的无关性"></a>Jvm的无关性</h3><p><strong>平台无关性</strong>是建立在操作系统上，虚拟机厂商提供了许多可以运行在各种不同平台的虚拟机，它们都可以载入和执行字节码，从而实现程序的“一次编写，到处运行”</p><p>各种不同平台的虚拟机与所有平台都统一使用的程序存储格式——字节码（ByteCode）是构成平台无关性的基石，也是<strong>语言无关性</strong>的基础。Java虚拟机不和包括Java在内的任何语言绑定，它只与“Class文件”这种特定的二进制文件格式所关联，Class文件中包含了Java虚拟机指令集和符号表以及若干其他辅助信息。</p><h3 id="Class类文件（字节码）"><a href="#Class类文件（字节码）" class="headerlink" title="Class类文件（字节码）"></a>Class类文件（字节码）</h3><p>整个Class文件中存储的内容几乎全部是程序运行的必要数据，没有空隙存在，各个数据严格按照顺序紧凑地排列，中间没有添加任何分隔符。Class文件是一组以8位字节为基础单位的二进制流，由于它没有任何分隔符号，所以在其中的数据项，无论是顺序还是数量，都是被严格限定的，哪个字节代表什么含义，长度是多少，先后顺序如何，都不允许改变。</p><p>Class文件格式采用一种类似于C语言结构体的伪结构来存储数据，这种伪结构中只有两种数据类型：无符号数和表。</p><p>无符号数属于基本的数据类型，以u1、u2、u4、u8来分别代表1个字节、2个字节、4个字节和8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8编码构成字符串值。</p><p>表是由多个无符号数或者其他表作为数据项构成的复合数据类型，所有表都习惯性地以“_info”结尾。表用于描述有层次关系的复合结构的数据，整个Class文件本质上就是一张表。</p><p>按顺序包括：</p><ol><li><p><strong>魔数与Class文件的版本</strong></p><p>每个Class文件的头4个字节称为魔数（Magic Number），它的唯一作用是确定这个文件是否为一个能被虚拟机接受的Class文件。使用魔数而不是扩展名来进行识别主要是基于安全方面的考虑，因为文件扩展名可以随意地改动。文件格式的制定者可以自由地选择魔数值，只要这个魔数值还没有被广泛采用过同时又不会引起混淆即可。紧接着魔数的4个字节存储的是Class文件的版本号：第5和第6个字节是次版本号（MinorVersion），第7和第8个字节是主版本号（Major Version）。Java的版本号是从45开始的，JDK 1.1之后的每个JDK大版本发布主版本号向上加1高版本的JDK能向下兼容以前版本的Class文件，但不能运行以后版本的Class文件，即使文件格式并未发生任何变化，虚拟机也必须拒绝执行超过其版本号的Class文件。</p></li><li><p><strong>常量池</strong></p><p>常量池中常量的数量是不固定的，所以在常量池的入口需要放置一项u2类型的数据，代表常量池容量计数值（constant_pool_count）。与Java中语言习惯不一样的是，这个容量计数是从1而不是0开始的</p><p>常量池中主要存放两大类常量：字面量（Literal）和符号引用（Symbolic References）。</p><p>字面量比较接近于Java语言层面的常量概念，如文本字符串、声明为final的常量值等。</p><p>而符号引用则属于编译原理方面的概念，包括了下面三类常量：</p><ul><li>类和接口的全限定名（Fully Qualified Name）</li><li>字段的名称和描述符（Descriptor）</li><li>方法的名称和描述符</li></ul></li><li><p><strong>访问标志</strong></p><p>用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口；是否定义为public类型；是否定义为abstract类型；如果是类的话，是否被声明为final等</p></li><li><p><strong>类索引、父类索引与接口索引集合</strong></p><p>这三项数据来确定这个类的继承关系。类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名。由于Java语言不允许多重继承，所以父类索引只有一个，除了java.lang.Object之外，所有的Java类都有父类，因此除了java.lang.Object外，所有Java类的父类索引都不为0。接口索引集合就用来描述这个类实现了哪些接口，这些被实现的接口将按implements语句（如果这个类本身是一个接口，则应当是extends语句）后的接口顺序从左到右排列在接口索引集合中</p></li><li><p><strong>字段表集合</strong></p><p>描述接口或者类中声明的变量。字段（field）包括类级变量以及实例级变量。而字段叫什么名字、字段被定义为什么数据类型，这些都是无法固定的，只能引用常量池中的常量来描述。</p><p>字段表集合中不会列出从超类或者父接口中继承而来的字段，但有可能列出原本Java代码之中不存在的字段，譬如在内部类中为了保持对外部类的访问性，会自动添加指向外部类实例的字段。</p></li><li><p><strong>方法表集合</strong></p><p>描述了方法的定义，但是方法里的Java代码，经过编译器编译成字节码指令后，存放在属性表集合中的方法属性表集合中一个名为“Code”的属性里面。</p><p>与字段表集合相类似的，如果父类方法在子类中没有被重写（Override），方法表集合中就不会出现来自父类的方法信息。但同样的，有可能会出现由编译器自动添加的方法，最典型的便是类构造器“＜clinit＞”方法和实例构造器“＜init＞”</p></li><li><p><strong>属性表集合</strong></p><p>存储Class文件、字段表、方法表都自己的属性表集合，以用于描述某些场景专有的信息。如方法的代码就存储在Code属性表中。</p></li></ol><h2 id="字节码指令"><a href="#字节码指令" class="headerlink" title="字节码指令"></a>字节码指令</h2><p>Java虚拟机的指令由一个字节长度的、代表着某种特定操作含义的数字（称为操作码，Opcode）以及跟随其后的零至多个代表此操作所需参数（称为操作数，Operands）而构成。</p><p>由于限制了Java虚拟机操作码的长度为一个字节（即0～255），这意味着指令集的操作码总数不可能超过256条。</p><p>大多数的指令都包含了其操作所对应的数据类型信息。例如：</p><p>iload指令用于从局部变量表中加载int型的数据到操作数栈中，而fload指令加载的则是float类型的数据。</p><p>大部分的指令都没有支持整数类型byte、char和short，甚至没有任何指令支持boolean类型。大多数对于boolean、byte、short和char类型数据的操作，实际上都是使用相应的int类型作为运算类型</p><p>常见指令一般有：</p><ul><li><p><strong>加载和存储指令</strong></p><p>用于将数据在栈帧中的局部变量表和操作数栈之间来回传输，这类指令包括如下内容。</p><p>将一个局部变量加载到操作栈：iload、iload_＜n＞、lload、lload_＜n＞、fload、fload_＜n＞、dload、dload_＜n＞、aload、aload_＜n＞。_</p><p>将一个数值从操作数栈存储到局部变量表：istore、istore_＜n＞、lstore、lstore_＜n＞、fstore、fstore_＜n＞、dstore、dstore_＜n＞、astore、astore_＜n＞。_</p><p>将一个常量加载到操作数栈：bipush、sipush、ldc、ldc_w、ldc2_w、aconst_null、iconst_m1、iconst_＜i＞、lconst_＜l＞、fconst_＜f＞、dconst_＜d＞。</p><p>扩充局部变量表的访问索引的指令：wide。</p></li><li><p><strong>运算或算术指令</strong></p><p>用于对两个操作数栈上的值进行某种特定运算，并把结果重新存入到操作栈顶。</p><p>加法指令：iadd、ladd、fadd、dadd。</p><p>减法指令：isub、lsub、fsub、dsub。</p><p>乘法指令：imul、lmul、fmul、dmul等等</p></li><li><p><strong>类型转换指令</strong></p><p>可以将两种不同的数值类型进行相互转换，</p><p>Java虚拟机直接支持以下数值类型的宽化类型转换（即小范围类型向大范围类型的安全转换）：</p><ul><li>int类型到long、float或者double类型。</li><li>long类型到float、double类型。</li><li>float类型到double类型。</li></ul><p>处理窄化类型转换（Narrowing Numeric Conversions）时，必须显式地使用转换指令来完成，这些转换指令包括：i2b、i2c、i2s、l2i、f2i、f2l、d2i、d2l和d2f。</p></li><li><p><strong>创建类实例的指令</strong></p><p>new</p></li><li><p><strong>创建数组的指令</strong></p><p>newarray、anewarray、multianewarray。</p></li><li><p><strong>访问字段指令</strong></p><p>getfield、putfield、getstatic、putstatic。</p></li><li><p><strong>数组存取相关指令</strong></p><p>把一个数组元素加载到操作数栈的指令：baload、caload、saload、iaload、laload、faload、daload、aaload。</p><p>将一个操作数栈的值存储到数组元素中的指令：bastore、castore、sastore、iastore、fastore、dastore、aastore。</p></li><li><p><strong>取数组长度的指令</strong></p><p>arraylength</p></li><li><p><strong>检查类实例类型的指令</strong></p><p>instanceof、checkcast。</p></li><li><p><strong>操作数栈管理指令</strong></p><p>如同操作一个普通数据结构中的堆栈那样，Java虚拟机提供了一些用于直接操作操作数栈的指令，包括：将操作数栈的栈顶一个或两个元素出栈：pop、pop2。</p><p>复制栈顶一个或两个数值并将复制值或双份的复制值重新压入栈顶：dup、dup2、dup_x1、dup2_x1、dup_x2、dup2_x2。</p><p>将栈最顶端的两个数值互换：swap。</p></li><li><p><strong>控制转移指令</strong></p><p>控制转移指令可以让Java虚拟机有条件或无条件地从指定的位置指令而不是控制转移指令的下一条指令继续执行程序，从概念模型上理解，可以认为控制转移指令就是在有条件或无条件地修改PC寄存器的值。控制转移指令如下。</p><ul><li>条件分支：ifeq、iflt、ifle、ifne、ifgt、ifge、ifnull、ifnonnull、if_icmpeq、if_icmpne、if_icmplt、if_icmpgt、if_icmple、if_icmpge、if_acmpeq和if_acmpne。</li><li>复合条件分支：tableswitch、lookupswitch。</li><li>无条件分支：goto、goto_w、jsr、jsr_w、ret。</li></ul></li><li><p><strong>方法调用指令</strong></p><p>invokevirtual指令用于调用对象的实例方法，根据对象的实际类型进行分派（虚方法分派），这也是Java语言中最常见的方法分派方式。</p><p>invokeinterface指令用于调用接口方法，它会在运行时搜索一个实现了这个接口方法的对象，找出适合的方法进行调用。</p><p>invokespecial指令用于调用一些需要特殊处理的实例方法，包括实例初始化方法、私有方法和父类方法。</p><p>invokestatic指令用于调用类方法（static方法）。</p><p>invokedynamic指令用于在运行时动态解析出调用点限定符所引用的方法，并执行该方法，前面4条调用指令的分派逻辑都固化在Java虚拟机内部，而invokedynamic指令的分派逻辑是由用户所设定的引导方法决定的。</p><p>方法调用指令与数据类型无关。</p></li><li><p><strong>方法返回指令</strong></p><p>是根据返回值的类型区分的，包括ireturn（当返回值是boolean、byte、char、short和int类型时使用）、lreturn、freturn、dreturn和areturn，另外还有一条return指令供声明为void的方法、实例初始化方法以及类和接口的类初始化方法使用。</p></li><li><p><strong>异常处理指令</strong></p><p>在Java程序中显式抛出异常的操作（throw语句）都由athrow指令来实现</p></li><li><p><strong>同步指令</strong></p><p>有monitorenter和monitorexit两条指令来支持synchronized关键字的语义</p></li></ul><h2 id="栈帧详解"><a href="#栈帧详解" class="headerlink" title="栈帧详解"></a>栈帧详解</h2><p>当前栈帧：一个线程的方法调用链可能会很长，这意味着虚拟机栈会被压入很多栈帧，但在线程执行的某个时间点只有位于栈顶的栈帧才是有效的，该栈帧称为“当前栈帧”，与这个栈帧相关联的方法称为“当前方法”。</p><img src="/2020/03/12/JVM%E7%9A%84%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F/pic1.png" srcset="/img/loading.gif" class=""><ul><li><p><strong>局部变量表</strong></p><p>局部变量表的容量以变量槽（Variable Slot，下称 Slot）为最小单位，虚拟机规范中导向性地说到每个 Slot 都应该能存放一个 boolean、byte、char、short、int、float、double、long 8 种数据类型和reference ，可以使用 32 位或更小的物理内存来存放。</p><p>对于 64 位的数据类型，虚拟机会以高位对齐的方式为其分配两个连续的 Slot 空间。Java 语言中明确的（reference 类型则可能是 32 位也可能是 64 位）64 位的数据类型只有 long 和 double 两种。</p></li><li><p><strong>操作数栈</strong></p><p>操作数栈（Operand Stack）也常称为操作栈，它是一个先进后出（First In Last Out,FILO）栈。 同局部变量表一样， 操作数栈的每一个元素可以是任意的Java数据类型，包括long和double。 32位数据类型所占的栈容量为1，64位数据类型所占的栈容量为2。 </p><p>当一个方法刚刚开始执行的时候，这个方法的操作数栈是空的，在方法的执行过程中，会有各种字节码指令往操作数栈中写入和提取内容，也就是出栈/入栈操作。 例如，在做算术运算的时候是通过操作数栈来进行的，又或者在”调用其他方法的时候是通过操作数栈来进行参数传递的”。</p><p>java虚拟机的解释执行引擎称为“基于栈的执行引擎”，其中所指的“栈”就是操作数栈。</p></li><li><p><strong>数据重叠优化</strong></p><p>虚拟机概念模型中每二个栈帧都是相互独立的，但在实际应用是我们知道一个方法调用另一个方法时，往往存在参数传递，这种做法在虚拟机实现过程中会做一些优化，具体做法如下：令两个栈帧出现一部分重叠。让下面栈帧的一部分操作数栈与上面栈帧的部分局部变量表重叠在一起，进行方法调用时就可以共用一部分数据，无须进行额外的参数复制传递。</p><img src="/2020/03/12/JVM%E7%9A%84%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F/pic2.png" srcset="/img/loading.gif" class=""></li><li><p><strong>动态连接</strong></p><p>栈帧执行方法是哪个方法，栈帧中会持有一个符号引用，该引用指向某个具体方法。</p><p>符号引用是一个地址位置的代号，在编译的时候我们是不知道某个方法在运行的时候是放到哪里的，这时我用代号com/enjoy/pojo/User.Say:()V指代某个类的方法，将来可以把符号引用转换成直接引用进行真实的调用。</p><p>用符号引用转化成直接引用的解析时机，把解析分为两大类 </p><ul><li><p><strong>静态解析</strong>：符号引用在类加载阶段或者第一次使用的时候就直接转换成直接引用。</p></li><li><p><strong>动态连接</strong>：符号引用在每次运行期间转换为直接引用，即每次运行都重新转换。</p></li></ul></li><li><p><strong>方法返回地址</strong></p><p>方法退出方式有：正常退出与异常退出</p><p>理论上，执行完当前栈帧的方法，需要返回到当前方法被调用的位置，所以栈帧需要记录一些信息，用来恢复上层方法的执行状态。正常退出：上层方法的PC计数器可以做为当前方法的返回地址，被保存在当前栈帧中。异常退出时：通过异常处理器表来确定返回地址。</p><p>方法退出时会做的操作：恢复上次方法的局部变量表、操作数栈，把当前方法的返回值，压入调用者栈帧的操作数栈中，使用当前栈帧保存的返回地址调整PC计数器的值，当前栈帧出栈，随后，执行PC计数器指向的指令。</p></li><li><p><strong>附加信息</strong></p><p>虚拟机规范允许实现虚拟机时增加一些额外信息，例如与调试相关的信息。</p><p>一般把动态连接、方法返回地址、其他额外信息归成一类，称为栈帧信息。</p></li></ul><h2 id="字节码执行引擎"><a href="#字节码执行引擎" class="headerlink" title="字节码执行引擎"></a>字节码执行引擎</h2><p>Java编译器输出的指令流基本上是一种基于栈的指令集架构，指令流中的指令大部分都是零地址指令，它们依赖操作数栈进行工作。</p><p>基于寄存器的指令集，最典型的就是x86的二地址指令集，说得通俗一些，就是现在我们主流PC机中直接支持的指令集架构，这些指令依赖寄存器进行工作。</p><p>举个最简单的例子，分别使用这两种指令集计算“1+1”的结果，基于栈的指令集会是这样子的：</p><p>iconst_1</p><p>iconst_1</p><p>iadd</p><p>istore_0</p><p>两条iconst_1指令连续把两个常量1压入栈后，iadd指令把栈顶的两个值出栈、相加，然后把结果放回栈顶，最后istore_0把栈顶的值放到局部变量表的第0个Slot中。</p><p>如果基于寄存器，那程序可能会是这个样子：</p><p>mov eax，1</p><p>add eax，1</p><p>mov指令把EAX寄存器的值设为1，然后add指令再把这个值加1，结果就保存在EAX寄存器里面。</p><p>基于栈的指令集主要的优点就是可移植，寄存器由硬件直接提供，程序直接依赖这些硬件寄存器则不可避免地要受到硬件的约束。栈架构指令集的主要缺点是执行速度相对来说会稍慢一些。所有主流物理机的指令集都是寄存器架构也从侧面印证了这一点。</p><h2 id="方法调用详解"><a href="#方法调用详解" class="headerlink" title="方法调用详解"></a>方法调用详解</h2><p>在Java语言中符合“编译期可知，运行期不可变”这个要求的方法，主要包括静态方法和私有方法两大类，前者与类型直接关联，后者在外部不可被访问，这两种方法各自的特点决定了它们都不可能通过继承或别的方式重写其他版本，因此它们都适合在类加载阶段进行解析。</p><h3 id="静态分派"><a href="#静态分派" class="headerlink" title="静态分派"></a>静态分派</h3><pre><code>public class StaticDispatch{    static abstract class Human{}    static class Man extends Human{    }    static class Woman extends Human{}    public void sayHello(Human guy){        System.out.println(&quot;hello,guy！&quot;);    }    public void sayHello(Man guy){        System.out.println(&quot;hello,gentleman！&quot;);    }    public void sayHello(Woman guy){        System.out.println(&quot;hello,lady！&quot;);    }    public static void main(String[]args){        Human h1 = new Man();        Human h2 = new Woman();        StaticDispatch sr = new StaticDispatch();        sr.sayHello(h1);        sr.sayHello(h2);        //实际类型变化        Human man=new Man();        //静态类型变化        sr.sayHello((Man)man);        man=new Woman();        sr.sayHello((Woman)man);    }}</code></pre><p>输出结果</p><pre><code>hello,guyhello,guy</code></pre><p>“Human”称为变量的静态类型（Static Type），或者叫做的外观类型（Apparent Type），后面的“Man”则称为变量的实际类型（Actual Type），静态类型和实际类型在程序中都可以发生一些变化，区别是静态类型的变化仅仅在使用时发生，变量本身的静态类型不会被改变，并且变量本身的静态类型是在编译期可知的；而实际类型变化的结果在运行期才可确定，编译器在编译程序的时候并不知道一个对象的实际类型是什么。</p><p>代码中定义了两个静态类型相同但实际类型不同的变量，但虚拟机（准确地说是编译器）在重载时是通过参数的静态类型而不是实际类型作为判定依据的。并且静态类型是编译期可知的，因此，在编译阶段，Javac编译器会根据参数的静态类型决定使用哪个重载版本，所以选择了sayHello（Human）作为调用目标。所有依赖静态类型来定位方法执行版本的分派动作称为静态分派。静态分派的典型应用是方法重载。静态分派发生在编译阶段，因此确定静态分派的动作实际上不是由虚拟机来执行的。</p><h3 id="动态分派"><a href="#动态分派" class="headerlink" title="动态分派"></a>动态分派</h3><pre><code>public class DynamicDispatch {    static abstract class Human{        protected abstract void sayHello();    }    static class Man extends Human{        @Override        protected void sayHello() {            System.out.println(&quot;hello,gentleman！&quot;);        }    }    static class Woman extends Human{        @Override        protected void sayHello() {            System.out.println(&quot;hello,lady！&quot;);        }    }    public static void main(String[]args){        Human h1 = new Man();        Human h2 = new Woman();        h1.sayHello();        h2.sayHello();        h1 = new Woman();        h1.sayHello();    }}</code></pre><p>输出结果</p><pre><code>hello,gentleman！hello,lady！hello,lady！</code></pre><p>上述代码的静态类型同样都是Human的两个变量h1和h2，但在调用sayHello()方法时执行了不同的行为，并且变量好在两次调用中执行了不同的方法。导致这个现象的原因很明显，是这两个变量的实际类型不同。</p><img src="/2020/03/12/JVM%E7%9A%84%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F/pic3.png" srcset="/img/loading.gif" class=""><p>动态分派最常用的实现手段就是为类在方法区中建立一个虚方法表。虚方法表中存放着各个方法的实际入口地址。如果某个方法在子类中没有被重写，那子类的虚方法表里面的地址入口和父类相同方法的地址入口是一致的，都指向父类的实现入口。如果子类中重写了这个方法，子类方法表中的地址将会替换为指向子类实现版本的入口地址。图中，Son重写了来自Father的全部方法，因此Son的方法表没有指向Father类型数据的箭头。但是Son和Father都没有重写来自Object的方法，所以它们的方法表中所有从Object继承来的方法都指向了Object的数据类型。</p><h2 id="类加载机制"><a href="#类加载机制" class="headerlink" title="类加载机制"></a>类加载机制</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）7个阶段。其中验证、准备、解析3个部分统称为连接（Linking）</p><h3 id="加载阶段"><a href="#加载阶段" class="headerlink" title="加载阶段"></a>加载阶段</h3><p>虚拟机需要完成以下3件事情：</p><ol><li><p>通过一个类的全限定名来获取定义此类的二进制字节流。</p></li><li><p>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。</p></li><li><p>在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。</p></li></ol><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p>是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。但从整体上看，验证阶段大致上会完成下面4个阶段的检验动作：文件格式验证、元数据验证、字节码验证、符号引用验证。</p><h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><p>是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。这个阶段中有两个容易产生混淆的概念需要强调一下，首先，这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。其次，这里所说的初始值通常情况下是数据类型的零值，假设一个类变量的定义为：</p><p>public static int value=123；</p><p>那变量value在准备阶段过后的初始值为0而不是123，因为这时候尚未开始执行任何Java方法，而把value赋值为123的putstatic指令是程序被编译后，存放于类构造器＜clinit＞()方法之中，所以把value赋值为123的动作将在初始化阶段才会执行。假设上面类变量value的定义变为：public static final int value=123；</p><p>编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为123。</p><h3 id="解析阶段"><a href="#解析阶段" class="headerlink" title="解析阶段"></a>解析阶段</h3><p>是虚拟机将常量池内的符号引用替换为直接引用的过程。</p><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>是类加载过程的最后一步，前面的类加载过程中，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的Java程序代码。在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则根据程序员通过程序制定的主观计划去初始化类变量和其他资源，或者可以从另外一个角度来表达：初始化阶段是执行类构造器＜clinit＞()方法的过程。＜clinit＞()方法是由编译器自动收集类中的所有类变量的赋值动作和静态代码块中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的。</p><p>＜clinit＞()方法对于类或接口来说并不是必需的，如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生成＜clinit＞()方法。</p><h4 id="触发类初始化的五种情况"><a href="#触发类初始化的五种情况" class="headerlink" title="触发类初始化的五种情况"></a>触发类初始化的五种情况</h4><p>初始化阶段，虚拟机规定有且只有5种情况必须立即对类进行初始化（而加载、验证、准备需要在此之前开始）：</p><ol><li><p>遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。</p></li><li><p>使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。</p></li><li><p>当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。</p></li><li><p>当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。</p></li><li><p>当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。</p></li></ol><h4 id="初始化时的几种特殊情况"><a href="#初始化时的几种特殊情况" class="headerlink" title="初始化时的几种特殊情况"></a>初始化时的几种特殊情况</h4><ol><li><p>对于静态字段，只有直接定义这个字段的类才会被初始化，当通过其子类来引用父类中定义的静态字段时，只会触发父类的初始化而不会触发子类的初始化。</p></li><li><p>数组形式的new(而不是构造方法)不会触发类初始化</p></li><li><p>直接打印类的常量会不会触发类的初始化</p><p>坑：如果常量发生变化，使用这个常量的其他类中不重新编译就会还是原来的值。其实在编译阶段通过常量传播优化，就已经将常量的值存储到了本类的常量池中，以后对其他类中常量的引用实际都已被转化为对自身常量的引用了。就是说，实际上当前类的Class文件之中并不存在常量所在类的符号引用入口，这两个类在编译成Class之后就不存在任何联系了。</p></li><li><p>如果使用常量去引用另外一个常量，这个时候编译阶段无法进行优化，也会触发类的初始化。</p></li></ol><h4 id="初始化的线程安全"><a href="#初始化的线程安全" class="headerlink" title="初始化的线程安全"></a>初始化的线程安全</h4><p>虚拟机会保证一个类的＜clinit＞()方法在多线程环境中被正确地加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的＜clinit＞()方法，其他线程都需要阻塞等待，直到活动线程执行＜clinit＞()方法完毕。如果在一个类的＜clinit＞()方法中有耗时很长的操作，就可能造成多个进程阻塞。所以类的初始化是线程安全的，项目中可以利用这点。</p><h2 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h2><p>类在JVM中的的唯一性是由它的类加载器及全限定名确定的。每一个类加载器都拥有一个独立的类名称空间，所以比较两个类是否“相等”的前提是这两个类是由同一个类加载器加载，否则，即使这两个类来源于同一个Class文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。</p><p>这里所指的“相等”，包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法的返回结果，也包括使用instanceof关键字做对象所属关系判定等情况。</p><h3 id="类加载器分类"><a href="#类加载器分类" class="headerlink" title="类加载器分类"></a>类加载器分类</h3><ul><li><p><strong>启动类加载器（Bootstrap ClassLoader）</strong>：这个类加载器使负责将存放在＜JAVA_HOME＞\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器，那直接使用null代替即可。</p></li><li><p><strong>扩展类加载器（Extension ClassLoader）</strong>：这个加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载＜JAVA_HOME＞\lib\ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。</p></li><li><p><strong>应用程序类加载器（Application ClassLoader）</strong>：这个类加载器由sun.misc.Launcher$App-ClassLoader实现。由于这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，所以一般也称它为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。</p></li></ul><p>但从JVM的角度来讲，只存在两种不同的类加载器，启动类加载器（Bootstrap ClassLoader）和所有其他的类加载器，启动类加载器用C++语言实现，是虚拟机自身的一部分，另一种所有其他的类加载器，使用java语言实现，独立于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader。</p><h3 id="双亲委派模型"><a href="#双亲委派模型" class="headerlink" title="双亲委派模型"></a>双亲委派模型</h3><p>我们的应用程序都是由这3种类加载器互相配合进行加载的，如果有必要，还可以加入自己定义的类加载器。</p><p>双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。这里类加载器之间的父子关系一般不会以继承（Inheritance）的关系来实现，而是都使用组合（Composition）关系即在代码中保存一个父加载器来复用父加载器的代码。</p><img src="/2020/03/12/JVM%E7%9A%84%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F/pic4.png" srcset="/img/loading.gif" class=""><p>某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父类加载器，依次递归，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。</p><p>使用双亲委派模型来组织类加载器之间的关系，有一个显而易见的好处就是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，保证java程序稳定运行。例如用户自己编写了一个称为java.lang.Object的类，并放在程序的ClassPath中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都是同一个类，即rt.jar中的Object类，用户编写的这个类不会被再次加载。相反，如果没有使用双亲委派模型，由各个类加载器自行去加载的话，系统中将会出现多个不同的Object类，Java类型体系中最基础的行为也就无法保证，应用程序也将会变得一片混乱。</p><h3 id="自定义类加载器"><a href="#自定义类加载器" class="headerlink" title="自定义类加载器"></a>自定义类加载器</h3><p>ClassLoader中的loadClass方法中的代码逻辑就是双亲委派模型：</p><p>在自定义ClassLoader的子类时候，我们常见的会有两种做法，一种是重写<strong>loadClass</strong>方法，另一种是重写<strong>findClass</strong>方法。其实这两种方法本质上差不多，毕竟loadClass也会调用findClass，但是从逻辑上讲最好不要直接修改loadClass的内部逻辑。建议的做法是只在findClass里重写自定义类的加载方法。<br> loadClass这个方法是实现双亲委托模型逻辑的地方，擅自修改这个方法会导致模型被破坏，容易造成问题。因此最好是在双亲委托模型框架内进行小范围的改动，不破坏原有的稳定结构。同时，也避免了自己重写loadClass方法的过程中必须写双亲委托的重复代码，从代码的复用性来看，不直接修改这个方法始终是比较好的选择。</p><h3 id="Tomcat类加载机制"><a href="#Tomcat类加载机制" class="headerlink" title="Tomcat类加载机制"></a>Tomcat类加载机制</h3><p>Tomcat本身也是一个java项目，因此其也需要被JDK的类加载机制加载，也就必然存在引导类加载器、扩展类加载器和应用(系统)类加载器。</p><p>当tomcat启动时，会创建几种类加载器：</p><ol><li><p><strong>Bootstrap 引导类加载器</strong>：加载JVM启动所需的类，以及标准扩展类（位于jre/lib/ext下）</p></li><li><p><strong>System系统类加载器</strong>：加载tomcat启动的类，比如bootstrap.jar，通常在catalina.bat或者catalina.sh中指定。位于CATALINA_HOME/bin下。</p></li><li><p><strong>Common通用类加载器</strong>：加载tomcat使用以及应用通用的一些类，位于CATALINA_HOME/lib下，比如servlet-api.jar</p></li><li><p><strong>webapp应用类加载器</strong>：每个应用在部署后，都会创建一个唯一的类加载器。该类加载器会加载位于 WEB-INF/lib下的jar文件中的class 和 WEB-INF/classes下的class文件。</p></li></ol><img src="/2020/03/12/JVM%E7%9A%84%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F/pic5.png" srcset="/img/loading.gif" class=""><p><strong>Common ClassLoader</strong>作为<strong>Catalina ClassLoader</strong>和<strong>Shared ClassLoader</strong>的parent，而<strong>Shared ClassLoader</strong>又可能存在多个children类加载器<strong>WebApp ClassLoader</strong>，一个<strong>WebApp ClassLoader</strong>实际上就对应一个Web应用，那Web应用就有可能存在Jsp页面，这些Jsp页面最终会转成class类被加载，因此也需要一个Jsp的类加载器。</p><p>需要注意的是，在代码层面<strong>Catalina ClassLoader</strong>、<strong>Shared ClassLoader</strong>、<strong>Common ClassLoader</strong>对应的实体类实际上都是<strong>URLClassLoader</strong>或者<strong>SecureClassLoader</strong>，一般我们只是根据加载内容的不同和加载父子顺序的关系，在逻辑上划分为这三个类加载器；而<strong>WebApp ClassLoader</strong>和<strong>JasperLoader</strong>都是存在对应的类加载器类的。</p><p>还需要注意的是：<strong>WebApp ClassLoadder</strong>中的<strong>loadClass</strong>方法已经被重写，重写后的<strong>loadClass</strong>方法不再维护<strong>双亲委派机制</strong>，这样就保证了不Tomcat容器下两个应用间类的隔离。</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>JVM</tag>
      
      <tag>Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>垃圾回收算法与垃圾回收器</title>
    <link href="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/"/>
    <url>/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="垃圾回收的区域"><a href="#垃圾回收的区域" class="headerlink" title="垃圾回收的区域"></a>垃圾回收的区域</h2><p>1、面试需要</p><p>2、GC对应用的性能是有影响的；</p><p>3、写代码有好处</p><p>栈中的生命周期是跟随线程，所以一般不需要关注，堆中的对象是垃圾回收的重点，方法区/元空间也会发生垃圾回收，不过这块的效率比较低，一般不是我们关注的重点</p><h2 id="GC判断对象的存活"><a href="#GC判断对象的存活" class="headerlink" title="GC判断对象的存活"></a>GC判断对象的存活</h2><h3 id="引用计数法"><a href="#引用计数法" class="headerlink" title="引用计数法"></a>引用计数法</h3><p>给对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。（Python在用，但主流虚拟机没有使用）</p><p>优点：快，方便，实现简单。</p><p>缺陷：对象相互引用时（A.instance=B同时B.instance=A），很难判断对象是否该回收。</p><h3 id="可达性分析"><a href="#可达性分析" class="headerlink" title="可达性分析"></a>可达性分析</h3><p>这个算法的基本思路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。</p><p>作为GC Roots的对象包括下面几种：</p><ul><li><p>当前虚拟机栈中局部变量表中的引用的对象</p></li><li><p>当前本地方法栈中局部变量表中的引用的对象</p></li><li><p>方法区中类静态属性引用的对象</p></li><li><p>方法区中的常量引用的对象</p></li></ul><p>注意：当垃圾回收器将要回收对象所占内存之前会调用finalize()方法，让此对象处理它生前的最后事情（这个对象可以趁这个时机挣脱死亡的命运）。finalize()可以完成对象的拯救，但是JVM不保证一定能执行。</p><h2 id="引用（Reference）"><a href="#引用（Reference）" class="headerlink" title="引用（Reference）"></a>引用（Reference）</h2><p>传统定义：Reference中存储的数据代表的是一块内存的起始地址。</p><h3 id="强引用"><a href="#强引用" class="headerlink" title="强引用"></a>强引用</h3><p>即使内存不足，垃圾回收器也绝对不会回收GC Roots的强引用对象。</p><p>一般的Object obj = new Object() ，就属于强引用。</p><h3 id="软引用（SoftReference）"><a href="#软引用（SoftReference）" class="headerlink" title="软引用（SoftReference）"></a>软引用（SoftReference）</h3><p>垃圾回收器在内存充足的时候不会回收GC Roots 的软引用对象，而在内存不足时才会回收。</p><p>软引用非常适合于创建缓存。当系统内存不足的时候，缓存中的内容是可以被释放的。例如，一个程序用来处理用户提供的图片。如果将所有图片读入内存，这样虽然可以很快的打开图片，但内存空间使用巨大，一些使用较少的图片浪费内存空间，需要手动从内存中移除。如果每次打开图片都从磁盘文件中读取到内存再显示出来，虽然内存占用较少，但一些经常使用的图片每次打开都要访问磁盘，代价巨大。这个时候就可以用软引用构建缓存。</p><p>用软引用关联的对象，系统将要发生OOM之前，这些对象就会被回收。参见代码：</p><p>VM参数 -Xms10m -Xmx10m -XX:+PrintGC</p><pre><code>public class TestSoftRef {    //对象    public static class User{        public int id = 0;        public String name = &quot;&quot;;        public User(int id, String name) {            super();            this.id = id;            this.name = name;        }        @Override        public String toString() {            return &quot;User [id=&quot; + id + &quot;, name=&quot; + name + &quot;]&quot;;        }    }    //    public static void main(String[] args) {        User u = new User(1,&quot;King&quot;); //new是强引用        SoftReference&lt;User&gt; userSoft = new SoftReference&lt;User&gt;(u);        u = null;//干掉强引用，确保这个实例只有userSoft的软引用        System.out.println(userSoft.get()); //看一下这个对象是否还在        System.gc();//进行一次GC垃圾回收  千万不要写在业务代码中。        System.out.println(&quot;After gc&quot;);        System.out.println(userSoft.get());        //往堆中填充数据，导致OOM        List&lt;byte[]&gt; list = new LinkedList&lt;&gt;();        try {            for(int i=0;i&lt;100;i++) {                System.out.println(&quot;*************&quot;+userSoft.get());                list.add(new byte[1024*1024*1]); //1M的对象            }        } catch (Throwable e) {            //抛出了OOM异常时打印软引用对象            System.out.println(&quot;Exception*************&quot;+userSoft.get());        }    }}</code></pre><p>运行结果</p><img src="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/pic1.png" srcset="/img/loading.gif" class=""><h3 id="弱引用-WeakReference"><a href="#弱引用-WeakReference" class="headerlink" title="弱引用 WeakReference"></a>弱引用 WeakReference</h3><p>垃圾回收器在扫描到弱引用的对象时，无论内存充足与否，都会回收该对象的内存。</p><p>一些有用（程度比软引用更低）但是并非必需，用弱引用关联的对象，只能生存到下一次垃圾回收之前，GC发生时，不管内存够不够都会被回收。</p><p>参看代码：</p><pre><code>public class TestWeakRef {    public static class User{        public int id = 0;        public String name = &quot;&quot;;        public User(int id, String name) {            super();            this.id = id;            this.name = name;        }        @Override        public String toString() {            return &quot;User [id=&quot; + id + &quot;, name=&quot; + name + &quot;]&quot;;        }    }    public static void main(String[] args) {        User u = new User(1,&quot;King&quot;);        WeakReference&lt;User&gt; userWeak = new WeakReference&lt;User&gt;(u);        u = null;//干掉强引用，确保这个实例只有userWeak的弱引用        System.out.println(userWeak.get());        System.gc();//进行一次GC垃圾回收        System.out.println(&quot;After gc&quot;);        System.out.println(userWeak.get());    }}</code></pre><p><strong>注意：</strong>软引用 SoftReference和弱引用 WeakReference，可以用在内存资源紧张的情况下或者创建不是很重要的数据缓存。JDK中WeakHashMap和ThreadLocal中的key使用的就是弱引用。</p><h3 id="虚引用-PhantomReference"><a href="#虚引用-PhantomReference" class="headerlink" title="虚引用 PhantomReference"></a>虚引用 PhantomReference</h3><p>虚引用也被称为幽灵引用，是最弱的引用类型，在被垃圾回收的时候可以收到一个通知，主要被用来跟踪对象被垃圾回收器回收的活动。如果一个对象只具有虚引用，那么它和没有任何引用一样，任何时候都可能被回收。</p><h2 id="GC（Garbage-Collection）"><a href="#GC（Garbage-Collection）" class="headerlink" title="GC（Garbage Collection）"></a>GC（Garbage Collection）</h2><h3 id="Minor-GC"><a href="#Minor-GC" class="headerlink" title="Minor GC"></a>Minor GC</h3><p><strong>特点</strong>：发生在新生代上，发生的较频繁，执行速度较快</p><p>触发条件： Eden区空间不足，空间分配担保成功</p><h3 id="Full-GC"><a href="#Full-GC" class="headerlink" title="Full GC"></a>Full GC</h3><p><strong>特点</strong>： 主要发生在老年代上（新生代也会回收），较少发生，执行速度较慢</p><p><strong>触发条件</strong>： </p><ul><li><p>调用 System.gc()</p></li><li><p>老年代区域空间不足</p></li><li><p>空间分配担保失败</p></li><li><p>JDK 1.7 及以前的永久代(方法区)空间不足</p></li><li><p>CMS GC处理浮动垃圾申请预留空间时，如果新生代空间不足，则采用空间分配担保机制，如果老年代空间不足，则触发Full GC</p></li></ul><h2 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h2><h3 id="复制算法（Copying）"><a href="#复制算法（Copying）" class="headerlink" title="复制算法（Copying）"></a>复制算法（Copying）</h3><p>将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。这块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间全部清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半。</p><p>新生代中的对象98%是“朝生夕死”的，所以一般来说回收占据10%的空间够用了，所以并不需要按照1:1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。</p><p>HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的内存会被“浪费”。</p><h3 id="标记-清除算法（Mark-Sweep）"><a href="#标记-清除算法（Mark-Sweep）" class="headerlink" title="标记-清除算法（Mark-Sweep）"></a>标记-清除算法（Mark-Sweep）</h3><p>首先标记所有需要回收的对象 ，之后统一回收被标记的对象。缺点是相对于复制算法标记和清除效率都不高，而且会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。</p><h3 id="标记-整理算法（Mark-Compact）"><a href="#标记-整理算法（Mark-Compact）" class="headerlink" title="标记-整理算法（Mark-Compact）"></a>标记-整理算法（Mark-Compact）</h3><p>首先标记出所有需要回收的对象，在标记完成后，后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。缺点是效率相对标记-清除会更低一点。</p><h2 id="垃圾回收器"><a href="#垃圾回收器" class="headerlink" title="垃圾回收器"></a>垃圾回收器</h2><h3 id="分代收集"><a href="#分代收集" class="headerlink" title="分代收集"></a>分代收集</h3><p>根据各个年代的特点选取不同的垃圾收集算法：新生代使用复制算法，老年代使用标记-整理或者标记-清除算法。</p><p>在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。</p><p>而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。</p><h3 id="各种垃圾回收器"><a href="#各种垃圾回收器" class="headerlink" title="各种垃圾回收器"></a>各种垃圾回收器</h3><h4 id="Serial-Serial-Old"><a href="#Serial-Serial-Old" class="headerlink" title="Serial/Serial Old"></a>Serial/Serial Old</h4><p>最古老、成熟的单线程（独占式）收集器，适用于单CPU 服务器。</p><p>Serial采用<strong>复制算法</strong>回收区域为新生代，Serial Old使用<strong>标记整理算法</strong>回收区域为老年代。</p><h4 id="ParNew"><a href="#ParNew" class="headerlink" title="ParNew"></a>ParNew</h4><p>和Serial基本没区别，唯一的区别在于ParNew是并行收集器，停顿时间比Serial少。</p><p>并行是指垃圾收集的多线程的同时进行。</p><p>ParNew回收区域为<strong>新生代</strong>，算法为<strong>复制算法</strong>。</p><h4 id="Parallel-Scavenge（ParallerGC）-Parallel-Old"><a href="#Parallel-Scavenge（ParallerGC）-Parallel-Old" class="headerlink" title="Parallel Scavenge（ParallerGC）/Parallel Old"></a>Parallel Scavenge（ParallerGC）/Parallel Old</h4><p>注重于吞吐量的并行收集器，高吞吐量可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台计算为主没有太多交互的任务。</p><p>吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。</p><p>Parallel Scavenge（ParallerGC）采用<strong>复制算法</strong>，回收的区域为新生代、Parallel Old采用<strong>标记整理算法</strong>，回收区域为老年代。</p><h4 id="Concurrent-Mark-Sweep-（CMS）"><a href="#Concurrent-Mark-Sweep-（CMS）" class="headerlink" title="Concurrent Mark Sweep （CMS）"></a>Concurrent Mark Sweep （CMS）</h4><p>以获取最短回收停顿时间为目标的并行与并发收集器。</p><p>并发是指垃圾收集的多线程和应用的多线程同时进行，不支持并发的收集器在回收时会暂停所有用户线程（STW -Stop the world）。</p><p>目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。</p><p>从名字（包含“Mark Sweep”）上就可以看出，CMS收集器是基于<strong>标记清除算法</strong>实现的，但它的运作过程相对于前面几种收集器来说更复杂一些，回收区域为<strong>老年代</strong>。</p><p><strong>收集过程</strong>：</p><ul><li><strong>初始标记：</strong>标记 GC Roots的直接关联到的对象，速度很快，需要暂停所有用户线程（STW -Stop the world）。</li><li><strong>并发标记：</strong>从GC Roots的直接关联的对象开始进行可达性分析，找到存活对象，它在整个回收过程中耗时最长，不需要停顿。</li><li><strong>重新标记：</strong>由于并发标记期间用户线程继续运作而导致部分对象的标记记录产生变动，需要停顿(STW)来修正这部分标记记录。停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。</li><li><strong>并发清除：</strong>不需要停顿。</li></ul><img src="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/pic3.png" srcset="/img/loading.gif" class=""><p>在整个过程中耗时最长的并发标记、并发清除，收集器线程可以与用户线程一起工作，所以总体上说CMS收集器的内存回收过程是与用户线程一起并发执行的。</p><p>由于采用标记 - 清除算法会导致产生不连续的空间碎片</p><p>在并发阶段多线程占据会占据比较多的CPU资源，如果CPU资源不足，效率会明显降低。</p><p>在CMS并发清理之前，标记过程之后用户线程继续运行产生的垃圾，CMS无法在当次收集中处理掉，只好留待下一次GC时再清理掉，这一部分垃圾就称为“浮动垃圾”。</p><p>由于浮动垃圾的存在，需要预留出一部分内存，这就意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。</p><p>在1.6的版本中老年代空间使用率阈值为92%</p><p>如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。</p><h4 id="G1（Garbage-First）垃圾回收器"><a href="#G1（Garbage-First）垃圾回收器" class="headerlink" title="G1（Garbage First）垃圾回收器"></a>G1（Garbage First）垃圾回收器</h4><p>G1（Garbage First）收集器是当今垃圾回收技术最前沿的成果之一。同CMS收集器一样，G1也是关注最小时延的<strong>并行与并发收集器</strong>，也同样适合大尺寸堆内存的垃圾收集，官方也推荐使用G1来代替选择CMS。</p><p>G1最大的特点是引入分区的思路，弱化了分代的概念，合理利用垃圾收集各个周期的资源，解决了其他收集器甚至CMS的众多缺陷。</p><p>G1 把堆划分成多个大小相等的独立区域（Region），每个独立区域会被标记为Eden/Survivor/Old/Humongous（用于存储大对象）中的一个，并使用标记—整理 （humongous） 和复制回收算法(survivor)，避免产生内存碎片。</p><img src="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/pic4.png" srcset="/img/loading.gif" class=""><p>G1可以将可以将停顿（STW）的时间尽可能的控制在设置的时间之内。</p><p>G1收集器之所以能建立可控制的停顿时间模型，是因为它可以避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。</p><h5 id="G1-GC模式"><a href="#G1-GC模式" class="headerlink" title="G1 GC模式"></a>G1 GC模式</h5><h6 id="Young-GC"><a href="#Young-GC" class="headerlink" title="Young GC"></a>Young GC</h6><p>选定所有年轻代里的Region。通过控制年轻代的region个数，即年轻代内存大小，来控制young GC（复制回收算法）的时间开销。</p><h6 id="Mixed-GC"><a href="#Mixed-GC" class="headerlink" title="Mixed GC"></a>Mixed GC</h6><p>选定所有年轻代里的Region，外加根据全局并发标记（global concurrent marking）统计得出收集收益高的若干老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。</p><p>Mixed GC不是full GC，它只能回收部分老年代的Region。如果mixed GC实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行Mixed GC，就会使用serial old GC（full GC）来收集整个GC heap。所以我们可以知道，G1是不提供full GC的。</p><h5 id="全局并发标记（global-concurrent-marking）"><a href="#全局并发标记（global-concurrent-marking）" class="headerlink" title="全局并发标记（global concurrent marking）"></a>全局并发标记（global concurrent marking）</h5><p><strong>初始标记：</strong>仅仅只是标记一下GC Roots 能直接关联到的对象，并且修改TAMS（Nest Top Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可以的Region中创建对象，此阶段需要停顿线程(STW)，但耗时很短。</p><p><strong>并发标记：</strong>对堆中直接关联到GC Roots之外的所有对象进行可达性分析，找到存活对象，此阶段耗时较长，但可与用户程序并发执行。</p><p><strong>最终标记：</strong>为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程(STW)，可并行执行。</p><p><strong>筛选回收：</strong>首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。</p><img src="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/pic5.png" srcset="/img/loading.gif" class=""><h5 id="G1-GC主要的参数"><a href="#G1-GC主要的参数" class="headerlink" title="G1 GC主要的参数"></a>G1 GC主要的参数</h5><table><thead><tr><th><strong>参数</strong></th><th><strong>含义</strong></th></tr></thead><tbody><tr><td>-XX:G1HeapRegionSize=n</td><td>设置Region大小，并非最终值</td></tr><tr><td>-XX:MaxGCPauseMillis</td><td>设置G1收集过程目标时间，默认值200ms，不是硬性条件</td></tr><tr><td>-XX:G1NewSizePercent</td><td>新生代最小值，默认值5%</td></tr><tr><td>-XX:G1MaxNewSizePercent</td><td>新生代最大值，默认值60%</td></tr><tr><td>-XX:ParallelGCThreads</td><td>STW期间，并行GC线程数</td></tr><tr><td>-XX:ConcGCThreads=n</td><td>并发标记阶段，并行执行的线程数</td></tr><tr><td>-XX:InitiatingHeapOccupancyPercent</td><td>设置触发标记周期的 Java 堆占用率阈值。默认值是45%。这里的java堆占比指的是non_young_capacity_bytes，包括old+humongous</td></tr></tbody></table><h4 id="新一代垃圾回收器-ZGC"><a href="#新一代垃圾回收器-ZGC" class="headerlink" title="新一代垃圾回收器-ZGC"></a>新一代垃圾回收器-ZGC</h4><p>Java 11推出了一个全新的垃圾收集器ZGC，它是由Oracle开发的，为实现以下几个目标而诞生的垃圾回收器：</p><ul><li>停顿时间不超过10ms</li><li>停顿时间不会因堆变大而变长</li><li>堆大小范围可支持几G到几T</li></ul><p>为了实现其目标（暂停时间和性能影响），ZGC使用了两种新的热点垃圾收集器技术：指针着色和负载屏障。</p><h5 id="指针着色"><a href="#指针着色" class="headerlink" title="指针着色"></a>指针着色</h5><p>指针表示虚拟内存中字节的位置。 但是，我们不一定要使用指针的所有位来执行此操作 - 某些位可以表示指针的属性。 这就是我们所说的指针着色。</p><p>使用32位，我们可以处理4GB字节（2的32次方）。 由于现在配置的内存已经远远超过了这个数量，我们显然不能使用32位。 因此，ZGC使用64位指针， 这意味着ZGC仅适用于64位平台：</p><img src="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/pic1.png" srcset="/img/loading.gif" class=""><p>ZGC指针使用42位来表示地址本身。 因此，ZGC指针可以处理4TB的内存空间（2的42次方）。</p><p>最重要的是，我们有4位来存储指针状态：</p><ul><li>finalizable bit：该对象只能通过终结器来访问</li><li>重映射位：参考指向对象的当前地址（下面的重定位）</li><li>marked0和marked1位：这些用于标记可到达的对象，我们还将这些位称为元数据位。</li></ul><h5 id="多重映射"><a href="#多重映射" class="headerlink" title="多重映射"></a>多重映射</h5><p>多重映射意味着我们将多个虚拟内存范围映射到物理内存。 在ZGC中，这些范围仅在前面提到的元数据位中不同。</p><p>指针着色使解除引用开销更加昂贵，因为我们必须屏蔽有用的位来访问地址本身。 但是，ZGC绕过这个成本，因为四个元数据位中只有一个是1。这样我们只有四个范围要映射，映射由操作系统处理。 此外，我们只使用其中三个范围，因为我们从不想取消引用可终结指针：</p><h5 id="负载屏障"><a href="#负载屏障" class="headerlink" title="负载屏障"></a>负载屏障</h5><p>负载屏障是一个代码片段，它在线程从堆加载引用时运行，例如，当我们访问对象的非基本字段时。</p><img src="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/pic2.png" srcset="/img/loading.gif" class=""><p>在上面的代码中，第一行（String name = person.name;）这行会对堆中对象数据的Person引用之后，然后加载对其所包含名称的引用，这时会触发负载屏障。</p><p>第二行触发打印到屏幕，不会直接导致负载屏障触发，因为引用名称(name)是局部变量，因此没有从堆加载引用。</p><p>在ZGC中，负载障碍检查引用的元数据位。 根据这些位，ZGC可能会在我们获得它之前对引用执行一些处理。 因此，它可能产生完全不同的引用。</p><h5 id="标记"><a href="#标记" class="headerlink" title="标记"></a>标记</h5><p>标记是垃圾收集器确定我们可以到达哪些对象的过程。 我们无法达到的被认为是垃圾。 ZGC将标记分为三个阶段：</p><ul><li><p>第一阶段是Stop The World阶段。 在这个阶段，我们寻找根引用并标记它们。 根引用是到达堆中对象的起点，例如，局部变量或静态字段。 由于根引用的数量通常较小，因此该阶段很短。</p></li><li><p>下一阶段是并发阶段。 在这个阶段，我们从根引用开始遍历对象图。 我们标记我们到达的每个对象。 此外，当负载屏障检测到未标记的引用时，也会进行标记。</p></li><li><p>最后阶段也是Stop The World阶段，用来处理一些边缘情况，比如弱引用。</p></li></ul><p>这几个阶段完成后，我们就知道哪些对象可达，哪些对象不可达。</p><p>ZGC使用marked0和marked1元数据位进行标记。</p><h5 id="重定位"><a href="#重定位" class="headerlink" title="重定位"></a>重定位</h5><p>当我们必须为新对象分配内存时，我们可以遵循两种策略。</p><p>首先，我们可以扫描内存中的可用空间，直到有空间间足以容纳我们的对象。但是扫描内存是一项昂贵的操作，此外，内存将变得碎片化。如果我们想要减小碎片化，让内存变得更紧凑，将消耗更多的CPU处理能力。</p><p>另一种策略是频繁地将碎片存储区域中的对象以更紧凑的格式重定位到空闲区域。为了更有效，我们将内存空间分成块。我们要么将所有对象重新定位到一个块中的或者一个块不存在一个对象。这样，内存分配会更快，因为我们知道内存中有整个空块。</p><p>在ZGC，重定位也包括三个阶段。</p><ul><li>并发阶段查找我们要重定位的块并将它们放入重定位集中。</li><li>Stop The World阶段将重定位集中的所有根引用进行重定位并更新其引用。</li><li>并发阶段将重定位集中的所有剩余对象进行重定位，并在转发表中存储旧地址和新地址之间的映射。</li></ul><h5 id="重新映射"><a href="#重新映射" class="headerlink" title="重新映射"></a>重新映射</h5><p>请注意，在重定位阶段，我们没有重写对重定位对象的所有引用。 因此，使用这些引用，我们将无法访问我们想要的对象。 更糟糕的是，我们会访问到垃圾对象。</p><p>ZGC使用负载屏障来解决这个问题。 负载屏障使用称为重新映射的技术来修复指向重定位对象的引用。</p><h5 id="如何启用ZGC？"><a href="#如何启用ZGC？" class="headerlink" title="如何启用ZGC？"></a>如何启用ZGC？</h5><p>运行我们的应用程序时，我们可以使用以下命令行选项启用ZGC：</p><p>-XX：+ UnlockExperimentalVMOptions -XX：+ UseZGC 请注意，目前ZGC是一个实验性GC，在生产平台上使用，还需要再考察。</p><h3 id="垃圾回收器之间的对应关系"><a href="#垃圾回收器之间的对应关系" class="headerlink" title="垃圾回收器之间的对应关系"></a>垃圾回收器之间的对应关系</h3><img src="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/pic2.png" srcset="/img/loading.gif" class=""><h3 id="垃圾回收器的重要参数"><a href="#垃圾回收器的重要参数" class="headerlink" title="垃圾回收器的重要参数"></a>垃圾回收器的重要参数</h3><table><thead><tr><th><strong>参数</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>-XX:UseSerialGC</td><td>虚拟机运行在Client模式下的默认值，打开此开关后，使用 Serial+Serial Old 的收集器组合进行内存回收</td></tr><tr><td>-XX:UseParNewGC</td><td>打开此开关后，使用 ParNew + Serial Old 的收集器组合进行内存回收</td></tr><tr><td>-XX:UseConcMarkSweepGC</td><td>打开此开关后，使用 ParNew + CMS + Serial Old 的收集器组合进行内存回收。Serial Old 收集器将作为 CMS 收集器出现 Concurrent Mode Failure 失败后的后备收集器使用</td></tr><tr><td>-XX:UseParallelGC</td><td>虚拟机运行在 Server 模式下的默认值，打开此开关后，使用 Parallel Scavenge + Serial Old(PS MarkSweep) 的收集器组合进行内存回收</td></tr><tr><td>-XX:UseParallelOldGC</td><td>打开此开关后，使用 Parallel Scavenge + Parallel Old 的收集器组合进行内存回收</td></tr><tr><td>-XX:SurvivorRatio</td><td>新生代中 Eden 区域与 Survivor 区域的容量比值，默认为8，代表 Eden : Survivor = 8 : 1</td></tr><tr><td>-XX:PretenureSizeThreshold</td><td>直接晋升到老年代的对象大小，设置这个参数后，大于这个参数的对象将直接在老年代分配</td></tr><tr><td>-XX:MaxTenuringThreshold</td><td>晋升到老年代的对象年龄，每个对象在坚持过一次 Minor GC 之后，年龄就增加1，当超过这个参数值时就进入老年代</td></tr><tr><td>-XX:UseAdaptiveSizePolicy</td><td>动态调整 Java 堆中各个区域的大小以及进入老年代的年龄</td></tr><tr><td>-XX:HandlePromotionFailure</td><td>是否允许分配担保失败，即老年代的剩余空间不足以应付新生代的整个 Eden 和 Survivor 区的所有对象都存活的极端情况</td></tr><tr><td>-XX:ParallelGCThreads</td><td>设置并行GC时进行内存回收的线程数</td></tr><tr><td>-XX:GCTimeRatio</td><td>GC 时间占总时间的比率，默认值为99，即允许 1% 的GC时间，仅在使用 Parallel Scavenge 收集器生效</td></tr><tr><td>-XX:MaxGCPauseMillis</td><td>设置 GC 的最大停顿时间，仅在使用 Parallel Scavenge 收集器时生效</td></tr><tr><td>-XX:CMSInitiatingOccupancyFraction</td><td>设置 CMS 收集器在老年代空间被使用多少后触发垃圾收集，默认值为 68%，仅在使用 CMS 收集器时生效</td></tr><tr><td>-XX:UseCMSCompactAtFullCollection</td><td>设置 CMS 收集器在完成垃圾收集后是否要进行一次内存碎片整理，仅在使用 CMS 收集器时生效</td></tr><tr><td>-XX:CMSFullGCsBeforeCompaction</td><td>设置 CMS 收集器在进行若干次垃圾收集后再启动一次内存碎片整理，仅在使用 CMS 收集器时生效</td></tr></tbody></table><p>使用jps -v可以查看当前虚拟机参数</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>JVM</tag>
      
      <tag>Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JVM中的对象</title>
    <link href="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"/>
    <url>/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/</url>
    
    <content type="html"><![CDATA[<h2 id="对象的分配"><a href="#对象的分配" class="headerlink" title="对象的分配"></a>对象的分配</h2><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic1.png" srcset="/img/loading.gif" class=""><h3 id="检查加载"><a href="#检查加载" class="headerlink" title="检查加载"></a>检查加载</h3><p>先检查对应的类是否已经加载。如果没有，则进行类加载</p><h3 id="分配内存"><a href="#分配内存" class="headerlink" title="分配内存"></a>分配内存</h3><p>虚拟机将为新生对象分配内存。为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来，内存的大小由方法区的信息确定</p><h4 id="内存的分配方式"><a href="#内存的分配方式" class="headerlink" title="内存的分配方式"></a>内存的分配方式</h4><ul><li><p><strong>指针碰撞</strong>：如果Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“<strong>指针碰撞</strong>”。    </p></li><li><p><strong>空闲列表</strong>：如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“<strong>空闲列表</strong>”。</p></li></ul><p>选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。</p><h4 id="并发安全"><a href="#并发安全" class="headerlink" title="并发安全"></a>并发安全</h4><p>对象创建在虚拟机中是非常频繁的行为，修改指针的指向位置可能存在线程安全问题。可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。</p><p>解决这个问题有两种方案一种是使用<strong>CAS机制</strong>及失败重试的方法保证分配内存空间的动作的线程安全。另一种是使用<strong>分配缓冲（Thread Local Allocation Buffer,TLAB）</strong>，即为每个线程在Java堆中预先分配一块大小约为Eden1%的私有内存，让线程在为新对象分配内存空间时使用自己专属的分配指针来分配空间，减少同步开销。</p><p>TLAB只是让每个线程有私有的分配指针，对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。当一个TLAB用满（分配指针top撞上分配极限end了），就需要重新从Eden区域申请。</p><h3 id="内存空间初始化"><a href="#内存空间初始化" class="headerlink" title="内存空间初始化"></a>内存空间初始化</h3><p>内存分配完成后，虚拟机需要将分配到的内存空间初始化为零值，这一步操作保证了对象的实例字段不赋初始值也可以访问对应的零值(如int值为0，boolean值为false，对象类型为null等)。</p><h3 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h3><p>接下来，虚拟机要对对象头的信息进行必要的设置，例如这个对象的hashcode、GC分代年龄、锁标志状态、线程持有的锁、偏向线程ID、偏向时间戳、对应的类的实例、类的元数据信息等。</p><h3 id="对象初始化"><a href="#对象初始化" class="headerlink" title="对象初始化"></a>对象初始化</h3><p>在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从程序的角度来看，对象创建才刚刚开始，所有的字段都还为零值。</p><h4 id="对象的内存布局"><a href="#对象的内存布局" class="headerlink" title="对象的内存布局"></a>对象的内存布局</h4><p>在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。</p><p>对象头包括两部分信息</p><ul><li><p>一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。</p></li><li><p>另外一部分是类型指针，即指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。</p></li></ul><p>实例数据就是指实际的数据，如int类型为1，String类型为字符串等</p><p>对齐填充这部分信息不一定存在，也没有特别的含义，仅仅起着占位符的作用。由于HotSpot VM的内存管理系统要求对对象的大小必须是8字节的整数倍，而对象正好是9字节的整数，所以当对象其他数据部分（对象实例数据）没有对齐时，就需要通过对齐填充来补全。</p><h2 id="对象的访问方式"><a href="#对象的访问方式" class="headerlink" title="对象的访问方式"></a>对象的访问方式</h2><p>建立对象是为了使用对象，我们的Java程序需要通过栈上的引用（reference）数据来操作堆上的具体对象。目前主流的访问方式有使用句柄和直接指针两种。</p><h3 id="句柄"><a href="#句柄" class="headerlink" title="句柄"></a>句柄</h3><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic2.png" srcset="/img/loading.gif" class=""><p>句柄是一种特殊的智能指针 。句柄与普通指针的区别在于，指针包含的是引用对象的内存地址，而句柄则是由系统所管理的引用标识，该标识可以被系统重新定位到一个内存地址上。</p><p>如果使用句柄访问的话，那么Java堆中将会划分出一块内存来作为句柄池，引用（reference）中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。</p><p>使用句柄来访问的最大好处就是引用（reference）中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而引用（reference）本身不需要修改。</p><h3 id="直接指针"><a href="#直接指针" class="headerlink" title="直接指针"></a>直接指针</h3><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic3.png" srcset="/img/loading.gif" class=""><p>如果使用直接指针访问， 引用（reference）中存储的直接就是对象地址。</p><p>使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。</p><p>HotSpot是使用直接指针访问方式进行对象访问的。</p><h2 id="堆内存分配策略"><a href="#堆内存分配策略" class="headerlink" title="堆内存分配策略"></a>堆内存分配策略</h2><h3 id="堆内存的划分"><a href="#堆内存的划分" class="headerlink" title="堆内存的划分"></a>堆内存的划分</h3><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic4.png" srcset="/img/loading.gif" class=""><p>在 Java 中，堆被划分成两个不同的区域：<strong>新生代 ( Young )</strong>、<strong>老年代 ( Old )</strong>。新生代 ( Young ) 又被划分为三个区域：<strong>Eden</strong>、<strong>From Survivor</strong>、<strong>To Survivor</strong>。 </p><p>参数设置</p><ul><li><p>-Xmn20m 表示新生代大小为20m（初始容量和最大容量）</p></li><li><p>-XX:SurvivorRatio=8 表示Eden和Survivor的比值，缺省为8 表示 Eden:From:To= 8:1:1，如果设置为2则表示 Eden:From:To= 2:1:1</p></li><li><p>-XX:PretenureSizeThreshold=4m 表示如果对象大小超过该数值将进入老年代</p></li><li><p>-XX:+PrintGCDetails 表示打印GC详细信息</p></li><li><p>-XX:+UseSerialGC</p></li><li><p>-XX:TargetSurvivorRatio=50% 设定survivor区的目标使用率，默认为50%（分配策略中会有详细解释）</p></li><li><p>-XX:MaxTenuringThreshold=15 晋升年龄最大阈值，默认15</p></li></ul><h3 id="分配策略"><a href="#分配策略" class="headerlink" title="分配策略"></a>分配策略</h3><ul><li><p><strong>对象优先在Eden分配</strong></p><p>大多数情况下，对象在新生代Eden区中分配。当Eden区没有足够空间分配时，虚拟机将发起一次Minor GC。</p></li><li><p><strong>大对象直接进入老年代</strong></p><p>如果对象的大小超过<strong>PretenureSizeThreshold</strong>的数值将直接进入老年代。</p></li><li><p><strong>长期存活的对象将进入老年代</strong></p><p>Minor GC进行回收后，新生代中所有区域存活对象的年龄会加1，Eden区域中存活的对象将进入Survivor(from)区或Survivor(to)区，Survivor(from)区的存活对象会进入Survivor(to)区，Survivor(to)区存活的对象会进入Survivor(from)区，当多次回收、对象的年龄达到<strong>MaxTenuringThreshold</strong>之后就会进入老年代。Survivor(to)区，Survivor(to)区的对象会频繁交换，这也是Survivor(from)区、Survivor(to)区使用复制回收算法的原因。</p></li><li><p><strong>动态对象年龄判定</strong></p><p>Survivor将区域的年龄从小到大进行累加，当加入某个年龄段后，累加和超过survivor区域<strong>*TargetSurvivorRatio</strong>的时候，就从这个年龄段往上的年龄的对象进入到老年代。</p></li><li><p><strong>空间分配担保</strong></p><p>在发生minor gc之前，虚拟机会检测老年代的连续空间是否大于新生代对象总大小，如果满足就会进行minor gc，如果不满足虚拟机查看HandlePromotionFailure参数是否允许担保失败，如果允许担保失败，会继续检测老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小。若大于，将尝试进行一次minor gc，如果minor gc失败，则重新进行一次full gc，若小于或者不允许担保，那这时也要改为进行一次Full GC。</p><p>JDK 6 Update 24之后HandlePromotionFailure参数不会再影响到虚拟机的空间分配担保策略，虽然源码中还定义了HandlePromotionFailure参数，但是在代码中已经不会再使用它。规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小就会进行Minor GC，否则将进行Full GC。</p></li></ul><h2 id="Java中的泛型"><a href="#Java中的泛型" class="headerlink" title="Java中的泛型"></a>Java中的泛型</h2><h3 id="泛型是什么"><a href="#泛型是什么" class="headerlink" title="泛型是什么"></a>泛型是什么</h3><p>泛型，即“参数化类型”。将所需类型由具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。</p><p>泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。</p><h4 id="泛型类"><a href="#泛型类" class="headerlink" title="泛型类"></a>泛型类</h4><p>引入一个类型变量T（其他大写字母都可以，不过常用的就是T，E，K，V等等），并且用&lt;&gt;括起来，并放在类名的后面。泛型类是允许有多个类型变量的。</p><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic5.png" srcset="/img/loading.gif" class=""><h4 id="泛型接口"><a href="#泛型接口" class="headerlink" title="泛型接口"></a>泛型接口</h4><p>泛型接口与泛型类的定义基本相同。</p><h4 id="泛型方法"><a href="#泛型方法" class="headerlink" title="泛型方法"></a>泛型方法</h4><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic7.png" srcset="/img/loading.gif" class=""><p>泛型方法，是在调用方法的时候指明泛型的具体类型 ，泛型方法可以在任何地方和任何场景中使用，包括普通类和泛型类。</p><h4 id="为什么我们需要泛型？"><a href="#为什么我们需要泛型？" class="headerlink" title="为什么我们需要泛型？"></a>为什么我们需要泛型？</h4><p>实际开发中，经常有数值类型求和的需求，例如实现int类型、long类型、double类型的求和，重新在重载三次add方法。所以范型的好处是：</p><ul><li>适用于多种数据类型执行相同的代码</li><li>泛型中的类型在使用时指定，不需要强制类型转换</li></ul><h4 id="虚拟机是如何实现泛型的？"><a href="#虚拟机是如何实现泛型的？" class="headerlink" title="虚拟机是如何实现泛型的？"></a>虚拟机是如何实现泛型的？</h4><p>泛型只在程序源码中存在，在编译后的字节码文件中，就已经替换为原来的类型了，并且在相应的地方插入了强制转型代码，因此，对于运行期的Java语言来说，ArrayList＜int＞与ArrayList＜String＞就是同一个类，所以泛型技术实际上是Java语言的一颗语法糖。</p><p>Java语言中的泛型实现方法称为类型擦除，基于这种方法实现的泛型称为伪泛型。</p><p>将一段Java代码编译成Class文件，然后再用字节码反编译工具进行反编译后，将会发现泛型都不见了，程序又变回了Java泛型出现之前的写法，泛型类型都变回了原生类型（因为）</p><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic8.png" srcset="/img/loading.gif" class=""><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic9.png" srcset="/img/loading.gif" class=""><h4 id="使用泛型注意事项"><a href="#使用泛型注意事项" class="headerlink" title="使用泛型注意事项"></a>使用泛型注意事项</h4><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic10.png" srcset="/img/loading.gif" class=""><p>上面这段代码是不能被编译的，因为参数List＜Integer＞和List＜String＞编译之后都被擦除了，变成了一样的原生类型List＜E＞，导致这两种方法的特征签名变得一模一样（在IDEA中不能通过，但是jdk的编译器是可以，因为jdk是根据方法返回值+方法名+参数）。</p><p>JVM版本兼容性问题：JDK1.5以前，为了确保泛型的兼容性，JVM除了擦除其实还是保留了泛型信息（Signature是其中最重要的一项属性，它的作用就是存储一个方法在字节码层面的特征签名，这个属性中保存的参数类型并不是原生类型，而是包括了参数化类型的信息）-弱记忆。</p><p>另外，从Signature属性的出现我们还可以得出结论，擦除仅仅是对方法的Code属性中的字节码进行擦除，实际上元数据中还是保留了泛型信息，这也是我们能通过反射手段取得参数化类型的根本依据。</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>JVM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入理解JVM内存区域</title>
    <link href="/2020/03/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/"/>
    <url>/2020/03/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="Java-SE体系架构"><a href="#Java-SE体系架构" class="headerlink" title="Java SE体系架构"></a>Java SE体系架构</h2><p>JavaSE，Java平台标准版，为Java EE和Java ME提供了基础。</p><p>JDK：Java开发工具包，JDK是JRE的超集，包含JRE中的所有内容，以及开发程序所需的编译器和调试程序等工具。</p><p>JRE：Java SE运行时环境 ，提供库、Java虚拟机和其他组件来运行用Java编程语言编写的程序。主要类库，包括：程序部署发布、用户界面工具类、继承库、其他基础库，语言和工具基础库</p><p>JVM：java虚拟机，负责JavaSE平台的硬件和操作系统无关性、编译执行代码（字节码）和平台安全性</p><img src="/2020/03/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/pic1.png" srcset="/img/loading.gif" class=""><h2 id="虚拟机的历史"><a href="#虚拟机的历史" class="headerlink" title="虚拟机的历史"></a>虚拟机的历史</h2><p>虚拟机的区别主要在于字节码的执行的方式，目前主要的执行方式有解释执行和编译执行（针对字节码的执行），解释执行就是边翻译为机器码边执行，编译执行（即时编译）就是先将一个方法中的所有字节码全部编译成机器码之后再执行。</p><h3 id="HotSpot-VM-SUN"><a href="#HotSpot-VM-SUN" class="headerlink" title="HotSpot VM(SUN)"></a>HotSpot VM(SUN)</h3><p>以前使用最广的Java虚拟机，采用的是先解释执行，到了一定时机后热点代码（多次执行、循环等）再翻译成机器码，具有热点代码探测技术（通过执行计数器找到最有编译价值的代码，如果代码用得非常频繁，就会把这些代码编译成本地代码）。</p><h3 id="JRcokit-VM-BEA"><a href="#JRcokit-VM-BEA" class="headerlink" title="JRcokit VM(BEA)"></a>JRcokit VM(BEA)</h3><p>号称“世界上最快的Java虚拟机 ”，JRockit采取的方法是在执行class时直接编译为机器码（Java程序启动速度会比较慢）。</p><h3 id="J9-VM-IBM"><a href="#J9-VM-IBM" class="headerlink" title="J9 VM(IBM)"></a>J9 VM(IBM)</h3><p>J9和Hotspot比较接近，主要是用在IBM产品（IBM WebSphere和IBM的AIX平台上），华为有的项目用的J9。</p><h3 id="Dalvik-VM-Google"><a href="#Dalvik-VM-Google" class="headerlink" title="Dalvik VM(Google)"></a>Dalvik VM(Google)</h3><p>Google Android Dalivk VM：谷歌移动端的虚拟机，使用的寄存器架构，执行dex（Dalvik Executable）通过class转化而来。</p><h3 id="HotSpot-VM-ORACLE"><a href="#HotSpot-VM-ORACLE" class="headerlink" title="HotSpot VM(ORACLE)"></a>HotSpot VM(ORACLE)</h3><p>目前使用范围最广的Java虚拟机，由ORACLE公司收购HotSpot VM(SUN)和JRcokit VM(BEA)之后合并而来。</p><h2 id="未来的Java发展"><a href="#未来的Java发展" class="headerlink" title="未来的Java发展"></a>未来的Java发展</h2><p><strong>模块化：</strong>OSGI（动态化、模块化），应用层面就是微服务，互联网的发展方向</p><p><strong>混合语言</strong>：多个语言都可以运行在JVM中，google的Kotlin 成为了 Android 的官方语言。Scala(Kafka)</p><p><strong>多核并行</strong>：CPU从高频次转变为多核心，多核时代。JDK1.7引入了Fork/Join，JDK1.8提出lambda表达式(函数式编程天生适合并行运行)</p><p><strong>丰富语法：</strong>JDK5提出自动装箱、泛型(并发编程讲到)、动态注解等语法。JDK7二进制原生支持。try-catch-finally 至try-with-resource</p><p><strong>64位：</strong>虽然同样的程序64位内存消耗比32位要多一点，但是支持内存大，所以虚拟机都会完全过渡到64位，32位的JVM有4G的堆大小限制。</p><p><strong>更强的垃圾回收器（现在主流CMS、G1）</strong>：JDK11 –ZGC（暂停时间不超过10毫秒，且不会随着堆的增加而增加，TB级别的堆回收））：有色指针、加载屏障。JDK12支持并发类卸载，进一步缩短暂停时间 JDK13(计划于2019年9月)将最大堆大小从4TB增加到16TB</p><h2 id="JVM的整体介绍"><a href="#JVM的整体介绍" class="headerlink" title="JVM的整体介绍"></a>JVM的整体介绍</h2><img src="/2020/03/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/pic2.png" srcset="/img/loading.gif" class=""><p>JDK将代码编译为class文件后经过类加载存储在JVM的运行时数据区（内存），执行时会由执行引擎使用c++语言去执行对应的机器码。</p><h3 id="运行时数据区域"><a href="#运行时数据区域" class="headerlink" title="运行时数据区域"></a>运行时数据区域</h3><p>JVM在运行过程中会把它管理的内存划分成不同的数据区域。</p><img src="/2020/03/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/pic3.png" srcset="/img/loading.gif" class=""><p>线程私有：程序计数器，虚拟机栈，本地方法栈，这部分区域会随着线程产生和消亡，不用担心内存回收问题</p><p>线程共享：堆、方法区</p><p>计算机的运行由指令和数据组成，线程私有的区域主要与指令的执行有关，线程共享区域通常用来存储共享数据。</p><h4 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h4><p>程序计数器是一个较小的内存空间，指向当前线程正在执行的字节码指令的地址。</p><p>由于java是多线程的存在线程切换的情况、当前线程在执行过程中可能会被挂起，所以JVM需要通过程序计数器记录当前线程的执行情况。</p><h4 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h4><p>以栈帧的方式存储<strong>当前线程</strong>运行方法所需的数据指令和返回地址，以及方法调用过程中变量，大小缺省为1M，可用参数 –Xss调整大小，例如-Xss256k。java.lang.StackOverflowError 一般的方法调用是很难出现的，如果出现了要考虑是否有无限递归。</p><p>每个方法在执行的同时都会创建一个<strong>栈帧</strong>并将其入栈，当前线程正在执行的方法就是其虚拟机栈顶的栈桢。</p><p>栈帧中主要包括：</p><ul><li><p><strong>局部变量表：</strong>用于存储方法中的变量（方法入参等）。如果是Java的八大基础数据类型可以直接存储，如果是对象则存放它的引用地址。大小在代码编译时就已经写入到方法表的Code属性，之后不会改变，仅仅取决于具体虚拟机的实现。</p></li><li><p><strong>操作数据栈</strong>：用于执行方法中对数据的操作，操作的的数据可以是任意的java数据类型。</p></li><li><p><strong>动态连接：</strong>提供符号引用和直接引用在运行时进行解析和链接。</p></li><li><p><strong>返回地址：</strong>记录方法执行完成后返回的位置。</p></li></ul><p>使用javap -v JavaStack.class &gt; a.txt之后可以得到字节码文件反编译后的汇编代码，通过汇编代码我们可以深入的了解java代码的工作机制。</p><p>例如将</p><pre><code>public void sub(int num){    num = num - 100;}</code></pre><p>反编译后</p><pre><code>public void sub(int);    descriptor: (I)V    flags: ACC_PUBLIC    Code:      stack=2, locals=2, args_size=2         0: iload_1    // 冒号前的数字表示字节码指令的地址行号，iload_1:下标为1的局部变量表入栈         1: bipush        100    // 将一个byte类型的常量入栈         3: isub    // 将栈顶的两个int的数据出栈、相减，结果入栈         4: istore_1  // 栈顶的int类型存入局部变量表1的位置         5: return      LineNumberTable:        line 9: 0        line 10: 5      LocalVariableTable:    //        Start  Length  Slot  Name   Signature            0       6     0  this   Lcom/jvm/ch01/JavaStack1;            0       6     1   num   I</code></pre><h4 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h4><p>本地方法栈保存的是native方法的信息，当一个JVM创建的线程调用native方法后，JVM不再为其在虚拟机栈中创建栈帧，JVM只是简单地动态链接并直接调用native方法。</p><p>虚拟机规范无强制规定，各版本虚拟机自由实现HotSpot直接把本地方法栈和虚拟机栈合二为一</p><h4 id="方法区（永久代（JDK1-7及以前）、元空间（JDK1-8））"><a href="#方法区（永久代（JDK1-7及以前）、元空间（JDK1-8））" class="headerlink" title="方法区（永久代（JDK1.7及以前）、元空间（JDK1.8））"></a>方法区（永久代（JDK1.7及以前）、元空间（JDK1.8））</h4><p>用于存储：</p><ul><li>类信息：包括类名、修饰符、变量名、方法名、方法代码、返回值、直接接口的有序列表</li><li>常量</li><li>静态变量</li><li>即时编译期编译后的代码</li></ul><h4 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h4><p>堆内存用来存储Java中的对象。无论是成员变量，局部变量，还是类变量，它们指向的对象都存储在堆内存中，堆是需要重点关注的一块区域，因为涉及到内存的分配(new关键字，反射等)与回收(回收算法，收集器等)，</p><p>几乎所有的对象都是在堆中分配，可用以下参数调整：</p><p>-Xms：堆的最小值；</p><p>-Xmx：堆的最大值；</p><p>-Xmn：新生代的大小；</p><p>-XX:NewSize；新生代最小值；</p><p>-XX:MaxNewSize：新生代最大值；</p><p>例如- Xmx256m</p><h4 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h4><p>Class 文件中的常量池（编译器生成的各种字面量和符号引用）会在类加载后被放入这个区域。</p><p>符号引用：通常是字符串，能根据这个字符串定位到指定的数据，比如java/lang/StringBuilder，用于存储：</p><ul><li>类和接口的全限定名</li><li>字段名称和描述符</li><li>方法名称和描述符</li></ul><p>字面量：在代码中直接出现的值，如：</p><ul><li>String a = “A”;</li><li>int b= 1;</li></ul><p>其中 “A”与1都是字面量</p><p>JDK1.6中运行时常量池存储在方法区</p><p>JDK1.7中运行时常量池存储在堆</p><p>JDK1.8中使用元空间替代永久代</p><p>永久代设置参数    -XX:PermSize；-XX:MaxPermSize =100M</p><p>元空间设置参数    -XX:MetaspaceSize； -XX:MaxMetaspaceSize</p><p>永久代的空间受制于MaxPermSize的大小，如果超过这个值就会OOM，所以永久代在存储类信息、常量、静态变量等数据，可能会遇到内存溢出的问题，而且对永久代进行调优是很困难的。</p><p>元空间的大小不会受制于堆内存的大小，而只受制于物理机的最大内存，因此如果元空间的占据了过多的物理机内存，就会挤压堆空间的大小。</p><h4 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h4><p>并不是JVM运行时数据区域的一部分，使用Native函数库直接分配堆外内存（NIO），如果使用了NIO会被频繁使用(可以通过-XX:MaxDirectMemorySize来设置（默认与堆内存最大值一样,也会出现OOM异常)。避免了在Java 堆和Native 堆中来回复制数据，能够提高效率。</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>JVM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>总复习和常见的并发面试题</title>
    <link href="/2020/03/04/%E6%80%BB%E5%A4%8D%E4%B9%A0%E5%92%8C%E5%B8%B8%E8%A7%81%E7%9A%84%E5%B9%B6%E5%8F%91%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <url>/2020/03/04/%E6%80%BB%E5%A4%8D%E4%B9%A0%E5%92%8C%E5%B8%B8%E8%A7%81%E7%9A%84%E5%B9%B6%E5%8F%91%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h2 id="总复习和常见并发面试题"><a href="#总复习和常见并发面试题" class="headerlink" title="总复习和常见并发面试题"></a>总复习和常见并发面试题</h2><h3 id="谈面试"><a href="#谈面试" class="headerlink" title="谈面试"></a>谈面试</h3><ol><li><p>面试主要分为两块：一块是考查工程师对基础知识（包括了技术广度、深度、对技术的热情度等）的掌握程度，因为<strong>基础知识决定了一个技术人员发展的上限</strong>；另一块是考察工程师的工程能力，比如：做过哪些项目？遇到最难的问题怎样解决的？说说最有成就感的一项任务？<strong>工程能力是考察工程师当下能为公司带来的利益</strong>。当然还有其它考核方面：抗压性、合作能力。</p></li><li><p>Java只是一门语言，即使是Java工程师也不能局限于Java，要从面向对象语言本身，甚至从整个计算机体系，从工程实际出发看Java。</p></li><li><p>很多知识在一般公司的开发中是用不到的，常有人戏称：“面试造火箭，工作拧螺丝”，但这只是通常情况下公司对程序员的标准——迅速产出，完成任务。所以，工程师为了自己职业的发展不能局限于公司对自己的要求，不能停留在应用层面，要能够很好地掌握基础知识，要多看源码，自己多实践，学成记得产出，比如多为开源社区贡献代码，帮助初学者指路等。</p></li></ol><h3 id="常见面试题"><a href="#常见面试题" class="headerlink" title="常见面试题"></a>常见面试题</h3><ul><li><p>在java中守护线程和用户线程的区别？</p><p>java中的线程分为两种：守护线程（Daemon）和用户线程（User）。</p><p>任何线程都可以设置为守护线程和用户线程，通过方法Thread.setDaemon(bool on)；true则把该线程设置为守护线程，反之则为用户线程。Thread.setDaemon()必须在Thread.start()之前调用，否则运行时会抛出异常。</p><p>两者的区别： </p><p>唯一的区别是判断虚拟机(JVM)何时离开，Daemon是为其他线程提供服务，如果全部的User Thread已经结束，Daemon 没有可服务的线程，JVM关闭。</p><p>扩展：Thread Dump打印出来的线程信息，含有daemon字样的线程即为守护进程</p></li><li><p>线程与进程的区别</p><p>进程是操作系统分配资源的最小单元，线程是操作系统调度的最小单元。</p><p>一个程序至少有一个进程,一个进程至少有一个线程。</p></li><li><p>什么是多线程中的上下文切换</p><p>多线程会共同使用一组计算机上的CPU，而线程数大于给程序分配的CPU数量时，为了让各个线程都有执行的机会，就需要轮转使用CPU。不同的线程切换使用CPU发生的切换数据等就是上下文切换。</p></li><li><p>死锁与活锁的区别，死锁与饥饿的区别？</p><p>死锁：是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。 </p><p>产生死锁的必要条件： </p><p>互斥条件：所谓互斥就是进程在某一时间内独占资源。</p><p>请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 </p><p>不剥夺条件:进程已获得资源，在末使用完之前，不能强行剥夺。 </p><p>循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。</p><p>活锁：任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。</p><p>活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，所谓的“活”， 而处于死锁的实体表现为等待；活锁有可能自行解开，死锁则不能。</p><p>饥饿：一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行的状态。</p></li><li><p>synchronized底层实现原理</p><p>synchronized (this)原理：涉及两条指令：monitorenter，monitorexit；再说同步方法，从同步方法反编译的结果来看，方法的同步并没有通过指令monitorenter和monitorexit来实现，相对于普通方法，其常量池中多了ACC_SYNCHRONIZED标示符。</p><p>JVM就是根据该标示符来实现方法的同步的：当方法被调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。</p><p>注意，这个问题可能会接着追问，java对象头信息，偏向锁，轻量锁，重量级锁及其他们相互间转化。</p></li><li><p>什么是线程组，为什么在Java中不推荐使用？</p><p>ThreadGroup类，可以把线程归属到某一个线程组中，线程组中可以有线程对象，也可以有线程组，组中还可以有线程，这样的组织结构有点类似于树的形式。</p><ol><li>线程组ThreadGroup对象中比较有用的方法是stop、resume、suspend等方法，由于这几个方法会导致线程的安全问题（主要是死锁问题），已经被官方废弃掉了，所以线程组本身的应用价值就大打折扣了。</li><li>线程组ThreadGroup不是线程安全的，这在使用过程中获取的信息并不全是及时有效的，这就降低了它的统计使用价值。</li></ol></li><li><p>什么是Executors框架？为什么使用Executor框架？</p><p>Executor框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架。</p><p>每次执行任务创建线程 new Thread()比较消耗性能，创建一个线程是比较耗时、耗资源的。</p><p>调用 new Thread()创建的线程缺乏管理，而且可以无限制的创建，线程之间的相互竞争会导致过多占用系统资源而导致系统瘫痪，还有线程之间的频繁交替也会消耗很多系统资源。</p><p>接使用new Thread() 启动的线程不利于扩展，比如定时执行、定期执行、定时定期执行、线程中断等都不便实现。</p></li><li><p>在Java中Executor和Executors的区别？</p><p>Executors 工具类的不同方法按照我们的需求创建了不同的线程池，来满足业务的需求。 </p><p>Executor 接口对象能执行我们的线程任务。 </p><p>ExecutorService接口继承了Executor接口并进行了扩展，提供了更多的方法我们能获得任务执行的状态并且可以获取任务的返回值。 </p><p>使用ThreadPoolExecutor 可以创建自定义线程池。</p></li><li><p>什么是原子操作？在Java Concurrency API中有哪些原子类(atomic classes)<strong>？</strong></p><p>原子操作（atomic operation）意为”不可被中断的一个或一系列操作” 。 </p><p>处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。 </p><p>在Java中可以通过锁和循环CAS的方式来实现原子操作。 CAS操作——Compare &amp; Set，或是 Compare &amp; Swap，现在几乎所有的CPU指令都支持CAS的原子操作。</p><p>java.util.concurrent.atomic下提供了大量的原子操作类，比如原子类：AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference ，原子数组：AtomicIntegerArray，AtomicLongArray，AtomicReferenceArray ，原子属性更新器：AtomicLongFieldUpdater，AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater</p></li><li><p>Java Concurrency API中的Lock接口(Lock interface)是什么？对比synchronized它有什么优势？</p><p>Lock接口比同步方法和同步块提供了更具扩展性的锁操作。 </p><p>他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。</p><p>它的优势有：可以使锁更公平，可以使线程在等待锁的时候响应中断，可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间，可以在不同的范围，以不同的顺序获取和释放锁。</p><p>整体上来说Lock是synchronized的扩展版，Lock提供了无条件的、可轮询的(tryLock方法)、定时的(tryLock带参方法)、可中断的(lockInterruptibly)、可多条件队列的(newCondition方法)锁操作。另外Lock的实现类基本都支持非公平锁(默认)和公平锁，synchronized只支持非公平锁，当然，在大部分情况下，非公平锁是高效的选择。</p></li><li><p>什么是阻塞队列？阻塞队列的实现原理是什么？如何使用阻塞队列来实现生产者-消费者模型？</p><p>阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。</p><p>这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。</p><p>阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。</p><p>JDK7提供了7个阻塞队列。在实现上，主要是利用了Condition和Lock的等待通知模式。</p></li><li><p>什么是Callable和Future?</p><p>Callable接口类似于Runnable，从名字就可以看出来了，但是Runnable不会返回结果，并且无法抛出返回结果的异常，而Callable功能更强大一些，被线程执行后，可以返回值，这个返回值可以被Future拿到，也就是说，</p><p>Future可以拿到异步执行任务的返回值，可以认为是带有回调的Runnable。</p><p>Future接口表示异步任务，是还没有完成的任务给出的未来结果。所以说Callable用于产生结果，Future用于获取结果。</p></li><li><p>什么是<strong>FutureTask?</strong></p><p>在Java并发程序中FutureTask表示一个可以取消的异步运算。它有启动和取消运算、查询运算是否完成和取回运算结果等方法。只有当运算完成的时候结果才能取回，如果运算尚未完成get方法将会阻塞。一个FutureTask对象可以对调用了Callable和Runnable的对象进行包装，由于FutureTask也是调用了Runnable接口所以它可以提交给Executor来执行。</p></li><li><p>什么是并发容器的实现？</p><p>何为同步容器：可以简单地理解为通过synchronized来实现同步的容器，如果有多个线程调用同步容器的方法，它们将会串行执行。比如Vector，Hashtable，以及Collections.synchronizedSet，synchronizedList等方法返回的容器。 </p><p>并发容器使用了与同步容器完全不同的加锁策略来提供更高的并发性和伸缩性，例如在ConcurrentHashMap中采用了一种粒度更细的加锁机制，可以称为分段锁，在这种锁机制下，允许任意数量的读线程并发地访问map，并且执行读操作的线程和写操作的线程也可以并发的访问map，同时允许一定数量的写操作线程并发地修改map，所以它可以在并发环境下实现更高的吞吐量。</p></li><li><p>多线程同步和互斥有几种实现方法，都是什么？</p><p>线程同步是指线程之间所具有的一种制约关系，一个线程的执行依赖另一个线程的消息，当它没有得到另一个线程的消息时应等待，直到消息到达时才被唤醒。 </p><p>线程互斥是指对于共享的进程系统资源，在各单个线程访问时的排它性。当有若干个线程都要使用某一共享资源时，任何时刻最多只允许一个线程去使用，其它要使用该资源的线程必须等待，直到占用资源者释放该资源。线程互斥可以看成是一种特殊的线程同步。</p><p>线程间的同步方法大体可分为两类：用户模式和内核模式。顾名思义，内核模式就是指利用系统内核对象的单一性来进行同步，使用时需要切换内核态与用户态，而用户模式就是不需要切换到内核态，只在用户态完成操作。 </p><p>用户模式下的方法有：原子操作（例如一个单一的全局变量），临界区。内核模式下的方法有：事件，信号量，互斥量。</p></li><li><p>什么是竞争条件？</p><p>当多个进程都企图对共享数据进行某种处理，而最后的结果又取决于进程运行的顺序时，则我们认为这发生了竞争条件（race condition）。</p></li><li><p>为什么我们调用start()方法时会执行run()方法，为什么我们不能直接调用run()方法？</p><p>当你调用start()方法时你将创建新的线程，并且执行在run()方法里的代码。 </p><p>但是如果你直接调用run()方法，它不会创建新的线程也不会执行调用线程的代码，只会把run方法当作普通方法去执行。</p></li><li><p>在Java中CycliBarriar和CountdownLatch有什么区别？</p><p>CyclicBarrier可以重复使用，而CountdownLatch不能重复使用。 </p></li><li><p>什么是不可变对象，它对写并发应用有什么帮助？</p><p>不可变对象(Immutable Objects)即对象一旦被创建它的状态（对象的数据，也即对象属性值）就不能改变，反之即为可变对象(Mutable Objects)。 </p><p>不可变对象的类即为不可变类(Immutable Class)。Java平台类库中包含许多不可变类，如String、基本类型的包装类、BigInteger和BigDecimal等。 </p><p>不可变对象天生是线程安全的。它们的常量（域）是在构造函数中创建的。既然它们的状态无法修改，这些常量永远不会变。</p><p>不可变对象永远是线程安全的。 </p><p>只有满足如下状态，一个对象才是不可变的； </p><p>它的状态不能在创建后再被修改； </p><p>所有域都是final类型；</p><p>它被正确创建；</p></li><li><p>notify()和notifyAll()有什么区别？</p><p>当一个线程进入wait之后，就必须等其他线程notify/notifyall,使用notifyall,可以唤醒所有处于wait状态的线程，使其重新进入锁的争夺队列中，而notify只能唤醒一个。</p><p>如果没把握，建议notifyAll，防止notigy因为信号丢失而造成程序异常。</p></li><li><p>什么是可重入锁（ReentrantLock）？谈谈它的实现。</p><p>线程可以重复进入任何一个它已经拥有的锁所同步着的代码块，synchronized、ReentrantLock都是可重入的锁。在实现上，就是线程每次获取锁时判定如果获得锁的线程是它自己时，简单将计数器累积即可，每 释放一次锁，进行计数器累减，直到计算器归零，表示线程已经彻底释放锁。</p></li><li><p>当一个线程进入某个对象的一个synchronized的实例方法后，其它线程是否可进入此对象的其它方法？</p><p>如果其他方法没有synchronized的话，其他线程是可以进入的。所以要开放一个线程安全的对象时，得保证每个方法都是线程安全的。</p></li><li><p>乐观锁和悲观锁的理解及如何实现，有哪些实现方式？</p><p><strong>悲观锁：</strong>总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。Java里面的同步原语synchronized关键字的实现是悲观锁。</p><p><strong>乐观锁：</strong>顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。在Java中j原子变量类就是使用了乐观锁的一种实现方式CAS实现的。</p><p>乐观锁的实现方式： </p><ul><li>使用版本标识来确定读到的数据与提交时的数据是否一致。提交后修改版本标识，不一致时可以采取丢弃和再次尝试的策略。 </li><li>java中的Compare and Swap即CAS ，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。</li></ul></li><li><p>什么是CAS操作，缺点是什么？</p><p>CAS的基本思路就是，如果这个地址上的值和期望的值相等，则给其赋予新值，否则不做任何事儿，但是要返回原值是多少。每一个CAS操作过程都包含三个运算符：一个内存地址V，一个期望的值A和一个新值B，操作的时候如果这个地址上存放的值等于这个期望的值A，则将地址上的值赋为新值B，否则不做任何操作。</p><p>CAS缺点： </p><p>ABA问题：比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但可能存在潜藏的问题。从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。 </p><p>循环时间长开销大： </p><p>对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。 </p><p>只能保证一个共享变量的原子操作： </p><p>当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。</p></li><li><p>SynchronizedMap和ConcurrentHashMap有什么区别？</p><p>SynchronizedMap一次锁住整张表来保证线程安全，所以每次只能有一个线程来访为map。</p><p>ConcurrentHashMap使用分段锁来保证在多线程下的性能。</p></li><li><p>写时复制容器可以用于什么应用场景？</p><p>CopyOnWrite并发容器用于对于绝大部分访问都是读，且<strong>偶尔写</strong>的并发场景。比如白名单，黑名单，商品类目的访问和更新场景。</p><p>透露的思想：</p><p>读写分离</p><p>最终一致性 </p><p>使用另外开辟空间的思路，来解决并发冲突</p></li><li><p>volatile有什么用？能否用一句话说明下volatile的应用场景？</p><p>volatile保证内存可见性和禁止指令重排。</p><p>volatile用于多线程环境下的一写多读，或者无关联的多写。</p></li><li><p>为什么代码会重排序？</p><p>在执行程序时，为了提供性能，处理器和编译器常常会对指令进行重排序，但是不能随意重排序，它需要满足以下两个条件：</p><p>在单线程环境下不能改变程序运行的结果；</p><p>存在数据依赖关系的不允许重排序</p></li><li><p>在java中wait和sleep方法的不同？</p><p>最大的不同是在等待时wait会释放锁，而sleep一直持有锁。Wait通常被用于线程间交互，sleep通常被用于暂停执行。</p></li><li><p>一个线程运行时发生异常会怎样？</p><p>如果异常没有被捕获该线程将会停止执行。Thread.UncaughtExceptionHandler是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。当一个未捕获异常将造成线程中断的时候JVM会使用Thread.getUncaughtExceptionHandler()来查询线程的UncaughtExceptionHandler并将线程和异常作为参数传递给handler的uncaughtException()方法进行处理。</p></li><li><p>为什么wait, notify 和 notifyAll这些方法不在thread类里面？</p><p>JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。如果线程需要等待某些锁那么调用对象中的wait()方法就有意义了。如果wait()方法定义在Thread类中，线程正在等待的是哪个锁就不明显了。简单的说，由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象。</p></li><li><p>什么是ThreadLocal变量？</p><p>ThreadLocal是Java里一种特殊的变量。每个线程都有一个ThreadLocal就是每个线程都拥有了自己独立的一个变量，竞争条件被彻底消除了。</p></li><li><p>Java中interrupted和isInterrupted方法的区别？</p><p>interrupted() 和 isInterrupted()的主要区别是前者会将中断状态清除而后者不会。Java多线程的中断机制是用内部标识来实现的，调用Thread.interrupt()来中断一个线程就会设置中断标识为true。当中断线程调用静态方法Thread.interrupted()来检查中断状态时，中断状态会被清零。而非静态方法isInterrupted()用来查询其它线程的中断状态且不会改变中断状态标识。</p></li><li><p>为什么wait和notify方法要在同步块中调用？</p><p>主要是因为Java API强制要求这样做，如果你不这么做，你的代码会抛出IllegalMonitorStateException异常。</p></li><li><p>为什么你应该在循环中检查等待条件<strong>?</strong></p><p>处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满足结束条件的情况下退出。因此，当一个等待线程醒来时，不能认为它原来的等待状态仍然是有效的，在notify()方法调用之后和等待线程醒来之前这段时间它可能会改变。这就是在循环中使用wait()方法效果更好的原因</p></li><li><p>怎么检测一个线程是否拥有锁？</p><p>在java.lang.Thread中有一个方法叫holdsLock()，它返回true如果当前线程拥有某个具体对象的锁。</p></li><li><p>你如何在Java中获取线程堆栈？</p><p>kill -3 [java pid] 不会在当前终端输出，它会输出到代码执行的或指定的地方去。比如，kill -3 tomcat pid, 输出堆栈到log目录下。</p><p>Jstack [java pid] 这个比较简单，在当前终端显示，也可以重定向到指定文件中。</p><p>或者使用Java提供的拟机线程系统的管理接口ManagementFactory.getThreadMXBean()。</p></li><li><p>Java线程池中submit() <strong>和</strong> execute()方法有什么区别？</p><p>两个方法都可以向线程池提交任务</p><p>execute()方法的返回类型是void，它定义在Executor接口中。</p><p>submit()方法可以返回持有计算结果的Future对象，它定义在ExecutorService接口中，它扩展了Executor接口</p></li><li><p>你对线程优先级的理解是什么？</p><p>每一个线程都是有优先级的，一般来说，高优先级的线程在运行时会具有优先权，但这依赖于线程调度的实现，这个实现是和操作系统相关的(OS dependent)。我们可以定义线程的优先级，但是这并不能保证高优先级的线程会在低优先级的线程前执行。线程优先级是一个int变量(从1-10)，1代表最低优先级，10代表最高优先级。</p><p>java的线程优先级调度会委托给操作系统去处理，所以与具体的操作系统优先级有关，如非特别需要，一般无需设置线程优先级。</p></li><li><p>你如何确保main()方法所在的线程是Java 程序最后结束的线程？</p><p>可以使用Thread类的join()方法（或者CountDownLatch工具类）来确保所有程序创建的线程在main()方法退出前结束。</p></li><li><p>为什么Thread类的sleep()和yield ()方法是静态的？</p><p>Thread类的sleep()和yield()方法将在当前正在执行的线程上运行。所以在其他处于等待状态的线程上调用这些方法是没有意义的。这就是为什么这些方法是静态的。它们可以在当前正在执行的线程中工作，并避免程序员错误的认为可以在其他非运行线程调用这些方法。</p></li><li><p>现在有T1、T2、T3三个线程，你怎样保证T2在T1执行完后执行，T3在T2执行完后执行？</p><p>可以用join方法实现。</p></li><li><p>你需要实现一个高效的缓存，它允许多个用户读，但只允许一个用户写，以此来保持它的完整性，你会怎样去实现它？</p><p>volatile关键字，读写锁，写时复制等等都可以实现。</p></li><li><p>用Java实现阻塞队列</p><p>见作业答案：包cn.enjoyedu.ch5.answer下</p></li><li><p>用Java写代码来解决生产者——消费者问题。</p><p>阻塞队列实现即可，也可以用wait和notify来解决这个问题，或者用Semaphore（信号量）</p></li><li><p>用Java编程一个会导致死锁的程序，你将怎么解决？</p><p> 参见代码cn.enjoyedu.ch7. NormalDeadLock，如何解决死锁，参见笔记。</p></li><li><p>Java中如何停止一个线程？</p><p>使用共享变量的方式 </p><p>在这种方式中，之所以引入共享变量，是因为该变量可以被多个执行相同任务的线程用来作为是否中断的信号，通知中断线程的执行。</p><p>使用interrupt方法终止线程 </p><p>如果一个线程由于等待某些事件的发生而被阻塞，比如当一个线程由于需要等候键盘输入而被阻塞，或者调用Thread.join()方法，或者Thread.sleep()方法，在网络中调用ServerSocket.accept()方法，或者调用了DatagramSocket.receive()方法时，都有可能导致线程阻塞，使线程处于处于不可运行状态时，即使主程序中将该线程的共享变量设置为true，但该线程此时根本无法检查循环标志，当然也就无法立即中断。所以应该尽量使用Thread提供的interrupt()方法，因为该方法虽然不会中断一个正在运行的线程，但是它可以使一个被阻塞的线程抛出一个中断异常，从而使线程提前结束阻塞状态。</p></li><li><p>JVM中哪个参数是用来控制线程的栈堆栈大小的</p><p>-Xss</p></li><li><p>如果同步块内的线程抛出异常锁会释放吗？</p><p>会</p></li><li><p>单例模式的双重检查实现是什么？为什么并不安全？如何在Java中创建线程安全的Singleton？</p><p>实现参见cn.enjoyedu.ch7.dcl. SingleDcl，不安全的根本原因是重排序会导致未初始化完成的对象可以被其他线程看见而导致错误。创建安全的单例模式有：延迟占位模式、在声明的时候就new这个类的实例、枚举</p></li><li><p>写出3条你遵循的多线程最佳实践</p><p>给你的线程起个有意义的名字。 这样可以方便找bug或追踪。OrderProcessor, QuoteProcessor or TradeProcessor 这种名字比 Thread-1. Thread-2 and Thread-3 好多了，给线程起一个和它要完成的任务相关的名字，所有的主要框架甚至JDK都遵循这个最佳实践。</p><p>避免锁定和缩小同步的范围 锁花费的代价高昂且上下文切换更耗费时间空间，试试最低限度的使用同步和锁，缩小临界区。因此相对于同步方法我更喜欢同步块，它给我拥有对锁的绝对控制权。</p><p>多用同步类少用wait 和 notify 首先，CountDownLatch, Semaphore, CyclicBarrier 和 Exchanger 这些同步类简化了编码操作，而用wait和notify很难实现对复杂控制流的控制。其次，这些类是由最好的企业编写和维护在后续的JDK中它们还会不断优化和完善，使用这些更高等级的同步工具你的程序可以不费吹灰之力获得优化。</p><p>多用并发集合少用同步集合 这是另外一个容易遵循且受益巨大的最佳实践，并发集合比同步集合的可扩展性更好，所以在并发编程时使用并发集合效果更好。</p><p>比如并发编程的黄金原则，尽量无锁化编程等等……..</p></li><li><p>请概述线程池的创建参数，怎么样合理配置一个线程池的参数？</p><p>参见笔记中线程池一章的内容</p></li><li><p>请概述锁的公平和非公平，JDK内部是如何实现的。</p><p>公平锁是指所有试图获得锁的线程按照获取锁的顺序依次获得锁，而非公平锁则是当前的锁状态没有被占用时,当前线程可以直接占用,而不需要等待。在实现上，非公平锁逻辑基本跟公平锁一致，唯一的区别是，当前线程不需要判断同步队列中是否有等待线程。</p><p>非公平锁性能高于公平锁性能。首先，在恢复一个被挂起的线程与该线程真正运行之间存在着严重的延迟。而且，非公平锁能更充分的利用cpu的时间片，尽量的减少cpu空闲的状态时间。</p><p>使用场景的话呢，其实还是和他们的属性一一相关，比如：如果业务中线程占用(处理)时间要远长于线程等待，那用非公平锁其实效率并不明显，但是用公平锁可以保证不会有线程被饿死。</p></li><li><p>请概述AQS</p><p>是用来构建锁或者其他同步组件的基础框架，比如ReentrantLock、ReentrantReadWriteLock和CountDownLatch就是基于AQS实现的。它使用了一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作。它是CLH队列锁的一种变体实现。它可以实现2种同步方式：独占式，共享式。</p><p>AQS的主要使用方式是继承，子类通过继承AQS并实现它的抽象方法来管理同步状态，同步器的设计基于模板方法模式，所以如果要实现我们自己的同步工具类就需要覆盖其中几个可重写的方法，如tryAcquire、tryReleaseShared等等。</p><p>这样设计的目的是同步组件（比如锁）是面向使用者的，它定义了使用者与同步组件交互的接口（比如可以允许两个线程并行访问），隐藏了实现细节；同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作。这样就很好地隔离了使用者和实现者所需关注的领域。</p><p>在内部，AQS维护一个共享资源state，通过内置的FIFO来完成获取资源线程的排队工作。该队列由一个一个的Node结点组成，每个Node结点维护一个prev引用和next引用，分别指向自己的前驱和后继结点，构成一个双端双向链表。</p><p>同时与Condition相关的等待队列，节点类型也是Node，构成一个单向链表。</p></li><li><p>请概述volatile</p><p>volatile关键字的作用主要有两点：</p><p>多线程主要围绕可见性和原子性两个特性而展开，使用volatile关键字修饰的变量，保证了其在多线程之间的可见性，即每次读取到volatile变量，一定是最新的数据。但是volatile只能以保证任意单个volatile变量的读/写具有原子性，但类似于++这种复合操作不具有原子性。</p><p>代码底层在执行时为了获取更好的性能会对指令进行重排序，多线程下可能会出现一些意想不到的问题。使用volatile则会对禁止重排序，当然这也一定程度上降低了代码执行效率。</p><p>同时在内存语义上，当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存，当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。</p><p>在Java中对于volatile修饰的变量，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序问题、强制刷新和读取。</p><p>在具体实现上，volatile关键字修饰的变量会存在一个“lock:”的前缀。它不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。</p><p>同时该指令会将当前处理器缓存行的数据直接写会到系统内存中，且这个写回内存的操作会使在其他CPU里缓存了该地址的数据无效。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程 - 面试题</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>java8新增的特性</title>
    <link href="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/"/>
    <url>/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/</url>
    
    <content type="html"><![CDATA[<h2 id="新增原子操作"><a href="#新增原子操作" class="headerlink" title="新增原子操作"></a>新增原子操作</h2><h3 id="LongAdder"><a href="#LongAdder" class="headerlink" title="LongAdder"></a>LongAdder</h3><p>JDK1.8时，java.util.concurrent.atomic包中提供了一个新的原子类：LongAdder。<br> 根据Oracle官方文档的介绍，LongAdder在高并发的场景下会比它的前辈AtomicLong 具有更好的性能，代价是消耗更多的内存空间。</p><p><strong>AtomicLong</strong>是利用了底层的CAS操作来提供并发性的，调用了<strong>Unsafe</strong>类的<strong>getAndAddLong</strong>方法，该方法是个<strong>native</strong>方法，它的逻辑是采用自旋的方式不断更新目标值，直到更新成功。</p><p>在并发量较低的环境下，线程冲突的概率比较小，自旋的次数不会很多。但是，高并发环境下，N个线程同时进行自旋操作，会出现大量失败并不断自旋的情况，此时<strong>AtomicLong</strong>的自旋会成为瓶颈。</p><p>这就是<strong>LongAdder</strong>引入的初衷——解决高并发环境下<strong>AtomicLong</strong>的自旋瓶颈问题。</p><p><strong>AtomicLong</strong>中有个内部变量<strong>value</strong>保存着实际的long值，所有的操作都是针对该变量进行。也就是说，高并发环境下，value变量其实是一个热点，也就是N个线程竞争一个热点。</p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic1.png" srcset="/img/loading.gif" class=""><p><strong>LongAdder</strong>的基本思路就是<strong>分散热点</strong>，将value值分散到一个数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行CAS操作，这样热点就被分散了，冲突的概率就小很多。如果要获取真正的long值，只要将各个槽中的变量值累加返回。</p><p>这种做法和ConcurrentHashMap中的“分段锁”其实就是类似的思路。</p><p><strong>LongAdder</strong>提供的API和<strong>AtomicLong</strong>比较接近，两者都能以原子的方式对long型变量进行增减。</p><p>但是<strong>AtomicLong</strong>提供的功能其实更丰富，尤其是<strong>addAndGet</strong>、<strong>decrementAndGet</strong>、<strong>compareAndSet</strong>这些方法。</p><p><strong>addAndGet</strong>、<strong>decrementAndGet</strong>除了单纯的做自增自减外，还可以立即获取增减后的值，而<strong>LongAdder</strong>则需要做同步控制才能精确获取增减后的值。如果业务需求需要精确的控制计数，做计数比较，<strong>AtomicLong</strong>也更合适。</p><p>另外，从空间方面考虑，<strong>LongAdder</strong>其实是一种“空间换时间”的思想，从这一点来讲<strong>AtomicLong</strong>更适合。</p><p>总之，低并发、一般的业务场景下AtomicLong是足够了。如果并发量很多，存在大量写多读少的情况，那LongAdder可能更合适。适合的才是最好的，如果真出现了需要考虑到底用AtomicLong好还是LongAdder的业务场景，那么这样的讨论是没有意义的，因为这种情况下要么进行性能测试，以准确评估在当前业务场景下两者的性能，要么换个思路寻求其它解决方案。</p><p>对于<strong>LongAdder</strong>来说，内部有一个base变量，一个Cell[]数组。</p><p>base变量：非竞态条件下，直接累加到该变量上。</p><p>Cell[]数组：竞态条件下，累加个各个线程自己的槽Cell[i]中。</p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic2.png" srcset="/img/loading.gif" class=""><p>所以，最终结果的计算应该是</p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic3.png" srcset="/img/loading.gif" class=""><p>在实际运用的时候，只有从未出现过并发冲突的时候，base基数才会使用到，一旦出现了并发冲突，之后所有的操作都只针对Cell[]数组中的单元Cell。</p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic4.png" srcset="/img/loading.gif" class=""><p>而LongAdder最终结果的求和，并没有使用全局锁，返回值不是绝对准确的，因为调用这个方法时还有其他线程可能正在进行计数累加，所以只能得到某个时刻的近似值，这也就是<strong>LongAdder</strong>并不能完全替代<strong>LongAtomic</strong>的原因之一。</p><p>而且从测试情况来看，线程数越多，并发操作数越大，LongAdder的优势越大，线程数较小时，AtomicLong的性能还超过了LongAdder。</p><h3 id="其他新增"><a href="#其他新增" class="headerlink" title="其他新增"></a>其他新增</h3><p>除了新引入LongAdder外，还有引入了它的三个兄弟类：<strong>LongAccumulator</strong>、<strong>DoubleAdder</strong>、<strong>DoubleAccumulator</strong>。</p><p>LongAccumulator是LongAdder的增强版。LongAdder只能针对数值的进行加减运算，而LongAccumulator提供了自定义的函数操作。</p><p>通过LongBinaryOperator，可以自定义对入参的任意操作，并返回结果（LongBinaryOperator接收2个long作为参数，并返回1个long）。</p><p>LongAccumulator内部原理和LongAdder几乎完全一样。</p><p>DoubleAdder和DoubleAccumulator用于操作double原始类型。</p><h2 id="新增显示锁"><a href="#新增显示锁" class="headerlink" title="新增显示锁"></a>新增显示锁</h2><h3 id="StampLock"><a href="#StampLock" class="headerlink" title="StampLock"></a>StampLock</h3><p>StampedLock是Java8引入的一种新的所机制,简单的理解,可以认为它是读写锁的一个改进版本,读写锁虽然分离了读和写的功能,使得读与读之间可以完全并发,但是读和写之间依然是冲突的,读锁会完全阻塞写锁,它使用的依然是悲观的锁策略.如果有大量的读线程,他也有可能引起写线程的饥饿。</p><p>而StampedLock则提供了一种乐观的读策略,这种乐观策略的锁非常类似于无锁的操作,使得乐观锁完全不会阻塞写线程。</p><p>它的思想是读写锁中读不仅不阻塞读，同时也不应该阻塞写。</p><h3 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h3><p>在读的时候如果发生了写，则应当重读而不是在读的时候直接阻塞写。即读写之间不会阻塞对方，但是写和写之间还是阻塞的。</p><p>StampedLock的内部实现是基于CLH的。</p><h3 id="CompletableFuture"><a href="#CompletableFuture" class="headerlink" title="CompletableFuture"></a>CompletableFuture</h3><h4 id="Future不足"><a href="#Future不足" class="headerlink" title="Future不足"></a>Future不足</h4><p>Future是Java 5添加的类，用来描述一个异步计算的结果。你可以使用isDone方法检查计算是否完成，或者使用get阻塞住调用线程，直到计算完成返回结果，你也可以使用cancel方法停止任务的执行。</p><p>虽然Future以及相关使用方法提供了异步执行任务的能力，但是对于结果的获取却是很不方便，只能通过阻塞或者轮询的方式得到任务的结果。阻塞的方式显然和我们的异步编程的初衷相违背，轮询的方式又会耗费无谓的CPU资源，而且也不能及时地得到计算结果，为什么不能用观察者设计模式当计算结果完成及时通知监听者呢？。</p><p>Java的一些框架，比如Netty，自己扩展了Java的 Future接口，提供了addListener等多个扩展方法，Google guava也提供了通用的扩展Future:ListenableFuture、SettableFuture 以及辅助类Futures等,方便异步编程。</p><p>同时Future接口很难直接表述多个Future 结果之间的依赖性。实际开发中，我们经常需要达成以下目的：</p><p>将两个异步计算合并为一个——这两个异步计算之间相互独立，同时第二个又依赖于第一个的结果。</p><p>等待 Future 集合中的所有任务都完成。</p><p>仅等待 Future集合中最快结束的任务完成（有可能因为它们试图通过不同的方式计算同一个值），并返回它的结果。</p><p>应对 Future 的完成事件（即当 Future 的完成事件发生时会收到通知，并能使用 Future 计算的结果进行下一步的操作，不只是简单地阻塞等待操作的结果）</p><h4 id="CompletableFuture-1"><a href="#CompletableFuture-1" class="headerlink" title="CompletableFuture"></a>CompletableFuture</h4><p>JDK1.8才新加入的一个实现类CompletableFuture，实现了Future<T>， CompletionStage<T>两个接口。实现了Future接口，意味着可以像以前一样通过阻塞或者轮询的方式获得结果。</p><h5 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h5><p>除了直接new出一个CompletableFuture的实例，还可以通过工厂方法创建CompletableFuture的实例</p><h5 id="工厂方法"><a href="#工厂方法" class="headerlink" title="工厂方法"></a>工厂方法</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic6.png" srcset="/img/loading.gif" class=""><p>Asynsc表示异步,而supplyAsync与runAsync不同在与前者异步返回一个结果,后者是void.第二个函数第二个参数表示是用我们自己创建的线程池,否则采用默认的ForkJoinPool.commonPool()作为它的线程池。</p><h5 id="获得结果的方法"><a href="#获得结果的方法" class="headerlink" title="获得结果的方法"></a>获得结果的方法</h5><p>public T get()</p><p>public T get(long timeout, TimeUnit unit)</p><p>public T getNow(T valueIfAbsent)</p><p>public T join()</p><p>getNow有点特殊，如果结果已经计算完则返回结果或者抛出异常，否则返回给定的valueIfAbsent值。</p><p>join返回计算的结果或者抛出一个unchecked异常(CompletionException)，它和get对抛出的异常的处理有些细微的区别。</p><h5 id="辅助方法"><a href="#辅助方法" class="headerlink" title="辅助方法"></a>辅助方法</h5><p>public static CompletableFuture<Void> allOf(CompletableFuture&lt;?&gt;… cfs)</p><p>public static CompletableFuture<Object> anyOf(CompletableFuture&lt;?&gt;… cfs)</p><p>allOf方法是当所有的CompletableFuture都执行完后执行计算。</p><p>anyOf方法是当任意一个CompletableFuture执行完后就会执行计算，计算的结果相同。</p><p>CompletionStage是一个接口，从命名上看得知是一个完成的阶段，它代表了一个特定的计算的阶段，可以同步或者异步的被完成。你可以把它看成一个计算流水线上的一个单元，并最终会产生一个最终结果，这意味着几个CompletionStage可以串联起来，一个完成的阶段可以触发下一阶段的执行，接着触发下一次，再接着触发下一次。</p><p>总结CompletableFuture几个关键点：</p><ol><li><p>计算可以由 Future ，Consumer 或者 Runnable 接口中的 apply，accept 或者 run等方法表示。</p></li><li><p>计算的执行主要有以下</p><p>a. 默认执行</p><p>b. 使用默认的CompletionStage的异步执行提供者异步执行。这些方法名使用someActionAsync这种格式表示。</p><p>c. 使用 Executor 提供者异步执行。这些方法同样也是someActionAsync这种格式，但是会增加一个Executor 参数。</p></li></ol><p>CompletableFuture中的方法归类</p><h5 id="变换类"><a href="#变换类" class="headerlink" title="变换类"></a>变换类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic7.png" srcset="/img/loading.gif" class=""><p>关键入参是函数式接口Function。它的入参是上一个阶段计算后的结果，返回值是经过转化后结果。</p><h5 id="消费类"><a href="#消费类" class="headerlink" title="消费类"></a>消费类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic8.png" srcset="/img/loading.gif" class=""><p>关键入参是函数式接口Consumer。它的入参是上一个阶段计算后的结果， 没有返回值。</p><h5 id="执行操作类"><a href="#执行操作类" class="headerlink" title="执行操作类"></a>执行操作类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic9.png" srcset="/img/loading.gif" class=""><p>对上一步的计算结果不关心，执行下一个操作，入参是一个Runnable的实例，表示上一步完成后执行的操作。</p><h5 id="结合转化类"><a href="#结合转化类" class="headerlink" title="结合转化类"></a>结合转化类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic10.png" srcset="/img/loading.gif" class=""><p>需要上一步的处理返回值，并且other代表的CompletionStage 有返回值之后，利用这两个返回值，进行转换后返回指定类型的值。</p><p>两个CompletionStage是并行执行的，它们之间并没有先后依赖顺序，other并不会等待先前的CompletableFuture执行完毕后再执行。</p><p><strong>结合转化类</strong></p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic11.png" srcset="/img/loading.gif" class=""><p>对于Compose可以连接两个CompletableFuture，其内部处理逻辑是当第一个CompletableFuture处理没有完成时会合并成一个CompletableFuture,如果处理完成，第二个future会紧接上一个CompletableFuture进行处理。</p><p>第一个CompletableFuture 的处理结果是第二个future需要的输入参数。</p><h5 id="结合消费类"><a href="#结合消费类" class="headerlink" title="结合消费类"></a>结合消费类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic12.png" srcset="/img/loading.gif" class=""><p>需要上一步的处理返回值，并且other代表的CompletionStage 有返回值之后，利用这两个返回值，进行消费</p><h5 id="运行后执行类"><a href="#运行后执行类" class="headerlink" title="运行后执行类"></a>运行后执行类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic13.png" srcset="/img/loading.gif" class=""><p>不关心这两个CompletionStage的结果，只关心这两个CompletionStage都执行完毕，之后再进行操作（Runnable）。</p><h5 id="取最快转换类"><a href="#取最快转换类" class="headerlink" title="取最快转换类"></a>取最快转换类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic14.png" srcset="/img/loading.gif" class=""><p>两个CompletionStage，谁计算的快，我就用那个CompletionStage的结果进行下一步的转化操作。现实开发场景中，总会碰到有两种渠道完成同一个事情，所以就可以调用这个方法，找一个最快的结果进行处理。</p><h5 id="取最快消费类"><a href="#取最快消费类" class="headerlink" title="取最快消费类"></a>取最快消费类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic15.png" srcset="/img/loading.gif" class=""><p>两个CompletionStage，谁计算的快，我就用那个CompletionStage的结果进行下一步的消费操作。</p><h5 id="取最快运行后执行类"><a href="#取最快运行后执行类" class="headerlink" title="取最快运行后执行类"></a>取最快运行后执行类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic16.png" srcset="/img/loading.gif" class=""><p>两个CompletionStage，任何一个完成了都会执行下一步的操作（Runnable）。</p><h5 id="异常补偿类"><a href="#异常补偿类" class="headerlink" title="异常补偿类"></a>异常补偿类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic17.png" srcset="/img/loading.gif" class=""><p>当运行时出现了异常，可以通过exceptionally进行补偿。</p><h5 id="运行后记录结果类"><a href="#运行后记录结果类" class="headerlink" title="运行后记录结果类"></a>运行后记录结果类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic18.png" srcset="/img/loading.gif" class=""><p>action执行完毕后它的结果返回原始的CompletableFuture的计算结果或者返回异常。所以不会对结果产生任何的作用。</p><h5 id="运行后处理结果类"><a href="#运行后处理结果类" class="headerlink" title="运行后处理结果类"></a>运行后处理结果类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic19.png" srcset="/img/loading.gif" class=""><p>运行完成时，对结果的处理。这里的完成时有两种情况，一种是正常执行，返回值。另外一种是遇到异常抛出造成程序的中断。</p><h2 id="Lambda表达式"><a href="#Lambda表达式" class="headerlink" title="Lambda表达式"></a>Lambda表达式</h2><p>在语法上，Lambda表达式包含三个部分，参数列表，箭头，主体，比如：</p><p> <strong>(parameters) -&gt; expression</strong></p><p>或</p><p> <strong>(parameters) -&gt; { statements; }</strong></p><p>Lambda表达式用在函数式接口上，所谓函数式接口，是只定义了一个抽象方法的接口（Interface），接口中是否有默认方法，不影响。注解@FunctionalInterface可以帮助我们在设计函数式接口时防止出错。</p><p><strong>函数描述符</strong>:函数式接口的抽象方法的签名基本上就是Lambda表达式的签名。我们将这种抽象方法叫作函数描述符。Runnable接口可以看作一个什么也不接受什么也不返回（void）的函数的签名，因为它只有一个叫作run的抽象方法，这个方法什么也不接受，什么也不返回（void）。我们可以用 () -&gt; void代表参数列表为空，且返回void的函数。这正是Runnable接口所代表的。我们于是可以称() -&gt; void是Runnable接口的函数描述符。</p><p>而Callable接口和Supplier接口的函数描述符是一样的，都是</p><p>() -&gt; X</p><p>所以同一个Lambda可以同时用在这两个函数式接口上，比如：</p><p>Callable&lt;Integer&gt; = () -&gt; 33;</p><p>Supplier&lt;Integer&gt; = () -&gt; 33;</p><p>我们常用的Runnable,Callable都是函数式接口，JDK8中新增了几个函数式接口：</p><p><strong>Predicate</strong></p><p>包含test方法，接受泛型的T，返回boolean，可以视为断言（检查）接口</p><p><strong>Consumer</strong></p><p>包含accept方法，接受泛型的T，无返回，可以视为数据消费接口</p><p><strong>Function&lt;T,R&gt;</strong></p><p>包含apply方法，接受泛型的T，返回R，可以视为映射转换接口</p><p><strong>Supplier</strong></p><p>包含get方法，无输入，返回T，可以视为创建一个新对象接口</p><p><strong>UnaryOperator</strong></p><p>扩展至Function&lt;T,T&gt;，所以这个本质上也是一个映射转换接口，只不过映射转换后的类型保持不变</p><p><strong>BiFunction</strong></p><p>包含apply方法，接受泛型的T、U，返回R，可以视为复合型映射转换接口</p><p><strong>BinaryOperator</strong></p><p>扩展至Function BiFunction&lt;T,T,T&gt;，所以这个本质上也是一个复合型映射转换接口，只不过映射转换后的类型保持不变</p><p><strong>BiPredicate</strong></p><p>包含test方法，接受泛型的T，U，返回boolean，可以视为复合型断言（检查）接口</p><p><strong>BiConsumer&lt;T,U&gt;</strong></p><p>包含accept方法，接受泛型的T，U，无返回，可以视为复合型数据消费接口</p><h2 id="扩充知识点-Disruptor"><a href="#扩充知识点-Disruptor" class="headerlink" title="扩充知识点- Disruptor"></a>扩充知识点- Disruptor</h2><h3 id="应用背景和介绍"><a href="#应用背景和介绍" class="headerlink" title="应用背景和介绍"></a>应用背景和介绍</h3><p>Disruptor是英国外汇交易公司LMAX开发的一个高性能队列，研发的初衷是解决内部的内存队列的延迟问题，而不是分布式队列。基于Disruptor开发的系统单线程能支撑每秒600万订单，2010年在QCon演讲后，获得了业界关注。</p><p>据目前资料显示：应用Disruptor的知名项目有如下的一些：Storm, Camel, Log4j2,还有目前的美团点评技术团队也有很多不少的应用，或者说有一些借鉴了它的设计机制。 </p><p>Disruptor是一个高性能的线程间异步通信的框架，即在同一个JVM进程中的多线程间消息传递。</p><h3 id="传统队列问题"><a href="#传统队列问题" class="headerlink" title="传统队列问题"></a>传统队列问题</h3><p>在JDK中，Java内部的队列BlockQueue的各种实现，仔细分析可以得知，队列的底层数据结构一般分成三种：数组、链表和堆，堆这里是为了实现带有优先级特性的队列暂且不考虑。 </p><p>在稳定性和性能要求特别高的系统中，为了防止生产者速度过快，导致内存溢出，只能选择有界队列；同时，为了减少Java的垃圾回收对系统性能的影响，会尽量选择 Array格式的数据结构。这样筛选下来，符合条件的队列就只有ArrayBlockingQueue。但是ArrayBlockingQueue是通过<strong>加锁</strong>的方式保证线程安全，而且ArrayBlockingQueue还存在<strong>伪共享</strong>问题，这两个问题严重影响了性能。</p><p>ArrayBlockingQueue的这个伪共享问题存在于哪里呢，分析下核心的部分源码，其中最核心的三个成员变量为</p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic20.png" srcset="/img/loading.gif" class=""><p>是在ArrayBlockingQueue的核心enqueue和dequeue方法中经常会用到的，这三个变量很容易放到同一个缓存行中，进而产生伪共享问题。</p><h3 id="高性能的原理"><a href="#高性能的原理" class="headerlink" title="高性能的原理"></a>高性能的原理</h3><ol><li><p>引入环形的数组结构：数组元素不会被回收，避免频繁的GC，</p></li><li><p>无锁的设计：采用CAS无锁方式，保证线程的安全性</p></li><li><p>属性填充：通过添加额外的无用信息，避免伪共享问题</p></li></ol><p>环形数组结构是整个Disruptor的核心所在。 </p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic21.png" srcset="/img/loading.gif" class=""><p>首先因为是数组，所以要比链表快，而且根据我们对上面缓存行的解释知道，数组中的一个元素加载，相邻的数组元素也是会被预加载的，因此在这样的结构中，cpu无需时不时去主存加载数组中的下一个元素。而且，你可以为数组预先分配内存，使得数组对象一直存在（除非程序终止）。这就意味着不需要花大量的时间用于垃圾回收。此外，不像链表那样，需要为每一个添加到其上面的对象创造节点对象—对应的，当删除节点时，需要执行相应的内存清理操作。环形数组中的元素采用覆盖方式，避免了jvm的GC。 </p><p>其次结构作为环形，数组的大小为2的n次方，这样元素定位可以通过位运算效率会更高，这个跟一致性哈希中的环形策略有点像。在disruptor中，这个牛逼的环形结构就是RingBuffer，既然是数组，那么就有大小，而且这个大小必须是2的n次方</p><p>其实质只是一个普通的数组，只是当放置数据填充满队列（即到达2^n-1位置）之后，再填充数据，就会从0开始，覆盖之前的数据，于是就相当于一个环。</p><p>每个生产者首先通过CAS竞争获取可以写的空间，然后再进行慢慢往里放数据，如果正好这个时候消费者要消费数据，那么每个消费者都需要获取最大可消费的下标。</p><p>同时，Disruptor 不像传统的队列，分为一个队头指针和一个队尾指针，而是只有一个角标（上图的seq），它属于一个volatile变量，同时也是我们能够不用锁操作就能实现Disruptor的原因之一，而且通过缓存行补充，避免伪共享问题。该指针是通过一直自增的方式来获取下一个可写或者可读数据。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JMM和底层实现原理</title>
    <link href="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
    <url>/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="JMM基础计算机原理"><a href="#JMM基础计算机原理" class="headerlink" title="JMM基础计算机原理"></a>JMM基础计算机原理</h2><p>Java内存模型即Java Memory Model，简称JMM。JMM定义了Java 虚拟机(JVM)在计算机内存(RAM)中的工作方式。JVM是整个计算机虚拟模型，所以JMM是隶属于JVM的。Java1.5版本对其进行了重构，现在的Java仍沿用了Java1.5的版本。Jmm遇到的问题与现代计算机中遇到的问题是差不多的。</p><p>物理计算机中的并发问题，物理机遇到的并发问题与虚拟机中的情况有不少相似之处，物理机对并发的处理方案对于虚拟机的实现也有相当大的参考意义。</p><p>根据《Jeff Dean在Google全体工程大会的报告》我们可以看到</p><table><thead><tr><th>操作</th><th>响应时间</th></tr></thead><tbody><tr><td>打开一个站点</td><td>几秒</td></tr><tr><td>数据库查询一条记录（有索引）</td><td>十几毫秒</td></tr><tr><td>1.6G的CPU执行一条指令</td><td>0.6纳秒</td></tr><tr><td>从机械磁盘顺序读取1M数据</td><td>2-10毫秒</td></tr><tr><td>从机械磁盘顺序读取1M数据</td><td>0.3毫秒</td></tr><tr><td>从机械磁盘顺序读取1M数据</td><td>250微秒</td></tr><tr><td>CPU读取一次内存</td><td>100纳秒</td></tr><tr><td>1G网卡，网络传输2Kb数据</td><td>20微秒</td></tr></tbody></table><p>计算机在做一些我们平时的基本操作时，需要的响应时间是不一样的。</p><p>如果从内存中读取1M的int型数据由CPU进行累加，耗时要多久？</p><p>做个简单的计算，1M的数据，Java里int型为32位，4个字节，共有1024<em>1024/4 = 262144个整数 ，则CPU 计算耗时：262144 *0.6 = 157 286 纳秒，而我们知道从内存读取1M数据需要250000纳秒，两者虽然有差距（当然这个差距并不小，十万纳秒的时间足够CPU执行将近二十万条指令了），但是还在一个数量级上。但是，没有任何缓存机制的情况下，意味着每个数都需要从内存中读取，这样加上CPU读取一次内存需要100纳秒，262144个整数从内存读取到CPU加上计算时间一共需要262144</em>100+250000 = 26 464 400 纳秒，这就存在着数量级上的差异了。</p><p>而且现实情况中绝大多数的运算任务都不可能只靠处理器“计算”就能完成，处理器至少要与内存交互，如读取运算数据、存储运算结果等，这个I/O操作是基本上是无法消除的（无法仅靠寄存器来完成所有运算任务）。早期计算机中cpu和内存的速度是差不多的，但在现代计算机中，cpu的指令速度远超内存的存取速度,由于计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic1.png" srcset="/img/loading.gif" class=""><p>在计算机系统中，寄存器划是L0级缓存，接着依次是L1，L2，L3（接下来是内存，本地磁盘，远程存储）。越往上的缓存存储空间越小，速度越快，成本也更高；越往下的存储空间越大，速度更慢，成本也更低。从上至下，每一层都可以看做是更下一层的缓存，即：L0寄存器是L1一级缓存的缓存，L1是L2的缓存，依次类推；每一层的数据都是来至它的下一层，所以每一层的数据是下一层的数据的子集。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic2.png" srcset="/img/loading.gif" class=""><p>在现代CPU上，一般来说L0， L1，L2，L3都集成在CPU内部，而L1还分为一级数据缓存（Data Cache，D-Cache，L1d）和一级指令缓存（Instruction Cache，I-Cache，L1i），分别用于存放数据和执行数据的指令解码。每个核心拥有独立的运算处理单元、控制器、寄存器、L1、L2缓存，然后一个CPU的多个核心共享最后一层CPU缓存L3</p><h2 id="物理内存模型带来的问题"><a href="#物理内存模型带来的问题" class="headerlink" title="物理内存模型带来的问题"></a>物理内存模型带来的问题</h2><p>基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是也为计算机系统带来更高的复杂度，因为它引入了一个新的问题：缓存一致性（Cache Coherence）。在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（MainMemory）。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic3.png" srcset="/img/loading.gif" class=""><p>现代的处理器使用写缓冲区临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读/写操作的执行顺序，不一定与内存实际发生的读/写操作顺序一致。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic5.png" srcset="/img/loading.gif" class=""><p>处理器A和处理器B按程序的顺序并行执行内存访问，最终可能得到x=y=0的结果。</p><p>处理器A和处理器B可以同时把共享变量写入自己的写缓冲区（步骤A1，B1），然后从内存中读取另一个共享变量（步骤A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（步骤A3，B3）。当以这种时序执行时，程序就可以得到x=y=0的结果。</p><p>从内存操作实际发生的顺序来看，直到处理器A执行A3来刷新自己的写缓存区，写操作A1才算真正执行了。虽然处理器A执行内存操作的顺序为：A1→A2，但内存操作实际发生的顺序却是A2→A1。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic4.png" srcset="/img/loading.gif" class=""><p>如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI（Illinois Protocol）、MOSI、Synapse、Firefly及Dragon Protocol等。</p><h2 id="伪共享"><a href="#伪共享" class="headerlink" title="伪共享"></a>伪共享</h2><p>前面我们已经知道，CPU中有好几级高速缓存。但是CPU缓存系统中是以缓存行（cache line）为单位存储的。目前主流的CPU Cache的Cache Line大小都是64Bytes。Cache Line可以简单的理解为CPU Cache中的最小缓存单位，今天的CPU不再是按字节访问内存，而是以64字节为单位的块(chunk)拿取，称为一个缓存行(cache line)。当读一个特定的内存地址，整个缓存行将从主存换入缓存。</p><p>一个缓存行可以存储多个变量（存满当前缓存行的字节数）；而CPU对缓存的修改又是以缓存行为最小单位的，在多线程情况下，如果同时修改一个缓存行中的变量，就会无意中影响彼此的性能，这就是伪共享（False Sharing）。</p><p>为了避免伪共享，我们可以使用数据填充的方式来避免，即单个数据填充满一个CacheLine。这本质是一种空间换时间的做法。但是这种方式在Java7以后可能失效。</p><p>Java8中已经提供了官方的解决方案，Java8中新增了一个注解@sun.misc.Contended。</p><p>比如JDK的ConcurrentHashMap中就有使用</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic6.png" srcset="/img/loading.gif" class=""><h2 id="Java内存模型（JMM）"><a href="#Java内存模型（JMM）" class="headerlink" title="Java内存模型（JMM）"></a>Java内存模型（JMM）</h2><p>从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic9.png" srcset="/img/loading.gif" class=""><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic7.png" srcset="/img/loading.gif" class=""><h2 id="Java内存模型带来的问题"><a href="#Java内存模型带来的问题" class="headerlink" title="Java内存模型带来的问题"></a>Java内存模型带来的问题</h2><h3 id="可见性问题"><a href="#可见性问题" class="headerlink" title="可见性问题"></a>可见性问题</h3><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic8.png" srcset="/img/loading.gif" class=""><p>左边CPU中运行的线程从主存中拷贝共享对象obj到它的CPU缓存，把对象obj的count变量改为2。但这个变更对运行在右边CPU中的线程不可见，因为这个更改还没有flush到主存中。</p><p>在多线程的环境下，如果某个线程首次读取共享变量，则首先到主内存中获取该变量，然后存入工作内存中，以后只需要在工作内存中读取该变量即可。同样如果对该变量执行了修改的操作，则先将新值写入工作内存中，然后再刷新至主内存中。但是什么时候最新的值会被刷新至主内存中是不太确定，一般来说会很快，但具体时间不知。</p><p>要解决共享对象可见性这个问题，我们可以使用volatile关键字或者是加锁。</p><h3 id="竞争问题"><a href="#竞争问题" class="headerlink" title="竞争问题"></a>竞争问题</h3><p>线程A和线程B共享一个对象obj。假设线程A从主存读取Obj.count变量到自己的CPU缓存，同时，线程B也读取了Obj.count变量到它的CPU缓存，并且这两个线程都对Obj.count做了加1操作。此时，Obj.count加1操作被执行了两次，不过都在不同的CPU缓存中。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic10.png" srcset="/img/loading.gif" class=""><p>如果这两个加1操作是串行执行的，那么Obj.count变量便会在原始值上加2，最终主存中的Obj.count的值会是3。然而图中两个加1操作是并行的，不管是线程A还是线程B先flush计算结果到主存，最终主存中的Obj.count只会增加1次变成2，尽管一共有两次加1操作。 要解决上面的问题我们可以使用java synchronized代码块</p><h3 id="重排序问题"><a href="#重排序问题" class="headerlink" title="重排序问题"></a>重排序问题</h3><h4 id="重排序类型"><a href="#重排序类型" class="headerlink" title="重排序类型"></a>重排序类型</h4><p>除了共享内存和工作内存带来的问题，还存在重排序的问题：在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型。</p><ol><li><p>编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。</p></li><li><p>指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-LevelParallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。</p></li><li><p>内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。</p></li></ol><h4 id="数据依赖性"><a href="#数据依赖性" class="headerlink" title="数据依赖性"></a>数据依赖性</h4><p>数据依赖性：如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分为下列3种类型</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic11.png" srcset="/img/loading.gif" class=""><p>上面3种情况，只要重排序两个操作的执行顺序，程序的执行结果就会被改变。</p><p>例如</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic12.png" srcset="/img/loading.gif" class=""><p>很明显，A和C存在数据依赖，B和C也存在数据依赖，而A和B之间不存在数据依赖，如果重排序了A和C或者B和C的执行顺序，程序的执行结果就会被改变。</p><p>很明显，不管如何重排序，都必须保证代码在单线程下的运行正确，连单线程下都无法正确，更不用讨论多线程并发的情况，所以就提出了一个as-if-serial的概念。</p><p>as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。</p><p>为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。（强调一下，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。）但是，如果操作之间不存在数据依赖关系，这些操作依然可能被编译器和处理器重排序。</p><p>A和C之间存在数据依赖关系，同时B和C之间也存在数据依赖关系。因此在最终执行的指令序列中，C不能被重排序到A和B的前面（C排到A和B的前面，程序的结果将会被改变）。但A和B之间没有数据依赖关系，编译器和处理器可以重排序A和B之间的执行顺序。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic13.png" srcset="/img/loading.gif" class=""><p>as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器、runtime和处理器可以让我们感觉到：单线程程序看起来是按程序的顺序来执行的。asif-serial语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。</p><h4 id="控制依赖性"><a href="#控制依赖性" class="headerlink" title="控制依赖性"></a>控制依赖性</h4><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic14.png" srcset="/img/loading.gif" class=""><p>上述代码中，flag变量是个标记，用来标识变量a是否已被写入，在use方法中变量i的赋值依赖if (flag)的判断，这里就叫控制依赖，如果发生了重排序，结果就不对了。</p><p>操作1和操作2没有数据依赖关系，编译器和处理器可以对这两个操作重排序；同样，操作3和操作4没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。操作3和操作4则存在所谓<strong>控制依赖关系</strong>。</p><p>在程序中，当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算a*a，然后把计算结果临时保存到一个名为重排序缓冲（Reorder Buffer，ROB）的硬件缓存中。当操作3的条件判断为真时，就把该计算结果写入变量i中。猜测执行实质上对操作3和4做了重排序，问题在于这时候，a的值还没被线程A赋值。</p><p>在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是as-if-serial语义允许对存在控制依赖的操作做重排序的原因）。</p><p>但是对多线程来说就完全不同了：这里假设有两个线程A和B，A首先执行init ()方法，随后B线程接着执行use ()方法。线程B在执行操作4时，能否看到线程A在操作1对共享变量a的写入呢？答案是：不一定能看到。</p><p>让我们先来看看，当操作1和操作2重排序，操作3和操作4重排序时，可能会产生什么效果？操作1和操作2做了重排序。程序执行时，线程A首先写标记变量flag，随后线程B读这个变量。由于条件判断为真，线程B将读取变量a。此时，变量a还没有被线程A写入，这时就会发生错误！</p><p>所以在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。</p><h3 id="解决在并发下的问题"><a href="#解决在并发下的问题" class="headerlink" title="解决在并发下的问题"></a>解决在并发下的问题</h3><h4 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h4><p>Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序，从而让程序按我们预想的流程去执行。</p><ol><li><p>保证特定操作的执行顺序。</p></li><li><p>影响某些数据（或则是某条指令的执行结果）的内存可见性。</p></li></ol><p>编译器和CPU能够重排序指令，保证最终相同的结果，尝试优化性能。插入一条Memory Barrier会告诉编译器和CPU：不管什么指令都不能和这条Memory Barrier指令重排序。</p><p>Memory Barrier所做的另外一件事是强制刷出各种CPU cache，如一个Write-Barrier（写入屏障）将刷出所有在Barrier之前写入 cache 的数据，因此，任何CPU上的线程都能读取到这些数据的最新版本。</p><p>JMM把内存屏障指令分为4类</p><table><thead><tr><th>屏障类型</th><th>指令示例</th><th>说明</th></tr></thead><tbody><tr><td>LoadLoad Barriers</td><td>Load1;LoadLoad;Load2</td><td>确保Load1数据的装载，之前于Load2及所有后续装载指令的装载。</td></tr><tr><td>StoreStore Barriers</td><td>Store1;StoreStore;Store2</td><td>确保Store1数据对其他处理器可见（刷新到内存），之前于Store2及所有后续存储指令的存储。</td></tr><tr><td>LoadStore Barriers</td><td>Load1;LoadStore;Store2</td><td>确保Load1数据装载，之前于Store2及所有后续存储指令刷新到内存。</td></tr><tr><td>StoreLoad Barriers</td><td>Store1;StoreLoad;Load2</td><td>确保Strore1数据对其他处理器可见（刷新到内存），之前于Load2及所有后续装载指令的装载。StoreLoad Barriers会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令。</td></tr></tbody></table><p>StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。现代的多处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。</p><h4 id="临界区"><a href="#临界区" class="headerlink" title="临界区"></a>临界区</h4><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic15.png" srcset="/img/loading.gif" class=""><p>JMM会在退出临界区和进入临界区这两个关键时间点做一些特别处理，使得多线程在这两个时间点按某种顺序执行。</p><p>临界区内的代码则可以重排序（但JMM不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。虽然线程A在临界区内做了重排序，但由于监视器互斥执行的特性，这里的线程B根本无法“观察”到线程A在临界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。</p><p>因为临界区内的代码依然会重排序，所以线程安全的单例模式中一般的双重检查并不能保证真正的线程安全。</p><h2 id="Happens-Before"><a href="#Happens-Before" class="headerlink" title="Happens-Before"></a>Happens-Before</h2><p>在Java 规范提案中为让大家理解内存可见性的这个概念，提出了happens-before的概念来阐述操作之间的内存可见性。对应Java程序员来说，理解happens-before是理解JMM的关键。</p><p>JMM这么做的原因是：程序员对于这两个操作是否真的被重排序并不关心，程序员关心的是程序执行时的语义不能被改变（即执行结果不能被改变）。因此，happens-before关系本质上和as-if-serial语义是一回事。as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证<strong>正确同步</strong>的多线程程序的执行结果不被改变。</p><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>用happens-before的概念来阐述操作之间的内存可见性。在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系 。 </p><p>两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）</p><h3 id="加深理解"><a href="#加深理解" class="headerlink" title="加深理解"></a>加深理解</h3><ol><li><p>站在Java程序员的角度来说：JMM保证，如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。</p></li><li><p>站在编译器和处理器的角度来说：JMM允许，两个操作之间存在happens-before关系，不要求Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序是允许的。</p></li></ol><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><pre><code>double x = 0.03;  //Adouble y = 0.01;  //Bdouble z = x*x*y; //C</code></pre><p>此时代码的逻辑顺序：</p><ol><li><p>A happens-before B</p></li><li><p>B happens-before C</p></li><li><p>A happens-before C</p></li></ol><p>但是仔细考察，2、3是必需的，而1并不是必需的，因此JMM对这三个happens-before关系的处理就分为两类：</p><ol><li><p>会改变程序执行结果的重排序</p></li><li><p>不会改变程序执行结果的重排序</p></li></ol><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic16.png" srcset="/img/loading.gif" class=""><p>JMM对这两种不同性质的重排序，采用了不同的策略，如下：</p><ol><li><p>对于会改变程序执行结果的重排序，JMM要求编译器和处理器必须禁止这种重排序；</p></li><li><p>对于不会改变程序执行结果的重排序，JMM对编译器和处理器不做要求。</p></li></ol><p>于是，站在我们程序员的角度，看起来这个三个操作满足了happens-before关系，而站在编译器和处理器的角度，进行了重排序，而排序后的执行结果，也是满足happens-before关系的。</p><h3 id="Happens-Before规则"><a href="#Happens-Before规则" class="headerlink" title="Happens-Before规则"></a>Happens-Before规则</h3><p>JMM为我们提供了以下的Happens-Before规则：</p><ol><li><p>程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。</p></li><li><p>监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。</p></li><li><p>volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。</p></li><li><p>传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。</p></li><li><p>start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。</p></li><li><p>join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。 </p></li><li><p>线程中断规则：对线程interrupt方法的调用happens-before于被中断线程的代码检测到中断事件的发生。</p></li></ol><h2 id="volatile详解"><a href="#volatile详解" class="headerlink" title="volatile详解"></a>volatile详解</h2><h3 id="volatile特性"><a href="#volatile特性" class="headerlink" title="volatile特性"></a>volatile特性</h3><p>可以把对volatile变量的单个读/写，看成是使用同一个锁对这些单个读/写操作做了同步</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic17.png" srcset="/img/loading.gif" class=""><p>可以看成</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic18.png" srcset="/img/loading.gif" class=""><p>所以volatile变量自身具有下列特性：</p><ul><li><p>可见性。对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。</p></li><li><p>原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。</p></li></ul><h3 id="volatile的内存语义"><a href="#volatile的内存语义" class="headerlink" title="volatile的内存语义"></a>volatile的内存语义</h3><p>内存语义：可以简单理解为 volatile，synchronize，atomic，lock 之类的在 JVM 中的内存方面实现原则。</p><p>volatile写的内存语义如下：<br>当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。 </p><p>volatile读的内存语义如下：<br>当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。 </p><p>所以对于代码</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic19.png" srcset="/img/loading.gif" class=""><p>如果我们将<strong>flag</strong>变量以<strong>volatile</strong>关键字修饰，那么实际上：线程A在写flag变量后，本地内存A中被线程A更新过的两个共享变量的值都被刷新到主内存中。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic20.png" srcset="/img/loading.gif" class=""><p>在读flag变量后，本地内存B包含的值已经被置为无效。此时，线程B必须从主内存中读取共享变量。线程B的读取操作将导致本地内存B与主内存中的共享变量的值变成一致。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic21.png" srcset="/img/loading.gif" class=""><p>如果我们把volatile写和volatile读两个步骤综合起来看的话，在读线程B读一个volatile变量后，写线程A在写这个volatile变量之前所有可见的共享变量的值都将立即变得对读线程B可见。</p><h3 id="为何volatile不是线程安全的"><a href="#为何volatile不是线程安全的" class="headerlink" title="为何volatile不是线程安全的"></a>为何volatile不是线程安全的</h3><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic22.png" srcset="/img/loading.gif" class=""><p>由于volatile只对任意单个volatile变量的读/写具有原子性，但volatile++这种复合操作并不具有原子性，所以仅仅依靠volatile而不对使用过程进行同步控制是不能保证线程安全的。</p><h3 id="volatile内存语义的实现"><a href="#volatile内存语义的实现" class="headerlink" title="volatile内存语义的实现"></a>volatile内存语义的实现</h3><h4 id="volatile重排序规则表"><a href="#volatile重排序规则表" class="headerlink" title="volatile重排序规则表"></a>volatile重排序规则表</h4><table><thead><tr><th>第一个操作/第二个操作</th><th>普通读/写</th><th>volatile读</th><th>volatile写</th></tr></thead><tbody><tr><td><strong>普通读/写</strong></td><td></td><td></td><td>不允许</td></tr><tr><td><strong>volatile读</strong></td><td>不允许</td><td>不允许</td><td>不允许</td></tr><tr><td><strong>volatile写</strong></td><td></td><td>不允许</td><td>不允许</td></tr></tbody></table><h4 id="volatile的内存屏障"><a href="#volatile的内存屏障" class="headerlink" title="volatile的内存屏障"></a>volatile的内存屏障</h4><p>在Java中对于volatile修饰的变量，编译器在生成字节码时，会在指令序列中插入<strong>内存屏障</strong>来禁止特定类型的处理器重排序问题。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic23.png" srcset="/img/loading.gif" class=""><p>storestore屏障：对于这样的语句store1;storestore;store2，在store2及后续写入操作执行前，保证store1的写入操作对其它处理器可见。（也就是说如果出现storestore屏障，那么store1指令一定会在store2之前执行，CPU不会store1与store2进行重排序）</p><p>storeload屏障：对于这样的语句store1;storeload;load2，在load2及后续所有读取操作执行前，保证store1的写入对所有处理器可见。（也就是说如果出现storeload屏障，那么store1指令一定会在load2之前执行，CPU不会对store1与load2进行重排序）</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic24.png" srcset="/img/loading.gif" class=""><p>在每个volatile读操作的后面插入LoadLoad屏障、loadstore屏障。</p><p>loadload屏障：对于这样的语句load1; loadload; load2，在load2及后续读取操作要读取的数据被访问前，保证load1要读取的数据被读取完毕。（也就是说，如果出现loadload屏障，那么load1指令一定会在load2之前执行，CPU不会对load1与load2进行重排序） </p><p>loadstore屏障：对于这样的语句load1; loadstore; store2，在store2及后续写入操作被刷出前，保证load1要读取的数据被读取完毕。（也就是说，如果出现loadstore屏障，那么load1指令一定会在store2之前执行，CPU不会对load1与store2进行重排序）</p><h3 id="volatile的实现原理"><a href="#volatile的实现原理" class="headerlink" title="volatile的实现原理"></a>volatile的实现原理</h3><p>通过对OpenJDK中的unsafe.cpp源码的分析，会发现被volatile关键字修饰的变量会存在一个“lock:”的前缀。</p><p>Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。</p><p>同时该指令会将当前处理器缓存行的数据直接写会到系统内存中，且这个写回内存的操作会使在其他CPU里缓存了该地址的数据无效。</p><p>在具体的执行上，它先对总线和缓存加锁，然后执行后面的指令，最后释放锁后会把高速缓存中的脏数据全部刷新回主内存。在Lock锁住总线的时候，其他CPU的读写请求都会被阻塞，直到锁释放。</p><h2 id="final的内存语义"><a href="#final的内存语义" class="headerlink" title="final的内存语义"></a>final的内存语义</h2><h3 id="编译器和处理器要遵守的两个重排序规则"><a href="#编译器和处理器要遵守的两个重排序规则" class="headerlink" title="编译器和处理器要遵守的两个重排序规则"></a>编译器和处理器要遵守的两个重排序规则</h3><ol><li><p><strong>在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。</strong></p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic25.png" srcset="/img/loading.gif" class=""><p>我们假设一个线程A执行writer方法，随后另一个线程B执行reader方法。</p><p>write()方法中只包含一行代码 <em>obj</em> = new FinalMemory();。这一行代码包含两个步骤：</p><ol><li>构造一个FinalMemory类型的对象。</li><li>把这个对象的引用赋值给引用变量obj。</li></ol><p>假设线程B读对象引用（FinalMemory object = obj）与读对象的成员域之间（int a = object.i;int b = object.j）没有重排序，下面的图是一种可能的执行时序：</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic26.png" srcset="/img/loading.gif" class=""><p>从上面可能的时序图中我们可以看到，读普通域被编译器重排序到了构造函数执行之前，读线程B错误的读取了普通变量i初始化之前的值。而写final域的操作，被写final域的重排序规则“限制”到了构造函数之内，读线程B正确读取了final变量初始化之后的值。</p><p>总结：写final域的重排序规则可以确保在对象引用为任意线程可见之前，对象的final域已经被正常的初始化了，而普通域不具有这样的保证。</p></li><li><p><strong>初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。</strong></p><p>在一个线程中，初次读对象引用与初次读该对象包含的final域，JMM禁止处理器重排序这两个操作。编译器会在读final域操作的前面插入一个LoadLoad屏障。</p><p>reader()方法包含3个步骤：</p><ol><li><p>初次读引用变量obj</p></li><li><p>初次读引用变量obj指向对象的普通域 i</p></li><li><p>初次读引用变量obj指向对象的final域 j</p></li></ol><p>我们假设写线程A没有发生任何重排序，则下图是一种可能的时序：</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic27.png" srcset="/img/loading.gif" class=""><p>读对象的普通域的操作被处理器重排序到读对象引用之前。读普通域时，该域还没有被线程A写入，所以上面的是一个错误的读取操作。但是读final域的重排序规则把读对象final域的操作“限定”在读对象引用之后，该final域已经被A线程初始化了，是一个正确的读取操作。</p><p>总结：读final域的重排序规则可以确保在读一个对象的final域之前，一定会先读包含这个final域的对象的引用.</p></li></ol><h3 id="final域为引用类型"><a href="#final域为引用类型" class="headerlink" title="final域为引用类型"></a>final域为引用类型</h3><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic28.png" srcset="/img/loading.gif" class=""><p>在上面的代码中，final域是一个引用类型，它引用了一个int类型的数组，对于引用类型，写final域的重排序规则对编译器和处理器增加了一下的约束：在构造函数内对一个final引用的对象的成员域的写入，与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。</p><p>我们假设线程A先执行write0操作，执行完后线程B执行write1操作，执行完后线程C执行reader操作，下图是一种可能的执行时序：</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic29.png" srcset="/img/loading.gif" class=""><p>1是对final域的写入，2是对这个final域引用的对象的成员域的写入，3是把被构造的对象的引用赋值给某个引用变量。这里除了前面提到的1不能和3重排序外，2和3也不能重排序。</p><p>JMM可以确保读线程C至少能看到写线程A在构造函数中对final引用对象的成员域的写入。即C至少能看到数组下标0的值为1。而写线程B对数组元素的写入，读线程C可能看得到，也可能看不到。JMM不保证线程B的写入对读线程C可见，因为写线程B和读线程C之间存在数据竞争，此时的执行结果不可预知。</p><p>如果想要确保读线程C看到写线程B对数组元素的写入，写线程B和读线程C之间需要使用同步（lock或volatile）来确保内存可见性。</p><h3 id="final引用不能从构造函数内逃逸"><a href="#final引用不能从构造函数内逃逸" class="headerlink" title="final引用不能从构造函数内逃逸"></a>final引用不能从构造函数内逃逸</h3><p>写final域的重排序规则可以确保：在引用变量为任意线程可见之前，该引用变量指向的对象的final域已经在构造函数中被正确初始化过了。其实，要得到这个效果，还需要一个保证：在构造函数内部，不能让这个被构造对象的引用为其他线程所见，也就是对象引用不能在构造函数中逃逸。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic30.png" srcset="/img/loading.gif" class=""><p>假设一个线程A执行writer()方法，另一个线程B执行reader()方法。这里的操作2使得对象还未完成构造前就为线程B可见。即使这里的操作2是构造函数的最后一步，且在程序中操作2排在操作1后面，执行read()方法的线程仍然可能无法看到final域被初始化后的值，因为这里的操作1和操作2之间可能被重排序。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic31.png" srcset="/img/loading.gif" class=""><p>因此在构造函数返回前，被构造对象的引用不能为其他线程所见，因为此时的final域可能还没有被初始化。</p><h3 id="final语义的实现"><a href="#final语义的实现" class="headerlink" title="final语义的实现"></a>final语义的实现</h3><p>会要求编译器在final域的写之后，构造函数return之前插入一个StoreStore障屏。</p><p>读final域的重排序规则要求编译器在读final域的操作前面插入一个LoadLoad屏障</p><h2 id="锁的内存语义"><a href="#锁的内存语义" class="headerlink" title="锁的内存语义"></a>锁的内存语义</h2><p>当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中。</p><p>当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。 </p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic32.png" srcset="/img/loading.gif" class=""><p>如果我们回顾第一章的VolatileCase，我们知道，为了让子线程可以及时看到<em>ready</em>变量的修改，我们需要将ready变量以volatile来修饰。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic33.png" srcset="/img/loading.gif" class=""><p>但是，当我们将程序做如下改造</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic34.png" srcset="/img/loading.gif" class=""><p>我们可以看见子线程同样可以中止，为何？我们观察System.out.println的实现，</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic35.png" srcset="/img/loading.gif" class=""><p>结合前面锁的内存语义，我们可以知道，当进入<strong>synchronized</strong>语句块时，子线程会被强制从主内存中读取共享变量，其中就包括了ready变量，所以子线程同样中止了。</p><h2 id="synchronized的实现原理"><a href="#synchronized的实现原理" class="headerlink" title="synchronized的实现原理"></a>synchronized的实现原理</h2><p>Synchronized在JVM里的实现都是基于进入和退出Monitor对象来实现方法同步和代码块同步，虽然具体实现细节不一样，但是都可以通过成对的MonitorEnter和MonitorExit指令来实现。</p><p>对同步块，MonitorEnter指令插入在同步代码块的开始位置，当代码执行到该指令时，将会尝试获取该对象Monitor的所有权，即尝试获得该对象的锁，而monitorExit指令则插入在方法结束处和异常处，JVM保证每个MonitorEnter必须有对应的MonitorExit。</p><p>对同步方法，从同步方法反编译的结果来看，方法的同步并没有通过指令monitorenter和monitorexit来实现，相对于普通方法，其常量池中多了ACC_SYNCHRONIZED标示符。</p><p>JVM就是根据该标示符来实现方法的同步的：当方法被调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。</p><p>synchronized使用的锁是存放在Java对象头里面。</p><table><thead><tr><th>长度</th><th>内容</th><th>说明</th></tr></thead><tbody><tr><td>32/64bit</td><td>Mark Word</td><td>存储对象的hashCode或锁信息等</td></tr><tr><td>32/64bit</td><td>Class Metadata Address</td><td>存储对象类型的数据的指针</td></tr><tr><td>32/64bit</td><td>Array length</td><td>数组的长度（如果当前对象是数组）</td></tr></tbody></table><p>具体位置是对象头里面的MarkWord，MarkWord里默认数据是存储对象的HashCode等信息，</p><table><thead><tr><th>锁状态</th><th>25bit</th><th>4bit</th><th>1bit是否是偏向锁</th><th>2bit锁标识位</th></tr></thead><tbody><tr><td>无锁状态</td><td>对象的hashCode</td><td>对象分代年龄</td><td>0</td><td>0</td></tr></tbody></table><p>但是会随着对象的运行改变而发生变化，不同的锁状态对应着不同的记录存储方式</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic36.png" srcset="/img/loading.gif" class=""><h2 id="了解各种锁"><a href="#了解各种锁" class="headerlink" title="了解各种锁"></a>了解各种锁</h2><h3 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。</p><p>但是线程自旋是需要消耗CPU的，说白了就是让CPU在做无用功，线程不能一直占用CPU自旋做无用功，所以需要设定一个自旋等待的最大时间。</p><p>如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。</p><h4 id="自旋锁的优缺点"><a href="#自旋锁的优缺点" class="headerlink" title="自旋锁的优缺点"></a>自旋锁的优缺点</h4><p>在锁的竞争不激烈，且占用锁的同步块执行时间非常短的情况下，自旋的消耗小于线程阻塞挂起操作的消耗，这时自旋锁能够尽可能的减少线程的阻塞，提升代码块性能。</p><p>但是如果锁的竞争激烈，或者占用锁的同步块执行时间比较长，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用cpu做无用功，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要cup的线程又不能获取到cpu，造成cpu的浪费。</p><h4 id="自旋锁时间阈值"><a href="#自旋锁时间阈值" class="headerlink" title="自旋锁时间阈值"></a>自旋锁时间阈值</h4><p>自旋锁的目的是为了占着CPU的资源不释放，等到获取到锁立即进行处理。但是如何去选择自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用CPU资源，进而会影响整体系统的性能。因此自旋次数很重要</p><p>JVM对于自旋次数的选择，jdk1.5默认为10次，在1.6引入了适应性自旋锁，适应性自旋锁意味着自旋的时间不在是固定的了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间。</p><p>JDK1.6中-XX:+UseSpinning开启自旋锁； JDK1.7后，去掉此参数，由jvm控制；</p><h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，只有一个线程访问锁，不存在多线程竞争的情况，则线程是不需要触发同步的，减少加锁／解锁的一些CAS操作（比如等待队列的一些CAS操作），这种情况下，就会给线程加一个偏向锁。 如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。它通过消除资源无竞争情况下的同步原语，进一步提高了程序的运行性能。</p><h4 id="引入背景"><a href="#引入背景" class="headerlink" title="引入背景"></a>引入背景</h4><p>大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁，减少不必要的CAS操作。</p><h4 id="锁的状态"><a href="#锁的状态" class="headerlink" title="锁的状态"></a>锁的状态</h4><p>一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，目的是为了提高获得锁和释放锁的效率。</p><h4 id="偏向锁获取过程"><a href="#偏向锁获取过程" class="headerlink" title="偏向锁获取过程"></a>偏向锁获取过程</h4><ol><li><p>访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，确认为可偏向状态。</p></li><li><p>如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤5，否则进入步骤3。</p></li><li><p>如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。</p></li><li><p>如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the word）</p></li><li><p>执行同步代码。</p></li></ol><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic37.png" srcset="/img/loading.gif" class=""><h4 id="偏向锁的释放"><a href="#偏向锁的释放" class="headerlink" title="偏向锁的释放"></a>偏向锁的释放</h4><p>偏向锁的撤销在上述第四步骤中有提到。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放偏向锁，线程不会主动去释放偏向锁。偏向锁的撤销需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。</p><h4 id="偏向锁的适用场景"><a href="#偏向锁的适用场景" class="headerlink" title="偏向锁的适用场景"></a>偏向锁的适用场景</h4><p>始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the word操作； </p><p>在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向所的时候会导致进入安全点，安全点会导致stw，导致性能下降，这种情况下应当禁用。</p><h4 id="jvm开启-关闭偏向锁"><a href="#jvm开启-关闭偏向锁" class="headerlink" title="jvm开启/关闭偏向锁"></a>jvm开启/关闭偏向锁</h4><p>开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0</p><p>关闭偏向锁：-XX:-UseBiasedLocking</p><h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>轻量级锁是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁。</p><h4 id="轻量级锁的加锁过程"><a href="#轻量级锁的加锁过程" class="headerlink" title="轻量级锁的加锁过程"></a>轻量级锁的加锁过程</h4><ol><li><p>在代码进入同步块的时候，如果同步对象锁状态为无锁状态且不允许进行偏向（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。</p></li><li><p>拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock record里的owner指针指向object mark word。</p></li><li><p>如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态</p></li><li><p>如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，当竞争线程尝试占用轻量级锁失败多次之后，轻量级锁就会膨胀为重量级锁，重量级线程指针指向竞争线程，竞争线程也会阻塞，等待轻量级线程释放锁后唤醒他。锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。</p></li></ol><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic38.png" srcset="/img/loading.gif" class=""><h3 id="不同锁的比较"><a href="#不同锁的比较" class="headerlink" title="不同锁的比较"></a>不同锁的比较</h3><table><thead><tr><th>锁</th><th>优点</th><th>缺点</th><th>适用场景</th></tr></thead><tbody><tr><td>偏向锁</td><td>加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。</td><td>如果线程间存在锁竞争,会带来额外的锁撤销的消耗。</td><td>适用于只有一个线程访问同步块场景。</td></tr><tr><td>轻量级锁</td><td>竞争的线程不会阻塞，提高了程序的响应速度。</td><td>如果线程始终得不到锁，使用自旋会消耗CPU。</td><td>追求响应时间。同步块执行速度非常快</td></tr><tr><td>重量级锁</td><td>线程竞争不使用自旋，不会消耗CPU.</td><td>线程阻塞,响应时间缓慢。</td><td>追求吞吐量。同步块执行速度较长。</td></tr></tbody></table><h3 id="JDK对锁的更多优化措施"><a href="#JDK对锁的更多优化措施" class="headerlink" title="JDK对锁的更多优化措施"></a>JDK对锁的更多优化措施</h3><h4 id="逃逸分析"><a href="#逃逸分析" class="headerlink" title="逃逸分析"></a>逃逸分析</h4><p>如果证明一个对象不会逃逸方法外或者线程外，则可针对此变量进行优化。</p><p>同步消除synchronization Elimination，如果一个对象不会逃逸出线程，则对此变量的同步措施可消除。</p><h4 id="锁消除和粗化"><a href="#锁消除和粗化" class="headerlink" title="锁消除和粗化"></a>锁消除和粗化</h4><p>锁消除：虚拟机的运行时编译器在运行时如果检测到一些要求同步的代码上不可能发生共享数据竞争，则会去掉这些锁。</p><p>锁粗化：将临近的代码块用同一个锁合并起来。</p><p>消除无意义的锁获取和释放，可以提高程序运行性能。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>实战项目</title>
    <link href="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/"/>
    <url>/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/</url>
    
    <content type="html"><![CDATA[<h2 id="可查询进度的并发任务执行框架"><a href="#可查询进度的并发任务执行框架" class="headerlink" title="可查询进度的并发任务执行框架"></a>可查询进度的并发任务执行框架</h2><h3 id="需求的产生和分析"><a href="#需求的产生和分析" class="headerlink" title="需求的产生和分析"></a>需求的产生和分析</h3><p>公司里有两个项目组，考试组有批量的离线文档要生成，题库组则经常有批量的题目进行排重和根据条件批量修改题目的内容。</p><p>架构组通过对实际的上线产品进行用户调查，发现这些功能在实际使用时，用户都反应速度很慢，而且提交任务后，不知道任务的进行情况，做没做？做到哪一步了？有哪些成功？哪些失败了？都一概不知道。</p><p>架构组和实际的开发人员沟通，他们都说，因为前端提交任务到Web后台以后，是一次要处理多个文档和题目，所以速度快不起来。提示用多线程进行改进，实际的开发人员表示多线程没有用过，不知道如何使用，也担心用不好。综合以上情况，架构组决定在公司的基础构件库中提供一个并发任务执行框架，以解决上述用户和业务开发人员的痛点：</p><ol><li><p>对批量型任务提供统一的开发接口</p></li><li><p>在使用上尽可能的对业务开发人员友好  </p></li><li><p>要求可以查询批量任务的执行进度</p></li></ol><h3 id="如何实现"><a href="#如何实现" class="headerlink" title="如何实现"></a>如何实现</h3><p>要实现这么一个批量任务并发执行的框架，我们来分析一下我们要做些什么？</p><ol><li><p>提高批量任务性能。必然的我们要使用java里的多线程，为了在使用上尽可能的对业务开发人员友好和简单，需要屏蔽一些底层java并发编程中的细节，让他们不需要去了解并发容器，阻塞队列，异步任务，线程安全等等方面的知识，只要专心于自己的业务处理即可。</p></li><li><p>每个批量任务拥有自己的上下文环境。因为一个项目组里同时要处理的批量任务可能有多个，比如考试组，可能就会有不同的学校的批量的离线文档生成，而题库组则会不同的学科都会有老师同时进行工作，因此需要一个并发安全的容器保存每个任务的属性信息，</p></li><li><p>自动清除已完成和过期任务。因为要提供进度查询，系统需要在内存中维护每个任务的进度信息以供查询，但是这种查询又是有时间限制的，一个任务完成一段时间后，就不再提供进度查询了，则就需要我们自动清除已完成和过期任务，用定时轮询吗？</p></li></ol><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic1.png" srcset="/img/loading.gif" class=""><h3 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h3><ol><li><p>框架使用者业务方法的执行结果共有三种，成功：按预想的流程出了结果；失败：按预想的流程没出结果；异常：没按预想的流程抛出了预料之外的错误。因此我们定义了一个枚举，表示这三种情况。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic2.png" srcset="/img/loading.gif" class=""><p>业务方法的返回值有很多种可能，基本类型、系统定义的对象类型、框架使用者自定义的对象类型都是存在的，所以需要用泛型来说表示这个结果。如果方法执行失败了，还需要告诉用户或者框架使用者失败的原因，还需要再定义一个任务的执行结束后的返回值类。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic3.png" srcset="/img/loading.gif" class=""></li><li><p>定义执行业务方法的接口，框架就只执行这个方法，框架的使用者都应该来实现这个接口，由于用户业务的数据多样性，方法的参数也应该用泛型。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic4.png" srcset="/img/loading.gif" class=""></li><li><p>提供一种封装机制，让框架使用者可以将用户在前端提交的工作（JOB）提交给这个封装机制，当用户的需要查询进度的时候，也从这个封装机制中取得，同时封装机制内部也要负责清除已完成任务。</p><p>在这个封装机制里我们定义了一个类JobInfo，抽象了对用户工作（JOB）的封装，一个工作可以包含多个子任务（TASK），这个JobInfo中就包括了这个工作的相关信息，比如工作名，用以区分框架中唯一的工作，也可以避免重复提交，也方便查询时快速定位工作，除了工作名以外，工作中任务（TASK）的列表，工作中任务的处理器都在其中定义。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic5.png" srcset="/img/loading.gif" class=""><p>同时JobInfo还有相当多的关于这个工作的方法，比如查询工作进度，查询每个任务的处理结果，记录每个任务的处理结果等等</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic6.png" srcset="/img/loading.gif" class=""><p>负责清除已完成任务，我们则交给CheckJobProcesser类来完成，定时轮询的机制不够优雅，因此我们选用了DelayQueue来实现这个功能</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic7.png" srcset="/img/loading.gif" class=""><p>并且在其中定义了清除已完成任务的Runnable和相关的工作线程。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic8.png" srcset="/img/loading.gif" class=""></li><li><p>框架的主体类则是PendingJobPool，这也是框架使用者主要使用的类。这个类主要负责调度，例如工作（JOB）和任务（TASK）的提交，任务（TASK）的保存，任务（TASK）的并发执行，工作进度的查询接口和任务执行情况的查询等等。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic9.png" srcset="/img/loading.gif" class=""><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic10.png" srcset="/img/loading.gif" class=""></li></ol><h3 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h3><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic11.png" srcset="/img/loading.gif" class=""><p>如果需要spring集成的话，某些单例化的部分就不需要了。</p><h2 id="项目优化"><a href="#项目优化" class="headerlink" title="项目优化"></a>项目优化</h2><h3 id="项目背景和问题"><a href="#项目背景和问题" class="headerlink" title="项目背景和问题"></a>项目背景和问题</h3><p>这个项目来自为电信教育系统设计开发的一套自适应的考试学习系统，面向的用户主要是职业学院的的老师和学生以及短时间脱产学习的在职人员。什么叫自适应呢？就是当时提出一种教育理念，对学员的学习要求经常考试进行检查，学员的成绩出来以后，老师会要求系统根据每个学员的考卷上错误的题目从容量为10万左右的题库中抽取题目，为每个学员生成一套各自个性化的考后复习和练习的离线练习册。所以，每次考完试，特别是比较大型的考试后，要求生成的离线文档数量是比较多的，一个考试2000多人，就要求生成2000多份文档。当时我们在做这个项目的时候，因为时间紧，人员少，很快做出第一版就上线运营了。</p><p>当然，大家可以想到，问题是很多的，但是反应最大，用户最不满意的就是这个离线文档生成的功能，用户最不满意的点：离线文档生成的速度非常慢，慢到什么程度呢？一份离线文档的生成平均时长在50~55秒左右，遇到成绩不好的学生，文档内容多的，生成甚至需要3分钟，大家可以算一下，2000人，平均55秒，全部生成完，需要2000*55=110000秒，大约是30个小时。</p><p>为什么如此之慢？这跟离线文档的生成机制密切相关，对于每一个题目要从保存题库的数据库中找到需要的题目，单个题目的表现形式如图，数据库中存储则采用类html形式保存，对于每个题目而言，解析题目文本，找到需要下载的图片，每道题目都含有大量或大型的图片需要下载，等到文档中所有题目图片下载到本地完成后，整个文档才能继续进行处理。</p><h3 id="分析和改进"><a href="#分析和改进" class="headerlink" title="分析和改进"></a>分析和改进</h3><p>第一版的实现，服务器在接收到老师的请求后，就会把批量生成请求分解为一个个单独的任务，然后串行的完成。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic12.png" srcset="/img/loading.gif" class=""><p>于是在第二版的实现上，首先我们做了个服务拆分，将生成离线文档的功能拆了出来成为了单独的服务，对外提供RPC接口，在WEB服务器接收到了老师们提出的批量生成离线文档的要求以后，将请求拆分后再一一调用离线文档生成RPC服务，这个RPC服务在实现的时候有一个缓冲的机制，会将收到的请求进行缓存，然后迅速返回一个结果给调用者，告诉调用者已经收到了请求，这样WEB服务器也可以很快的对用户的请求进行应答。</p><p>所以我们有了第一次改进，参见cn.enjoyedu.ch8b. RpcServiceWebV1</p><p> 我们看这个离线文档，每份文档的生成独立性是很高的，天生就适用于多线程并发进行。所以在RPC服务实现的时候，使用了生产者消费者模式，RPC接口的实现收到了一个调用方的请求时，会把请求打包放入一个容器，然后会有多个线程进行消费处理，也就是生成每个具体文档。</p><p>当文档生成后，再使用一次生产者消费者模式，投入另一个阻塞队列，由另外的一组线程负责进行上传。当上传成功完成后，由上传线程返回文档的下载地址，表示当前文档已经成功完成。</p><p>文档具体的下载地址则由WEB服务器单独去数据库或者缓存中去查询。</p><p><img src="blob:file:///808f1ea5-3745-41ac-b3fb-dac06fe50317" srcset="/img/loading.gif" alt="pastedGraphic_1.png"></p><p>对于每个离线文档生成本身，我们来看看它的业务，</p><p>1、从容量为10万左右的题库中为每个学生抽取适合他的题目，</p><p>2、每道题目都含有大量的图片需要下载到本地，和文字部分一起渲染。</p><p>但是我们仔细考察整个系统的业务就会发现，我们是在一次考试后为学员生成自适应的练习册，换句话说，不管考试考察的内容如何，学生的成绩如何，每次考试的知识点是有限的，而从这些知识点中可以抽取的相关联的题目数也总是有限的，不同的学生之间所需要的题目会有很大的重复性。</p><p>举个例子我们为甲学生因为他考卷上的错误部分抽取了80个题目，有很大的概率其他学生跟甲学生错误的地方会有重复，相对应的题目也会有重复。对于这部分题目，我们是完全没有必要重复处理的，包括从数据库中重新获取题目、解析和下载图片。这也是我们可供优化的一大突破点。</p><p>其次，一篇练习册是由很多的题目组成的，每个题目相互之间是独立的，我们也可以完全并行的、异步的处理每个题目。</p><p>具体怎么做？要避免重复工作肯定是使用缓存机制，对已处理过的题目进行缓存。我们看看怎么使用缓存机制进行优化。这个业务，毋庸置疑，map肯定是最适合的，因为我们要根据题目的id来找题目的详情，用哪个map？我们现在是在多线程下使用，考虑的是并发安全的concurrentHashMap。</p><p>当我们的服务接收到处理一个题目的请求，首先会在缓存中get一次，没有找到，可以认为这是个新题目，准备向数据库请求题目数据并进行题目的解析，图片的下载。</p><p>这里有一个并发安全的点需要注意，因为是多线程的应用，会发生多个线程在处理多个文档时有同时进行处理相同题目的情况，这种情况下不做控制，一是会造成数据冲突和混乱，比如同时读写同一个磁盘文件，二是会造成计算资源的浪费，同时为了防止文档的生成阻塞在当前题目上，因此每个新题目的处理过程会包装成一个Callable投入一个线程池中 而把处理结果作为一个Future返回，等到线程在实际生成文档时再从Future中get出结果进行处理。因此在每个新题目实际处理前，还会检查当前是否有这个题目的处理任务正在进行。</p><p>如果题目在缓存中被找到，并不是直接引用就可以了，因为题库中的题目因为种种关系存在被修改的可能，比如存在错误，比如可能内容被替换，这个时候缓存中数据其实是失效过期的，所以需要先行检查一次。如何检查？</p><p>我们前面说过题库中的题目平均长度在800个字节左右，直接equals来检查题目正文是否变动过，明显效率比较低，所以我们这里又做了一番处理，什么处理？对题目正文事先做了一次SHA的摘要并保存在数据库，并且要求题库开发小组在处理题目数据入库的时候进行SHA摘要。</p><p>在本机缓存中同样保存了这个摘要信息，在比较题目是否变动过时，首先检查摘要是否一致，摘要一致说明题目不需要更新，摘要不一致时，才需要更新题目文本，将这个题目视为新题目，进入新题目的处理流程，这样的话就减少了数据的传输量，也降低了数据库的压力。</p><p>题目处理的流程就变为：</p><p><img src="blob:file:///5a45d7e5-6994-4eae-9ff7-7feb13186194" srcset="/img/loading.gif" alt="pastedGraphic_2.png"></p><p>所以我们有了第二次改进，</p><p>1、在题目实体类QuestionInDBVo中增加一个</p><p><img src="blob:file:///0d5213fa-8bc0-435c-8088-3bded0d7bd21" srcset="/img/loading.gif" alt="pastedGraphic_3.png"></p><p>2、增加一个题目保存在缓存中的实体类QuestionInCacheVo</p><p><img src="blob:file:///c567de1d-7575-4bd9-8a0b-ec9949b5aacd" srcset="/img/loading.gif" alt="pastedGraphic_4.png"></p><p>3、增加一个并发处理时返回的题目结果实体类TaskResultVo</p><p><img src="blob:file:///658f3823-8257-49ac-a425-0ed1517749e9" srcset="/img/loading.gif" alt="pastedGraphic_5.png"></p><p>按照我们前面的描述，我们可以得知，题目要么已经处理完成，要么正在处理，所以在获取题目结果时，先从questionDetail获取一次，获取为null，则从questionFuture获取。那么这个类的构造方法需要单独处理一下。</p><p><img src="blob:file:///e07738ef-3a22-46fa-9e04-43ce2bad9014" srcset="/img/loading.gif" alt="pastedGraphic_6.png"></p><p>4、在处理文档的服务的类ProduceDocService中增加一个处理文档的新方法makeDocAsyn</p><p><img src="blob:file:///40cc1cc3-ddc5-40ed-95fe-4dc65cfd87ae" srcset="/img/loading.gif" alt="pastedGraphic_7.png"></p><p>在这个方法中，会调用一个并发处理题目的方法。</p><p>5、增加一个优化题目处理的类ParallelQstService，其中提供了并发处理题目的方法，还包括了</p><p><img src="blob:file:///4f69b9df-654b-4d27-b6ca-0eb2ae208a22" srcset="/img/loading.gif" alt="pastedGraphic_8.png"></p><p>主程序参见cn.enjoyedu.ch8b. RpcServiceWebV2</p><p><strong>继续改进</strong></p><p><strong>数据结构的改进</strong></p><p>但是我们仔细分析就会发现，作为一个长期运行的服务，如果我们使用concurrentHashMap，意味着随着时间的推进，缓存对内存的占用会不断的增长。最极端的情况，十万个题目全部被加载到内存，这种情况下会占据多少内存呢？我们做了统计，题库中题目的平均长度在800个字节左右，十万个题目大约会使用75M左右的空间。</p><p>看起来还好，但是有几点，第一，我们除了题目本身还会有其他的一些附属信息需要缓存，比如题目图片在本地磁盘的存储位置等等，那就说，实际缓存的数据内容会远远超过800个字节，</p><p>第二，map类型的的内存使用效率是比较低的，以hashmap为例，内存利用率一般只有20%到40%左右，而concurrentHashMap只会更低，有时候只有hashmap的十分之一到4分之一，这也就是说十万个题目放在concurrentHashMap中会实际占据几百兆的内存空间，是很容易造成内存溢出的，也就是大家常见的OOM。</p><p>考虑到这种情况，我们需要一种数据结构有map的方便但同时可以限制内存的占用大小或者可以根据需要按照某种策略刷新缓存。最后，在实际的工作中，我们选择了ConcurrentLinkedHashMap，这是由Google开源一个线程安全的hashmap，它本身是对ConcurrentHashMap的封装，可以限定最大容量，并实现一个了基于LRU也就是最近最少使用算法策略的进行更新的缓存。很完美的契合了我们的要求，对于已经缓冲的题目，越少使用的就可以认为这个题目离当前考试考察的章节越远，被再次选中的概率就越小，在容量已满，需要腾出空间给新缓冲的题目时，越少使用就会优先被清除。</p><p><strong>线程数的设置</strong></p><p>原来我们设置的线程数按照我们通用的IO密集型任务，两个线程池设置的都是机器的CPU核心数<em>2，但是这个就是最佳的吗？不一定，通过反复试验我们发现，处理文档的线程池线程数设置为CPU核心数</em>4，继续提高线程数并不能带来性能上的提升。而因为我们改进后处理文档的时间和上传文档的时间基本在1：4到1：3的样子，所以处理文档的线程池线程数设置为CPU核心数<em>4</em>3。</p><p>这时我们有了第三次改进，参见cn.enjoyedu.ch8b. RpcServiceWebV3</p><p><strong>缓存的改进</strong></p><p>在这里我们除了本地内存缓存还使用了本地文件存储，启用了一个二级缓存机制。为什么要使用本地文件存储？因为考虑到服务器会升级、会宕机，已经在内存中缓存的数据会丢失，为了避免这一点，我们将相关的数据在本地进行了一个持久化的操作，保存在了本地磁盘。</p><p><strong>改进后的效果</strong></p><p>1、原单WEB串行处理，3个文档耗时</p><p><img src="blob:file:///be0c58ca-0688-4cb3-879c-44286023edc4" srcset="/img/loading.gif" alt="pastedGraphic_9.png"></p><p><strong>平均一个文档耗时**</strong>51<strong>**秒。</strong></p><p>2、服务化，文档生成并行化后，60个文档耗时</p><p><img src="blob:file:///ee6d333f-60d4-4c7e-a816-1b4f7952a0f4" srcset="/img/loading.gif" alt="pastedGraphic_10.png"></p><p><strong>平均一个文档耗时**</strong>3.5<strong><strong>秒，已经比单</strong></strong>WEB<strong>**串行版的实现有了数量级上的提高。</strong></p><p>3、引入缓存避免重复工作、题目处理并行和异步化后，60个文档耗时</p><p><img src="blob:file:///b7138258-6a03-4bf9-adba-85ccf901fa2e" srcset="/img/loading.gif" alt="pastedGraphic_11.png"></p><p><strong>平均一个文档耗时**</strong>0.65<strong>**秒，再次有了数量级上的提高。</strong></p><p>4、调整线程数后，60个文档耗时</p><p><img src="blob:file:///e71d7f5a-2eb8-494a-a6ba-abe801fcef1e" srcset="/img/loading.gif" alt="pastedGraphic_12.png"></p><p><strong>平均一个文档耗时**</strong>0.23<strong><strong>秒，再次提升了</strong></strong>3<strong><strong>倍的速度</strong></strong>,<strong><strong>而相对我们第一版的性能而言，平均一个文档处理性能提升了</strong></strong>51/0.23=221<strong>**倍。</strong></p><p><strong>这就是善用并发编程后威力！</strong></p><p><strong>用户体验的改进</strong></p><p>还可以和我们前面实战的并发任务执行框架中的思想相结合，在前端显示处理进度，給用户带来更好的使用体验。</p><p><strong>启示</strong></p><p>这次项目的优化给我们带来了什么样的启示呢？</p><p>性能优化一定要建立在对业务的深入分析上，比如我们在性能优化的切入点，在缓存数据结构的选择就建立在对业务的深入理解上；</p><p>性能优化要善于利用语言的高并发特性，</p><p>性能优化多多利用缓存，异步任务等机制，正是因为我们使用这些特性和机制，才让我们的应用在性能上有个了质的飞跃；</p><ol><li>引入各种机制的同时要注意避免带来新的不安全因素和瓶颈，比如说缓存数据过期的问题，并发时的线程安全问题，都是需要我们去克服和解决的。</li></ol>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程 - 实战项目</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>并发安全</title>
    <link href="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/"/>
    <url>/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="线程安全性"><a href="#线程安全性" class="headerlink" title="线程安全性"></a>线程安全性</h2><p>在《Java并发编程实战》中，定义如下：</p><p>类是线程安全是指当多个线程访问某个类时，不管线程将如何交替执行，调用代码中不需要增加任何额外保证安全性的代码，这个类也能始终表现出正确的行为。</p><h2 id="线程封闭"><a href="#线程封闭" class="headerlink" title="线程封闭"></a>线程封闭</h2><p>实现安全的并发是一件困难的事情，所以很多时候我们都想躲避并发。避免并发最简单的方法就是线程封闭。</p><p>线程封闭就是把对象封装到一个线程里，只有这一个线程能看到此对象。那么这个对象就算不是线程安全的也不会出现任何安全问题。</p><h3 id="ad-hoc线程封闭"><a href="#ad-hoc线程封闭" class="headerlink" title="ad-hoc线程封闭"></a>ad-hoc线程封闭</h3><p>Ad-hoc线程封闭是完全靠开发者控制的线程封闭，但没有任何一种语言特性能够将对象封闭到线程上，所以Ad-hoc线程封闭对开发的要求比较苛刻，非常脆弱，应该尽量避免使用。</p><h3 id="栈封闭"><a href="#栈封闭" class="headerlink" title="栈封闭"></a>栈封闭</h3><p>栈封闭是我们编程当中遇到的最多的线程封闭，栈封闭简单的说就是局部变量。当多个线程访问一个方法时，方法中的局部变量都会被线程在栈中重新创建，也就不会出现并发问题。全局变量一般是放在堆中，容易引起并发问题。在开发过程中应该尽量使用局部变量，避免使用全局变量。ThreadLocal本质上是每个线程内部都有一个value副本，相当于将value的副本封闭在栈中，所以使用ThreadLocal不会引发线程安全问题。</p><h3 id="无状态的类"><a href="#无状态的类" class="headerlink" title="无状态的类"></a>无状态的类</h3><p>成员变量被称为类的状态，没有任何成员变量的类，就是无状态的类，这种类一定是线程安全的。</p><p>即使这个类的方法参数中使用了对象，也是线程安全的，比如：</p><img src="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/pic4.png" srcset="/img/loading.gif" class=""><p>因为多线程下的使用，虽然user这个对象的实例会出现问题，但是它并不被StatelessClass这个类的对象实例所持有，所以Stateless这个类还是线程安全的。如果要避免在使用过程中出现问题的话，可以在user类中实现线程安全。</p><h3 id="让类不可变"><a href="#让类不可变" class="headerlink" title="让类不可变"></a>让类不可变</h3><p>让状态不可变，两种方式：</p><ol><li><p>使用final关键字：为该类的所有成员变量都应该加上final关键字。如果成员变量是一个对象时，这个对象所对应的类也应该是不可变类，才能保证整个类是不可变的。</p></li><li><p>不提供任何可供修改成员变量的地方，同时成员变量也不作为方法的返回值。</p></li></ol><p>注意：反射不属于正常使用方式，不在考虑范围内。如果类的成员变量中有对象，final关键字是保证引用不可变，并不能保证对应的实例不可变。在多线程下，对象在堆上的实例是有可能被多个线程同时修改的，没有正确处理的情况下，对象实例在堆中的数据是不可预知的，这就牵涉到了如何安全的发布对象这个问题。</p><h3 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h3><p>只能保证类的可见性，并不能保证类的线程安全性。适合一个线程写，多个线程读的情景。</p><h3 id="加锁和CAS"><a href="#加锁和CAS" class="headerlink" title="加锁和CAS"></a>加锁和CAS</h3><p>是最常使用的保证线程安全的手段，包括使用<strong>synchronized</strong>关键字、显式锁、原子变量，或者修改数据时使用CAS机制等。</p><h3 id="安全的发布"><a href="#安全的发布" class="headerlink" title="安全的发布"></a>安全的发布</h3><p>类中持有的成员变量如果是基本类型，可以直接发布出去，此时发布出去的其实是这个变量的一个副本。</p><p>如果类中持有的成员变量是对象的引用，这个成员对象不是线程安全的，通过get等方法发布出去，会造成这个成员对象本身持有的数据在多线程下不正确的修改，从而造成整个类线程不安全的问题。</p><pre><code>/** * 不安全的发布 */public class UnSafePublish {   private List&lt;Integer&gt; list = new ArrayList&lt;&gt;(3);    public UnSafePublish() {       list.add(1);       list.add(2);       list.add(3);    }   public List getList() {      return list;   }   public static void main(String[] args) {      UnSafePublish unSafePublish = new UnSafePublish();      List&lt;Integer&gt; list = unSafePublish.getList();      System.out.println(list);      list.add(4);      System.out.println(list);      System.out.println(unSafePublish.getList());   }}</code></pre><p>将list发布出去后，外部线程就可以修改这个list，如果有多个线程同时修改就会出现不安全的情况，所以在发布这对象出去的时，就应该用线程安全的方式包装这个对象。</p><pre><code>/** * 安全的发布 */public class SafePublishToo {    private List&lt;Integer&gt; list            = Collections.synchronizedList(new ArrayList&lt;&gt;(3));    public SafePublishToo() {        list.add(1);        list.add(2);        list.add(3);    }    public List getList() {        return list;    }    public static void main(String[] args) {        SafePublishToo safePublishToo = new SafePublishToo();        List&lt;Integer&gt; list = safePublishToo.getList();        System.out.println(list);        list.add(4);        System.out.println(list);        System.out.println(safePublishToo.getList());    }}</code></pre><p>将list用Collections.synchronizedList()进行包装以后，无论多少线程使用这个list，就都是线程安全的了。</p><p>对于我们自己使用或者声明的类，JDK自然没有提供这种包装类的办法，但是我们可以仿造这种模式或者委托给线程安全的类。</p><pre><code>/** * 仿Collections对容器的包装，将内部成员对象进行线程安全包装 */public class SoftPublicUser {    private final UserVo user;    public UserVo getUser() {        return user;    }    public SoftPublicUser(UserVo user) {        this.user = new SynUser(user);    }    private static class SynUser extends UserVo{        private final UserVo userVo;        private final Object lock = new Object();        public SynUser(UserVo userVo) {            this.userVo = userVo;        }        @Override        public int getAge() {            synchronized (lock){                System.out.println(&quot;lock success&quot;);                return userVo.getAge();            }        }        @Override        public void setAge(int age) {            synchronized (lock){                userVo.setAge(age);            }        }    }}</code></pre><p>如果为final类，则可以采用委托的方式，将一些方法委托给一个线程安全的类。</p><pre><code>/** * 类说明：委托给线程安全的类来做 */public class SafePublicFinalUser {    private final SynFinalUser user;    public SynFinalUser getUser() {        return user;    }    public SafePublicFinalUser(FinalUserVo user) {        this.user = new SynFinalUser(user);    }    public static class SynFinalUser{        private final FinalUserVo userVo;        private final Object lock = new Object();        public SynFinalUser(FinalUserVo userVo) {            this.userVo = userVo;        }        public int getAge() {            synchronized (lock){                return userVo.getAge();            }        }        public void setAge(int age) {            synchronized (lock){                userVo.setAge(age);            }        }    }}</code></pre><p>对这种通过get等方法发布出去的对象，最根本的解决办法还是应该在实现上就考虑到线程安全问题。</p><h3 id="TheadLocal"><a href="#TheadLocal" class="headerlink" title="TheadLocal"></a>TheadLocal</h3><p>ThreadLocal是实现线程封闭的最好方法。ThreadLocal为每个线程都创建一个ThreadLocalMap，Map的key是ThreadLoacl对象，Map的值就是我们要封闭的对象。每个线程中的ThreadLocalMap互不影响，避免了多个线程操作同一个对象的情况。</p><h3 id="Servlet辨析"><a href="#Servlet辨析" class="headerlink" title="Servlet辨析"></a>Servlet辨析</h3><p>servlet其实不是线程安全的类，由于很少有对Servlet中成员变量的写操作的需求，一般情况下并不会引发线程安全问题，但是一旦有多线程下写servlet中的成员变量，就很容易产生线程安全问题。</p><p>servlet会为每个单独的请求创建单独的线程，即请求自始至终只有一个线程在处理，避免了并发读写的问题。</p><p>spring容器并没有使用ConcurrentHashMap而是使用了普通的Map，在初始化时通过Sync关键字来保证线程安全。这样做主要是因为spring只在初始化时进行放入Map的操作，之后的使用都是获取，相对于使用ConcurrentHashMap性能会更高。</p><h2 id="线程不安全引发的问题"><a href="#线程不安全引发的问题" class="headerlink" title="线程不安全引发的问题"></a>线程不安全引发的问题</h2><h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><p>是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法继续进行下去。此时称系统处于死锁状态或系统产生了死锁。</p><p>死锁是必然发生在多操作者（M&gt;=2个）情况下，争夺多个资源（N&gt;=2个，且N&lt;=M）才会发生这种情况。很明显，单线程自然不会有死锁；单资源情况下线程之间只会产生激烈竞争，也不会产生死锁。同时，死锁还有一个重要的要求，争夺资源的顺序不同，如果争夺资源的顺序是一样的，也不会产生死锁。</p><h4 id="学术化的定义"><a href="#学术化的定义" class="headerlink" title="学术化的定义"></a>学术化的定义</h4><p>死锁的发生必须具备以下四个必要条件。 </p><ol><li><p>互斥条件：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。</p></li><li><p>请求和保持条件：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。</p></li><li><p>不剥夺条件：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。</p></li><li><p>环路等待条件：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源。</p></li></ol><p>理解了死锁的原因，尤其是产生死锁的四个必要条件，就可以最大可能地避免、预防和解除死锁。只要打破四个必要条件之一就能有效预防死锁的发生。</p><ul><li>打破互斥条件：改造独占性资源为虚拟资源，大部分资源已无法改造。</li><li>打破不可抢占条件：当一进程占有一独占性资源后又申请一独占性资源而无法满足，则退出原占有的资源。</li><li>打破占有且申请条件：采用资源预先分配策略，即进程运行前申请全部资源，满足则运行，不然就等待，这样就不会占有且申请。</li><li>打破循环等待条件：实现资源有序分配策略，对所有设备实现分类编号，所有进程只能采用按序号递增的形式申请资源。</li></ul><p>避免死锁常见的算法有有序资源分配法、银行家算法。</p><h4 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h4><p>数据库里多事务而且要同时操作多个表的情况下就可能产生死锁。所以数据库设计的时候就考虑到了检测死锁和从死锁中恢复的机制。比如oracle提供了检测和处理死锁的语句，而mysql也提供了“循环依赖检测的机制”</p><img src="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/pic6.png" srcset="/img/loading.gif" class=""><h5 id="简单顺序死锁"><a href="#简单顺序死锁" class="headerlink" title="简单顺序死锁"></a>简单顺序死锁</h5><pre><code>/** *类说明：演示普通账户的死锁和解决 */public class NormalDeadLock {    private static Object valueFirst = new Object();//第一个锁    private static Object valueSecond = new Object();//第二个锁    //先拿第一个锁，再拿第二个锁    private static void fisrtToSecond() throws InterruptedException {        String threadName = Thread.currentThread().getName();        synchronized (valueFirst){            System.out.println(threadName+&quot; get 1st&quot;);            Thread.sleep(100);            synchronized (valueSecond){                System.out.println(threadName+&quot; get 2nd&quot;);            }        }    }    //先拿第二个锁，再拿第一个锁    private static void SecondToFisrt() throws InterruptedException {        String threadName = Thread.currentThread().getName();        synchronized (valueFirst){            System.out.println(threadName+&quot; get 2nd&quot;);            Thread.sleep(100);            synchronized (valueSecond){                System.out.println(threadName+&quot; get 1st&quot;);            }        }    }    private static class TestThread extends Thread{        private String name;        public TestThread(String name) {            this.name = name;        }        public void run(){            Thread.currentThread().setName(name);            try {                SecondToFisrt();            } catch (InterruptedException e) {                e.printStackTrace();            }        }    }    public static void main(String[] args) {        Thread.currentThread().setName(&quot;TestDeadLock&quot;);        TestThread testThread = new TestThread(&quot;SubTestThread&quot;);        testThread.start();        try {            fisrtToSecond();        } catch (InterruptedException e) {            e.printStackTrace();        }    }}</code></pre><h5 id="动态顺序死锁"><a href="#动态顺序死锁" class="headerlink" title="动态顺序死锁"></a>动态顺序死锁</h5><p>顾名思义也是和获取锁的顺序有关，但是比较隐蔽，不像简单顺序死锁，往往从代码一眼就看出获取锁的顺序不对。</p><pre><code>/** *类说明：不安全的转账动作的实现 */public class TrasnferAccount implements ITransfer {    @Override    public void transfer(UserAccount from, UserAccount to, int amount)          throws InterruptedException {        synchronized (from){            System.out.println(Thread.currentThread().getName()                  +&quot; get&quot;+from.getName());            Thread.sleep(100);            synchronized (to){                System.out.println(Thread.currentThread().getName()                      +&quot; get&quot;+to.getName());                from.flyMoney(amount);                to.addMoney(amount);            }        }    }}</code></pre><pre><code>/** *@author Mark老师   享学课堂 https://enjoy.ke.qq.com  * *类说明：模拟支付公司转账的动作 */public class PayCompany {   /*执行转账动作的线程*/    private static class TransferThread extends Thread{        private String name;        private UserAccount from;        private UserAccount to;        private int amount;        private ITransfer transfer;        public TransferThread(String name, UserAccount from, UserAccount to,                              int amount, ITransfer transfer) {            this.name = name;            this.from = from;            this.to = to;            this.amount = amount;            this.transfer = transfer;        }        public void run(){            Thread.currentThread().setName(name);            try {                transfer.transfer(from,to,amount);            } catch (InterruptedException e) {                e.printStackTrace();            }        }    }    public static void main(String[] args) {        PayCompany payCompany = new PayCompany();        UserAccount zhangsan = new UserAccount(&quot;zhangsan&quot;,20000);        UserAccount lisi = new UserAccount(&quot;lisi&quot;,20000);        ITransfer transfer = new SafeOperateToo();        TransferThread zhangsanToLisi = new TransferThread(&quot;zhangsanToLisi&quot;                ,zhangsan,lisi,2000,transfer);        TransferThread lisiToZhangsan = new TransferThread(&quot;lisiToZhangsan&quot;                ,lisi,zhangsan,4000,transfer);        zhangsanToLisi.start();        lisiToZhangsan.start();    }}</code></pre><h4 id="危害"><a href="#危害" class="headerlink" title="危害"></a>危害</h4><p>时间不定，不是每次必现；一旦出现没有任何异常信息，只知道这个应用的所有业务越来越慢，最后停止服务，无法确定是哪个具体业务导致的问题；测试部门也无法复现，并发量不够。</p><ol><li>线程不工作了，但是整个程序还是活着的</li><li>没有任何的异常信息可以供我们检查。</li><li>一旦程序发生了发生了死锁，是没有任何的办法恢复的，只能重启程序，对生产平台的程序来说，这是个很严重的问题。</li></ol><h4 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h4><h5 id="定位"><a href="#定位" class="headerlink" title="定位"></a>定位</h5><p>通过<strong>jps</strong> 查询应用的id，再通过<strong>jstack[id]</strong> 查看应用的锁的持有情况</p><img src="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/pic1.png" srcset="/img/loading.gif" class=""><img src="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/pic2.png" srcset="/img/loading.gif" class=""><img src="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/pic3.png" srcset="/img/loading.gif" class=""><h5 id="修正"><a href="#修正" class="headerlink" title="修正"></a>修正</h5><p>关键是保证拿锁的顺序一致</p><p>两种解决方式：</p><ol><li>内部通过顺序比较，确定拿锁的顺序；</li></ol><pre><code>/** *@author Mark老师   享学课堂 https://enjoy.ke.qq.com  * *类说明：不会产生死锁的安全转账 */public class SafeOperate implements ITransfer {    private static Object tieLock = new Object();//第三把锁    @Override    public void transfer(UserAccount from, UserAccount to, int amount)            throws InterruptedException {        int fromHash = System.identityHashCode(from);        int toHash = System.identityHashCode(to);        if(fromHash&lt;toHash){            synchronized (from){                System.out.println(Thread.currentThread().getName()+&quot; get &quot;+from.getName());                Thread.sleep(100);                synchronized (to){                    System.out.println(Thread.currentThread().getName()+&quot; get &quot;+to.getName());                    from.flyMoney(amount);                    to.addMoney(amount);                    System.out.println(from);                    System.out.println(to);                }            }        }else if(toHash&lt;fromHash){            synchronized (to){                System.out.println(Thread.currentThread().getName()+&quot; get&quot;+to.getName());                Thread.sleep(100);                synchronized (from){                    System.out.println(Thread.currentThread().getName()+&quot; get&quot;+from.getName());                    from.flyMoney(amount);                    to.addMoney(amount);                    System.out.println(from);                    System.out.println(to);                }            }        }else{            synchronized (tieLock){                synchronized (from){                    synchronized (to){                        from.flyMoney(amount);                        to.addMoney(amount);                    }                }            }        }    }}</code></pre><ol start="2"><li>采用尝试拿锁的机制。</li></ol><pre><code>/** * @author Mark老师   享学课堂 https://enjoy.ke.qq.com * &lt;p&gt; * 类说明：不会产生死锁的安全转账第二种方法 */public class SafeOperateToo implements ITransfer {    @Override    public void transfer(UserAccount from, UserAccount to, int amount)            throws InterruptedException {        Random r = new Random();        while (true) {            if (from.getLock().tryLock()) {                try {                    System.out.println(Thread.currentThread().getName()                            + &quot; get&quot; + from.getName());                    if (to.getLock().tryLock()) {                        try {                            System.out.println(Thread.currentThread().getName()                                    + &quot; get&quot; + to.getName());                            from.flyMoney(amount);                            to.addMoney(amount);                            System.out.println(from);                            System.out.println(to);                            break;                        } finally {                            to.getLock().unlock();                        }                    }                } finally {                    from.getLock().unlock();                }            }            Thread.sleep(r.nextInt(2));        }    }}</code></pre><h3 id="活锁"><a href="#活锁" class="headerlink" title="活锁"></a>活锁</h3><p>两个线程在尝试拿锁的机制中，发生多个线程之间互相谦让，不断发生同一个线程总是拿到同一把锁，在尝试拿另一把锁时因为拿不到，而将本来已经持有的锁释放的过程。</p><p>解决办法：每个线程休眠随机数，错开拿锁的时间。</p><h3 id="线程饥饿"><a href="#线程饥饿" class="headerlink" title="线程饥饿"></a>线程饥饿</h3><p>低优先级的线程，总是拿不到执行时间</p><h3 id="性能和思考"><a href="#性能和思考" class="headerlink" title="性能和思考"></a>性能和思考</h3><p>使用并发的目标是为了提高性能，引入多线程后，其实会引入额外的开销，如线程之间的协调、增加的上下文切换，线程的创建和销毁，线程的调度等等。过度的使用和不恰当的使用，会导致多线程程序甚至比单线程还要低。</p><p>衡量应用的程序的性能：服务时间，延迟时间，吞吐量，可伸缩性等等，其中服务时间，延迟时间（多快），吞吐量（处理能力的指标，完成工作的多少）。多快和多少，完全独立，甚至是相互矛盾的。</p><p>对服务器应用来说：多少（可伸缩性，吞吐量）这个方面比多快更受重视。</p><p>我们做应用的时候：</p><ol><li><p>先保证程序正确，确实达不到要求的时候，再提高速度（黄金原则）。</p></li><li><p>一定要以测试为基准。</p></li></ol><h4 id="线程引入的开销"><a href="#线程引入的开销" class="headerlink" title="线程引入的开销"></a>线程引入的开销</h4><h5 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h5><p>如果主线程是唯一的线程，那么它基本上不会被调度出去。另一方面,如果可运行的线程数大于CPU的数量,那么操作系统最终会将某个正在运行的线程调度出来，从而使其他线程能够使用CPU。这将导致一次上下文切换，在这个过程中将保存当前运行线程的执行上下文，并将新调度进来的线程的执行上下文设置为当前上下文。上下文切换有点像我们同时阅读几本书，在来回切换书本的同时我们需要记住每本书当前读到的页码。</p><p>切换上下文需要一定的开销，而在线程调度过程中需要访问由操作系统和JVM共享的数据结构。由于应用程序、操作系统以及JVM都使用同一组CPU，所以在JVM和操作系统中消耗越多的CPU时钟周期，应用程序的可用CPU时钟周期就越少。而且上下文切换的开销并不只是包含JVM和操作系统的开销，由于当一个新的线程被切换进来时，它所需要的数据可能不在当前处理器的本地缓存，所以上下文切换也将导致一些缓存缺失，线程在首次调度运行时会更加缓慢。</p><p>当线程由于等待某个发生竞争的锁而被阻塞时，JVM通常会将这个线程挂起，并允许它被交换出去。如果线程频繁地发生阻塞，那么它们将无法使用完整的调度时间片。在程序中发生越多的阻塞（包括阻塞IO、等待获取发生竞争的锁或者在条件变量上等待）与CPU密集型的程序就会发生越多的上下文切换，从而增加调度开销，降低吞吐量。</p><p>上下文切换是计算密集型操作。也就是说，它需要相当可观的处理器时间。所以上下文切换对系统来说意味着消耗大量的 CPU 时间，而且可能是操作系统中时间消耗最大的操作。上下文切换的实际开销会随着平台的不同而变化，按照实际经验来看，在大多数通用的处理器中，上下文切换的开销相当于50~10000个时钟周期,也就是几微秒。</p><p>UNIX系统的vmstat命令能报告上下文切换次数以及在内核中执行时间所占比例等信息。如果内核占用率较高（超过10%），那么通常表示调度活动发生得很频繁，这很可能是由IO或竞争锁导致的阻塞引起的。</p><h5 id="内存同步"><a href="#内存同步" class="headerlink" title="内存同步"></a>内存同步</h5><p>同步操作的性能开销包括多个方面。在 synchronized和 volatile提供的可见性保证中可能会使用一些特殊指令，即内存栅栏( Memory Barrier)。</p><p>内存栅栏可以刷新缓存，使缓存无效从而刷新硬件的写缓冲，以及停止执行管道。</p><p>内存栅栏可能同样会对性能带来间接的影响，因为它们将抑制一些编译器优化操作。在内存栅栏中，大多数操作都是不能被重排序的。</p><h5 id="阻塞"><a href="#阻塞" class="headerlink" title="阻塞"></a>阻塞</h5><p>引起阻塞的原因：包括阻塞IO，等待获取发生竞争的锁或者在条件变量上的等待等等。</p><p>阻塞会导致线程挂起，挂起进程在操作系统中可以定义为暂时被淘汰出内存的进程，机器的资源是有限的，在资源不足的情况下，操作系统对在内存中的程序进行合理的安排，其中有的进程被暂时调离出内存，当条件允许的时候，会被操作系统再次调回内存，重新进入等待被执行的状态即就绪态。这个操作至少包括两次额外的上下文切换，还有相关的操作系统级的操作等等。</p><h4 id="如何减少锁的竞争"><a href="#如何减少锁的竞争" class="headerlink" title="如何减少锁的竞争"></a>如何减少锁的竞争</h4><h5 id="减少锁的粒度"><a href="#减少锁的粒度" class="headerlink" title="减少锁的粒度"></a>减少锁的粒度</h5><p>使用锁的时候，锁所保护的对象是多个，当这些多个对象其实是独立变化的时候，不如用多个锁来一一保护这些对象。但是如果有同时要持有多个锁的业务方法，要注意避免发生死锁。</p><h5 id="缩小锁的范围"><a href="#缩小锁的范围" class="headerlink" title="缩小锁的范围"></a>缩小锁的范围</h5><p>对锁的持有实现快进快出，尽量缩短持由锁的的时间。将一些与锁无关的代码移出锁的范围，特别是一些耗时，可能阻塞的操作</p><h5 id="避免多余的锁"><a href="#避免多余的锁" class="headerlink" title="避免多余的锁"></a>避免多余的锁</h5><p>两次加锁之间的语句非常简单，导致加锁的时间比执行这些语句还长，这个时候应该进行锁粗化即扩大锁的范围。</p><h5 id="锁分段"><a href="#锁分段" class="headerlink" title="锁分段"></a>锁分段</h5><p>ConcurrrentHashMap就是典型的锁分段。</p><h5 id="替换独占锁"><a href="#替换独占锁" class="headerlink" title="替换独占锁"></a>替换独占锁</h5><p>在业务允许的情况下：</p><ol><li>使用读写锁，</li><li>用自旋CAS</li><li>使用系统的并发容器</li></ol><h2 id="线程安全的单例模式"><a href="#线程安全的单例模式" class="headerlink" title="线程安全的单例模式"></a>线程安全的单例模式</h2><h3 id="双重检查锁定"><a href="#双重检查锁定" class="headerlink" title="双重检查锁定"></a>双重检查锁定</h3><pre><code>/** * 懒汉式-双重检查 */public class SingleDcl {    private volatile static SingleDcl singleDcl;    //私有化    private SingleDcl(){    }    public static SingleDcl getInstance(){        if (singleDcl == null){ //第一次检查，不加锁            System.out.println(Thread.currentThread()+&quot; is null&quot;);            synchronized(SingleDcl.class){ //加锁                if (singleDcl == null){ //第二次检查，加锁情况下                    System.out.println(Thread.currentThread()+&quot; is null&quot;);                    singleDcl = new SingleDcl();                }            }        }        return singleDcl;    }}</code></pre><p>仅仅是双重检查无法保证多线程下使用的安全性，因为在创建对象时为内存中分配空间、对象在内存空间的初始化、把这个内存空间的地址赋值给引用这三个步骤是可能被重新排序的，只要引用指向了内存空间的地址判断条件singleDc1==null就会不成立，而此时对象很可能还没有完成初始化，所以还需要加入volatile关键字保证指令不会被重排序。</p><h3 id="饿汉式"><a href="#饿汉式" class="headerlink" title="饿汉式"></a>饿汉式</h3><pre><code>/** * 饿汉式 */public class SingleEHan {    private SingleEHan(){}    private static SingleEHan singleDcl = new SingleEHan();}</code></pre><p>JVM对类的加载和类初始化，由虚拟机保证线程安全。多个线程同时加载一个类时会为其加锁保证只有一个类加载成功，所以饿汉式单例模式是线程安全的。</p><h3 id="延迟初始化占位类模式"><a href="#延迟初始化占位类模式" class="headerlink" title="延迟初始化占位类模式"></a>延迟初始化占位类模式</h3><pre><code>/** * 懒汉式-延迟初始化占位类模式 */public class SingleInit {    private SingleInit(){}    private static class InstanceHolder{        private static SingleInit instance = new SingleInit();    }    public static SingleInit getInstance(){        return InstanceHolder.instance;    }}</code></pre><p>延迟初始化占位类模式其实也是利用JVM类加载的线程安全，在子类中完成实例的初始化，如果在其他地方没有对子类的引用，子类的初始化将只在首次获取实例时完成，以此来解决饿汉式单例模式资源占用的问题。延迟占位模式也可以用在多线程下实例域的延迟赋值。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线程池</title>
    <link href="/2020/01/16/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"/>
    <url>/2020/01/16/%E7%BA%BF%E7%A8%8B%E6%B1%A0/</url>
    
    <content type="html"><![CDATA[<h2 id="使用线程池的优势"><a href="#使用线程池的优势" class="headerlink" title="使用线程池的优势"></a>使用线程池的优势</h2><ol><li><p>降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。</p></li><li><p>提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。假设一个服务器完成一项任务所需时间为：T1 创建线程时间，T2 在线程中执行任务的时间，T3 销毁线程时间。  如果：T1 + T3 远大于 T2，使用线程池就能显著服务器的性能。线程池技术正是关注如何缩短或调整T1,T3时间的技术，从而提高服务器程序性能的。它把T1，T3分别安排在服务器程序的启动和结束的时间段或者一些空闲的时间段，这样在服务器程序处理客户请求时，不会有T1，T3的开销了。</p></li><li><p>提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。</p></li></ol><p>假设一个服务器一天要处理50000个请求，并且每个请求需要一个单独的线程完成。线程池中的线程数一般是固定的，产生线程总数不会超过线程池中线程的数目。如果服务器不利用线程池来处理这些请求，则需要创建50000个线程，一般线程池大小是远小于50000，利用线程池去处理请求就可以减少线程创建的时间，从而提高效率。</p><h2 id="自定义线程池的实现"><a href="#自定义线程池的实现" class="headerlink" title="自定义线程池的实现"></a>自定义线程池的实现</h2><pre><code>/** *类说明：自定义线程池实现 */public class MyThreadPool2 {    /*缺省线程数据量*/    private static int WORK_COUNT = 5;    /*存放任务*/    private final BlockingQueue&lt;Runnable&gt; taskQueue;    /*工作线程*/    private WorkThread[] workThreads;    private final int work_number;    public MyThreadPool2(){        this(100,WORK_COUNT);    }    /*任务数，线程的数量*/    public MyThreadPool2(int task_count,                         int work_number) {        if (work_number&lt;=0) work_number = WORK_COUNT;        if(task_count&lt;=0) task_count = 100;        this.taskQueue = new ArrayBlockingQueue&lt;&gt;(task_count);        this.work_number = work_number;        workThreads = new WorkThread[work_number];        /*工作线程准备好了*/        for(int i=0;i&lt;work_number;i++){            workThreads[i] = new WorkThread();            workThreads[i].start();        }    }    /*销毁线程池*/    public void destroy(){        System.out.println(&quot;ready close pool....&quot;);        for(int i=0;i&lt;work_number;i++){            workThreads[i].stopWorker();            workThreads[i] = null;//help gc        }        taskQueue.clear();    }    /*放入任务，但是只是加入队列*/    public void execute(Runnable task){        try {            taskQueue.put(task);        } catch (InterruptedException e) {            e.printStackTrace();        }    }    @Override    public String toString() {        return &quot;WorkThread number:&quot;+work_number                +&quot; wait task number:&quot;+taskQueue.size();    }    /*内部类，工作线程的实现*/    private class WorkThread extends Thread{        @Override        public void run() {            Runnable r = null;            try {                while(!isInterrupted()){                    r = taskQueue.take();                    if(r!=null){                        System.out.println(getId()+&quot; ready execute&quot;                                +((TestMyThreadPool.MyTask)r).getName());                        r.run();                    }                   r = null;                }            } catch (InterruptedException e) {                //e.printStackTrace();            }        }        /*停止工作*/        public void stopWorker() {            interrupt();        }    }}</code></pre><p>测试类</p><pre><code>/** *类说明：测试自定义线程池实现 */public class TestMyThreadPool {    public static void main(String[] args) throws InterruptedException {//         创建3个线程的线程池        MyThreadPool2 t = new MyThreadPool2(0,3);        t.execute(new MyTask(&quot;testA&quot;));        t.execute(new MyTask(&quot;testB&quot;));        t.execute(new MyTask(&quot;testC&quot;));        t.execute(new MyTask(&quot;testD&quot;));        t.execute(new MyTask(&quot;testE&quot;));        System.out.println(t);        Thread.sleep(10000);        t.destroy();// 所有线程都执行完成才destory        System.out.println(t);    }    // 任务类    static class MyTask implements Runnable {        private String name;        private Random r = new Random();        public MyTask(String name) {            this.name = name;        }        public String getName() {            return name;        }        @Override        public void run() {// 执行任务            try {                Thread.sleep(r.nextInt(1000)+2000);            } catch (InterruptedException e) {                System.out.println(Thread.currentThread().getId()+&quot; sleep InterruptedException:&quot;                        +Thread.currentThread().isInterrupted());            }            System.out.println(&quot;任务 &quot; + name + &quot; 完成&quot;);        }    }}</code></pre><h2 id="Executor框架"><a href="#Executor框架" class="headerlink" title="Executor框架"></a>Executor框架</h2><img src="/2020/01/16/%E7%BA%BF%E7%A8%8B%E6%B1%A0/pic1.png" srcset="/img/loading.gif" class=""><p>Executor接口是Executor框架的基础，其中只有一个execute()方法，主要作用是将任务的提交与任务的执行分离开来；</p><p>ExecutorService接口继承了Executor接口，在其上做了一些shutdown()、submit()的扩展，可以说是真正的线程池接口；</p><p>AbstractExecutorService抽象类实现了ExecutorService接口中的大部分方法；</p><p>ThreadPoolExecutor类是线程池的核心实现类，用来执行被提交的任务。</p><p>ScheduledExecutorService接口继承了ExecutorService接口，提供了带周期执行功能ExecutorService；</p><p>ScheduledThreadPoolExecutor类继承ThreadPoolExecutor类、实现ScheduledExecutorService接口，可以在给定的延迟后执行任务，或者定期执行任务。ScheduledThreadPoolExecutor比Timer更灵活，功能更强大。</p><h2 id="线程池的创建各个参数含义"><a href="#线程池的创建各个参数含义" class="headerlink" title="线程池的创建各个参数含义"></a>线程池的创建各个参数含义</h2><p>public ThreadPoolExecutor(int <strong>corePoolSize</strong>,int <strong>maximumPoolSize</strong>,long <strong>keepAliveTime</strong>,TimeUnit <strong>unit</strong>,BlockingQueue&lt;Runnable&gt; <strong>workQueue</strong>,ThreadFactory <strong>threadFactory</strong>,RejectedExecutionHandler <strong>handler</strong>)</p><ul><li><p><strong>corePoolSize</strong>：线程池中的核心线程数。当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize；如果当前线程数已经达到corePoolSize，继续提交的任务会被保存到阻塞队列中，等待被执行；如果执行了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有核心线程。</p></li><li><p><strong>maximumPoolSize</strong>：线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，前提是当前线程数小于maximumPoolSize</p></li><li><p><strong>keepAliveTime</strong>：线程空闲时的存活时间，即当线程没有任务执行时，继续存活的时间。默认情况下，该参数只在线程数大于corePoolSize时才有用</p></li><li><p><strong>unit</strong>：keepAliveTime的时间单位</p></li><li><p><strong>workQueue</strong>：workQueue必须是BlockingQueue阻塞队列，通过workQueue，线程池实现了阻塞功能。当线程池中的线程数超过它的corePoolSize的时候，线程会进入阻塞队列进行阻塞等待。一般来说，我们应该尽量使用有界队列，因为使用无界队列作为工作队列会对线程池带来如下影响：</p><ol><li>当线程池中的线程数达到corePoolSize后，新任务将在无界队列中等待，因此线程池中的线程数不会超过corePoolSize。</li><li>由于1，使用无界队列时maximumPoolSize将是一个无效参数。</li><li>由于1和2，使用无界队列时keepAliveTime将是一个无效参数。</li><li>更重要的，使用无界queue可能会耗尽系统资源，有界队列则有助于防止资源耗尽，同时即使使用有界队列，也要尽量控制队列的大小在一个合适的范围。</li></ol><p>所以我们一般会使用，ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue、PriorityBlockingQueue。</p></li><li><p><strong>threadFactory</strong>：创建线程的工厂，通过自定义的线程工厂可以给每个新建的线程设置一个具有识别度的线程名，当然还可以更加自由的对线程做更多的设置，比如设置所有的线程为守护线程。Executors静态工厂里默认的threadFactory，线程的命名规则是“pool-数字-thread-数字”。</p></li><li><p><strong>handler</strong>：线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，线程池提供了4种策略：</p><ol><li>AbortPolicy：默认策略直接抛出异常；</li><li>CallerRunsPolicy：用调用者所在的线程来执行任务；</li><li>DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；</li><li>DiscardPolicy：直接丢弃任务；</li></ol><p>当然也可以根据应用场景实现RejectedExecutionHandler接口，自定义饱和策略，如记录日志或持久化存储不能处理的任务。</p></li></ul><h2 id="扩展线程池"><a href="#扩展线程池" class="headerlink" title="扩展线程池"></a>扩展线程池</h2><p>在JDK的线程池核心方法中预留出了三个空的方法，分别为任务执行前的方法、执行后的方法、线程池退出时执行的方法，我们可以通过这些方法执行我们自己的逻辑。如果要对Runnable任务做调整，如修改线程名字、设置线程为守护线程，则可以通过实现ThreadFactory接口，在newThread()方法中对runnable进行调整。</p><pre><code>/** * 类说明：扩展线程池的使用范例 */public class ThreadPoolExt {    static class Worker implements Runnable {        private String taskName;        private Random r = new Random();        public Worker(String taskName) {            this.taskName = taskName;        }        public String getName() {            return taskName;        }        @Override        public void run() {            System.out.println(Thread.currentThread().getName()                    + &quot; process the task : &quot; + taskName);            SleepTools.ms(r.nextInt(100) * 5);        }    }    public static void main(String[] args) throws InterruptedException, ExecutionException {        ExecutorService threadPool = new ThreadPoolExecutor(2, 4, 3,                TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(10),                new ThreadPoolExecutor.DiscardOldestPolicy()) {            @Override            protected void beforeExecute(Thread t, Runnable r) {                System.out.println(&quot;Ready Execute &quot; + ((Worker) r).getName());            }            @Override            protected void afterExecute(Runnable r, Throwable t) {                System.out.println(&quot;Complete Execute &quot; + ((Worker) r).getName());            }            @Override            protected void terminated() {                System.out.println(&quot;线程池退出&quot;);            }        };        for (int i = 0; i &lt;= 6; i++) {            Worker worker = new Worker(&quot;worker &quot; + i);            System.out.println(&quot;A new task has been added : &quot; + worker.getName());            threadPool.execute(worker);        }        threadPool.shutdown();    }}</code></pre><p>可以看到，每个任务执行前后都会调用 beforeExecute和 afterExecute方法。相当于执行了一个切面。而在调用shutdown 方法后则会调用 terminated 方法。</p><h2 id="线程池的工作机制"><a href="#线程池的工作机制" class="headerlink" title="线程池的工作机制"></a>线程池的工作机制</h2><ol><li>如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。</li><li>如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。</li><li>如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务。</li><li>如果继续添加任务导致当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。</li></ol><img src="/2020/01/16/%E7%BA%BF%E7%A8%8B%E6%B1%A0/pic2.png" srcset="/img/loading.gif" class=""><p>内存资源相比线程资源要廉价一下，所以优先使用阻塞队列容纳多余线程数，在阻塞队列容纳不下的情况下才会创建新的线程（个人猜测）。</p><h2 id="提交任务"><a href="#提交任务" class="headerlink" title="提交任务"></a>提交任务</h2><p>execute()方法用于提交不需要返回值的任务（Runnable），所以无法判断任务是否被线程池执行成功。</p><p>submit()方法用于提交需要返回值的任务（Callable）。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用get(long timeout，TimeUnit unit)方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。</p><h2 id="关闭线程池"><a href="#关闭线程池" class="headerlink" title="关闭线程池"></a>关闭线程池</h2><p>可以通过调用线程池的shutdown()或shutdownNow()方法来关闭线程池。它们的原理是遍历线程池中的工作线程，然后逐个调用线程的interrupt()方法来中断线程，所以无法响应中断的任务可能永远无法终止。但是它们存在一定的区别，shutdownNow()首先将线程池的状态设置成STOP，然后尝试停止所有的<strong>正在或暂停执行任务的线程</strong>，并返回等待执行任务的列表，而shutdown()只是将线程池的状态设置成SHUTDOWN状态，然后中断所有<strong>没有正在执行任务的线程</strong>。</p><p>只要调用了这两个关闭方法中的任意一个，isShutdown方法就会返回true。当所有的任务都已关闭后，线程池关闭成功，这时调用isTerminaed方法会返回true。至于应该调用哪一种方法来关闭线程池，应该由提交到线程池的任务特性决定，通常调用shutdown()方法来关闭线程池，如果任务不一定要执行完，则可以调用shutdownNow()方法。</p><h2 id="合理地配置线程池"><a href="#合理地配置线程池" class="headerlink" title="合理地配置线程池"></a>合理地配置线程池</h2><p>要想合理地配置线程池，就必须首先分析任务特性，可以从以下几个角度来分析：</p><ul><li><p>任务的性质：CPU密集型任务、IO密集型任务和混合型任务。</p></li><li><p>任务的优先级：高、中和低。</p></li><li><p>任务的执行时间：长、中和短。</p></li><li><p>任务的依赖性：是否依赖其他系统资源，如数据库连接。</p></li></ul><p>性质不同的任务可以用不同规模的线程池分开处理：</p><ul><li><p>CPU密集型任务（字符串的正则匹配、加密解密，数据的计算）应配置尽可能小的线程，如配置Ncpu+1个线程的线程池。</p></li><li><p>IO密集型任务（读写文件，数据库，http请求）线程并不是一直在执行任务，则应配置尽可能多的线程，如Ncpu*2，如果此时CPU占用率比较低的话可以尝试Ncpu*3。</p></li><li><p>混合型的任务（包括CPU密集及IO密集），如果将其拆分成一个CPU密集型任务和一个IO密集型任务，这两个任务执行的时间相差不是太大，那么分解后执行的吞吐量将高于串行执行的吞吐量，如果这两个任务执行时间相差太大，则没必要进行分解。</p></li></ul><p>可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数。</p><p>优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高的任务先执行。</p><p>执行时间不同的任务可以交给不同规模的线程池来处理，或者可以使用优先级队列，让执行时间短的任务先执行。</p><p>依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，等待的时间越长，则CPU空闲时间就越长，那么线程数应该设置得越大，这样才能更好地利用CPU。</p><p>在有界队列和无界队列的选择上，建议使用有界队列。有界队列能增加系统的稳定性和预警能力，队列的长度可以设置的大一些，比如几千。假设，我们现在有一个Web系统，里面使用了线程池来处理业务，在某些情况下，系统里后台任务线程池的队列和线程池全满了，不断抛出抛弃任务的异常，通过排查发现是数据库出现了问题，导致执行SQL变得非常缓慢，因为后台任务线程池里的任务全是需要向数据库查询和插入数据的，所以导致线程池里的工作线程全部阻塞，任务积压在线程池里。如果当时我们设置成无界队列，那么线程池的队列就会越来越多，有可能会撑满内存，导致整个系统不可用，而不只是后台任务出现问题。</p><h2 id="预定义线程池"><a href="#预定义线程池" class="headerlink" title="预定义线程池"></a>预定义线程池</h2><p>JDK在Executor中为我们提供了一些预定义的线程池，可以通过Executors.newFixedThreadPool()等方法来获取，但尽量还是自己通过构造方法根据当前场景创建。</p><h3 id="FixedThreadPool"><a href="#FixedThreadPool" class="headerlink" title="FixedThreadPool"></a>FixedThreadPool</h3><p>创建使用固定线程数的FixedThreadPool的API。适用于为了满足资源管理的需求，而需要限制当前线程数量的应用场景，它适用于负载比较重的服务器。FixedThreadPool的corePoolSize和maximumPoolSize都被设置为创建FixedThreadPool时指定的参数nThreads。</p><p>当线程池中的线程数大于corePoolSize时，keepAliveTime为多余的空闲线程等待新任务的最长时间，超过这个时间后多余的线程将被终止。这里把keepAliveTime设置为0L，意味着多余的空闲线程会被立即终止。</p><p>FixedThreadPool使用有界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为Integer.MAX_VALUE）。</p><h3 id="SingleThreadExecutor"><a href="#SingleThreadExecutor" class="headerlink" title="SingleThreadExecutor"></a>SingleThreadExecutor</h3><p>创建使用单个线程的SingleThread-Executor的API，于需要保证顺序地执行各个任务；并且在任意时间点，不会有多个线程是活动的应用场景。</p><p>corePoolSize和maximumPoolSize被设置为1。其他参数与FixedThreadPool相同。SingleThreadExecutor使用有界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为Integer.MAX_VALUE）。</p><h3 id="CachedThreadPool"><a href="#CachedThreadPool" class="headerlink" title="CachedThreadPool"></a>CachedThreadPool</h3><p>创建一个为所有任务创建新线程的CachedThreadPool的API。大小无界的线程池，适用于执行很多的短期异步任务的小程序，或者是负载较轻的服务器。</p><p>corePoolSize被设置为0，即corePool为空；maximumPoolSize被设置为Integer.MAX_VALUE。这里把keepAliveTime设置为60L，意味着CachedThreadPool中的空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被终止。</p><p>FixedThreadPool和SingleThreadExecutor使用有界队列LinkedBlockingQueue作为线程池的工作队列。CachedThreadPool使用没有容量的SynchronousQueue作为线程池的工作队列，但CachedThreadPool的maximumPool是无界的。这意味着，如果主线程提交任务的速度高于maximumPool中线程处理任务的速度时，CachedThreadPool会不断创建新线程。极端情况下，CachedThreadPool会因为创建过多线程而耗尽CPU和内存资源。</p><h3 id="WorkStealingPool"><a href="#WorkStealingPool" class="headerlink" title="WorkStealingPool"></a>WorkStealingPool</h3><p>利用所有运行的处理器数目来创建一个工作窃取的线程池，使用forkjoin实现</p><h3 id="ScheduledThreadPoolExecutor"><a href="#ScheduledThreadPoolExecutor" class="headerlink" title="ScheduledThreadPoolExecutor"></a>ScheduledThreadPoolExecutor</h3><p>使用工厂类Executors来创建。Executors可以创建2种类型的ScheduledThreadPoolExecutor，如下。</p><ul><li><p>ScheduledThreadPoolExecutor。包含若干个线程的ScheduledThreadPoolExecutor。</p></li><li><p>SingleThreadScheduledExecutor。只包含一个线程的ScheduledThreadPoolExecutor。</p></li></ul><p>ScheduledThreadPoolExecutor适用于需要多个后台线程执行周期任务，同时为了满足资源管理的需求而需要限制后台线程的数量的应用场景。</p><p>SingleThreadScheduledExecutor适用于需要单个后台线程执行周期任务，同时需要保证顺序地执行各个任务的应用场景。</p><p>提交定时任务：</p><ul><li><p>public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit)：向定时任务线程池提交一个延时Runnable任务（仅执行一次）</p></li><li><p>public <V> ScheduledFuture<V> schedule(Callable<V> callable, long delay, TimeUnit unit)：向定时任务线程池提交一个延时的Callable任务（仅执行一次）</p></li><li><p>public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay,   long period, TimeUnit unit)：向定时任务线程池提交一个固定时间间隔执行的任务</p></li><li><p>public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit)：向定时任务线程池提交一个固定延时间隔执行的任务</p></li></ul><p>固定延时间隔的任务是指每次执行完任务以后都延时一个固定的时间。由于操作系统调度以及每次任务执行的语句可能不同，所以每次任务执行所花费的时间是不确定的，也就导致了每次任务的执行周期存在一定的波动。</p><p>固定时间间隔的任务不论每次任务花费多少时间，下次任务开始执行时间从理论上讲是确定的，当然执行任务的时间不能超过执行周期。</p><p>定时任务异常问题：</p><p>如果任务在执行过程中出现了异常而且不进行捕捉的话，next周期将不会运行。</p><p>定时任务超时问题：</p><p>scheduleAtFixedRate中，若任务处理时长超出设置的定时频率时长，本次任务执行完才开始下次任务，下次任务已经处于超时状态，会马上开始执行。若任务处理时长小于定时频率时长，任务执行完后，定时器等待，下次任务会在定时器等待频率时长后执行。</p><p>如下例子：</p><p>设置定时任务每60s执行一次，那么从理论上应该第一次任务在第0s开始,第二次任务在第60s开始，第三次任务在120s开始，但实际运行时第一次任务时长80s，第二次任务时长30s，第三次任务时长50s，则实际运行结果为：</p><p>第一次任务第0s开始,第80s结束；</p><p>第二次任务第80s开始,第110s结束(上次任务已超时,本次不会再等待60s,会马上开始)；</p><p>第三次任务第120s开始,第170s结束.</p><p>第四次任务第180s开始…..</p><h2 id="Executor框架的基本使用流程"><a href="#Executor框架的基本使用流程" class="headerlink" title="Executor框架的基本使用流程"></a>Executor框架的基本使用流程</h2><img src="/2020/01/16/%E7%BA%BF%E7%A8%8B%E6%B1%A0/pic3.png" srcset="/img/loading.gif" class=""><h3 id="了解CompletionService"><a href="#了解CompletionService" class="headerlink" title="了解CompletionService"></a>了解CompletionService</h3><p>CompletionService实际上可以看做是Executor和BlockingQueue的结合体。CompletionService在接收到要执行的任务时，把任务交给Executor来完成，再通过类似BlockingQueue的put()和take()来存入和获得任务执行的结果。</p><p>CompletionService的一个实现是ExecutorCompletionService，ExecutorCompletionService的构造函数可以接收一个Executor类型的executor和一个BlockingQueue&lt;Future&lt;V&gt;&gt;类型的completionQueue，completionQueue的作用是保存Executor执行的结果。当只传入executor时，构造函数中会创建一个LinkedBlockingQueue作为completionQueue。</p><p>当提交一个任务到ExecutorCompletionService时，首先将任务包装成QueueingFuture，它是FutureTask的一个子类，改写了FutureTask中的done方法，使QueueingFuture在结束时把Executor执行的计算结果放入completionQueue中。所以只有当QueueingFuture对象结束时，才会加入到completionQueue中，completionQueue的类型是BlockingQueue，其中的take()方法类似于Producer-Consumer模式中的Consumer。当从Queue中取出Future对象时，如果Queue是空的就会阻塞，直到有完成的Future对象加入到Queue中。所以先完成的必定先被取出，这样就减少了不必要的等待时间。</p><p>测试一：不使用CompletionService，自己创建一个集合来保存Future，并循环通过get()方法获取其返回结果。这时获取的结果与加入线程池时的顺序相同。因为get()方法是阻塞方法，如果后面的任务已经完成，前面的任务没有完成，获取结果的线程就会被阻塞直到前面的任务完成，才能得到后面任务的返回结果。</p><p>测试二：使用CompletionService来维护处理线程的返回结果，这时获取的结果与任务完成顺序相同，因为只有在Future完成是才会被加入completionQueue，所以completionQueue的Future的顺序与任务完成的顺序相同。</p><pre><code>/** *类说明： */public class CompletionCase {    private final int POOL_SIZE = Runtime.getRuntime().availableProcessors();    private final int TOTAL_TASK = Runtime.getRuntime().availableProcessors()*10;    // 方法一，自己写集合来实现获取线程池中任务的返回结果    public void testByQueue() throws Exception {       long start = System.currentTimeMillis();       AtomicInteger count = new AtomicInteger(0);        // 创建线程池        ExecutorService pool = Executors.newFixedThreadPool(POOL_SIZE);        // 拿任务的执行结果        BlockingQueue&lt;Future&lt;Integer&gt;&gt; queue =              new LinkedBlockingQueue&lt;Future&lt;Integer&gt;&gt;();        // 向里面扔任务        for (int i = 0; i &lt; TOTAL_TASK; i++) {            Future&lt;Integer&gt; future = pool.submit(new WorkTask(&quot;ExecTask&quot; + i));            queue.add(future);        }        // 检查线程池任务执行结果        for (int i = 0; i &lt; TOTAL_TASK; i++) {           int sleptTime = queue.take().get();           //System.out.println(&quot; slept &quot;+sleptTime+&quot; ms ...&quot;);           count.addAndGet(sleptTime);        }        // 关闭线程池        pool.shutdown();        System.out.println(&quot;-------------tasks sleep time &quot;+count.get()              +&quot;ms,and spend time &quot;              +(System.currentTimeMillis()-start)+&quot; ms&quot;);    }    public void testByCompletion() throws InterruptedException, ExecutionException {        long start = System.currentTimeMillis();        AtomicInteger count = new AtomicInteger(0);        // 创建线程池        ExecutorService pool = Executors.newFixedThreadPool(POOL_SIZE);        CompletionService&lt;Integer&gt; cService = new ExecutorCompletionService&lt;&gt;(pool);        // 向里面扔任务        for (int i = 0; i &lt; TOTAL_TASK; i++) {            cService.submit(new WorkTask(&quot;ExecTask&quot; + i));        }        // 检查线程池任务执行结果        for (int i = 0; i &lt; TOTAL_TASK; i++) {            int sleptTime = cService.take().get();            //System.out.println(&quot; slept &quot;+sleptTime+&quot; ms ...&quot;);            count.addAndGet(sleptTime);        }        // 关闭线程池        pool.shutdown();        System.out.println(&quot;-------------tasks sleep time &quot;+count.get()                +&quot;ms,and spend time &quot;                +(System.currentTimeMillis()-start)+&quot; ms&quot;);    }    public static void main(String[] args) throws Exception {        CompletionCase t = new CompletionCase();        t.testByQueue();        t.testByCompletion();    }}</code></pre><p>两种方法对比</p><pre><code>-------------tasks sleep time 38314ms,and spend time 5136 ms-------------tasks sleep time 40876ms,and spend time 5707 ms</code></pre>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Tomcat性能优化</title>
    <link href="/2020/01/10/tomcat%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    <url>/2020/01/10/tomcat%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="Tomcat内存优化"><a href="#Tomcat内存优化" class="headerlink" title="Tomcat内存优化"></a>Tomcat内存优化</h2><p>tomcat默认参数是为开发环境制定，而非适合生产环境，尤其是内存和线程的配置，默认都很低，容易成为性能瓶颈。</p><p>TOMCAT_HOME/bin/catalina.sh，在前面加入</p><pre><code>JAVA_OPTS=&quot;-XX:PermSize=64M -XX:MaxPermSize=128m -Xms512m -Xmx1024m -Duser.timezone=Asia/Shanghai&quot;</code></pre><p>此设置将最大堆内存改为1024m，实际调整时还是按照服务器的具体配置优化。</p><ul><li>JVM初始化堆大小：Xms</li><li>JVM堆的最大值：Xmx</li><li>JVM初始分配的非堆内存：PermSize</li><li>JVM最大允许分配的非堆内存：MaxPermSize</li></ul><h2 id="Tomcat线程优化"><a href="#Tomcat线程优化" class="headerlink" title="Tomcat线程优化"></a>Tomcat线程优化</h2><p>在TOMCAT_HOME/conf/server.xml中设置</p><pre><code>&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; maxThreads=&quot;600&quot; minSpareThreads=&quot;100&quot; maxSpareThreads=&quot;500&quot; acceptCount=&quot;700&quot;connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt;</code></pre><ul><li>maxThreads：最大线程数</li><li>minSpareThreads：最小空闲线程数（tomcat初始化时创建的线程数）</li><li>maxSpareThreads：最大空闲线程数（超过这个值之后，tomcat会关闭多余的socket线程）</li><li>acceptCount：等待队列长度。超过这个数的请求将不予处理，http请求将返回502状态码</li></ul><p>如果使用apache和tomcat做集群的负载均衡，并且使用ajp协议做apache和tomcat的协议转发，那么还需要优化ajp connector。</p><pre><code>&lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; maxThreads=&quot;600&quot; minSpareThreads=&quot;100&quot; maxSpareThreads=&quot;500&quot; acceptCount=&quot;700&quot;connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt;</code></pre><p>由于tomcat有多个connector，所以tomcat线程的配置可以支持多个connector共享一个线程池。</p><pre><code>&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot; maxThreads=&quot;500&quot; minSpareThreads=&quot;20&quot; maxIdleTime=&quot;60000&quot; /&gt;</code></pre><p>修改Connector节点，增加executor属性设置为线程池的名字</p><pre><code>&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;80&quot; protocol=&quot;HTTP/1.1&quot;  connectionTimeout=&quot;60000&quot; keepAliveTimeout=&quot;15000&quot; maxKeepAliveRequests=&quot;1&quot;  redirectPort=&quot;443&quot; /&gt;</code></pre><p>可以多个connector公用1个线程池，所以ajp connector也同样可以设置使用tomcatThreadPool线程池。</p><h2 id="Tomcat的连接器优化"><a href="#Tomcat的连接器优化" class="headerlink" title="Tomcat的连接器优化"></a>Tomcat的连接器优化</h2><p>Tomcat Connector(Tomcat连接器)有bio、nio、apr三种运行模式</p><h3 id="BIO"><a href="#BIO" class="headerlink" title="BIO"></a>BIO</h3><p>bio（blocking I/O，阻塞式I/O操作），表示Tomcat使用的是传统的Java I/O操作(即java.io包及其子包)。<br><strong>默认的模式，性能最差，没有经过任何优化处理和支持。</strong></p><h3 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h3><p>nio(non-blocking I/O，非阻塞式I/O操作)，也被看成是<code>non-blocking I/O</code>的缩写，是Java SE 1.4及后续版本提供的一种新的I/O操作方式(即java.nio包及其子包)。Java nio是一个基于缓冲区、并能提供非阻塞I/O操作的Java API。拥有比传统I/O操作(bio)更好的并发运行性能。 tomcat在8.0之后已经将nio作为默认运行模式，在8.0之前要让tomcat以nio方式来运行也比较简单，只需要修改tomcat目录下的/conf/servcer.xml中的protocol设置为<code>org.apache.coyote.http11.Http11NioProtocol</code>即可</p><pre><code>&lt;Connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot;connectionTimeout=&quot;20000&quot;redirectPort=&quot;8443&quot; /&gt;</code></pre><p>点击tomcat管理页面的server status之后就可以看到当前的运行模式</p><img src="/2020/01/10/tomcat%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic1.png" srcset="/img/loading.gif" class=""><h3 id="APR"><a href="#APR" class="headerlink" title="APR"></a>APR</h3><p>apr(Apache Portable Runtime/Apache可移植运行时库)，Tomcat将以JNI(Java Native Interface)的形式调用Apache HTTP服务器的核心动态链接库来处理文件读取或网络传输操作，从而大大地提高Tomcat对静态文件的处理性能。使用操作系统的部分本地操作，解决异步的IO问题，大幅度的提高性能。 Tomcat apr也是在Tomcat上运行高并发应用的首选模式。</p><p>Tomcat apr运行模式的配置是三种运行模式之中相对比较麻烦的一种。据官方文档所述，Tomcat apr需要以下三个组件的支持：</p><ul><li>APR library[APR库]</li><li>JNI wrappers for APR used by Tomcat (libtcnative)[简单地说，如果是在Windows操作系统上，就是一个名为tcnative-1.dll的动态链接库文件]</li><li>OpenSSL libraries[OpenSSL库]</li></ul><h3 id="centos7下tomcat8开启APR步骤"><a href="#centos7下tomcat8开启APR步骤" class="headerlink" title="centos7下tomcat8开启APR步骤"></a>centos7下tomcat8开启APR步骤</h3><ol><li>下载APR组件依赖</li></ol><img src="/2020/01/10/tomcat%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic2.png" srcset="/img/loading.gif" class=""><ol start="2"><li>安装apr</li></ol><pre><code>tar zxvf apr-1.6.5.tar.gzcd apr-1.6.5./configure --prefix=/usr/local/aprmake &amp;&amp; make install</code></pre><ol start="3"><li>安装apr-iconv</li></ol><pre><code>tar zxvf apr-iconv.1.2.2.tar.gzcd apr-iconv-1.2.2./configure --prefix=/usr/local/apr-iconv --with-apr=/usr/local/aprmake &amp;&amp; make install</code></pre><ol start="4"><li>安装apr-util</li></ol><pre><code>tar zxvf apr-util.1.6.1.tar.gzcd apr-util-1.6.1./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr --with-apr-iconv=/usr/local/apr-iconv/bin/apriconvmake &amp;&amp; make install</code></pre><ol start="5"><li>安装tomcat的bin目录下的tomcat-native-1.2.21-src.tar.gz</li></ol><pre><code>tar zxf tomcat-native-1.2.21-src.tar.gzcd tomcat-native-1.2.21cd native./configure --with-apr=/usr/local/apr --with-java-home=/usr/java/jdk1.8.0_65make &amp;&amp; make install</code></pre><ol start="6"><li>在tomcat的bin目录下的catalina.sh的最后一行添加变量</li></ol><pre><code>JAVA_OPTS=”$JAVA_OPTS -Djava.library.path=/usr/local/apr/lib”</code></pre><ol start="7"><li>重启tomcat启动日志中出现以下内容证明APR模式启动</li></ol><pre><code>10-Jan-2020 17:23:29.744 信息 [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [&quot;http-apr-9080&quot;]</code></pre><p>同理，通过tomcat的启动日志也可以判断出其运行状态</p><ul><li>bio</li></ul><pre><code>INFO: Initializing ProtocolHandler [&quot;http-bio-8080&quot;]Aug 04, 2015 10:20:35 PM org.apache.coyote.AbstractProtocol init</code></pre><ul><li>nio</li></ul><pre><code>INFO: Initializing ProtocolHandler [&quot;http-nio-8080&quot;]Aug 04, 2015 10:27:58 PM org.apache.coyote.AbstractProtocol init</code></pre><ul><li>apr</li></ul><pre><code>INFO: Initializing ProtocolHandler [&quot;http-apr-8080&quot;]Aug 04, 2015 10:33:45 PM org.apache.coyote.AbstractProtocol init</code></pre><h2 id="禁用DNS查询"><a href="#禁用DNS查询" class="headerlink" title="禁用DNS查询"></a>禁用DNS查询</h2><p>当web应用程序向要记录客户端的信息时，它也会记录客户端的IP地址或者通过域名服务器查找机器名 转换为IP地址。</p><p>DNS查询需要占用网络，并且包括可能从很多很远的服务器或者不起作用的服务器上去获取对应的IP的过程，这样会消耗一定的时间。</p><p>修改server.xml文件中的Connector元素，修改属性enableLookups参数值: enableLookups=”false”</p><p>如果为true，则可以通过调用request.getRemoteHost()进行DNS查询来得到远程客户端的实际主机名，若为false则不进行DNS查询，而是返回其ip地址</p><h2 id="设置session过期时间"><a href="#设置session过期时间" class="headerlink" title="设置session过期时间"></a>设置session过期时间</h2><p>在tomcat目录下的conf\web.xml中通过参数指定，单位为分钟。</p><pre><code>&lt;session-config&gt;       &lt;session-timeout&gt;180&lt;/session-timeout&gt;     &lt;/session-config&gt;</code></pre><h2 id="Maven项目远程部署到Tomcat"><a href="#Maven项目远程部署到Tomcat" class="headerlink" title="Maven项目远程部署到Tomcat"></a>Maven项目远程部署到Tomcat</h2><p>其实本节内容并不属于tomcat性能调优，但内容较少不足以再开一篇文章，凑合凑合塞到这吧。</p><ol><li>在tomcat根目录下的/conf/tomcat-users.xml添加用户</li></ol><pre><code>&lt;tomcat-users version=&quot;1.0&quot; xmlns=&quot;http://tomcat.apache.org/xml&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://tomcat.apache.org/xml tomcat-users.xsd&quot;&gt;&lt;role rolename=&quot;manager-gui&quot; /&gt;&lt;role rolename=&quot;manager-script&quot; /&gt;&lt;role rolename=&quot;admin-gui&quot; /&gt;&lt;role rolename=&quot;admin-script&quot; /&gt;&lt;user username=&quot;admin&quot; password=&quot;tomcat&quot; roles=&quot;manager-gui,manager-script,admin-gui,admin-script&quot; /&gt;&lt;/tomcat-users&gt;</code></pre><ol start="2"><li>pom文件中加入maven插件</li></ol><pre><code>&lt;plugin&gt;    &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt;    &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt;    &lt;version&gt;2.2&lt;/version&gt;    &lt;configuration&gt;        &lt;charset&gt;utf-8&lt;/charset&gt;        &lt;update&gt;true&lt;/update&gt;        &lt;url&gt;http://{yourIP}:8080/manager/text&lt;/url&gt;        &lt;mode&gt;war&lt;/mode&gt;        &lt;username&gt;username&lt;/username&gt;        &lt;password&gt;password&lt;/password&gt;        &lt;path&gt;/${project.artifactId}&lt;/path&gt;    &lt;/configuration&gt;&lt;/plugin&gt;</code></pre><p>tomcat7-maven-plugin是很久以前的插件版本，默认支持到Tomcat7，但是对于目前最新的Tomcat9同样可以使用该插件</p><p>官方介绍文档为：<code>http://tomcat.apache.org/maven-plugin-2.1/index.html</code></p><p>参数说明：</p><p>以下参数必选，但是可以在pom中空缺，空缺时将采用默认值</p><table><thead><tr><th>名称</th><th>描述</th><th>默认值</th></tr></thead><tbody><tr><td>charset</td><td>在与Tomcat Manager通信是的URL编 码字符集</td><td>ISO-8859-1</td></tr><tr><td>mode</td><td>部署的模式，值可为：war,context,both</td><td>war</td></tr><tr><td>path</td><td>应用程序运行的上下文路径，必须以’/‘开始</td><td>/${project.artifactId}</td></tr><tr><td>update</td><td>当部署已存在的应用时，是否自动 undeploy该应用</td><td>false</td></tr><tr><td>url</td><td>Tomcat Manager实例使用的全路径</td><td>tomcat的根路径/manager/text</td></tr><tr><td>warFile</td><td>部署warFile的路径</td><td>${project.build.directory} ${project.build.finalName}.war</td></tr></tbody></table><p>对于个性化的需求，tomcat7插件提供了可配置的参数</p><table><thead><tr><th>名称</th><th>描述</th></tr></thead><tbody><tr><td>contextFile</td><td>Tomcat的context的XML路径，对于mode=war不适用，默认为 ${project.build.directory}/${project.build.finalName}/ META-INF/context.xml</td></tr><tr><td>ignorePackaging</td><td>如果设置为true，忽略类型不是war的项目</td></tr><tr><td>username</td><td>部署到Tomcat的username</td></tr><tr><td>password</td><td>部署到Tomcat的password</td></tr><tr><td>server</td><td>指定Maven的setting.xml中配置的server id用于Tomcat认证</td></tr><tr><td>tag</td><td>应用程序在Tomcat中使用的标签的名字</td></tr></tbody></table><p>还可以在maven目录中的conf/setting.xml中添加tomcat的用户名和密码</p><pre><code>&lt;servers&gt;    &lt;server&gt;        &lt;id&gt;tomcatServer&lt;/id&gt;        &lt;username&gt;username&lt;/username&gt;        &lt;password&gt;password&lt;/password&gt;    &lt;/server&gt;&lt;/servers&gt;</code></pre><p>之后在pom文件中指定server的id即可，不在需要用户名密码</p><pre><code>&lt;plugin&gt;    &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt;    &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt;    &lt;version&gt;2.2&lt;/version&gt;    &lt;configuration&gt;        &lt;url&gt;http://{yourIP}:8080/manager/text&lt;/url&gt;        &lt;server&gt;tomcatServer&lt;/server&gt;        &lt;update&gt;true&lt;/update&gt;        &lt;path&gt;/${project.artifactId}&lt;/path&gt;    &lt;/configuration&gt;        &lt;/plugin&gt;</code></pre><ol start="3"><li>idea部署项目</li></ol><p>idea可以直接在右侧边栏中的plugins中找到tomcat7，第一次部署时选择deploy之后选择redeploy就可以了</p><p>mvn命令</p><pre><code>mvn tomcat7:deploymvn tomcat7:redeploymvn tomcat7:undeploy</code></pre>]]></content>
    
    
    <categories>
      
      <category>性能优化</category>
      
    </categories>
    
    
    <tags>
      
      <tag>tomcat</tag>
      
      <tag>性能优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>并发容器</title>
    <link href="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/"/>
    <url>/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="Hash算法"><a href="#Hash算法" class="headerlink" title="Hash算法"></a>Hash算法</h2><p>Hash一般译做散列，就是把任意长度的输入（又叫做预映射， pre-image），通过散列算法，变换成固定长度的输出，该输出就是散列值。这种转换是一种压缩映射，也就是散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能从散列值来确定唯一的输入值。简单的说Hash算法就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。因为其不可逆的特性，Hash算法也可以用来作为加密算法。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic1.png" srcset="/img/loading.gif" class=""><p>处理Hash冲突方法:</p><ol><li>开放寻址法：出现hash冲突时，从当前地址向后寻找</li><li>再散列法：出现hash冲突时，再次进行hash运算</li><li>链地址法（拉链法）：将有hash冲突的元素存储在链表或其他数据结构中</li></ol><p>常用hash算法的介绍：</p><ol><li>MD4 </li><li>MD5（常被用为加密算法）</li><li>SHA-1及其他。</li></ol><h2 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h2><h3 id="常用位运算"><a href="#常用位运算" class="headerlink" title="常用位运算"></a>常用位运算</h3><ul><li><p>位与 &amp; (1&amp;1=1,0&amp;0=0,1&amp;0=0)</p></li><li><p>位或 | (1|1=1,0|0=0,1|0=1)</p></li><li><p>位非 ~ ( ~1=0,~0=1)</p></li><li><p>位异或 ^ (1^1=0,1^0=1,0^0=0)</p></li><li><p>有符号右移&gt;&gt;(正数高位补0,负数高位补1)</p></li><li><p>有符号左移&lt;&lt;(低位补0)</p></li><li><p>无符号右移&gt;&gt;&gt;(不论正负,高位均补0)</p></li></ul><p>有趣的取模性质：取模a % (2^n) 等价于 a &amp; (2^n - 1)，所以在map里的数组个数一定是2的乘方数，计算key值在哪个元素中的时候，就用位运算来快速定位。</p><pre><code>public class IntToBinary {    public static void main(String[] args) throws UnsupportedEncodingException {        System.out.println(&quot;the 4 is : &quot; + Integer.toBinaryString(4));        System.out.println(&quot;the 6 is : &quot; + Integer.toBinaryString(6));        //位与&amp;(真真为真 真假为假 假假为假)        System.out.println(&quot;the 4&amp;6 is : &quot; + Integer.toBinaryString(6&amp;4));        //位或|(真真为真 真假为真 假假为假)        System.out.println(&quot;the 4|6 is : &quot; + Integer.toBinaryString(6|4));        //位非~        System.out.println(&quot;the ~4 is : &quot; + Integer.toBinaryString(~4));        //位异或^(真真为假 真假为真 假假为假)        System.out.println(&quot;the 4^6 is : &quot; + Integer.toBinaryString(6^4));        //有符号右移&gt;&gt;(若正数,高位补0,负数,高位补1)        System.out.println(&quot;the 4&gt;&gt;1 is : &quot; + Integer.toBinaryString(4&gt;&gt;1));        //有符号左移&lt;&lt;(若正数,高位补0,负数,高位补1)        System.out.println(&quot;the 4&lt;&lt;1 is : &quot; + Integer.toBinaryString(4&lt;&lt;1));        //无符号右移&gt;&gt;&gt;(不论正负,高位均补0)        System.out.println(&quot;the 234567 is : &quot; + Integer.toBinaryString(234567));        System.out.println(&quot;the 234567&gt;&gt;&gt;4 is : &quot; + Integer.toBinaryString(234567&gt;&gt;&gt;4));        //无符号右移&gt;&gt;&gt;(不论正负,高位均补0)        System.out.println(&quot;the -4 is : &quot; + Integer.toBinaryString(-4));        System.out.println(&quot;the -4&gt;&gt;&gt;4 is : &quot; + Integer.toBinaryString(-4&gt;&gt;&gt;4));        System.out.println(Integer.parseInt(Integer.toBinaryString(-4&gt;&gt;&gt;4), 2));        //取模a % (2^n) 等价于 a &amp; (2^n - 1)         System.out.println(&quot;the 345 % 16 is : &quot; + (345%16)+&quot; or &quot;+(345&amp;(16-1)));        System.out.println(&quot;Mark hashCode is : &quot;+&quot;Mark&quot;.hashCode()+&quot;=&quot;              +Integer.toBinaryString(&quot;Mark&quot;.hashCode()));        System.out.println(&quot;Bill hashCode is : &quot;+&quot;Bill&quot;.hashCode()+&quot;=&quot;              +Integer.toBinaryString(&quot;Bill&quot;.hashCode()));            } }</code></pre><h3 id="位运算运用场景"><a href="#位运算运用场景" class="headerlink" title="位运算运用场景"></a>位运算运用场景</h3><ul><li><p>Java中的类修饰符、成员变量修饰符、方法修饰符，比如Class类中</p></li><li><p>Java容器中的HashMap和ConcurrentHashMap的实现</p></li><li><p>权限控制或者商品属性</p></li><li><p>简单可逆加密，比如异或运算(1^1=0,0^1=1 )</p></li></ul><p>实战：权限控制</p><pre><code>public class Permission {    private static final int ALLOW_SELECT = 1 &lt;&lt; 0;    private static final int ALLOW_INSERT = 1 &lt;&lt; 1;    private static final int ALLOW_UPDATE = 1 &lt;&lt; 2;    private static final int ALLOW_DELETE = 1 &lt;&lt; 3;    // 当前状态    private int flag;    public void setPermission(int permission) {        this.flag = permission;    }    // 增加权限，可以一项或者多项    public void addPermission(int permission) {        this.flag = flag | permission;    }    // 删除权限，可以一项或者多项    public void disablePermission(int permission) {        this.flag = flag &amp; ~permission;    }    // 是否拥有权限    public boolean isAllow(int permission) {        return (this.flag &amp; permission) == permission;    }    // 是否不拥有权限    public boolean isNotAllow(int permission) {        return (this.flag &amp; permission) == 0;    }    public static void main(String[] args) {      int flag = 15;      Permission permission = new Permission();      permission.setPermission(flag);      permission.disablePermission(ALLOW_DELETE|ALLOW_INSERT);      System.out.println(&quot;ALLOW_SELECT=&quot;+permission.isAllow(ALLOW_SELECT));      System.out.println(&quot;ALLOW_INSERT=&quot;+permission.isAllow(ALLOW_INSERT));      System.out.println(&quot;ALLOW_UPDATE=&quot;+permission.isAllow(ALLOW_UPDATE));      System.out.println(&quot;ALLOW_DELETE=&quot;+permission.isAllow(ALLOW_DELETE));    }</code></pre><p>使用位运算可以节省很多代码量，而且效率高、属性变动影响小，但位运算不太直观，会对代码可读性产生一定的影响。</p><h2 id="JDK1-7中HashMap死循环分析"><a href="#JDK1-7中HashMap死循环分析" class="headerlink" title="JDK1.7中HashMap死循环分析"></a>JDK1.7中HashMap死循环分析</h2><p>在多线程环境下，HashMap在并发执行put操作时会导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry，导致CPU利用率接近100%。</p><h3 id="HashMap扩容流程"><a href="#HashMap扩容流程" class="headerlink" title="HashMap扩容流程"></a>HashMap扩容流程</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>正常的扩容操作是这个流程。HashMap的扩容在put操作中会触发扩容，主要是三个方法：</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic2.png" srcset="/img/loading.gif" class=""><p>综合来说，HashMap一次扩容的过程：</p><ol><li><p>取当前table的2倍作为新table的大小</p></li><li><p>根据算出的新table的大小new出一个新的Entry数组来，名为newTable</p></li><li><p>轮询原table的每一个位置，将每个位置上连接的Entry，算出在新table上的位置，并以链表形式连接</p></li><li><p>原table上的所有Entry全部轮询完毕之后，意味着原table上面的所有Entry已经移到了新的table上，HashMap中的table指向newTable</p></li></ol><h4 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h4><p>现在hashmap中有三个元素，key分别为3、7、5，Hash表的size=2, 通过hash计算后这三个元素都将分配到table[1]。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic3.png" srcset="/img/loading.gif" class=""><p>按照方法中的代码</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic4.png" srcset="/img/loading.gif" class=""><p>对table[1]中的链表来说，进入while循环，此时e=key(3)，那么next=key(7)，经过计算重新定位e=key(3)在新表中的位置，并把e=key(3)分配newTable[3]的位置</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic5.png" srcset="/img/loading.gif" class=""><p>这样循环下去，将table[1]中的链表循环完成后，于是HashMap就完成了扩容</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic6.png" srcset="/img/loading.gif" class=""><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic7.png" srcset="/img/loading.gif" class=""><p>HashMap在hash冲突插入元素时采用的是头插法，先将新的元素的next指向当前table[i]，之后再将table[i]指向当前元素</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic8.png" srcset="/img/loading.gif" class=""><h3 id="并发下的扩容"><a href="#并发下的扩容" class="headerlink" title="并发下的扩容"></a>并发下的扩容</h3><p>初始的HashMap还是：</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic9.png" srcset="/img/loading.gif" class=""><p>现在假设有两个线程并发操作，都进入了扩容操作线程1执行到Entry&lt;K,V&gt; next = e.next;时被操作系统调度挂起了，而线程2执行完成了扩容操作:</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic10.png" srcset="/img/loading.gif" class=""><p>于是，在线程1,2看来，就应该是这个样子</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic11.png" srcset="/img/loading.gif" class=""><p>接下来，线程1被调度回来执行： </p><ol><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic12.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic13.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic14.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic15.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic16.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic17.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic18.png" srcset="/img/loading.gif" class=""></li></ol><p>循环列表产生后，一旦线程1调用get（11,15之类的元素）时，就会进入一个死循环的情况，将CPU的消耗到100%。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>HashMap之所以在并发下的扩容造成死循环，是因为多个线程并发进行时，一个线程先期完成了扩容，将原Map的链表重新散列到自己的表中，并将链表变成了倒序，后一个线程再扩容时，又进行自己的散列，再次将倒序链表变为正序链表，于是形成了一个环形链表，当get表中不存在的元素时，会去遍历链表造成死循环。</p><h2 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h2><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>除了Map系列应该有的线程安全的get，put等方法外，ConcurrentHashMap还提供了一个在并发下比较有用的方法 putIfAbsent，如果传入key对应的value已经存在，就返回存在的value，不进行替换。如果不存在，就添加key和value，返回null。在代码层面它的作用类似于：</p><pre><code>synchronized(map){    if (map.get(key) == null){         return map.put(key, value);    } else{         return map.get(key);    }}</code></pre><p>它让上述代码的整个操作是线程安全的。</p><h3 id="ConcurrentHashMap实现分析"><a href="#ConcurrentHashMap实现分析" class="headerlink" title="ConcurrentHashMap实现分析"></a>ConcurrentHashMap实现分析</h3><h4 id="在1-7下的实现"><a href="#在1-7下的实现" class="headerlink" title="在1.7下的实现"></a>在1.7下的实现</h4><h5 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic19.png" srcset="/img/loading.gif" class=""><p>ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁（ReentrantLock），在ConcurrentHashMap里扮演锁的角色；HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组。Segment的结构和HashMap类似，是一种数组和链表结构。一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素，每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得与它对应的Segment锁。Segment数组初始化之后大小不再改变，当需要扩容时Segment下的table数组进行扩容。</p><h5 id="初始化方法"><a href="#初始化方法" class="headerlink" title="初始化方法"></a>初始化方法</h5><p>ConcurrentHashMap初始化方法是通过initialCapacity（初始化容量）、loadFactor（负载因子）和concurrencyLevel（并发级别）来初始化segment数组、段偏移量segmentShift、段掩码segmentMask和每个segment里的HashEntry数组来实现的。</p><p>参数concurrencyLevel（并发度）可以理解为程序运行时能够同时更新ConccurentHashMap且不产生锁竞争的最大线程数，实际上就是ConcurrentHashMap中的分段锁个数，即Segment[]的数组长度。ConcurrentHashMap默认的并发度为16，用户也可以在构造函数中设置并发度，设置之后将不再改变。当用户设置并发度时，ConcurrentHashMap会使用大于等于该值的最小2幂指数作为实际并发度（假如用户设置并发度为17，实际并发度则为32）。如果设置的过小，会带来严重的锁竞争问题；如果设置的过大，原本位于同一个Segment内的访问会扩散到不同的Segment中，CPU cache命中率会下降，从而引起程序性能下降。大小可以通过cpu核心数或实际使用该Map的线程数量来确定。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic20.png" srcset="/img/loading.gif" class=""><p>参数initialCapacity是ConcurrentHashMap的初始化容量，loadfactor是每个Segment的负载因子，在构造方法里需要通过这两个参数来初始化数组中的每个Segment。上面代码中的变量cap就是Segment里HashEntry数组的长度，它等于initialCapacity除以ssize的倍数c，如果c大于1，就会取大于等于c的2的N次方值，所以segment里HashEntry数组的长度不是1，就是2的N次方。</p><p>在默认情况下， ssize = 16，initialCapacity = 16，loadFactor = 0.75f，那么cap = 1，threshold = (int) cap * loadFactor = 0。</p><p>在初始化时，默认只初始化Segment[0]中的table，其他Segment中的table在put时再进行初始化。</p><p>初始化segmentShift和segmentMask（了解即可，无需深究）这两个全局变量需要在定位segment时的散列算法里使用，shift等于size从1向左移位的次数，在默认情况下concurrencyLevel等于16，1需要向左移位移动4次，所以sshift等于4。segmentShift用于定位参与散列运算的位数，segmentShift等于32减sshift，所以等于28，这里之所以用<em>32</em>是因为ConcurrentHashMap里的hash()方法输出的最大数是<em>32</em>位的。segmentMask是散列运算的掩码，等于ssize减1，即15，掩码的二进制各个位的值都是<em>1</em>。因为ssize的最大长度是65536，所以segmentShift最大值是16，segmentMask最大值是65535，对应的二进制是16位，每个位都是1。</p><h5 id="get方法"><a href="#get方法" class="headerlink" title="get方法"></a>get方法</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic21.png" srcset="/img/loading.gif" class=""><p>既然ConcurrentHashMap使用分段锁Segment来保护不同段的数据，那么在插入和获取元素的时候，必须先通过散列算法定位到Segment。get操作先获取hash值，然后使用这个hash值通过hash运算定位到Segment(使用了hash值的高位部分)，再通过hash算法定位到table(使用了散列值的全部)。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic22.png" srcset="/img/loading.gif" class=""><p>整个get过程没有加锁，而是通过volatile保证get总是可以拿到最新值。</p><p>ConcurrentHashMap中使用的hash算法为Wang/Jenkins hash的变种算法，其产生的hash的值更加均匀，减少了hash冲突</p><h5 id="put方法"><a href="#put方法" class="headerlink" title="put方法"></a>put方法</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic24.png" srcset="/img/loading.gif" class=""><p>put方法首先会根据key计算出所在的Segment，然后调用ensureSegment()方法获取Segment。因为ConcurrentHashMap初始化时只会初始化第一个槽 segment[0]，所以其他槽在插入第一个值时会在ensureSegment()方法中进行初始化。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic25.png" srcset="/img/loading.gif" class=""><p>ensureSegment方法考虑了并发情况，当多个线程同时进入初始化同一个槽 segment[k]会进行循环CAS操作保证只有一个线程成功。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic26.png" srcset="/img/loading.gif" class=""><p>put方法在获取到Segment之后会调用Segment中的put方法，Segment中的put方法会通过tryLock()方法尝试获得锁，如果成功获得锁会将node置为null然后进入try语句块，如果没有获得锁会调用scanAndLockForPut()方法自旋等待获得锁。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic27.png" srcset="/img/loading.gif" class=""><p>scanAndLockForPut方法里在尝试获得锁的过程中会对对应HashEntity链表进行遍历，如果遍历完毕仍然找不到与key相同的HashEntry节点，则为后续的put操作提前创建一个HashEntry。当tryLock一定次数（当cpu可用核心数大于1时重试64次，否则只重试1次）后仍无法获得锁，则通过lock()阻塞式申请锁。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic28.png" srcset="/img/loading.gif" class=""><p>在获得锁之后，Segment对链表进行遍历，如果某个HashEntry节点具有相同的key，则更新该HashEntry的value值</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic29.png" srcset="/img/loading.gif" class=""><p>否则新建一个HashEntry节点，采用头插法，将它设置为链表的新head节点并将原头节点设为新head的下一个节点。新建过程中如果节点总数（含新建的HashEntry）超过threshold，则调用rehash()方法对Segment进行扩容，最后将新建HashEntry写入到数组中。</p><h5 id="rehash方法"><a href="#rehash方法" class="headerlink" title="rehash方法"></a>rehash方法</h5><p>rehash方法扩容时会先创建数组newTable，然后进行将table中的节点迁移至newTable，最后用newTable取代table。</p><p>由于扩容是基于2的幂指来操作，假设扩容前某HashEntry对应到Segment中数组的index为i，数组的容量为capacity，那么扩容后该HashEntry对应到新数组中的index只可能为i或者i+capacity，因此很多HashEntry节点在扩容前后index可以保持不变，避免让所有的节点都进行复制操作。</p><p>假设原来table长度为4，那么元素在table中的分布是这样的</p><table><thead><tr><th>Hash值</th><th>15</th><th>23</th><th>34</th><th>56</th><th>77</th></tr></thead><tbody><tr><td>在table中的下标</td><td>3 = 15%4</td><td>3=23%4</td><td>2 = 34%4</td><td>0= 56%4</td><td>1 =77 %4</td></tr></tbody></table><p>扩容后table长度变为8，那么元素在table中的分布变成：</p><table><thead><tr><th>Hash值</th><th>15</th><th>23</th><th>34</th><th>56</th><th>77</th></tr></thead><tbody><tr><td>在table中的下标</td><td>7</td><td>7</td><td>2</td><td>0</td><td>5</td></tr></tbody></table><p>可以看见 hash值为34和56的下标保持不变，而15,23,77的下标都是在原来下标的基础上+4即可，可以快速定位和减少重排次数。</p><p>该方法没有考虑并发，因为执行该方法之前已经获取了锁。</p><h5 id="remove方法"><a href="#remove方法" class="headerlink" title="remove方法"></a>remove方法</h5><p>与put方法类似，都是在操作前需要拿到锁，以保证操作的线程安全性。</p><h5 id="size、containsValue方法"><a href="#size、containsValue方法" class="headerlink" title="size、containsValue方法"></a>size、containsValue方法</h5><p>这些方法都是基于整个ConcurrentHashMap来进行操作的，他们的原理也基本类似：首先不加锁循环执行以下操作：循环所有的Segment，获得对应的值以及所有Segment的modcount之和。在 put、remove 和 clean 方法里操作元素前都会将变量 modCount 进行变动，如果连续两次所有Segment的modcount和相等，则过程中没有发生其他线程修改ConcurrentHashMap的情况，返回获得的值。</p><p>当循环次数超过预定义的值时，这时需要对所有的Segment依次进行加锁，获取返回值后再依次解锁。所以一般来说，应该避免在多线程环境下使用size和containsValue方法。</p><h5 id="ConcurrentHashMap的弱一致性"><a href="#ConcurrentHashMap的弱一致性" class="headerlink" title="ConcurrentHashMap的弱一致性"></a>ConcurrentHashMap的弱一致性</h5><p>ConcurrentHashMap的get()和containsKey()方法并没有加锁，在遍历链表节点判断key是否相同以及获得该节点的value时，其他线程对链表结构做的调整（put新的key或者remove操作）会由于HashEntity数组并不是volita修饰的导致返回的可能是过时的数据。如果要求强一致性，那么必须使用Collections.synchronizedMap()方法。</p><h4 id="在1-8下的实现"><a href="#在1-8下的实现" class="headerlink" title="在1.8下的实现"></a>在1.8下的实现</h4><h5 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h5><ol><li>取消segments字段，直接采用transient volatile HashEntry&lt;K,V&gt;[] table保存数据，使用table数组元素作为锁，由于table是可以扩容的，数据的增加时锁的粒度也会缩小以减少并发冲突的概率，同时大量使用了使用 CAS + synchronized 来保证并发安全性。</li><li>将原本的table数组＋单向链表的数据结构，变更为table数组＋单向链表＋红黑树的结构。hash表最核心的能力在于将key hash之后能均匀的分布在数组中，理想的情况下table数组中的每个队列长度主要为0或者1，但实际情况并非如此。在数据量过大的情况下，即使ConcurrentHashMap类会依据默认的加载因子0.75进行扩容、增加table数组长度，但是如果hash结果不均匀，也会使数据集中在某个队列导致队列过长。此时查询某个节点的时间复杂度为O(n)。所以对于个数超过8(默认值)的列表jdk1.8中采用了红黑树的结构，查询的时间复杂度可以降低到O(logN)，从而改进性能。</li><li>使用 Node（jdk1.7 为 HashEntry）作为链表的数据结点，仍然包含 key，value，hash 和 next 四个属性。 红黑树中使用的是 TreeNode（extends Node）。所以根据数组元素中第一个结点数据类型是 Node 还是 TreeNode 可以判断该位置下是链表还是红黑树。</li></ol><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic30.png" srcset="/img/loading.gif" class=""><p>当链表的长度大于8时会转为红黑树</p><p>当红黑树的大小小于6时会转为链表</p><h5 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h5><p>Node是最核心的内部类，它包装了key-value键值对。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic31.png" srcset="/img/loading.gif" class=""><p>定义基本和1.7中的HashEntry相同。Map本身所持有的也是一个Node型的数组</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic32.png" srcset="/img/loading.gif" class=""><p>增加了一个find方法来用以辅助map.get()方法。其实就是遍历链表，子类中会覆盖这个方法。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic35.png" srcset="/img/loading.gif" class=""><p>在map中还定义了Segment这个类，不过只是为了向前兼容而已，不做过多考虑。</p><h5 id="TreeNode"><a href="#TreeNode" class="headerlink" title="TreeNode"></a>TreeNode</h5><p>树节点类，另外一个核心的数据结构。当链表长度过长的时候，会转换为TreeNode。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic33.png" srcset="/img/loading.gif" class=""><p>与1.8中HashMap不同点：</p><ol><li><p>它并不是直接转换为红黑树，而是把这些结点放在TreeBin对象中，由TreeBin完成对红黑树的包装。</p></li><li><p>TreeNode在ConcurrentHashMap继承Node类，HashMap中的继承LinkedHashMap.Entry&lt;K,V&gt;类，ConcurrentHashMap中的TreeNode带有next指针。</p></li></ol><h5 id="TreeBin"><a href="#TreeBin" class="headerlink" title="TreeBin"></a>TreeBin</h5><p>负责TreeNode节点。它代替了TreeNode的根节点，也就是说在实际ConcurrentHashMap的table数组中存放的是TreeBin对象，而不是TreeNode对象。另外这个类还带有了读写锁机制。</p><h5 id="特殊的ForwardingNode"><a href="#特殊的ForwardingNode" class="headerlink" title="特殊的ForwardingNode"></a>特殊的ForwardingNode</h5><p>ForwardingNode是一个特殊的 Node 结点，hash 值为 -1，内部存储nextTable的引用。在table发生扩容的时作为一个占位符放在 table 中表示当前结点为 null 或者已经被移动。</p><h5 id="sizeCtl"><a href="#sizeCtl" class="headerlink" title="sizeCtl"></a>sizeCtl</h5><p>用来控制 table 的初始化和扩容操作。</p><p>负数代表正在进行初始化或扩容操作：-1代表正在初始化，-N 表示有N-1个线程正在进行扩容操作，0为默认值，代表当时的table还没有被初始化。</p><p>正数表示初始化大小或Map中的元素达到这个数量时，需要进行扩容了。</p><h5 id="核心方法"><a href="#核心方法" class="headerlink" title="核心方法"></a>核心方法</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic36.png" srcset="/img/loading.gif" class=""><h5 id="构造方法"><a href="#构造方法" class="headerlink" title="构造方法"></a>构造方法</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic37.png" srcset="/img/loading.gif" class=""><p>可以发现，在new出一个map的实例时，并不会创建其中的数组等等相关的部件，只是进行简单的属性设置而已。同样的，table的大小也被规定为必须是2的乘方数。</p><p>真正的初始化在放在了是在向ConcurrentHashMap中插入元素的时候发生的。如调用put()、computeIfAbsent()、compute()、merge()等方法的时候，调用时机是检查table==null。</p><h5 id="get操作"><a href="#get操作" class="headerlink" title="get操作"></a>get操作</h5><p>get方法比较简单，给定一个key来确定value的时候，必须满足两个条件 key相同 hash值相同，对于节点可能在链表或树上的情况，需要分别去查找。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic38.png" srcset="/img/loading.gif" class=""><h5 id="put操作"><a href="#put操作" class="headerlink" title="put操作"></a>put操作</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic40.png" srcset="/img/loading.gif" class=""><p>总结来说，put方法也继续沿用HashMap的put方法的思想，首先不允许key或value为null的情况放入，对于每一个放入的值，利用spread方法对key的hashcode进行一次hash计算，由此来确定这个值在table中的位置i，如果i位置是空的，直接放进去且不需要加锁操作，否则对i位置节点进行加锁，然后对节点进行判断，如果是树节点则按照树的方式插入新的节点，如果是链表节点，则得到的结点就是由hash值相同的节点组成的链表的头节点。此时需要向后遍历链表，如果遇到key值一致的情况，则需要更新其value值，否则依次向后遍历，到链表尾插入这个结点（尾插法）。如果加入这个节点以后链表长度大于8，就把这个链表转换成红黑树。</p><h5 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic39.png" srcset="/img/loading.gif" class=""><p>前面说过，构造方法中并没有真正初始化，真正的初始化在放在了是在向ConcurrentHashMap中插入元素的时候发生的。具体实现的方法就是initTable</p><h5 id="transfer"><a href="#transfer" class="headerlink" title="transfer"></a>transfer</h5><p>当ConcurrentHashMap容量不足的时需要对table进行扩容。这个方法的基本思想跟HashMap是很像的，但是由于它是支持并发扩容的，所以要复杂的多。我们不深入源码去讲述，只讲述其大概原理。</p><p>扩容的时总是会涉及到从一个“数组”到另一个“数组”拷贝的操作，并发扩容就是使这个操作能够并发进行，利用并发处理去减少扩容带来的时间影响。transfer中的并发扩容就是将数据迁移任务根据变量stride作为步长拆分成多个小迁移任务，每个线程每次负责迁移其中的一部分。</p><p>整个扩容操作分为两个部分：</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic41.png" srcset="/img/loading.gif" class=""><p>第一部分是构建一个nextTable,它的容量是原来的2倍。</p><p>第二个部分就是将原来table中的元素复制到nextTable中，这里允许多线程进行操作。</p><p>整个扩容流程就是遍历和复制：</p><p>为null或者已经处理过的节点，会被设置为forwardNode节点，当线程准备扩容时，发现节点是forwardNode节点，跳过这个节点，继续寻找未处理的节点，找到之后对节点上锁。</p><p>如果这个位置是Node节点（fh&gt;=0），说明它是一个链表，就构造一个反序链表，把他们分别放在nextTable的i和i+n的位置上</p><p>如果这个位置是TreeBin节点（fh&lt;0），也做一个反序处理，并且判断是否需要红黑树转链表，把处理的结果分别放在nextTable的i和i+n的位置上</p><p>遍历过所有的节点以后就完成了复制工作，这时让nextTable作为新的table，并且更新sizeCtl为新容量的0.75倍 ，完成扩容。</p><h5 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h5><p>移除方法的基本流程和put方法很类似，只不过操作由插入数据变为移除数据而已，而且如果存在红黑树的情况下，会检查是否需要将红黑树转为链表的步骤。不再重复讲述。</p><h5 id="treeifyBin"><a href="#treeifyBin" class="headerlink" title="treeifyBin"></a>treeifyBin</h5><p>用于将过长的链表转换为TreeBin对象。但是他并不是直接转换，而是进行一次容量判断，没有达到转换的要求，直接进行扩容操作并返回；如果满足条件才将链表的结构转换为TreeBin ，这与HashMap不同的是，它并没有把TreeNode直接放入红黑树，而是利用了TreeBin这个小容器来封装所有的TreeNode。</p><h5 id="size"><a href="#size" class="headerlink" title="size"></a>size</h5><p>JDK1.8中，调用put()方法时就会调用addCount()方法计算size的数量，扩容过程也会修改size的数量，因此在调用size()方法时可以直接返回，JDK1.7是调用size()方法时才会去计算。</p><p>调用addCount()方法时，会使用CAS更新baseCount，因为CAS只允许一个线程做修改，如果修改失败就会使用counterCells，大致的流程就是：</p><ol><li><p>对 baseCount 做 CAS 自增操作。</p></li><li><p>如果并发导致 baseCount CAS 失败了，则使用 counterCells。</p></li><li><p>如果counterCells CAS 失败了，在 fullAddCount 方法中，会继续死循环操作，直到成功。</p></li></ol><p>在具体实现上，计算大小的核心方法都是 sumCount()</p><p>JDK1.8中sumCount()会获取baseCount和CounterCell数组然后遍历CounterCell数组，将baseCount与CounterCell的值累加后返回。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic42.png" srcset="/img/loading.gif" class=""><p>其实去计算并发集合中实时在变的size是没有多大的意义的，但Doug Lea仍花费了很多心思去优化他的性能。</p><h2 id="HashTable"><a href="#HashTable" class="headerlink" title="HashTable"></a>HashTable</h2><p>HashTable容器使用synchronized来保证线程安全，这会导致在线程竞争激烈的情况下HashTable的效率非常低下。当一个线程访问HashTable的同步方法，其他线程也访问HashTable的同步方法时，会进入阻塞或轮询状态。如线程1使用put进行元素添加，线程2不但不能使用put方法添加元素，也不能使用get方法来获取元素，所以竞争越激烈效率越低。</p><h2 id="并发下的Map常见面试题汇总"><a href="#并发下的Map常见面试题汇总" class="headerlink" title="并发下的Map常见面试题汇总"></a>并发下的Map常见面试题汇总</h2><h3 id="HashMap-和-HashTable-有什么区别？"><a href="#HashMap-和-HashTable-有什么区别？" class="headerlink" title="HashMap 和 HashTable 有什么区别？"></a>HashMap 和 HashTable 有什么区别？</h3><ol><li><p>HashMap 是线程不安全的，HashTable 是线程安全的；</p></li><li><p>由于线程安全，所以 HashTable 的效率比不上 HashMap；</p></li><li><p>HashMap是允许key为value的，HashTable是不允许的，ConcurrentHashMap也是不允许的。</p></li><li><p>HashMap最多只允许一条记录的键为null，允许多条记录的值为null，而 HashTable 不允许；</p></li><li><p>HashMap 默认初始化数组的大小为16，HashTable 为 11，前者扩容时，扩大两倍，后者扩大两倍+1；</p></li><li><p>HashMap 需要重新计算 hash 值，而 HashTable 直接使用对象的 hashCode</p></li></ol><h3 id="Java-中的另一个线程安全的与-HashMap-极其类似的类是什么？同样是线程安全，它与-HashTable-在线程同步上有什么不同？"><a href="#Java-中的另一个线程安全的与-HashMap-极其类似的类是什么？同样是线程安全，它与-HashTable-在线程同步上有什么不同？" class="headerlink" title="Java 中的另一个线程安全的与 HashMap 极其类似的类是什么？同样是线程安全，它与 HashTable 在线程同步上有什么不同？"></a>Java 中的另一个线程安全的与 HashMap 极其类似的类是什么？同样是线程安全，它与 HashTable 在线程同步上有什么不同？</h3><p>ConcurrentHashMap 类（是 Java并发包 java.util.concurrent 中提供的一个线程安全且高效的 HashMap 实现）。</p><p>HashTable 是使用 synchronize 关键字加锁的原理（就是对对象加锁）；</p><p>而针对 ConcurrentHashMap，在 JDK 1.7 中采用Segment分段锁的方式；JDK 1.8 中直接采用了CAS（无锁算法）+ synchronized，也采用分段锁的方式但1.8中的分段锁是使用synchronized锁住table中的节点来实现的，缩小了锁的粒度。</p><h3 id="HashMap-amp-ConcurrentHashMap-的区别？"><a href="#HashMap-amp-ConcurrentHashMap-的区别？" class="headerlink" title="HashMap &amp; ConcurrentHashMap 的区别？"></a>HashMap &amp; ConcurrentHashMap 的区别？</h3><p>除了加锁，原理上无太大区别。</p><p>另外，HashMap 的键值对允许有null，但是ConCurrentHashMap 都不允许。</p><p>在数据结构上，红黑树相关的节点类不同继承的类不同</p><h3 id="为什么ConcurrentHashMap比HashTable效率要高？"><a href="#为什么ConcurrentHashMap比HashTable效率要高？" class="headerlink" title="为什么ConcurrentHashMap比HashTable效率要高？"></a>为什么ConcurrentHashMap比HashTable效率要高？</h3><p>HashTable 使用一把锁（锁住整个链表结构）处理并发问题，多个线程竞争一把锁，容易阻塞ConcurrentHashMap在JDK 1.7 中使用分段锁（ReentrantLock + Segment + HashEntry），相当于把一个 HashMap 分成多个段，每段分配一把锁，这样支持多线程访问。锁粒度基于 Segment，Segment中包含多个 HashEntry。JDK 1.8 中使用 CAS + synchronized + Node + 红黑树。锁粒度基于Node（首结点）（实现 Map.Entry&lt;K,V&gt;），锁粒度相对1.7降低了。</p><h3 id="针对ConcurrentHashMap-锁机制具体分析？"><a href="#针对ConcurrentHashMap-锁机制具体分析？" class="headerlink" title="针对ConcurrentHashMap 锁机制具体分析？"></a>针对ConcurrentHashMap 锁机制具体分析？</h3><p>JDK 1.7 中，采用分段锁的机制，实现并发的更新操作，底层采用数组+链表的存储结构，包括两个核心静态内部类 Segment 和 HashEntry。Segment 继承 ReentrantLock（重入锁） 用来充当锁的角色，每个 Segment 对象守护每个散列映射表的若干个桶；HashEntry 用来封装映射表的键-值对；每个桶是由若干个 HashEntry 对象链接起来的链表。</p><p>JDK 1.8 中，采用Node + CAS + Synchronized来保证并发安全。取消类 Segment，当需要锁时直接用synchronized锁住table数组中的对象，键值对直接存储在table中；当 Node 对象组成的链表长度超过 TREEIFY_THRESHOLD 时，链表转换为红黑树，Node对象被包装为TreeNode，以提升检索性能。此时底层变更为数组 + 链表 + 红黑树。</p><h3 id="ConcurrentHashMap在JDK-1-8中，为什么要使用内置锁-synchronized-来代替重入锁-ReentrantLock？"><a href="#ConcurrentHashMap在JDK-1-8中，为什么要使用内置锁-synchronized-来代替重入锁-ReentrantLock？" class="headerlink" title="ConcurrentHashMap在JDK 1.8中，为什么要使用内置锁 synchronized 来代替重入锁 ReentrantLock？"></a>ConcurrentHashMap在JDK 1.8中，为什么要使用内置锁 synchronized 来代替重入锁 ReentrantLock？</h3><ol><li><p>JVM 开发团队在1.8中对 synchronized做了大量性能上的优化，而且基于 JVM 的 synchronized 优化空间更大，更加自然。</p></li><li><p>在大量的数据操作下，对于 JVM 的内存压力，基于 API 的 ReentrantLock 会开销更多的内存。</p></li></ol><h3 id="ConcurrentHashMap简单介绍？"><a href="#ConcurrentHashMap简单介绍？" class="headerlink" title="ConcurrentHashMap简单介绍？"></a>ConcurrentHashMap简单介绍？</h3><ol><li><p>重要的常量：<strong>private transient volatile int sizeCtl</strong>，当为负数时，-1 表示正在初始化，-N 表示 N - 1 个线程正在进行扩容；当为 0 时，表示 table 还没有初始化；当为其他正数时，表示初始化或者下一次进行扩容的大小。</p></li><li><p>数据结构：<strong>Node 是存储结构的基本单元</strong>，继承 HashMap 中的 Entry，用于存储数据；TreeNode 继承 Node，但是数据结构换成了二叉树结构，是红黑树的存储结构，用于红黑树中存储数据；TreeBin 是封装 TreeNode 的容器，提供转换红黑树的一些条件和锁的控制。</p></li><li><p>put()方法：如果没有初始化，就调用 initTable() 方法来进行初始化；如果没有 hash 冲突就直接 CAS 无锁插入；如果需要扩容，就先进行扩容；如果存在 hash 冲突，就加锁来保证线程安全，两种情况：一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入；如果该链表的数量大于阀值 8，就要先转换成红黑树的结构，break 再一次进入循环如果添加成功就调用 addCount() 方法统计 size，并且检查是否需要扩容。</p></li><li><p>扩容方法 transfer()：默认容量为 16，扩容时，容量变为原来的两倍。helpTransfer()：调用多个工作线程一起帮助进行扩容，这样的效率就会更高。</p></li><li><p>get()方法：计算 hash 值，定位到该 table 索引位置，如果是首结点符合就返回；如果遇到扩容时，会调用标记正在扩容结点 ForwardingNode.find()方法，查找该结点，匹配就返回；以上都不符合的话，就往下遍历结点，匹配就返回，否则最后就返回 null。</p></li></ol><h3 id="ConcurrentHashMap的并发度是什么？"><a href="#ConcurrentHashMap的并发度是什么？" class="headerlink" title="ConcurrentHashMap的并发度是什么？"></a>ConcurrentHashMap的并发度是什么？</h3><p>1.7中程序运行时能够同时更新 ConccurentHashMap 且不产生锁竞争的最大线程数。默认为 16即Segment的数量，可以在构造函数中设置。当用户设置并发度时，ConcurrentHashMap 会使用大于等于该值的最小2幂指数作为实际并发度（假如用户设置并发度为17，实际并发度则为32）。1.8中由于直接使用table中的节点数量作为分段锁的数量，并发度已经没有太大的实际意义了，主要用处就是当设置的初始容量小于并发度，将初始容量提升至并发度大小。 </p><h2 id="ConcurrentSkipListMap和ConcurrentSkipListSet"><a href="#ConcurrentSkipListMap和ConcurrentSkipListSet" class="headerlink" title="ConcurrentSkipListMap和ConcurrentSkipListSet"></a>ConcurrentSkipListMap和ConcurrentSkipListSet</h2><p>TreeMap和TreeSet使用红黑树按照key的顺序（自然顺序、自定义顺序）来使得键值对有序存储，但是只能在单线程下安全使用；多线程下想要使键值对按照key的顺序来存储，则需要使用ConcurrentSkipListMap和ConcurrentSkipListSet，分别用以代替TreeMap和TreeSet，存入的数据按key排序。在实现上，ConcurrentSkipListSet 本质上就是ConcurrentSkipListMap，ConcurrentSkipListMap实际上就是一个跳表的实现。</p><p>ConcurrentSkipListMap和ConcurrentHashMap都是线程安全的Map实现，ConcurrentHashMap的性能和存储空间要优于ConcurrentSkipListMap，但是ConcurrentSkipListMap有一个功能： 它会按照键的顺序进行排序。</p><h3 id="二分查找和AVL树查找"><a href="#二分查找和AVL树查找" class="headerlink" title="二分查找和AVL树查找"></a>二分查找和AVL树查找</h3><p>二分查找要求元素可以随机访问，所以决定了需要把元素存储在连续内存。这样查找确实很快，但是插入和删除元素的时候，为了保证元素的有序性，就需要大量的移动元素了。</p><p>如果需要的是一个能够进行二分查找，又能快速添加和删除元素的数据结构，首先就是二叉查找树，二叉查找树在最坏情况下可能变成一个链表。</p><p>于是，就出现了平衡二叉树，根据平衡算法的不同有AVL树，B-Tree，B+Tree，红黑树等，但是AVL树实现起来比较复杂，平衡操作较难理解，这时候就可以用SkipList跳跃表结构。</p><h3 id="跳表（SkipList）"><a href="#跳表（SkipList）" class="headerlink" title="跳表（SkipList）"></a>跳表（SkipList）</h3><p>传统意义的单链表是一个线性结构，向有序的链表中插入一个节点需要O(n)的时间，查找操作需要O(n)的时间。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic43.png" srcset="/img/loading.gif" class=""><p>如果我们使用上图所示的跳跃表，就可以减少查找所需时间为O(n/2)，因为我们可以先通过每个节点的最上面的指针先进行查找，这样子就能跳过一半的节点。</p><p>比如我们想查找50，首先和20比较，大于20之后，在和40进行比较，然后在和70进行比较，发现70大于50，说明查找的点在40和50之间，从这个过程中，我们可以看出，查找的时候跳过了30。</p><p>跳跃表其实也是一种通过“空间来换取时间”的一个算法，令链表的每个结点不仅记录next结点位置，还可以按照level层级分别记录后继第level个结点。此法使用的就是“<strong>先大步查找确定范围，再逐渐缩小迫近</strong>”的思想进行的查找。跳跃表在算法效率上很接近红黑树。</p><p>跳跃表又被称为概率，或者说是随机化的数据结构，目前开源软件 Redis 和 lucence都有用到它。</p><h2 id="CopyOnWriteArrayList和CopyOnWriteArraySet"><a href="#CopyOnWriteArrayList和CopyOnWriteArraySet" class="headerlink" title="CopyOnWriteArrayList和CopyOnWriteArraySet"></a>CopyOnWriteArrayList和CopyOnWriteArraySet</h2><h3 id="什么是写时复制容器"><a href="#什么是写时复制容器" class="headerlink" title="什么是写时复制容器"></a>什么是写时复制容器</h3><p>CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。</p><p>这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。如果读的时候有多个线程正在向CopyOnWriteArrayList添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的CopyOnWriteArrayList。</p><p>CopyOnWrite容器用于对于绝大部分访问都是读，且只是偶尔写的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单当中，黑名单每天晚上更新一次。当用户搜索时，会检查当前关键字在不在黑名单当中，如果在，则提示不能搜索。</p><h3 id="使用CopyOnWriteMap需要注意两件事情："><a href="#使用CopyOnWriteMap需要注意两件事情：" class="headerlink" title="使用CopyOnWriteMap需要注意两件事情："></a>使用CopyOnWriteMap需要注意两件事情：</h3><ol><li><p>减少扩容开销。根据实际需要，初始化CopyOnWriteMap的大小，避免写时CopyOnWriteMap扩容的开销。</p></li><li><p>使用批量添加。因为每次添加，容器每次都会进行复制，所以减少添加次数，可以减少容器的复制次数。</p></li></ol><h3 id="写时复制容器的问题："><a href="#写时复制容器的问题：" class="headerlink" title="写时复制容器的问题："></a>写时复制容器的问题：</h3><ol><li><p>性能问题：每次修改都创建一个新数组，然后复制所有内容，如果数组比较大，修改操作又比较频繁，可以想象，性能是很低的，而且内存开销会很大。</p></li><li><p>数据一致性问题：CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，不要使用CopyOnWrite容器。</p></li></ol><h2 id="BlockingQueue"><a href="#BlockingQueue" class="headerlink" title="BlockingQueue"></a>BlockingQueue</h2><h3 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h3><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic44.png" srcset="/img/loading.gif" class=""><p>队列是一种特殊的线性表，特殊之处在于它只允许在表的前端（front）进行删除操作，而在表的后端（rear）进行插入操作，和栈一样，队列是一种操作受限制的线性表。进行插入操作的端称为队尾，进行删除操作的端称为队头。</p><p>在队列中插入一个队列元素称为入队，从队列中删除一个队列元素称为出队。因为队列只允许在一端插入，在另一端删除，所以只有最早进入队列的元素才能最先从队列中删除，故队列又称为先进先出（FIFO—first in first out）线性表。</p><h3 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h3><table><thead><tr><th>方法/处理方式</th><th>抛出异常</th><th>返回特殊值</th><th>一直阻塞</th><th>超时退出</th></tr></thead><tbody><tr><td><strong>插入方法</strong></td><td>add(e)</td><td>offer(e)</td><td>put(e)</td><td>offer(e,time,unit)</td></tr><tr><td><strong>移除方法</strong></td><td>remove()</td><td>poll()</td><td>take()</td><td>poll(time, unit)</td></tr><tr><td><strong>检查方法</strong></td><td>element()</td><td>peek()</td><td>不可用</td><td>不可用</td></tr></tbody></table><ul><li><p>支持阻塞的插入方法：当队列满时，队列会阻塞插入元素的线程直到队列不满。</p></li><li><p>支持阻塞的移除方法：在队列为空时，获取元素的线程会被阻塞直到队列变为非空。</p></li><li><p>抛出异常：当队列满时，如果再往队列里插入元素，会抛出IllegalStateException（”Queuefull”）异常。当队列空时，从队列里获取元素会抛出NoSuchElementException异常。</p></li><li><p>返回特殊值：当往队列插入元素时，会返回元素是否插入成功，成功返回true。如果是移除方法，则是从队列里取出一个元素，如果没有则返回null。</p></li><li><p>一直阻塞：当阻塞队列满时，如果线程往队列里put元素，队列会一直阻塞线程，直到队列可用或者响应中断退出。当队列空时，如果线程从队列里take元素，队列会阻塞住消费者线程，直到队列不为空。</p></li><li><p>超时退出：当阻塞队列满时，如果线程往队列里插入元素，队列会阻塞生产者线程一段时间，如果超过了指定的时间，线程就会退出。</p></li></ul><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序整体处理数据的速度。</p><p>在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。</p><p>为了解决这种生产消费能力不均衡的问题，便有了生产者和消费者模式。生产者和消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通信，而是通过阻塞队列来进行通信，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。</p><p>阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器。</p><h3 id="有界无界"><a href="#有界无界" class="headerlink" title="有界无界"></a>有界无界</h3><p>有限队列就是长度有限，满了以后生产者会阻塞，无界队列就是里面能放无数的东西而不会因为队列长度限制被阻塞，当然空间限制来源于系统资源的限制，如果处理不及时，导致队列越来越大越来越大，超出一定的限制致使内存超限，操作系统或者JVM帮你解决烦恼，直接把你 OOM kill 省事了。</p><h3 id="阻塞队列的实现原理"><a href="#阻塞队列的实现原理" class="headerlink" title="阻塞队列的实现原理"></a>阻塞队列的实现原理</h3><p>使用了等待通知模式实现。所谓通知模式，就是当生产者往满的队列里添加元素时会阻塞住生产者，当消费者消费了一个队列中的元素后，会通知生产者当前队列可用。通过查看JDK源码发现ArrayBlockingQueue使用了Condition来实现。其余队列的实现，大家可以自行查看，队列的实现的代码总体来说，并不复杂。</p><h3 id="常用阻塞队列"><a href="#常用阻塞队列" class="headerlink" title="常用阻塞队列"></a>常用阻塞队列</h3><ul><li><p>ArrayBlockingQueue：是一个用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下不保证线程公平的访问队列，所谓公平访问队列是指阻塞的线程，可以按照阻塞的先后顺序访问队列，即先阻塞线程先访问队列。非公平性是对先等待的线程是非公平的，当队列可用时，阻塞的线程都可以争夺访问队列的资格，有可能先阻塞的线程最后才访问队列。初始化时有参数可以设置</p></li><li><p>LinkedBlockingQueue：是一个用链表实现的有界阻塞队列。此队列的默认和最大长度为Integer.MAX_VALUE，按照先进先出的原则对元素进行排序。和ArrayBlockingQueue实现的区别：</p><ol><li><p>队列中锁的实现不同ArrayBlockingQueue实现的队列中的锁是没有分离的，即生产和消费用的是同一个锁；LinkedBlockingQueue实现的队列中的锁是分离的，即生产用的是putLock，消费是takeLock。</p></li><li><p>在生产或消费时操作不同：ArrayBlockingQueue实现的队列中在生产和消费的时候，是直接将枚举对象插入或移除的；LinkedBlockingQueue实现的队列中在生产和消费的时候，需要把枚举对象转换为Node<E>进行插入或移除，会影响性能。</p></li><li><p>队列大小初始化方式不同：ArrayBlockingQueue实现的队列中必须指定队列的大小LinkedBlockingQueue实现的队列中可以不指定队列的大小，但是默认是Integer.MAX_VALUE（20来个亿）一般的服务器是扛不住的，所以在使用LinkedBlockingQueue时还是尽量指定大小。</p></li></ol></li><li><p>PriorityBlockingQueue：是一个支持优先级的无界阻塞队列。默认情况下元素采取自然顺序升序排列。也可以自定义类实现compareTo()方法来指定元素排序规则，或者初始化PriorityBlockingQueue时，指定构造参数Comparator来对元素进行排序。需要注意的是不能保证同优先级元素的顺序。</p></li><li><p>DelayQueue：是一个支持延时获取元素的无界阻塞队列。队列使用PriorityQueue来实现。队列中的元素必须实现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。DelayQueue非常有用，可以将DelayQueue运用在以下应用场景。缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。还有订单到期，限时支付等等</p></li><li><p>SynchronousQueue：是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。SynchronousQueue可以看成是一个传球手，负责把生产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常适合传递性场景。SynchronousQueue的吞吐量高于LinkedBlockingQueue和ArrayBlockingQueue。</p></li><li><p>LinkedTransferQueue：一个由链表结构组成的无界阻塞队列，多了tryTransfer和transfer方法。如果当前有消费者正在等待接收元素（消费者使用take()方法或带时间限制的poll()方法时），transfer方法可以把生产者传入的元素立刻transfer（传输）给消费者。如果没有消费者在等待接收元素，transfer方法会将元素存放在队列的tail节点，并等到该元素被消费者消费了才返回。tryTransfer方法是用来试探生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回false。和transfer方法的区别是tryTransfer方法无论消费者是否接收，方法立即返回，而transfer方法是必须等到消费者消费了才返回。</p></li><li><p>LinkedBlockingDeque：是一个由链表结构组成的双向阻塞队列。所谓双向队列指的是可以从队列的两端插入和移出元素。双向队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。多了addFirst、addLast、offerFirst、offerLast、peekFirst和peekLast等方法，以First单词结尾的方法，表示插入、获取（peek）或移除双端队列的第一个元素。以Last单词结尾的方法，表示插入、获取或移除双端队列的最后一个元素。另外，插入方法add等同于addLast，移除方法remove等效于removeFirst。但是take方法却等同于takeFirst，不知道是不是JDK的bug，使用时还是用带有First和Last后缀的方法更清楚。在初始化LinkedBlockingDeque时可以设置容量防止其过度膨胀。另外，双向阻塞队列可以运用在“工作窃取”模式中。</p></li></ul><h2 id="ConcurrentLinkedQueue"><a href="#ConcurrentLinkedQueue" class="headerlink" title="ConcurrentLinkedQueue"></a>ConcurrentLinkedQueue</h2><p>ConcurrentLinkedQueue是一个无界非阻塞队列，它是基于链表的无界线程安全队列。该队列的元素遵循先进先出的原则。头是最先加入的，尾是最近加入的。插入元素是追加到尾上，提取一个元素是从头提取。</p><p>可以看成是LinkedList的并发版本，常用方法：</p><ul><li><p>add(e):插入指定元素</p></li><li><p>offer(e):将指定元素插入到此队列的尾部。  </p></li><li><p>peek():检索此队列的头但并不移除，如果此队列为空，则返回 null。  </p></li><li><p>poll(): 检索并移除此队列的头，如果此队列为空，则返回 null。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>显式锁和AQS</title>
    <link href="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/"/>
    <url>/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/</url>
    
    <content type="html"><![CDATA[<h2 id="显式锁"><a href="#显式锁" class="headerlink" title="显式锁"></a>显式锁</h2><p>通过synchronized关键字实现锁功能时，对锁的获取和释放都是固化的、隐式的，也被称为内置锁。Lock接口需要手动、显式的获取和释放锁，这就是显式锁名称的由来。</p><h3 id="Lock接口和synchronized的比较"><a href="#Lock接口和synchronized的比较" class="headerlink" title="Lock接口和synchronized的比较"></a>Lock接口和synchronized的比较</h3><p>synchronized获取锁时会一直等待直到获取锁为止。Lock提供lockInterruptibly()方法可以在等待获取到锁的过程中能够响应中断，tryLock()方法可以尝试获取锁如果失败会返回false，然后线程可以做其他的事，之后再进行tryLock()，tryLock()方法还可以接收long类型及TimeUnit类型的参数超时的获取锁。</p><p>如果尝试取锁及中断取锁尽量使用synchronized关键字，在目前的发展趋势jdk一直在对synchronized进行优化，synchronized的开销要比Lock接口更少。</p><h3 id="Lock的标准用法"><a href="#Lock的标准用法" class="headerlink" title="Lock的标准用法"></a>Lock的标准用法</h3><pre><code>lock.lock()try{    // 逻辑代码}finally{    lock.unlock();}</code></pre><p>在finally块中释放锁，目的是保证在获取到锁之后，最终能够被释放。</p><p>不能将获取锁的过程写在try块中，如果在获取锁（自定义锁的实现）时发生了异常，异常抛出的同时会导致锁的无故释放。</p><h3 id="可重入锁ReentrantLock、锁的公平和非公平"><a href="#可重入锁ReentrantLock、锁的公平和非公平" class="headerlink" title="可重入锁ReentrantLock、锁的公平和非公平"></a>可重入锁ReentrantLock、锁的公平和非公平</h3><h4 id="可重入"><a href="#可重入" class="headerlink" title="可重入"></a>可重入</h4><p>同一个线程对于已经获得到的锁，可以多次继续申请到该锁的使用权。synchronized关键字也支持隐式的支持重进入，比如一个synchronized修饰的递归方法，在方法执行时，执行线程在获取了锁之后仍能连续多次地获得该锁。ReentrantLock可重入锁在调用lock()方法时，如果当前线程已经获取到锁就能够再次调用lock()方法获取锁而不被阻塞。</p><h4 id="公平和非公平"><a href="#公平和非公平" class="headerlink" title="公平和非公平"></a>公平和非公平</h4><p>如果在时间上，先对锁进行获取的线程即等待时间最长的线程一定先获取到锁，那么这个锁是公平的，也可以说锁获取是顺序的，反之就是不公平的。 ReentrantLock提供了一个构造函数，能够控制锁是否是公平的，synchronized是非公平锁。事实上，公平的锁机制往往没有非公平的效率高。  </p><p>线程被唤醒的上下文切换时间周期在5000-10000之间，在激烈竞争的情况下，非公平锁的性能高于公平锁的性能的一个原因是：在恢复一个被挂起的线程与该线程真正开始运行之间存在着严重的延迟。假设线程A持有一个锁，并且线程B请求这个锁。由于这个锁已被线程A持有，因此B将被挂起。当A释放锁时，B将被唤醒，B完全唤醒后会再次尝试获取锁。与此同时，如果C也请求这个锁，那么C很可能会在B被完全唤醒之前获得、使用以及释放这个锁。这样的情况是一种“双赢”的局面：B获得锁的时刻并没有推迟，C更早地获得了锁，并且吞吐量也获得了提高。</p><h3 id="读写锁ReentrantReadWriteLock"><a href="#读写锁ReentrantReadWriteLock" class="headerlink" title="读写锁ReentrantReadWriteLock"></a>读写锁ReentrantReadWriteLock</h3><p>之前提到锁（如synchronized和ReentrantLock）基本都是排他锁即独占锁，这些锁在同一时刻只允许一个线程进行访问，而读写锁在同一时刻可以允许多个读线程访问，但是在写线程访问时，所有的读线程和其他写线程均被阻塞。读写锁维护了一对锁，一个读锁和一个写锁，通过分离读锁和写锁，使得并发性相比一般的排他锁有了很大提升。写锁为独占锁，读锁为共享锁，读写之前相互排斥。</p><p>除了保证写操作对读操作的可见性以及提升并发性之外，读写锁能够简化读写交互场景的编程方式。假设在程序中定义一个共享的用作缓存数据结构，它大部分时间提供读服务（例如查询和搜索），而写操作占有的时间很少，但是写操作完成之后的更新需要对后续的读服务可见。在没有读写锁支持的（Java 5之前）时候，如果需要完成上述工作就要使用Java的等待通知机制，就是当写操作开始时，所有晚于写操作的读操作均会进入等待状态，只有写操作完成并进行通知之后，所有等待的读操作才能继续执行（写操作之间依靠synchronized关键进行同步），这样做的目的是使读操作能读取到正确的数据，不会出现脏读。改用读写锁实现上述功能，只需要在读操作时获取读锁，写操作时获取写锁即可。当写锁被获取到时，后续（非当前写操作线程）的读写操作都会被阻塞，写锁释放之后，所有操作继续执行，编程方式相对于使用等待通知机制的实现方式而言，变得简单明了。 </p><p>ReentrantReadWriteLock实现了ReadAndWriteLock接口，ReadAndWriteLock接口提供了readLock()方法获取读锁，writeLock()方法获取写锁，读锁和写锁的使用方式与Lock标准用法相同。</p><p>一般情况下，读写锁的性能都会比排它锁好，因为大多数场景读是多于写的，读写的比例约为10:1。在读多于写的情况下，读写锁能够提供比排它锁更好的并发性和吞吐量。</p><h3 id="Condition接口"><a href="#Condition接口" class="headerlink" title="Condition接口"></a>Condition接口</h3><p>任意一个Java对象，都拥有一组监视器方法（定义在java.lang.Object上），主要包括wait()、wait(long timeout)、notify()以及notifyAll()方法，这些方法与synchronized同步关键字配合，可以实现等待/通知模式。Condition接口也提供了类似Object的监视器方法await()，signal()，以便与Lock配合可以实现等待/通知模式。</p><h3 id="用Lock和Condition实现等待通知"><a href="#用Lock和Condition实现等待通知" class="headerlink" title="用Lock和Condition实现等待通知"></a>用Lock和Condition实现等待通知</h3><pre><code>/** * 类说明： */public class ExpressCond {    public final static String CITY = &quot;ShangHai&quot;;    /**     * 快递运输里程数     */    private int km;    /**     * 快递到达地点     */    private String site;    private Lock kmLock = new ReentrantLock();    private Lock siteLock = new ReentrantLock();    private Condition kmCondition = kmLock.newCondition();    private Condition siteCondition = siteLock.newCondition();    public ExpressCond(int km, String site) {        this.km = km;        this.site = site;    }    /**     * 变化公里数，然后通知处于wait状态并需要处理公里数的线程进行业务处理     */    public void changeKm() {        kmLock.lock();        try {            this.km = 101;            kmCondition.signal();        } finally {            kmLock.unlock();        }    }    /**     * 变化地点，然后通知处于wait状态并需要处理地点的线程进行业务处理     */    public void changeSite() {        siteLock.lock();        try {            this.site = &quot;BeiJing&quot;;            siteCondition.signal();        } finally {            siteLock.unlock();        }    }    /**     * 当快递的里程数大于100时更新数据库     */    public void waitKm() {        kmLock.lock();        try {            while (this.km &lt; 100) {                try {                    kmCondition.await();                    System.out.println(&quot;check Site thread[&quot; + Thread.currentThread().getId()                            + &quot;] is be notified&quot;);                } catch (InterruptedException e) {                    e.printStackTrace();                }            }        } finally {            kmLock.unlock();        }        System.out.println(&quot;the Km is &quot; + this.km + &quot;,I will change db&quot;);    }    /**     * 当快递到达目的地时通知用户     */    public void waitSite() {        siteLock.lock();        try {            while (this.site.equals(CITY)) {                try {                    siteCondition.await();//当前线程进行等待                    System.out.println(&quot;check Site thread[&quot; + Thread.currentThread().getName()                            + &quot;] is be notify&quot;);                } catch (InterruptedException e) {                    e.printStackTrace();                }            }        } finally {            siteLock.unlock();        }        System.out.println(&quot;the site is &quot; + this.site + &quot;,I will call user&quot;);    }    private static ExpressCond express = new ExpressCond(0, ExpressCond.CITY);    /**     * 检查里程数变化的线程,不满足条件，线程一直等待     */    private static class CheckKm extends Thread {        @Override        public void run() {            express.waitKm();        }    }    /**     * 检查地点变化的线程,不满足条件，线程一直等待     */    private static class CheckSite extends Thread {        @Override        public void run() {            express.waitSite();        }    }    public static void main(String[] args) throws InterruptedException {        for (int i = 0; i &lt; 3; i++) {            new ExpressCond.CheckSite().start();        }        for (int i = 0; i &lt; 3; i++) {            new ExpressCond.CheckKm().start();        }        Thread.sleep(1000);        express.changeKm();//快递里程变化    }}    </code></pre><h2 id="了解LockSupport工具"><a href="#了解LockSupport工具" class="headerlink" title="了解LockSupport工具"></a>了解LockSupport工具</h2><p>LockSupport定义了一组的公共静态方法，这些方法提供了最基本的线程阻塞和唤醒功能，而LockSupport也成为构建同步组件的基础工具。</p><p>LockSupport定义了一组以park开头的方法用来阻塞当前线程，以及unpark(Thread thread)方法来唤醒一个被阻塞的线程。在JDK1.6之后LockSupport增加了park(Object blocker)、parkNanos(Object blocker,long nanos)和parkUntil(Object blocker,long deadline)3个方法，便于问题排查和系统监控，其中参数blocker是用来标识当前线程在等待的对象即被阻塞对象。</p><h2 id="CLH队列锁"><a href="#CLH队列锁" class="headerlink" title="CLH队列锁"></a>CLH队列锁</h2><p>CLH队列锁即Craig, Landin, and Hagersten (CLH) locks。</p><p>CLH队列锁是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程仅仅在本地变量上自旋，它不断自旋判断前驱节点的状态，假设发现前驱节点释放了锁就结束自旋。</p><p>当一个线程需要获取锁时会创建一个的QNode，将其中的locked设置为true表示需要获取锁，myPred表示对其前驱节点的引用</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic1.png" srcset="/img/loading.gif" class=""><p>线程A对tail域调用getAndSet方法，使自己成为队列的尾部，同时获取一个指向其前驱结点的引用myPred</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic2.png" srcset="/img/loading.gif" class=""><p>线程B需要获得锁，同样的流程再来一遍</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic3.png" srcset="/img/loading.gif" class=""><p>线程就在前驱结点的locked字段上自旋，直到前驱结点释放锁(前驱节点的锁值 locked == false)</p><p>当一个线程需要释放锁时，将当前结点的locked域设置为false，同时回收前驱结点</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic4.png" srcset="/img/loading.gif" class=""><p>如上图所示，前驱结点释放锁，线程A的myPred所指向的前驱结点的locked字段变为false，线程A就可以获取到锁。</p><p>CLH队列锁的优点是空间复杂度低（如果有n个线程，L个锁，每个线程每次只获取一个锁，那么需要的存储空间是O（L+n），n个线程有n个myNode，L个锁有L个tail）。CLH队列锁常用在SMP体系结构下。</p><p>Java中的AQS是CLH队列锁的一种变体实现。</p><p><strong>扩展知识点</strong></p><p>SMP（Symmetric Multi-Processor）对称多处理器结构，指server中多个CPU对称工作，每一个CPU访问内存地址所需时间同样。其主要特征是共享，包括对CPU，内存，I/O等进行共享。SMP的长处是可以保证内存一致性。缺点是这些共享的资源非常可能成为性能瓶颈。随着CPU数量的添加，每一个CPU都要访问同样的内存资源，可能导致内存访问冲突，可能会导致CPU资源的浪费。经常使用的PC机就属于这样的。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic5.png" srcset="/img/loading.gif" class=""><p>NUMA（Non Uniform Memory Access Architecture）非一致存储访问，将CPU分为CPU模块，每个CPU模块由多个<em>CPU*组成，并且具有独立的本地内存、I/O槽口等，模块之间可以通过互联模块相互访问，访问本地内存（本CPU模块的内存）的速度将远远高于访问远地内存</em>(<em>其他CPU模块的内存</em>)*的速度，这也是非一致存储访问的由来。NUMA较好地解决SMP的扩展问题，当CPU数量增加时，因为访问远地内存的延时远远超过本地内存，系统性能无法线性增加。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic6.png" srcset="/img/loading.gif" class=""><p>CLH唯一的缺点是在NUMA系统结构下性能很差，但是在SMP系统结构下该法还是非常有效的。解决NUMA系统结构的思路是MCS队列锁。</p><h2 id="AbstractQueuedSynchronizer深入分析"><a href="#AbstractQueuedSynchronizer深入分析" class="headerlink" title="AbstractQueuedSynchronizer深入分析"></a>AbstractQueuedSynchronizer深入分析</h2><h3 id="学习AQS的必要性"><a href="#学习AQS的必要性" class="headerlink" title="学习AQS的必要性"></a>学习AQS的必要性</h3><p>队列同步器AbstractQueuedSynchronizer（以下简称同步器或AQS），是用来构建锁或者其他同步组件的基础框架，它使用了一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作。并发包的大师（Doug Lea）期望它能够成为实现大部分同步需求的基础。</p><h3 id="AQS使用方式和其中的设计模式"><a href="#AQS使用方式和其中的设计模式" class="headerlink" title="AQS使用方式和其中的设计模式"></a>AQS使用方式和其中的设计模式</h3><p>AQS的主要使用方式是继承，子类通过继承AQS并实现它的抽象方法来管理同步状态，在AQS里由一个int型的state来代表这个状态，在抽象方法的实现过程中免不了要对同步状态进行更改，这时就需要使用同步器提供的3个方法（getState()、setState(int newState)和compareAndSetState(int expect,int update)）来进行操作，因为它们能够保证状态的改变是安全的。</p><p>AQS自身没有实现任何同步接口，它仅仅是定义了若干同步状态获取和释放的方法来供自定义同步组件使用，同步器既可以支持独占式地获取同步状态，也可以支持共享式地获取同步状态，这样就可以方便实现不同类型的同步组件（ReentrantLock、ReentrantReadWriteLock和CountDownLatch等）。</p><p>同步器是实现锁（也可以是任意同步组件）的关键，在锁的实现中聚合同步器。可以这样理解二者之间的关系：锁是面向使用者的，它定义了使用者与锁交互的接口（比如可以允许两个线程并行访问），隐藏了实现细节；同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作。锁和同步器很好地隔离了使用者和实现者所需关注的领域。</p><p>实现者需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法。</p><h3 id="模板方法模式"><a href="#模板方法模式" class="headerlink" title="模板方法模式"></a>模板方法模式</h3><p>同步器的设计基于模板方法模式。模板方法模式的意图是，定义一个操作中的算法的骨架，而将一些步骤的实现延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。我们最常见的就是Spring框架里的各种Template。</p><p>实际例子</p><p>假设蛋糕店中奶油蛋糕，芝士蛋糕和慕斯蛋糕。这三种蛋糕在制作方式上一样，都包括造型，烘焙和涂抹蛋糕上的东西。所以可以定义一个抽象蛋糕模型</p><pre><code>/** * 类说明：抽象蛋糕模型 */public abstract class AbstractCake {    protected abstract void shape();    protected abstract void apply();    protected abstract void brake();    /*模板方法*/    public final void run(){        this.shape();        this.apply();        this.brake();    }    protected boolean shouldApply(){        return true;    }}</code></pre><p>然后就可以批量生产三种蛋糕</p><pre><code>/** * 类说明：芝士蛋糕 */public class CheeseCake  extends AbstractCake {    @Override    protected void shape() {        System.out.println(&quot;芝士蛋糕造型&quot;);    }    @Override    protected void apply() {        System.out.println(&quot;芝士蛋糕涂抹&quot;);    }    @Override    protected void brake() {        System.out.println(&quot;芝士蛋糕烘焙&quot;);    }}</code></pre><p>这样一来，不但可以批量生产三种蛋糕，而且如果日后有扩展，只需要继承抽象蛋糕方法就可以了，突然有一天，我们发现市面有一种最简单的小蛋糕销量很好，这种蛋糕就是简单烘烤成型就可以卖，并不需要涂抹什么食材，于是我们也想要生产这种蛋糕。但是我们发现了一个问题，抽象蛋糕是定义了抽象的涂抹方法的，也就是说扩展的这种蛋糕是必须要实现涂抹方法，这时可以将原来的模板修改为带钩子的模板。</p><pre><code>/** * 类说明：抽象蛋糕模型 */public abstract class AbstractCake {    protected abstract void shape();    protected abstract void apply();    protected abstract void brake();    /*模板方法*/    public final void run() {        this.shape();        if (shouldApply()) {            this.apply();        }        this.brake();    }    protected boolean shouldApply(){        return true;    }}</code></pre><p>做小蛋糕的时候通过flag来控制是否涂抹，其余已有的蛋糕制作不需要任何修改可以照常进行。</p><pre><code>/** * 类说明：小蛋糕 */public class SmallCake extends AbstractCake {    private boolean flag = false;    public void setFlag(boolean shouldApply){        flag = shouldApply;    }    @Override    protected boolean shouldApply() {        return this.flag;    }    @Override    protected void shape() {        System.out.println(&quot;小蛋糕造型&quot;);    }    @Override    protected void apply() {        System.out.println(&quot;小蛋糕涂抹&quot;);    }    @Override    protected void brake() {        System.out.println(&quot;小蛋糕烘焙&quot;);    }}</code></pre><h3 id="AQS中的方法"><a href="#AQS中的方法" class="headerlink" title="AQS中的方法"></a>AQS中的方法</h3><h4 id="模板方法"><a href="#模板方法" class="headerlink" title="模板方法"></a>模板方法</h4><p>实现自定义同步组件时，将会调用同步器提供的模板方法，</p><table><thead><tr><th align="center">方法名称</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">void acquire(int arg)</td><td align="center">独占式获取同步状态，如果当前线程获取同步状态成功，则由该方法返回，否则，将会进人同步队列等待，该方法将会调用重写的tryAcquire(int  arg)方法</td></tr><tr><td align="center">void acquireInterruptibly(int arg)</td><td align="center">与acquire(int arg)相同，但是该方法响应中断，当前线程未获取到同步状态而进入同步队列中，如果当前线程被中断，则该方法会抛出InterruptedException并返回</td></tr><tr><td align="center">boolean tryAcquireNanos(int arg,long nanos)</td><td align="center">在acquireInterruptibly(int arg)基础上增加了超时限制，如果当前线程在超时时间内没有获取到同步状态，那么将会返回false.如果获取到了返回true</td></tr><tr><td align="center">void acquireShared(int arg)</td><td align="center">共享式的获取同步状态，如果当前线程未获取到同步状态,将会进人同步队列等待，与独占式获取的主要区别是在同一时刻可以有多个线程获取到同步状态</td></tr><tr><td align="center">void acquireSharedInteruptibly(int arg)</td><td align="center">与acquireShared(int arg)相同，该方法响应中断</td></tr><tr><td align="center">boolean tryAcquireSharedNanos(int arg, long nanos)</td><td align="center">在acquireSharedInterruptibly(int arg)基础上增加了超时限制</td></tr><tr><td align="center">boolean release(int arg)</td><td align="center">独占式的释放同步状态，该方法会在释放同步状态之后，将同步队列中第一个节点包含的线程唤醒</td></tr><tr><td align="center">boolean releaseShared(int arg)</td><td align="center">共享式的释放同步状态</td></tr><tr><td align="center">Collection&lt; Thread&gt; getQueuedThreads()</td><td align="center">获取等待在同步队列上的线程集合</td></tr></tbody></table><p>这些模板方法同步器提供的模板方法基本上分为3类：独占式获取与释放同步状态、共享式获取与释放、同步状态和查询同步队列中的等待线程情况。</p><h4 id="可重写的方法"><a href="#可重写的方法" class="headerlink" title="可重写的方法"></a>可重写的方法</h4><table><thead><tr><th align="center">方法名称</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">protected boolean tryAcquire(int arg)</td><td align="center">独占式获取同步状态，实现该方法需要查询当前状态并判断同步状态是否符合预期，然后再进行CAS设置同步状态</td></tr><tr><td align="center">protected boolean tryRelease(int arg)</td><td align="center">独占式释放同步状态，等待获取同步状态的线程将有机会获取同步状态</td></tr><tr><td align="center">protected int tryAcquireShared(int arg)</td><td align="center">共享式获取同步状态，返回大于等于0的值，表示获取成功，反之，获取失败</td></tr><tr><td align="center">protected boolean tryReleaseShared(int arg)</td><td align="center">共享式释放同步状态</td></tr><tr><td align="center">protected boolean isHeldExclusively()</td><td align="center">当前同步器是否在独占模式下被线程占用，一般该方法表示是否被当前线程所独占</td></tr></tbody></table><h4 id="访问或修改同步状态的方法"><a href="#访问或修改同步状态的方法" class="headerlink" title="访问或修改同步状态的方法"></a>访问或修改同步状态的方法</h4><p>重写同步器指定的方法时，需要使用同步器提供的如下3个方法来访问或修改同步状态。</p><ul><li><p>getState()：获取当前同步状态。</p></li><li><p>setState(int newState)：设置当前同步状态。</p></li><li><p>compareAndSetState(int expect,int update)：使用CAS设置当前状态，该方法能够保证状态设置的原子性。 </p></li></ul><h3 id="实现一个自己的独占锁"><a href="#实现一个自己的独占锁" class="headerlink" title="实现一个自己的独占锁"></a>实现一个自己的独占锁</h3><pre><code>public class SelfLock implements Lock {    /**     * 静态内部类，自定义同步器     */    private static class Sync extends AbstractQueuedSynchronizer {        //private static final long serialVersionUID = -4387327721959839431L;        /**         * 是否处于占用状态         */        @Override        protected boolean isHeldExclusively() {            return getState() == 1;        }        /**         * 获得锁         */        @Override        protected boolean tryAcquire(int arg) {            if (compareAndSetState(0, 1)) {                setExclusiveOwnerThread(Thread.currentThread());                return true;            }            return false;        }        /**         * 释放锁         */        @Override        protected boolean tryRelease(int arg) {            if (getState() == 0) {                throw new IllegalMonitorStateException();            }            setExclusiveOwnerThread(null);            setState(0);            return true;        }        /**         * 返回一个Condition，每个condition都包含了一个condition队列         */        Condition newCondition() {            return new ConditionObject();        }    }    /**     * 仅需要将操作代理到Sync上即可     */    private final Sync sync = new Sync();    @Override    public void lock() {        System.out.println(Thread.currentThread().getName() + &quot; ready get lock&quot;);        sync.acquire(1);        System.out.println(Thread.currentThread().getName() + &quot; already got lock&quot;);    }    @Override    public boolean tryLock() {        return sync.tryAcquire(1);    }    @Override    public void unlock() {        System.out.println(Thread.currentThread().getName() + &quot; ready release lock&quot;);        sync.release(1);        System.out.println(Thread.currentThread().getName() + &quot; already released lock&quot;);    }    @Override    public Condition newCondition() {        return sync.newCondition();    }    public boolean isLocked() {        return sync.isHeldExclusively();    }    public boolean hasQueuedThreads() {        return sync.hasQueuedThreads();    }    @Override    public void lockInterruptibly() throws InterruptedException {        sync.acquireInterruptibly(1);    }    @Override    public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {        return sync.tryAcquireNanos(1, unit.toNanos(timeout));    }}</code></pre><p><strong>测试类</strong></p><pre><code>public class TestMyLock {    public void test() {        final Lock lock = new SelfLock();        class Worker extends Thread {         @Override            public void run() {                lock.lock();                System.out.println(Thread.currentThread().getName());                try {                    SleepTools.second(1);                } finally {                    lock.unlock();                }            }        }        // 启动4个子线程        for (int i = 0; i &lt; 4; i++) {            Worker w = new Worker();            //w.setDaemon(true);            w.start();        }        // 主线程每隔1秒换行        for (int i = 0; i &lt; 10; i++) {           SleepTools.second(1);            //System.out.println();        }    }    public static void main(String[] args) {        TestMyLock testMyLock = new TestMyLock();        testMyLock.test();    }}</code></pre><h3 id="AQS中的数据结构节点和同步队列"><a href="#AQS中的数据结构节点和同步队列" class="headerlink" title="AQS中的数据结构节点和同步队列"></a>AQS中的数据结构节点和同步队列</h3><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic8.png" srcset="/img/loading.gif" class=""><h4 id="节点Node"><a href="#节点Node" class="headerlink" title="节点Node"></a>节点Node</h4><p>AQS其实是CLH队列锁的一种变体实现，所以必然要有一个节点的数据结构来保存我们前面所说的CLH中的各种域，比如前驱节点，节点的状态等，这个数据结构就是AQS中的内部类Node。Node中保存的信息有：</p><ul><li><p>前驱和后继线程</p></li><li><p>线程信息</p></li><li><p>队列中线程状态</p></li></ul><h4 id="Node类的设计"><a href="#Node类的设计" class="headerlink" title="Node类的设计"></a>Node类的设计</h4><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic7.png" srcset="/img/loading.gif" class=""><p>线程的2种等待模式：</p><ul><li><p><strong>SHARED</strong>：表示线程以共享的模式等待锁（如ReadLock）</p></li><li><p><strong>EXCLUSIVE</strong>：表示线程以互斥的模式等待锁（如ReetrantLock）</p></li></ul><p>线程在队列中的状态枚举：</p><ul><li><p><strong>CANCELLED</strong>：值为1，表示线程已经取消获取锁的请求</p></li><li><p><strong>SIGNAL</strong>：值为-1，表示该线程已经准备就绪，等待获取锁</p></li><li><p><strong>CONDITION</strong>：值为-2，表示线程等待某一个条件（Condition）被满足</p></li><li><p><strong>PROPAGATE</strong>：值为-3，表示下一个的acquireShared值应该被无条件的传播下去，在线程处于SHARED模式时才会被用到。</p></li></ul><p>成员变量：</p><ul><li><p><strong>waitStatus</strong>：该int变量表示线程在队列中的状态，其值就是上述提到的状态：CANCELLED、SIGNAL、CONDITION、PROPAGATE</p></li><li><p><strong>prev</strong>：该变量类型为Node对象，表示该节点的前一个Node节点（前驱）</p></li><li><p><strong>next</strong>：该变量类型为Node对象，表示该节点的后一个Node节点（后继）</p></li><li><p><strong>thread</strong>：该变量类型为Thread对象，表示该节点的代表的线程</p></li><li><p><strong>nextWaiter</strong>：该变量类型为Node对象，表示等待condition条件的Node节点</p></li></ul><p>当前线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成为一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒，使其再次尝试获取同步状态。同步队列中的节点（Node）用来保存获取同步状态失败的线程引用、等待状态以及前驱和后继节点。</p><h4 id="head和tail"><a href="#head和tail" class="headerlink" title="head和tail"></a>head和tail</h4><p>AQS还拥有首节点（head）和尾节点（tail）两个引用，一个指向队列头节点，而另一个指向队列尾节点。</p><p>注意 ：因为首节点head是不保存线程信息的节点，仅仅是因为数据结构设计上的需要，在数据结构上，这种做法往往叫做“空头节点链表”，对应的就有“非空头结点链表”。</p><h4 id="节点在同步队列中的增加和移出"><a href="#节点在同步队列中的增加和移出" class="headerlink" title="节点在同步队列中的增加和移出"></a>节点在同步队列中的增加和移出</h4><h5 id="节点加入到同步队列"><a href="#节点加入到同步队列" class="headerlink" title="节点加入到同步队列"></a>节点加入到同步队列</h5><p>当一个线程成功地获取了同步状态（或者锁），其他线程将无法获取到同步状态，也就是获取同步状态失败，AQS会通过addWaiter()方法将这个线程以及等待状态等信息构造成为一个节点（Node）并将其加入同步队列的尾部。而这个加入队列的过程必须要保证线程安全，因此同步器提供了一个基于CAS的设置尾节点的方法：compareAndSetTail(Node expect,Nodeupdate)，AQS它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic9.png" srcset="/img/loading.gif" class=""><h5 id="首节点的变化"><a href="#首节点的变化" class="headerlink" title="首节点的变化"></a>首节点的变化</h5><p>首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点。设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节点的方法并不需要使用CAS来保证，它只需要将首节点设置成为原首节点的后继节点并断开原首节点的next引用即可。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic10.png" srcset="/img/loading.gif" class=""><h5 id="独占式同步状态获取与释放"><a href="#独占式同步状态获取与释放" class="headerlink" title="独占式同步状态获取与释放"></a>独占式同步状态获取与释放</h5><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic11.png" srcset="/img/loading.gif" class=""><h6 id="获取"><a href="#获取" class="headerlink" title="获取"></a>获取</h6><p>通过调用同步器的acquire(int arg)方法可以获取同步状态，主要完成了同步状态获取、节点构造、加入同步队列以及在同步队列中自旋等待的相关工作，其主要逻辑是：</p><p>首先调用自定义同步器实现的tryAcquire(int arg)方法，该方法需要保证线程安全的获取同步状态。</p><p>如果同步状态获取失败（tryAcquire返回false），则构造同步节点（独占式Node.EXCLUSIVE，同一时刻只能有一个线程成功获取同步状态）并通过addWaiter(Node node)方法将该节点加入到同步队列的尾部，在addWaiter()方法中会尝试通过compareAndSetTail()方法设置首尾节点关系，如果设置不成功才会进入enq()方法循环尝试设置节点关系。</p><p>最后调用acquireQueued(Node node,int arg)方法，使得该节点以“死循环”的方式获取同步状态。如果获取不到则阻塞节点中的线程，而被阻塞线程的唤醒主要依靠前驱节点的出队或阻塞线程被中断来实现。</p><p>addWaiter(Node node)方法中</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic12.png" srcset="/img/loading.gif" class=""><p>将当前线程包装成Node后，队列不为空的情况下，先尝试把当前节点加入队列并成为尾节点，如果不成功或者队列为空进入enq(final Node node)方法。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic13.png" srcset="/img/loading.gif" class=""><p>在enq(final Node node)方法中，同步器通过“死循环”来保证节点的正确添加，这个死循环中，做了两件事，第一件，如果队列为空，初始化队列，new出一个空节点，并让<strong>首节点</strong>（head）和<strong>尾节点</strong>（tail）两个引用都指向这个空节点；第二件事，把当前节点加入队列。</p><p>在“死循环”中只有通过CAS将节点设置成为尾节点之后，当前线程才能从该方法返回，否则，当前线程不断地尝试设置。</p><p>节点进入同步队列之后，观察acquireQueued(Node node,int arg)方法</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic14.png" srcset="/img/loading.gif" class=""><p>其实就是一个自旋的过程，每个节点（或者说每个线程）都在自省地观察，当条件满足，获取到了同步状态，就可以从这个自旋过程中退出，否则依旧留在这个自旋过程中（并会阻塞节点的线程）。</p><p>在acquireQueued(final Node node,int arg)方法中，当前线程在“死循环”中尝试获取同步状态，而只有前驱节点是头节点才能够尝试获取同步状态，这是为什么？原因有两个。</p><p>第一，头节点是成功获取到同步状态的节点，而头节点的线程释放了同步状态之后，将会唤醒其后继节点，后继节点的线程被唤醒后需要检查自己的前驱节点是否是头节点。</p><p>第二，维护同步队列的FIFO原则。</p><p>当前线程获取到同步状态后，让<strong>首节点</strong>（head）这个引用指向自己所在节点。当同步状态获取成功后，当前线程就从acquire方法返回了。如果同步器实现的是锁，那就代表当前线程获得了锁。</p><h6 id="释放"><a href="#释放" class="headerlink" title="释放"></a>释放</h6><p>当前线程获取同步状态并执行了相应逻辑之后，就需要释放同步状态，使得后续节点能够继续获取同步状态。通过调用同步器的release(int arg)方法可以释放同步状态，该方法在释放了同步状态之后，会唤醒其后继节点（进而使后继节点重新尝试获取同步状态）。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic15.png" srcset="/img/loading.gif" class=""><p>该方法执行时，会唤醒<strong>首节点</strong>（head）所指向节点的后继节点线程，unparkSuccessor(Node node)方法使用LockSupport来唤醒处于等待状态的线程。</p><p>而在unparkSuccessor中， </p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic16.png" srcset="/img/loading.gif" class=""><p>这段代码的意思，一般情况下，被唤醒的是head指向节点的后继节点线程，如果这个后继节点处于被cancel状态，（我推测开发者的思路这样的：后继节点处于被cancel状态，意味着当锁竞争激烈时，队列的第一个节点等了很久（一直被还未加入队列的节点抢走锁），包括后续的节点cancel的几率都比较大，所以）先从尾开始遍历，找到最前面且没有被cancel的节点。</p><h6 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h6><p>在获取同步状态时，同步器维护一个同步队列，获取状态失败的线程都会被加入到队列中并在队列中进行自旋；移出队列（或停止自旋）的条件是前驱节点为头节点且成功获取了同步状态。在释放同步状态时，同步器调用tryRelease(int arg)方法释放同步状态，然后唤醒head指向节点的后继节点。</p><h5 id="共享式同步状态获取与释放"><a href="#共享式同步状态获取与释放" class="headerlink" title="共享式同步状态获取与释放"></a>共享式同步状态获取与释放</h5><p>共享式获取与独占式获取最主要的区别在于同一时刻能否有多个线程同时获取到同步状态。以读写为例，如果一个程序在进行读操作，那么这一时刻写操作均被阻塞，而读操作能够同时进行。写操作要求对资源的独占式访问，而读操作可以是共享式访问。</p><p>在acquireShared(int arg)方法中，同步器调用tryAcquireShared(int arg)方法尝试获取同步状态，tryAcquireShared(int arg)方法返回值为int类型，当返回值大于等于0时，表示能够获取到同步状态。因此，在共享式获取的自旋过程中，成功获取到同步状态并退出自旋的条件就是tryAcquireShared(int arg)方法返回值大于等于0。可以看到，在doAcquireShared(int arg)方法的自旋过程中，如果当前节点的前驱为头节点时，尝试获取同步状态，如果返回值大于等于0，表示该次获取同步状态成功并从自旋过程中退出。</p><p>该方法在释放同步状态之后，将会唤醒后续处于等待状态的节点。对于能够支持多个线程同时访问的并发组件（比如Semaphore），它和独占式主要区别在于tryReleaseShared(int arg)方法必须确保同步状态（或者资源数）线程安全释放，一般是通过循环和CAS来保证的，因为释放同步状态的操作会同时来自多个线程。</p><h5 id="共享式的同步工具类"><a href="#共享式的同步工具类" class="headerlink" title="共享式的同步工具类"></a>共享式的同步工具类</h5><p>设计一个同步工具：该工具在同一时刻，只允许至多3个线程同时访问，超过3个线程的访问将被阻塞。</p><p>首先，确定访问模式。TrinityLock能够在同一时刻支持多个线程的访问，这显然是共享式访问，因此，需要使用同步器提供的acquireShared(int args)方法等和Shared相关的方法，这就要求TwinsLock必须重写tryAcquireShared(int args)方法和tryReleaseShared(int args)方法，这样才能保证同步器的共享式同步状态的获取与释放方法得以执行。</p><p>其次，定义资源数。TrinityLock在同一时刻允许至多三个线程的同时访问，表明同步资源数为3，这样可以设置初始状态status为3，当一个线程进行获取，status减1，该线程释放，则status加1，状态的合法范围为0、1和2,3，其中0表示当前已经有3个线程获取了同步资源，此时再有其他线程对同步状态进行获取，该线程只能被阻塞。在同步状态变更时，需要使用compareAndSet(int expect,int update)方法做原子性保障。</p><p>最后，组合自定义同步器。前面的章节提到，自定义同步组件通过组合自定义同步器来完成同步功能，一般情况下自定义同步器会被定义为自定义同步组件的内部类。</p><pre><code>/** *类说明：共享同步工具类 */public class TrinityLock  implements Lock {    //为n表示允许n个线程同时获得锁    private final Sync sync = new Sync(4);    private static final class Sync extends AbstractQueuedSynchronizer {        //private static final long serialVersionUID = -7889272986162341211L;        Sync(int count) {            if (count &lt;= 0) {                throw new IllegalArgumentException(&quot;count must large than zero.&quot;);            }            setState(count);        }        /**         *         * @param reduceCount  扣减个数         * @return  返回小于0，表示当前线程获得同步状态失败         * 大于0，表示当前线程获得同步状态成功         */        public int tryAcquireShared(int reduceCount) {            for (;;) {                int current = getState();                int newCount = current - reduceCount;                if (newCount &lt; 0 || compareAndSetState(current, newCount)) {                    return newCount;                }            }        }        /**         *         * @param returnCount 归还个数         * @return         */        public boolean tryReleaseShared(int returnCount) {            for (;;) {                int current = getState();                int newCount = current + returnCount;                if (compareAndSetState(current, newCount)) {                    return true;                }            }        }        final ConditionObject newCondition() {            return new ConditionObject();        }    }    public void lock() {        sync.acquireShared(1);    }    public void unlock() {        sync.releaseShared(1);    }    public void lockInterruptibly() throws InterruptedException {        sync.acquireSharedInterruptibly(1);    }    public boolean tryLock() {        return sync.tryAcquireShared(1) &gt;= 0;    }    public boolean tryLock(long time, TimeUnit unit) throws InterruptedException {        return sync.tryAcquireSharedNanos(1, unit.toNanos(time));    }    @Override    public Condition newCondition() {        return sync.newCondition();    }}</code></pre><h3 id="Condition分析"><a href="#Condition分析" class="headerlink" title="Condition分析"></a>Condition分析</h3><h4 id="Condition的数据结构"><a href="#Condition的数据结构" class="headerlink" title="Condition的数据结构"></a>Condition的数据结构</h4><p>等待队列是一个FIFO的队列，在队列中的每个节点都包含了一个线程引用，该线程就是在Condition对象上等待的线程，如果一个线程调用了Condition.await()方法，那么该线程将会释放锁、构造成节点加入等待队列并进入等待状态。事实上，节点的定义复用了同步器中节点的定义，也就是说，同步队列和等待队列中节点类型都是同步器的静态内部类。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic17.png" srcset="/img/loading.gif" class=""><p>一个Condition包含一个等待队列，Condition拥有首节点（firstWaiter）和尾节点（lastWaiter）。当前线程调用Condition.await()方法，将会以当前线程构造节点，并将节点从尾部加入等待队列。Condition拥有首尾节点的引用，而新增节点只需要将原有的尾节点nextWaiter指向它，并且更新尾节点即可。上述节点引用更新的过程并没有使用CAS保证，原因在于调用await()方法的线程必定是获取了锁的线程，也就是说该过程是由锁来保证线程安全的。</p><p>Lock（更确切地说是同步器）拥有一个同步队列和多个等待队列。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic18.png" srcset="/img/loading.gif" class=""><p>调用Condition的await()方法（或者以await开头的方法），会使当前线程进入等待队列并释放锁，同时线程状态变为等待状态。当从await()方法返回时，当前线程一定获取了Condition相关联的锁。</p><p>如果从队列（同步队列和等待队列）的角度看await()方法，当调用await()方法时，相当于同步队列的首节点（获取了锁的节点）移动到Condition的等待队列中。调用该方法的线程成功获取了锁的线程，也就是同步队列中的首节点，该方法会将当前线程构造成节点并加入等待队列中，然后释放同步状态，唤醒同步队列中的后继节点，然后当前线程会进入等待状态。当等待队列中的节点被唤醒，则唤醒节点的线程开始尝试获取同步状态。如果不是通过其他线程调用Condition.signal()方法唤醒，而是对等待线程进行中断，则会抛出InterruptedException。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic19.png" srcset="/img/loading.gif" class=""><p>如图所示，同步队列的首节点并不会直接加入等待队列，而是通过addConditionWaiter()方法把当前线程构造成一个新的节点并将其加入等待队列中。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic20.png" srcset="/img/loading.gif" class=""><p>调用Condition的signal()方法，将会唤醒在等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节点移到同步队列中。</p><p>调用该方法的前置条件是当前线程必须获取了锁，可以看到signal()方法进行了isHeldExclusively()检查，也就是当前线程必须是获取了锁的线程。接着获取等待队列的首节点，将其移动到同步队列并使用LockSupport唤醒节点中的线程。</p><p>通过调用同步器的enq(Node node)方法，等待队列中的头节点线程安全地移动到同步队列。当节点移动到同步队列后，当前线程再使用LockSupport唤醒该节点的线程。</p><p>被唤醒后的线程，将从await()方法中的while循环中退出（isOnSyncQueue(Node node)方法返回true，节点已经在同步队列中），进而调用同步器的acquireQueued()方法加入到获取同步状态的竞争中。</p><p>成功获取同步状态（或者说锁）之后，被唤醒的线程将从先前调用的await()方法返回，此时该线程已经成功地获取了锁。</p><p>Condition的signalAll()方法，相当于对等待队列中的每个节点均执行一次signal()方法，效果就是将等待队列中所有节点全部移动到同步队列中，并唤醒每个节点的线程。</p><h2 id="Lock的实现"><a href="#Lock的实现" class="headerlink" title="Lock的实现"></a>Lock的实现</h2><h3 id="ReentrantLock的实现"><a href="#ReentrantLock的实现" class="headerlink" title="ReentrantLock的实现"></a>ReentrantLock的实现</h3><h4 id="锁的可重入"><a href="#锁的可重入" class="headerlink" title="锁的可重入"></a>锁的可重入</h4><p>重进入是指任意线程在获取到锁之后能够再次获取该锁而不会被锁所阻塞，该特性的实现需要解决以下两个问题。</p><ol><li><p>线程再次获取锁。锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取。</p></li><li><p>锁的最终释放。线程重复n次获取了锁，随后在第n次释放该锁后，其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增，计数表示当前锁被重复获取的次数，而锁被释放时，计数自减，当计数等于0时表示锁已经成功释放。</p></li></ol><p>nonfairTryAcquire方法增加了再次获取同步状态的处理逻辑：通过判断当前线程是否为获取锁的线程来决定获取操作是否成功，如果是获取锁的线程再次请求，则将同步状态值进行增加并返回true，表示获取同步状态成功。同步状态表示锁被一个线程重复获取的次数。</p><p>如果该锁被获取了n次，那么前(n-1)次tryRelease(int releases)方法必须返回false，而只有同步状态完全释放了，才能返回true。可以看到，该方法将同步状态是否为0作为最终释放的条件，当同步状态为0时，将占有线程设置为null，并返回true，表示释放成功。</p><h4 id="公平和非公平锁"><a href="#公平和非公平锁" class="headerlink" title="公平和非公平锁"></a>公平和非公平锁</h4><p>ReentrantLock的构造函数中，默认的无参构造函数将会把Sync对象创建为NonfairSync对象，这是一个非公平锁；而另一个构造函数ReentrantLock(boolean fair)传入参数为true时将会把Sync对象创建为公平锁FairSync。</p><p>公平锁的tryAcquire()方法与非公平锁的nonfairTryAcquire(int acquires)相比，唯一不同的位置为判断条件多了hasQueuedPredecessors()方法，即加入了同步队列中当前节点是否有前驱节点的判断，如果该方法返回true，则表示有线程比当前线程更早地请求获取锁，因此需要等待前驱线程获取并释放锁之后才能继续获取锁，而非公平锁只要CAS设置同步状态成功，则表示当前线程获取了锁。</p><h4 id="改造之前的独占锁为可重入"><a href="#改造之前的独占锁为可重入" class="headerlink" title="改造之前的独占锁为可重入"></a>改造之前的独占锁为可重入</h4><pre><code>/** *类说明：实现我们自己独占锁,可重入 */public class ReenterSelfLock implements Lock {    // 静态内部类，自定义同步器    private static class Sync extends AbstractQueuedSynchronizer {        // 是否处于占用状态        protected boolean isHeldExclusively() {            return getState() &gt; 0;        }        // 当状态为0的时候获取锁        public boolean tryAcquire(int acquires) {            if (compareAndSetState(0, 1)) {                setExclusiveOwnerThread(Thread.currentThread());                return true;            }else if(getExclusiveOwnerThread()==Thread.currentThread()){                setState(getState()+1);                return  true;            }            return false;        }        // 释放锁，将状态设置为0        protected boolean tryRelease(int releases) {            if(getExclusiveOwnerThread()!=Thread.currentThread()){                throw new IllegalMonitorStateException();            }            if (getState() == 0)                throw new IllegalMonitorStateException();            setState(getState()-1);            if(getState()==0){                setExclusiveOwnerThread(null);            }            return true;        }        // 返回一个Condition，每个condition都包含了一个condition队列        Condition newCondition() {            return new ConditionObject();        }    }    // 仅需要将操作代理到Sync上即可    private final Sync sync = new Sync();    public void lock() {       System.out.println(Thread.currentThread().getName()+&quot; ready get lock&quot;);        sync.acquire(1);        System.out.println(Thread.currentThread().getName()+&quot; already got lock&quot;);    }    public boolean tryLock() {        return sync.tryAcquire(1);    }    public void unlock() {       System.out.println(Thread.currentThread().getName()+&quot; ready release lock&quot;);        sync.release(1);        System.out.println(Thread.currentThread().getName()+&quot; already released lock&quot;);    }    public Condition newCondition() {        return sync.newCondition();    }    public boolean isLocked() {        return sync.isHeldExclusively();    }    public boolean hasQueuedThreads() {        return sync.hasQueuedThreads();    }    public void lockInterruptibly() throws InterruptedException {        sync.acquireInterruptibly(1);    }    public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {        return sync.tryAcquireNanos(1, unit.toNanos(timeout));    }}</code></pre><p>测试类</p><pre><code>/** *类说明： */public class TestReenterSelfLock {    static final Lock lock = new ReenterSelfLock();    public void reenter(int x){        lock.lock();        try {            System.out.println(Thread.currentThread().getName()+&quot;:递归层级:&quot;+x);            int y = x - 1;            if (y==0) return;            else{                reenter(y);            }        } finally {            lock.unlock();        }    }    public void test() {        class Worker extends Thread {            public void run() {                System.out.println(Thread.currentThread().getName());                SleepTools.second(1);                reenter(3);            }        }        // 启动3个子线程        for (int i = 0; i &lt; 3; i++) {            Worker w = new Worker();            w.start();        }        // 主线程每隔1秒换行        for (int i = 0; i &lt; 100; i++) {            SleepTools.second(1);        }    }    public static void main(String[] args) {        TestReenterSelfLock testMyLock = new TestReenterSelfLock();        testMyLock.test();    }}</code></pre><h3 id="ReentrantReadWriteLock的实现"><a href="#ReentrantReadWriteLock的实现" class="headerlink" title="ReentrantReadWriteLock的实现"></a>ReentrantReadWriteLock的实现</h3><h4 id="读写状态的设计"><a href="#读写状态的设计" class="headerlink" title="读写状态的设计"></a>读写状态的设计</h4><p>读写锁同样依赖自定义同步器来实现同步功能，而读写状态就是其同步器的同步状态。</p><p>回想ReentrantLock中自定义同步器的实现，同步状态表示锁被一个线程重复获取的次数，而读写锁的自定义同步器需要在同步状态（一个整型变量）上维护多个读线程和一个写线程的状态，使得该状态的设计成为读写锁实现的关键。</p><p>如果在一个整型变量上维护多种状态，就一定需要按位切割使用这个变量，读写锁将变量切分成了两个部分，高16位表示读，低16位表示写，读写锁通过位运算来维护各自的运算。假设当前同步状态值为S，写状态等于S&amp;0x0000FFFF（将高16位全部抹去），读状态等于S&gt;&gt;&gt;16（无符号补0右移16位）。当写状态增加1时，等于S+1，当读状态增加1时，等于S+(1&lt;&lt;16)，也就是S+0x00010000。根据状态的划分能得出一个推论：S不等于0时，当写状态（S&amp;0x0000FFFF）等于0时，则读状态（S&gt;&gt;&gt;16）大于0，即读锁已被获取。</p><h4 id="写锁的获取与释放"><a href="#写锁的获取与释放" class="headerlink" title="写锁的获取与释放"></a>写锁的获取与释放</h4><p>写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。读写锁在内部有一个ThreadLocal记录写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态。</p><p>该方法除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。如果存在读锁，则写锁不能被获取，原因在于：读写锁要确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。</p><p>写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，从而等待的读写线程能够继续访问读写锁，同时前次写线程的修改对后续读写线程可见。</p><h4 id="读锁的获取与释放"><a href="#读锁的获取与释放" class="headerlink" title="读锁的获取与释放"></a>读锁的获取与释放</h4><p>读锁是一个支持重进入的共享锁，它能够被多个线程同时获取，在没有其他写线程访问（或者写状态为0）时，读锁总会被成功地获取，而所做的也只是（线程安全的）增加读状态。如果当前线程已经获取了读锁，则增加读状态。</p><p>如果当前线程在获取读锁时，写锁已被其他线程获取，则进入等待状态。读状态是所有线程获取读锁次数的总和，而每个线程各自获取读锁的次数只能选择保存在ThreadLocal中，由线程自身维护。在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态。</p><h4 id="锁的升降级"><a href="#锁的升降级" class="headerlink" title="锁的升降级"></a>锁的升降级</h4><p>锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。</p><p>锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。</p><p>RentrantReadWriteLock不支持锁升级（把持读锁、获取写锁，最后释放读锁的过程）。目的是保证数据可见性，如果读锁已被多个线程获取，其中任意线程成功获取了写锁并更新了数据，则其更新对其他获取到读锁的线程是不可见的。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>原子操作CAS(Compare And Swap)</title>
    <link href="/2019/12/24/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9CCAS/"/>
    <url>/2019/12/24/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9CCAS/</url>
    
    <content type="html"><![CDATA[<h2 id="什么是原子操作，如何实现？"><a href="#什么是原子操作，如何实现？" class="headerlink" title="什么是原子操作，如何实现？"></a>什么是原子操作，如何实现？</h2><p>谓原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束。</p><p>实现原子操作可以使用锁机制即synchronized关键字来实现，但synchronized关键字是基于阻塞的锁机制，也就是说当一个线程拥有锁的时候，访问同一资源的其它线程需要等待该线程执行完毕释放锁。这种机制不是很灵活，如果被阻塞的线程优先级比较高、获得锁的线程一直不释放锁，导致大量的线程来竞争资源，这时就需要会花费更多的资源来处理这些竞争，还可能出现一些例如死锁之类的情况，这些都会严重影响程序的性能。其实锁机制是一种比较粗糙，粒度比较大的机制，相对于简单的需求就过于笨重。</p><p>CAS是利用CPU的多处理能力，实现硬件层面的阻塞，再加上volatile变量的特性即可实现基于原子操作的线程安全。当前的处理器基本都支持CAS指令，只不过每个厂家所实现的算法并不一样。每一个CAS操作过程都包含三个运算符：一个内存地址V，一个期望的值A和一个新值B，操作的时候如果这个地址上存放的值等于这个期望的值A，则将地址上的值赋为新值B，否则将循环这个指令直到成功为止。</p><img src="/2019/12/24/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9CCAS/pic1.png" srcset="/img/loading.gif" class=""><h2 id="CAS实现原子操作的三大问题"><a href="#CAS实现原子操作的三大问题" class="headerlink" title="CAS实现原子操作的三大问题"></a>CAS实现原子操作的三大问题</h2><h3 id="ABA问题"><a href="#ABA问题" class="headerlink" title="ABA问题"></a>ABA问题</h3><p>CAS在更新值的时候，需要检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。</p><p>ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A→B→A就会变成1A→2B→3A。</p><h3 id="循环时间长开销大"><a href="#循环时间长开销大" class="headerlink" title="循环时间长开销大"></a>循环时间长开销大</h3><p>多个线程争夺同一个资源时，如果自旋一直不成功，将会一直占用CPU。</p><p>解决方法：破坏掉死循环，当超过一定时间或者一定次数时退出。或者使用JDK8新增的LongAddr和ConcurrentHashMap类似的方法，当多个线程竞争时将粒度变小，将一个变量拆分为多个变量，达到多个线程访问多个资源的效果，最后再调用sum把它合起来。</p><h3 id="只能保证一个共享变量的原子操作"><a href="#只能保证一个共享变量的原子操作" class="headerlink" title="只能保证一个共享变量的原子操作"></a>只能保证一个共享变量的原子操作</h3><p>CAS指令同时刻只能保证对一个地址的操作是原子的，当同时刻对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法使用，这个时候就可以用锁。还有一个取巧的办法，就是把多个共享变量合并成一个共享变量或者封装为对象来操作。比如，有两个共享变量i＝2，j=a，合并一下ij=2a，然后用CAS来操作ij。从Java 1.5开始，JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。</p><h2 id="Jdk中相关原子操作类的使用"><a href="#Jdk中相关原子操作类的使用" class="headerlink" title="Jdk中相关原子操作类的使用"></a>Jdk中相关原子操作类的使用</h2><h3 id="jdk中提供的原子操作类"><a href="#jdk中提供的原子操作类" class="headerlink" title="jdk中提供的原子操作类"></a>jdk中提供的原子操作类</h3><ul><li>更新基本类型：AtomicBoolean,AtomicInteger,AtomicLong</li><li>更新数组类型：AtomicIntegerArray,AtomicLongArray,AtomicReferenceArray</li><li>更新基本引用类型：AtomicReference,AtomicMarkableReference,AtomicStampedReference</li><li>更新字段类型：AtomicReferenceFieldUpdater,AtomicIntegerFieldUpdater,AtomicLongFieldUpdater</li></ul><h3 id="更新基本类型"><a href="#更新基本类型" class="headerlink" title="更新基本类型"></a>更新基本类型</h3><p><strong>AtomicInteger</strong></p><ul><li><p>int addAndGet(int delta)：以原子方式将输入的数值与实例中的值相加，并返回结果。</p></li><li><p>Int  (int delta)：返回实例中的值之后，以原子操作与输入的值相加。</p></li><li><p>int getAndIncrement()：返回实例中的值之后以原子方式加1</p></li><li><p>int incrementAndGet()：以原子操作将实例中的值加1之后返回</p></li><li><p>int getAndDecrement()：返回实例中的值之后以原子方式减1</p></li><li><p>int decrementAndGet()：以原子操作将实例中的值减1之后返回</p></li><li><p>int getAndSet(int newValue)：返回实例中的值之后以原子方式设置为newValue的值。</p></li><li><p>boolean compareAndSet(int expect，int update)：如果实例中的值等于expect值，则以原子方式设置为update的值。</p></li></ul><h3 id="更新数组类型"><a href="#更新数组类型" class="headerlink" title="更新数组类型"></a>更新数组类型</h3><p><strong>AtomicIntegerArray</strong></p><p>主要是提供原子的方式更新数组里的整型，其常用方法如下。</p><ul><li><p>int addAndGet(int i，int delta)：以原子方式将输入值与实例中索引i的元素相加后返回。</p></li><li><p>boolean compareAndSet(int i，int expect，int update)：如果实例中索引i的元素等于预期值，则以原子方式将实例中索引i的元素设置成update值。</p></li><li><p>int getAndAccumulate(int i, int x,IntBinaryOperator accumulatorFunction)：将实例中索引i的元素返回之后以原子方式设置为accumulatorFunction中的操作返回的值，accumulatorFunction的left为原始值，left为传入的值。</p></li></ul><p>需要注意的是，AtomicIntegerArray中存储的数组是复制之后的原数组，当使用AtomicIntegerArray对内部的数组元素进行修改时，不会影响原数组。</p><h3 id="更新引用类型"><a href="#更新引用类型" class="headerlink" title="更新引用类型"></a>更新引用类型</h3><p>原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包提供了以下3个类。</p><p><strong>AtomicReference</strong></p><p>原子更新引用类型（不能解决ABA问题）。</p><ul><li>boolean compareAndSet(V expect，V update)：如果实例中对象等于预期值，则以原子方式将实例中对象替换为输入的对象</li></ul><p><strong>AtomicMarkableReference</strong></p><p>可以解决ABA问题，  可以记录更新过程中有没有变化</p><ul><li>AtomicMarkableReference(V initialRef, boolean initialMark)：initialRef（要关联的对象），initialMark（版本戳）</li></ul><p>AtomicStampedReference利用版本戳的形式记录了每次改变以后的版本号，版本戳为boolean类型，可以记录值是否被修改过。</p><p><strong>AtomicStampedReference</strong></p><p>能够解决ABA问题，并且可以记录变化次数</p><ul><li>AtpmicStampedReference(V initialRef,int initialStamp)：构造函数，initialRef（要关联的对象），initialStamp（版本戳）</li><li>V getStamp()：获取当前版本号</li><li>V getReference()：获取当前对象</li><li>boolean compareAndSet(V   expectedReference,V   newReference,int expectedStamp,int newStamp) ：更新当前对象及版本号</li></ul><p>AtomicStampedReference跟AtomicMarkableReference差不多， AtomicStampedReference是使用int类型的值作为版本戳，AtomicMarkableReference使用boolean mark作为版本戳。 </p><h3 id="原子更新字段类"><a href="#原子更新字段类" class="headerlink" title="原子更新字段类"></a>原子更新字段类</h3><p>如果需原子地更新某个类里的某个字段时，就需要使用原子更新字段类，Atomic包提供了以下3个类进行原子字段更新。</p><ul><li><p>AtomicIntegerFieldUpdater：原子更新整型的字段的更新器。</p></li><li><p>AtomicLongFieldUpdater：原子更新长整型字段的更新器。</p></li><li><p>AtomicReferenceFieldUpdater：原子更新引用类型里的字段。</p></li></ul><p>要想原子地更新字段类需要两步。第一步，因为原子更新字段类都是抽象类，每次使用的时候必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。第二步，更新类的字段（属性）必须使用public volatile修饰符。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线程的并发工具类</title>
    <link href="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/"/>
    <url>/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<h1 id="Fork-Join"><a href="#Fork-Join" class="headerlink" title="Fork-Join"></a>Fork-Join</h1><p>forkjoin体现了分而治之的策略。forkjoin可以让我们不去了解Thread，Runnable等相关的知识，只要遵循forkjoin的开发模式，就可以很好的利用多线程提高我们项目的性能。</p><h3 id="分而治之"><a href="#分而治之" class="headerlink" title="分而治之"></a>分而治之</h3><p>分治策略是：对于一个规模为n的问题，若该问题可以容易地解决（比如说规模n较小）则直接解决，否则将其分解为k个规模较小的子问题，这些子问题互相独立（子问题相互之间有联系就会变为动态规范算法）且与原问题形式相同，递归地解这些子问题，然后将各子问题的解合并得到原问题的解，这种算法设计策略叫做分治法。</p><p>例如归并排序，快速排序，二分查找及大数据中M/R都体现了分而治之的策略。</p><h3 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h3><p>若将两个有序表合并成一个有序表，称为2-路归并，与之对应的还有多路归并。</p><p>对于给定的一组数据，利用递归与分治技术将数据序列划分成为越来越小的半子表，在对半子表排序后，再用递归方法将排好序的半子表合并成为越来越大的有序序列。</p><p>为了提升性能，有时我们在半子表的个数小于某个数（比如15）的情况下，对半子表的排序采用其他排序算法，比如插入排序。</p><h3 id="归并排序（降序）示例"><a href="#归并排序（降序）示例" class="headerlink" title="归并排序（降序）示例"></a>归并排序（降序）示例</h3><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic1.png" srcset="/img/loading.gif" class=""><p>先讲数组划分为左右两个子表：</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic2.png" srcset="/img/loading.gif" class=""> <img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic3.png" srcset="/img/loading.gif" class=""><p>然后继续左右两个子表拆分：</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic4.png" srcset="/img/loading.gif" class=""><p>对最后的拆分的子表，两两进行排序</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic5.png" srcset="/img/loading.gif" class=""><p>对有序的子表进行排序和比较合并</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic6.png" srcset="/img/loading.gif" class=""><p>对合并后的子表继续比较合并</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic7.png" srcset="/img/loading.gif" class=""><h2 id="Fork-Join原理"><a href="#Fork-Join原理" class="headerlink" title="Fork-Join原理"></a>Fork-Join原理</h2><p>forkjoin就是将一个大任务，进行拆分（fork）成若干个小任务（拆到不可在拆时），再将一个个小任务进行join汇总。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic8.png" srcset="/img/loading.gif" class=""><h3 id="工作密取"><a href="#工作密取" class="headerlink" title="工作密取"></a>工作密取</h3><p>即当前线程的Task已经全被执行完毕，则自动取到其他线程的Task池中取出Task继续执行。</p><p>ForkJoinPool中维护着多个线程（一般为CPU核数）在不断地执行Task，每个线程除了执行自己职务内的Task之外，还会根据自己工作线程的闲置情况去获取其他繁忙的工作线程的Task，如此一来就能能够减少线程阻塞或是闲置的时间，提高CPU利用率。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic9.png" srcset="/img/loading.gif" class=""><h2 id="Fork-Join实战"><a href="#Fork-Join实战" class="headerlink" title="Fork-Join实战"></a>Fork-Join实战</h2><h3 id="Fork-Join使用的标准范式"><a href="#Fork-Join使用的标准范式" class="headerlink" title="Fork/Join使用的标准范式"></a>Fork/Join使用的标准范式</h3><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic10.png" srcset="/img/loading.gif" class=""><p>要使用ForkJoin框架，必须首先创建一个ForkJoin任务，创建方式为继承ForkJoin的子类RecursiveAction（没有返回结果的任务）或RecursiveTask（有返回值的任务），然后实现其中的compute方法。ForkJoin框架依据compute()中的逻辑来进行fork或join操作。</p><p>在compute()中，首先需要判断任务是否足够小，如果足够小就直接执行任务。如果不足够小，就必须分割成两个并创建子任务，然后调用invokeAll()方法将创建的子任务提交，如果子任务有返回值，则调用join()方法获取子任务的执行结果之后将执行结果合并、返回，提交之后的子任务会再次进入compute()，判断子任务是否需要继续拆分，如果不需要继续拆分，则执行当前子任务并返回结果。</p><p>继承之后的子类要提交到ForkJoinPool中执行，可以使用invoke()，submit()，execture()提交，区别是：invoke()是同步执行，调用之后当前线程阻塞，等待任务完成；submit()和execture()是异步执行不会阻塞当前线程，submit()可以返回结果值，execute()不会返回结果值。之后可以通过join()或get()方法获取执行结果，如果是异步执行，join()和get()方法会阻塞当前线程直到所有任务执行完毕。</p><h3 id="实现数组排序"><a href="#实现数组排序" class="headerlink" title="实现数组排序"></a>实现数组排序</h3><pre><code>public class MergeSort {    //数组长度    public static final int ARRAY_LENGTH  = 40000000;    public final static int THRESHOLD = 47;    public static int[] makeArray() {        //new一个随机数发生器        Random r = new Random();        int[] result = new int[ARRAY_LENGTH];        for(int i=0;i&lt;ARRAY_LENGTH;i++){            //用随机数填充数组            result[i] =  r.nextInt(ARRAY_LENGTH*3);        }        return result;    }    /**     * 归并排序——将两段排序好的数组结合成一个排序数组     *     * @param left     * @param right     * @return     */    public static int[] merge(int[] left, int[] right) {        int[] result = new int[left.length + right.length];        for (int index = 0, i = 0, j = 0; index &lt; result.length; index++) {            if (i &gt;= left.length)/*左边数组已经取完，完全取右边数组的值即可*/                result[index] = right[j++];            else if (j &gt;= right.length)/*右边数组已经取完，完全取左边数组的值即可*/                result[index] = left[i++];            else if (left[i] &gt; right[j])/*左边数组的元素值大于右边数组，取右边数组的值*/                result[index] = right[j++];            else/*右边数组的元素值大于左边数组，取左边数组的值*/                result[index] = left[i++];        }        return result;    }     /**     * 插入排序     *     * @param array     * @return     */    public static int[] sort(int[] array) {        if (array.length == 0)            return array;        int currentValue;/*当前待排序数据，该元素之前的元素均已被排序过*/        for (int i = 0; i &lt; array.length - 1; i++) {            int preIndex = i;/*已被排序数据的索引*/            currentValue = array[preIndex + 1];            /*在已被排序过数据中倒序寻找合适的位置，如果当前待排序数据比比较的元素要小，            将比较的元素元素后移一位*/            while (preIndex &gt;= 0 &amp;&amp; currentValue &lt; array[preIndex]) {                //将当前元素后移一位                array[preIndex + 1] = array[preIndex];                preIndex--;            }            /*while循环结束时，说明已经找到了当前待排序数据的合适位置，插入*/            array[preIndex + 1] = currentValue;        }        return array;    }    public static void main(String[] args) {        System.out.println(&quot;============================================&quot;);        long start = System.currentTimeMillis();        ForkJoinPool forkJoinPool = new ForkJoinPool();        MergeSortTask sortTask = new MergeSortTask(MakeArray.makeArray());        forkJoinPool.invoke(sortTask);        //forkJoinPool.submit(sortTask);        //int[] array = sortTask.join();        System.out.println(&quot; spend time:&quot;+(System.currentTimeMillis()-start)+&quot;ms&quot;);        System.out.println(&quot;============================================&quot;);    }    private static class MergeSortTask extends RecursiveTask&lt;int[]&gt;{        private int[] array;        public MergeSortTask(int[] array){            this.array = array;        }        @Override        protected int[] compute() {            if (array.length&lt;= THRESHOLD) {                return sort(array);            }else{                int mid = array.length / 2;                int[] leftArray = Arrays.copyOfRange(array, 0, mid);                int[] rightArray = Arrays.copyOfRange(array, mid, array.length);                MergeSortTask leftTask = new MergeSortTask(leftArray);                MergeSortTask rightTask = new MergeSortTask(rightArray);                invokeAll(leftTask, rightTask);                return merge(leftTask.join(), rightTask.join());            }        }    }}</code></pre><h3 id="异步寻找目录下的文件"><a href="#异步寻找目录下的文件" class="headerlink" title="异步寻找目录下的文件"></a>异步寻找目录下的文件</h3><pre><code>public class FindDirsFiles extends RecursiveAction {    private File path;    public FindDirsFiles(File path) {        this.path = path;    }    @Override    protected void compute() {        List&lt;FindDirsFiles&gt; subTasks = new ArrayList&lt;&gt;();        File[] files = path.listFiles();        if (files!=null){            for (File file : files) {                if (file.isDirectory()) {                    // 对每个子目录都新建一个子任务。                    subTasks.add(new FindDirsFiles(file));                } else {                    // 遇到文件，检查。                    if (file.getAbsolutePath().endsWith(&quot;txt&quot;)){                        System.out.println(&quot;文件:&quot; + file.getAbsolutePath());                    }                }            }            if (!subTasks.isEmpty()) {                // 在当前的 ForkJoinPool 上调度所有的子任务。                for (FindDirsFiles subTask : invokeAll(subTasks)) {                    subTask.join();                }            }        }    }    public static void main(String [] args){        try {            // 用一个 ForkJoinPool 实例调度总任务            ForkJoinPool pool = new ForkJoinPool();            FindDirsFiles task = new FindDirsFiles(new File(&quot;./&quot;));            /*异步提交*/            pool.execute(task);            /*主线程做自己的业务工作*/            System.out.println(&quot;Task is Running......&quot;);            Thread.sleep(1);            int otherWork = 0;            for(int i=0;i&lt;100;i++){                otherWork = otherWork+i;            }            System.out.println(&quot;Main Thread done sth......,otherWork=&quot;                    +otherWork);            task.join();//阻塞方法            System.out.println(&quot;Task end&quot;);        } catch (Exception e) {            // TODO Auto-generated catch block            e.printStackTrace();        }    }}</code></pre><h1 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h1><p>闭锁，CountDownLatch这个类能够使一个线程或多个线程等待其他线程完成后再执行。例如，应用程序的主线程希望在负责启动框架服务的线程已经完成之后再执行。</p><p>CountDownLatch是通过一个计数器来实现的，计数器的初始值为初始任务的数量（也可以大于线程数即线程中可以多次执行countDown()，线程执行countDown()之后也可以继续执行）。每当完成了一个任务后，计数器的值就会减1（CountDownLatch.countDown()方法）。当计数器值到达0时，它表示所有的已经完成了任务，然后在闭锁上等待CountDownLatch.await()方法的线程就可以继续执行。</p><p>CountDownLatch是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当CountDownLatch使用完毕后，它不能再次被使用。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic11.png" srcset="/img/loading.gif" class=""><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>通常用来使多个线程实现最大程度的并行性，使多个线程在某一时刻同时开始执行。某一线程在开始运行前等待n个线程执行完毕。将CountDownLatch的计数器初始化为new CountDownLatch(n)，每当一个任务线程执行完毕，就将计数器减1 countdownLatch.countDown()，当计数器的值变为0时，在CountDownLatch上await()的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。</p><p>开始执行前等待n个线程完成各自任务：例如应用程序启动类要确保在处理用户请求前，所有N个外部系统已经启动和运行了，例如处理excel中多个表单。</p><h3 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h3><pre><code>/** *类说明：演示CountDownLatch用法， * 共5个初始化子线程，6个闭锁扣除点，扣除完毕后，主线程和业务线程才能继续执行 */public class UseCountDownLatch {    static CountDownLatch latch = new CountDownLatch(6);    /*初始化线程*/    private static class InitThread implements Runnable{        public void run() {            System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                    +&quot; ready init work......&quot;);            latch.countDown();            for(int i =0;i&lt;2;i++) {                System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                        +&quot; ........continue do its work&quot;);            }        }    }    /*业务线程等待latch的计数器为0完成*/    private static class BusiThread implements Runnable{        public void run() {            try {                latch.await();            } catch (InterruptedException e) {                e.printStackTrace();            }            for(int i =0;i&lt;3;i++) {                System.out.println(&quot;BusiThread_&quot;+Thread.currentThread().getId()                        +&quot; do business-----&quot;);            }        }    }    public static void main(String[] args) throws InterruptedException {        new Thread(new Runnable() {            public void run() {                SleepTools.ms(1);                System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                        +&quot; ready init work step 1st......&quot;);                latch.countDown();                System.out.println(&quot;begin step 2nd.......&quot;);                SleepTools.ms(1);                System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                        +&quot; ready init work step 2nd......&quot;);                latch.countDown();            }        }).start();        new Thread(new BusiThread()).start();        for(int i=0;i&lt;=3;i++){            Thread thread = new Thread(new InitThread());            thread.start();        }        latch.await();        System.out.println(&quot;Main do ites work........&quot;);    }}</code></pre><h1 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h1><p>CyclicBarrier的字面意思是可循环使用（Cyclic）的屏障（Barrier）。可以让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到所有线程到达屏障时解除屏障，所有被屏障拦截的线程才会继续运行。CyclicBarrier默认的构造方法是CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await()方法告诉CyclicBarrier当前线程已经到达了屏障，然后这个线程被阻塞。</p><p>CyclicBarrier还提供一个更高级的构造函数CyclicBarrier(int parties，Runnable barrierAction)，用于在线程到达屏障时，执行barrierAction，方便处理更复杂的业务场景。</p><p>await()方法可以执行多次，当满足条件屏障解除之后，CyclicBarrier就会被复位。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic12.png" srcset="/img/loading.gif" class=""><h3 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h3><p>CyclicBarrier可以用于多线程计算数据，最后合并计算结果的场景。</p><h3 id="用法-1"><a href="#用法-1" class="headerlink" title="用法"></a>用法</h3><pre><code>/** * 类说明：演示CyclicBarrier用法,共4个子线程，他们全部完成工作后，交出自己结果， * 再被统一释放去做自己的事情，而交出的结果被另外的线程拿来拼接字符串 */public class UseCyclicBarrier {    private static CyclicBarrier barrier = new CyclicBarrier(4, new CollectThread());    //存放子线程工作结果的容器    private static ConcurrentHashMap&lt;String, Long&gt; resultMap            = new ConcurrentHashMap&lt;&gt;();    public static void main(String[] args) {        for (int i = 0; i &lt; 4; i++) {            Thread thread = new Thread(new SubThread());            thread.start();        }    }    /*汇总的任务*/    private static class CollectThread implements Runnable {        @Override        public void run() {            StringBuilder result = new StringBuilder();            for (Map.Entry&lt;String, Long&gt; workResult : resultMap.entrySet()) {                result.append(&quot;[&quot; + workResult.getValue() + &quot;]&quot;);            }            System.out.println(&quot; the result = &quot; + result);            System.out.println(&quot;do other business........&quot;);        }    }    /*相互等待的子线程*/    private static class SubThread implements Runnable {        @Override        public void run() {            long id = Thread.currentThread().getId();            resultMap.put(Thread.currentThread().getId() + &quot;&quot;, id);            try {                Thread.sleep(1000 + id);                System.out.println(&quot;Thread_&quot; + id + &quot; ....do something &quot;);                barrier.await();                Thread.sleep(1000 + id);                System.out.println(&quot;Thread_&quot; + id + &quot; ....do its business &quot;);            } catch (Exception e) {                e.printStackTrace();            }        }    }}</code></pre><h3 id="CountDownLatch和CyclicBarrier辨析"><a href="#CountDownLatch和CyclicBarrier辨析" class="headerlink" title="CountDownLatch和CyclicBarrier辨析"></a>CountDownLatch和CyclicBarrier辨析</h3><ul><li><p>CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以反复使用。</p></li><li><p>CountDownLatch.await()会阻塞当前线程，等待所有工作线程执行countDown()之后继续执行，而CyclicBarrier通过线程调用await()阻塞工作线程，直到所有工作线程达到指定屏障，所有工作线程再继续执行。</p></li><li><p>在控制多个线程同时运行上，CountDownLatch可以不限线程数量，而CyclicBarrier是固定线程数。</p></li><li><p>CyclicBarrier还可以提供一个barrierAction，用于进行到达屏障后的工作，如：合并多线程计算结果。</p></li></ul><h1 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h1><p>Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。</p><p>Semaphore可以用于做流量控制，特别是公用资源有限的应用场景，比如数据库连接。假如有一个需求，要读取几万个文件的数据并存储到数据库中，因为都是IO密集型任务，我们可以启动几十个线程并发地读取，但数据库的连接数只有10个，这时就可以使用Semaphore控制最多只有10个线程同时获取数据库连接保存数据。</p><p>Semaphore的构造方法Semaphore（int permits）接受一个整型的数字，表示可用的许可证数量。Semaphore的用法也很简单，首先线程使用Semaphore的acquire()方法获取一个许可证 ，使用完之后调用release()方法归还许可证。还可以用tryAcquire()方法尝试获取许可证。</p><p>Semaphore还提供一些其他方法，具体如下。</p><ul><li><p><strong>int availablePermits()：</strong>返回此信号量中当前可用的许可证数。</p></li><li><p><strong>int getQueueLength()：</strong>返回正在等待获取许可证的线程数。</p></li><li><p><strong>boolean hasQueuedThreads()：</strong>是否有线程正在等待获取许可证。</p></li><li><p><strong>void reducePermits(int reduction)：</strong>减少reduction个许可证，是个protected方法。</p></li><li><p><strong>Collection getQueuedThreads()</strong>：返回所有等待获取许可证的线程集合，是个protected方法。</p></li></ul><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic13.png" srcset="/img/loading.gif" class=""><h3 id="用Semaphore实现数据库连接池"><a href="#用Semaphore实现数据库连接池" class="headerlink" title="用Semaphore实现数据库连接池"></a>用Semaphore实现数据库连接池</h3><pre><code>/** *类说明：演示Semaphore用法，一个数据库连接池的实现 */public class DBPoolSemaphore {    private final static int POOL_SIZE = 10;    //两个指示器，分别表示池子还有可用连接和已用连接    private final Semaphore useful, useless;    //存放数据库连接的容器    private static LinkedList&lt;Connection&gt; pool = new LinkedList&lt;Connection&gt;();    //初始化池    static {        for (int i = 0; i &lt; POOL_SIZE; i++) {            pool.addLast(SqlConnectImpl.fetchConnection());        }    }    public DBPoolSemaphore() {        this.useful = new Semaphore(10);        this.useless = new Semaphore(0);    }    /*归还连接*/    public void returnConnect(Connection connection) throws InterruptedException {        if(connection!=null) {            System.out.println(&quot;当前有&quot;+useful.getQueueLength()+&quot;个线程等待数据库连接!!&quot;                    +&quot;可用连接数：&quot;+useful.availablePermits());            useless.acquire();            synchronized (pool) {                pool.addLast(connection);            }            useful.release();        }    }    /*从池子拿连接*/    public Connection takeConnect() throws InterruptedException {        useful.acquire();        Connection connection;        synchronized (pool) {            connection = pool.removeFirst();        }        useless.release();        return connection;    }    private static DBPoolSemaphore dbPool = new DBPoolSemaphore();    private static class BusiThread extends Thread{        @Override        public void run() {            Random r = new Random();//让每个线程持有连接的时间不一样            long start = System.currentTimeMillis();            try {                Connection connect = dbPool.takeConnect();                System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                        +&quot;_获取数据库连接共耗时【&quot;+(System.currentTimeMillis()-start)+&quot;】ms.&quot;);                SleepTools.ms(100+r.nextInt(100));//模拟业务操作，线程持有连接查询数据                System.out.println(&quot;查询数据完成，归还连接！&quot;);                dbPool.returnConnect(connect);            } catch (InterruptedException e) {            }        }    }    public static void main(String[] args) {        for (int i = 0; i &lt; 50; i++) {            Thread thread = new BusiThread();            thread.start();        }    }}</code></pre><h3 id="Semaphore注意事项"><a href="#Semaphore注意事项" class="headerlink" title="Semaphore注意事项"></a>Semaphore注意事项</h3><p>上面的代码是用了两个指示器useful和useless，分别表示可用连接和已用连接。使用userless控制可归还的链接数的目的，是为了解决归还其他方式创建的链接，导致useful的数量增加的问题。</p><pre><code>/** *类说明：演示Semaphore用法，一个数据库连接池的实现 */public class DBPoolNoUseless {    private final static int POOL_SIZE = 10;    private final Semaphore useful;    //存放数据库连接的容器    private static LinkedList&lt;Connection&gt; pool = new LinkedList&lt;Connection&gt;();    //初始化池    static {        for (int i = 0; i &lt; POOL_SIZE; i++) {            pool.addLast(SqlConnectImpl.fetchConnection());        }    }    public DBPoolNoUseless() {        this.useful = new Semaphore(10);    }    /*归还连接*/    public void returnConnect(Connection connection) throws InterruptedException {        if(connection!=null) {            System.out.println(&quot;当前有&quot;+useful.getQueueLength()+&quot;个线程等待数据库连接!!&quot;                    +&quot;可用连接数：&quot;+useful.availablePermits());            synchronized (pool) {                pool.addLast(connection);            }            useful.release();        }    }    /*从池子拿连接*/    public Connection takeConnect() throws InterruptedException {        useful.acquire();        Connection connection;        synchronized (pool) {            connection = pool.removeFirst();        }        return connection;    }    private static DBPoolNoUseless dbPoolNoUseless = new DBPoolNoUseless();    private static class BusiThread extends Thread{        @Override        public void run() {            Random r = new Random();//让每个线程持有连接的时间不一样            long start = System.currentTimeMillis();            try {                System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                        +&quot;_获取数据库连接共耗时【&quot;+(System.currentTimeMillis()-start)+&quot;】ms.&quot;);                SleepTools.ms(100+r.nextInt(100));//模拟业务操作，线程持有连接查询数据                System.out.println(&quot;查询数据完成，归还连接！&quot;);                dbPoolNoUseless.returnConnect(new SqlConnectImpl());            } catch (InterruptedException e) {            }        }    }    public static void main(String[] args) {        for (int i = 0; i &lt; 50; i++) {            Thread thread = new BusiThread();            thread.start();        }    }}</code></pre><h1 id="Exchange"><a href="#Exchange" class="headerlink" title="Exchange"></a>Exchange</h1><p>Exchanger（交换者）是一个用于线程间协作的工具类，常用于线程间的数据交换。</p><p>Exchanger提供一个允许两个线程交换彼此数据的同步点。线程可以通过exchange方法交换数据，如果第一个线程先执行exchange()方法，它会一直等待第二个线程也执行exchange()方法，当两个线程都到达同步点时，这两个线程就可以交换数据，将本线程生产出来的数据传递给对方。交换过程由jdk保证线程安全。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic14.png" srcset="/img/loading.gif" class=""><h3 id="用法-2"><a href="#用法-2" class="headerlink" title="用法"></a>用法</h3><pre><code>/** * 类说明：演示CyclicExchange用法 */public class UseExchange {    private static final Exchanger&lt;Set&lt;String&gt;&gt; exchange = new Exchanger&lt;Set&lt;String&gt;&gt;();    public static void main(String[] args) {        new Thread(new Runnable() {            @Override            public void run() {                Set&lt;String&gt; setA = new HashSet&lt;String&gt;();//存放数据的容器                try {                    setA.add(&quot;A&quot;);                    setA = exchange.exchange(setA);//交换set                    System.out.println(&quot;A:&quot; + setA);                    /*处理交换后的数据*/                } catch (InterruptedException e) {                }            }        }).start();        new Thread(new Runnable() {            @Override            public void run() {                Set&lt;String&gt; setB = new HashSet&lt;String&gt;();//存放数据的容器                try {                    setB.add(&quot;B&quot;);                    setB = exchange.exchange(setB);//交换set                    System.out.println(&quot;B:&quot; + setB);                    /*处理交换后的数据*/                } catch (InterruptedException e) {                }            }        }).start();    }}</code></pre><h1 id="Callable、Future和FutureTask"><a href="#Callable、Future和FutureTask" class="headerlink" title="Callable、Future和FutureTask"></a>Callable、Future和FutureTask</h1><p>Runnable是一个接口，在它里面只声明了一个run()方法，由于run()方法返回值为void类型，所以在执行完任务之后无法返回任何结果。</p><p>Callable接口位于java.util.concurrent包下，它也是一个接口，在它里面也只声明了一个call()方法，但这是一个有返回值的接口，call()方法返回的类型就是传递进来的泛型。 Callable无法直接交给Thread执行，这时就需要一个类来包装Callable使其能够被Thread类执行。</p><p>Future接口的作用就是对任务进行取消、查询是否完成、获取结果。可以通过get()方法获取执行结果，该方法会阻塞直到任务返回结果。但Future只是一个接口，所以是无法直接用来创建对象使用的，就有了下面的FutureTask。</p><p>RunnableFuture继承了Runnable接口和Future接口，所以RunnableFuture接口可以被Thread执行也可以用来获取结果等操作，FutureTask类实现了RunnableFuture接口，所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic15.png" srcset="/img/loading.gif" class=""><p>FutureTask类的构造函数接收一个Callable类型的参数，所以需要先手动实现Callable接口，之后再创建一个FutureTask类，再将FutureTask交给Thread运行后，就可以通过get()方法获取到Callable的返回值。</p><h3 id="用法-3"><a href="#用法-3" class="headerlink" title="用法"></a>用法</h3><pre><code>/** * 类说明：演示Future等的使用 */public class UseFuture {    /*实现Callable接口，允许有返回值*/    private static class UseCallable implements Callable&lt;Integer&gt; {        private int sum;        @Override        public Integer call() throws Exception {            System.out.println(&quot;Callable子线程开始计算！&quot;);            for (int i = 0; i &lt; 500; i++) {                if (Thread.currentThread().isInterrupted()) {                    System.out.println(&quot;Callable子线程计算任务中断！&quot;);                    return null;                }                sum = sum + i;            }            System.out.println(&quot;Callable子线程计算结束！结果为: &quot; + sum);            return sum;        }    }    public static void main(String[] args) throws InterruptedException, ExecutionException {        UseCallable useCallable = new UseCallable();        FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(useCallable);        new Thread(futureTask).start();        Random r = new Random();        if (r.nextInt(100) &gt; 50) {            System.out.println(&quot;result = &quot; + futureTask.get());        } else {            System.out.println(&quot;cancel&quot;);            futureTask.cancel(true);        }    }}</code></pre>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线程基础、线程之间的共享和合作</title>
    <link href="/2019/12/17/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B1%E4%BA%AB%E5%92%8C%E5%90%88%E4%BD%9C/"/>
    <url>/2019/12/17/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B1%E4%BA%AB%E5%92%8C%E5%90%88%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><ul><li><strong>CPU核心和线程数的关系</strong>：核心数比线程数一般为1:1，超线程技术1:2</li><li><strong>CPU时间片轮转机制(RR调度)</strong>：古老、简单、公平、应用最广泛的算法。在时间片用完、线程阻塞、线程完成时会剥夺线程cpu使用权。在进行线程调度时会产生上下文切换，上下文切换时需要保存上个线程在寄存器中的数据，同时载入下个线程的数据，这个步骤大约需要5000-20000个cpu时钟周期。如果线程过多导致上下文切换频繁进行，多线程的效率可能不如单线程。</li><li><strong>进程和线程</strong>：进程是程序进行资源分配的最小单位，一个进程可能会有多个线程会共享这个进程的资源。线程是cpu资源调度的最小单位。</li><li><strong>并行和并发</strong>：并行是指同一时刻的处理能力、并发和事件相关是指在单位时间内处理事件的能力。</li><li><strong>高并发编程的意义、好处和注意事项</strong>：提高资源利用效率，但由于共享资源可能存在冲突、死锁，过多的线程还会造成服务器崩溃。</li></ul><h2 id="Java中的线程"><a href="#Java中的线程" class="headerlink" title="Java中的线程"></a>Java中的线程</h2><p>java中的程序天生就是多线程的，线程间的关系为协作式。可以通过虚拟机的线程管理接口查看当前进行的线程。</p><pre><code>public static void main(String[] args) {    ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();    ThreadInfo[] threadInfos=threadMXBean.dumpAllThreads(false, false);    for(ThreadInfo threadInfo:threadInfos){        System.out.println(&quot;[&quot;+threadInfo.getThreadId()+&quot;]&quot;+&quot; &quot;+threadInfo.getThreadName());    }}</code></pre><h3 id="启动线程的方式"><a href="#启动线程的方式" class="headerlink" title="启动线程的方式"></a>启动线程的方式</h3><ol><li>继承Thread类后通过start()方法启动。</li><li>实现Runable接口后通过new Thread(runable).start()启动。</li><li>实现Callable接口之后使用new FutureTask&lt;&gt;(callable)创建task后通过new Thread(task).start()启动，启动后可以通过futureTask的get()方法获取线程返回值，获取返回值时当前线程会阻塞直至task执行结束。</li></ol><p>注：</p><ul><li><p>start()方法会判断线程是否被启动，如果已经被启动会抛出异常。</p></li><li><p>Thread是线程的抽象，Runnable是任务的抽象。</p></li></ul><h3 id="停止线程的方式"><a href="#停止线程的方式" class="headerlink" title="停止线程的方式"></a>停止线程的方式</h3><ol><li>thread中的stop()，resume()，suspend()方法都可以停止线程，但是这三个方法过于强势，stop()无法保证线程资源释放可能导致不可知的错误，suspend()挂起线程时不会释放资源可能导致死锁问题。</li><li>interrupt()可以中断一个线程，并不是强行关闭这个线程，调用interrupt()方法后，讲线程的中断标识为置为true，线程是否停止由线程决定，以此确保每个线程有充足的时间做好后续工作。</li><li>isInterrupted()、interrupted()都可以判断当前线程是否处于中断状态（中断标志位是否为true），但是interrupted()调用之后将中断标识为改为flase。</li><li>如果使用自定义标志位停止线程，如果线程被挂起，标识位的判断就无法进行，但调用interrupt()方法会使中断方法抛出InterruptException，此时可以捕获这个异常，然后进行资源的释放，但要注意抛出异常后interrupt标志位将重新设置为false，如果要中断线程还需要在调用一次interrupt()方法。</li></ol><h3 id="interrupt-的使用示例"><a href="#interrupt-的使用示例" class="headerlink" title="interrupt()的使用示例"></a>interrupt()的使用示例</h3><pre><code>public class Main {    private static class UserThread extends Thread{        public UserThread(String name){            super(name);        }        @Override        public void run() {            String threadName=Thread.currentThread().getName();            while(!isInterrupted()){                System.out.println(threadName);            }            System.out.println(threadName+&quot; interrput flag is &quot;+isInterrupted());        }    }    // 实现Runnable中断的方法    private static class UserThread implements Runnable{        @Override        public void run() {            String threadName=Thread.currentThread().getName();            while(!Thread.currentThread().isInterrupted()){                System.out.println(threadName);            }            System.out.println(threadName+&quot; interrput flag is &quot;+Thread.currentThread().isInterrupted());        }    }    public static void main(String[] args) throws InterruptedException {        Thread endThread=new UserThread(&quot;endThread&quot;);        endThread.start();        Thread.sleep(20L);        endThread.interrupt();    }}</code></pre><p>当线程处于阻塞状态时调用interrupted方法时会抛出InterruptedExcetion异常时，抛出异常后，线程的中断标识为会被复位为false。</p><pre><code>public class Main {    private static class UserThread extends Thread {        public UserThread(String name) {            super(name);        }        @Override        public void run() {            String threadName = Thread.currentThread().getName();            while (!isInterrupted()) {                try {                    Thread.sleep(100);                } catch (InterruptedException e) {                    System.out.println(threadName+&quot; interrput flag is &quot;+isInterrupted());                    interrupt();                    e.printStackTrace();                }                System.out.println(threadName);            }            System.out.println(threadName+&quot; interrput flag is &quot;+isInterrupted());        }    }    public static void main(String[] args) throws InterruptedException {        Thread endThread=new UserThread(&quot;endThread&quot;);        endThread.start();        Thread.sleep(500);        endThread.interrupt();    }}</code></pre><h3 id="线程常用方法和线程的状态"><a href="#线程常用方法和线程的状态" class="headerlink" title="线程常用方法和线程的状态"></a>线程常用方法和线程的状态</h3><img src="/2019/12/17/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B1%E4%BA%AB%E5%92%8C%E5%90%88%E4%BD%9C/pic1.png" srcset="/img/loading.gif" class=""><ul><li><p>线程处于阻塞态时，系统不会进行资源分配。</p></li><li><p>守护线程大多用来支持程序，可以用线程的setDaemon()方法设置，当用户线程停止后，所有的守护线程也将停止。守护线程大多用于资源管理，当用户线程结束后，作为资源管理的守护线程也就没有必要释放资源。操作系统在判定当前线程被结束时就不会分配资源，但也有可能在终止进程关闭时有一段很短的时间使守护线程执行finally中的方法。 守护线程中的finally不一定会执行，用户线程中的finally一定会执行。</p></li><li><p>线程从阻塞态唤醒时会进入就绪态，等待cpu使用权。</p></li><li><p>interrupt()：改变线程中断标识位，对线程的影响取决于开发者对标志位的处理。</p></li><li><p>yield()：让出当前线程的cpu使用权进入就绪态，并参与下次cpu时间片分配。与sleep()方法的区别在于 sleep()是让出线程资源及cpu使用权进入阻塞态，且不会参与时间片分配直至休眠结束。</p></li><li><p>join()：让出当前线程资源及cpu使用权后进入阻塞态，等待join的线程执行完之后唤醒当前线程。</p></li><li><p>setPriority()：设置线程的优先级但不一定会起作用。范围为1-10，有些系统范围为1-3，优先级是否发挥作用完全由操作系统决定。 通常将需要休眠或者io操作比较多的设置高优先级，计算操作设置低优先级，确保处理器时间不会被计算型的线程占据。</p></li><li><p><strong>run()方法和start()方法</strong>：调用run()方法后，run()方法会被打包为栈帧在当前线程所在栈进行入栈，调用start()方法后，虚拟机会创建新的线程，在新线程中调用run()方法，此时打包后的栈帧会在新线程所在的栈进行入栈。</p></li></ul><h3 id="线程间的共享"><a href="#线程间的共享" class="headerlink" title="线程间的共享"></a>线程间的共享</h3><h4 id="synchronized内置锁"><a href="#synchronized内置锁" class="headerlink" title="synchronized内置锁"></a>synchronized内置锁</h4><p>synchronized可以修饰方法或者设置同步块，确保在同一时刻只有一个线程处于同步方法或者同步块中，保证线程对变量访问的可见性和排它性，又称为内置锁机制。</p><h5 id="实例锁和类锁"><a href="#实例锁和类锁" class="headerlink" title="实例锁和类锁"></a>实例锁和类锁</h5><p>实例锁是加在实例对象上的，实例对象是存储在堆上的，每个实例都有自己的堆内存空间，所以不同实例间的实例锁互不影响。实例锁的用法共有三种：锁住类的非静态变量、锁住this对象、直接在非静态方法上加synchronized。类锁是加在类上的，JVM会为每个类创建类对象，类对象是存储在在方法区的，且整个JVM只有一份，所以类锁所有线程共享的。类锁的用法也有三种：锁住类中的静态变量、直接在静态方法上加 synchronized、锁住 xxx.class。</p><h5 id="错误的加锁和原因分析"><a href="#错误的加锁和原因分析" class="headerlink" title="错误的加锁和原因分析"></a>错误的加锁和原因分析</h5><p>通常是在线程执行过程中，锁住的对象被改变，导致加锁的对象并不是同一个。</p><h4 id="volatile关键字"><a href="#volatile关键字" class="headerlink" title="volatile关键字"></a>volatile关键字</h4><p>volatile是<strong>最轻量的同步机制</strong>。volatile保证多个线程对volatile变量的可见性，但不能保证原子性。当一个线程改变了volatile变量的值，改变后的值对其他线程是可见的，但volatile变量在多个线程写的情况下是不安全的，volatile最适用的场景为一写多读。</p><h2 id="ThreadLocal辨析"><a href="#ThreadLocal辨析" class="headerlink" title="ThreadLocal辨析"></a>ThreadLocal辨析</h2><h3 id="与Synchronized的比较"><a href="#与Synchronized的比较" class="headerlink" title="与Synchronized的比较"></a>与Synchronized的比较</h3><p>ThreadLocal和Synchonized都用于解决多线程并发访问，ThreadLocal与synchronized有本质的差别。synchronized是利用锁的机制，使变量或代码块在某一时该仅仅能被一个线程访问，而ThreadLocal为每个线程都提供了变量的副本，使得每个线程在某一时间访问到的并非同一个对象，相当于就隔离了多个线程的数据共享。</p><p>spring事务就借助了ThreadLocal类来实现。jdbc事务是以对connection的操作为整体，tomcat会为每一次请求创建一个单独的线程，spring事务使用ThreadLocal保证每一个线程的connection都互不影响，这样就保证每个请求对数据库所有的操作在不同的connection中进行，从而保证事务的边界。</p><h3 id="ThreadLocal的使用"><a href="#ThreadLocal的使用" class="headerlink" title="ThreadLocal的使用"></a>ThreadLocal的使用</h3><p>ThreadLocal类接口很简单，只有4个方法</p><ul><li><p><strong>void set(Object value)</strong> ：设置当前线程的线程局部变量的值。</p></li><li><p><strong>public Object get()</strong> ：返回当前线程所对应的线程局部变量。</p></li><li><p><strong>public void remove()</strong> ：将当前线程局部变量的值删除，目的是为了减少内存的占用，该方法是JDK 5.0新增的方法。需要指出的是，当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显式调用该方法清除线程的局部变量并不是必须的操作，但它可以加快内存回收的速度。</p></li><li><p><strong>protected Object initialValue()</strong>： 返回该线程局部变量的初始值，该方法是一个protected的方法，显然是为了让子类覆盖而设计的。这个方法是一个延迟调用方法，在线程第1次调用get()或set(Object)时才执行，并且仅执行1次。ThreadLocal中的缺省实现直接返回一个null。</p></li><li><p><strong>public final static ThreadLocal<String> RESOURCE = new ThreadLocal<String>();</strong>RESOURCE代表一个能够存放String类型的ThreadLocal对象。此时不论什么一个线程能够并发访问这个变量，对它进行写入、读取操作，都是线程安全的。</p></li></ul><h3 id="实现解析"><a href="#实现解析" class="headerlink" title="实现解析"></a>实现解析</h3><img src="/2019/12/17/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B1%E4%BA%AB%E5%92%8C%E5%90%88%E4%BD%9C/pic2.png" srcset="/img/loading.gif" class=""><p>Thread中有一个ThreadLocalMap对象，ThreadLocalMap是ThreadLocal的静态内部类，存储的对象为Entry类型的数组，Entry类型的键为ThreadLocal对象，值为ThreadLocal对象的值，ThreadLocal的get方法会获取当前Thread，然后调用getMap()获取当前Thread的ThreadLocalMap，再从ThreadLocalMap中通过ThreadLocal找到对应的值。</p><h3 id="引发的内存泄露分析"><a href="#引发的内存泄露分析" class="headerlink" title="引发的内存泄露分析"></a>引发的内存泄露分析</h3><h4 id="jvm中的引用类型"><a href="#jvm中的引用类型" class="headerlink" title="jvm中的引用类型"></a>jvm中的引用类型</h4><p><strong>强引用：</strong>常用的Object o = new Object()就是强引用，在线程中执行方法时， 方法会被打包为栈帧在栈上运行，方法中创建的对象实例存储在在堆上，而方法中对象的命名指向堆上的实例，这就是引用（类似于c++的指针）。当强引用存在时即栈上有一个引用指向堆中的对象实例，gc就不会回收该对象实例。</p><p><strong>软引用：</strong>用来描述一些还有用但并非必需的对象。将要发生内存溢出时，会把软引用对象实例列入回收范围，进入第二次回收。如果回收之后还是没有足够的内存才会抛出内存溢出异常。在JDK 1.2之后，提供了SoftReference类来实现软引用。</p><p><strong>弱饮用</strong>：用来描述非必需对象的，强度低于软引用，只要发生垃圾回收，弱引用指向的对象实例就一定会被回收掉，不管是否将要发生内存溢出。在JDK 1.2之后，提供了WeakReference类来实现弱引用。</p><p><strong>虚引用</strong>：也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象实例是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象实例被收集器回收时收到一个系统通知。在JDK 1.2之后，提供了PhantomReference类来实现虚引用。</p><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><img src="/2019/12/17/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B1%E4%BA%AB%E5%92%8C%E5%90%88%E4%BD%9C/pic3.png" srcset="/img/loading.gif" class=""><p>Thread维护的ThreadLocalMap中的Entry的key使用的是ThreadLocal的的弱引用 ，方法执行完出栈后，threadLocal变量会被置为null，此时强引用消失，没有强引用指向ThreadLocal实例，ThreadLocal会被gc回收即Entry中的key被回收，但Thread对ThreadLocalMap的应用是强引用，所以Entry中的value会依然存在，这就有可能造成内存泄漏。只有当前thread结束以后，ThreadLocalMap强引用断开才会被GC回收。</p><p>jdk对此提供了相应的补偿机制，ThreadLocal的get()，set()有可能会去调用expungeStaleEntry()，replaceStaleEntry()方法去清除key为null（ThreadLocal为null）的value值。但最好还是在使用完threadLocal变量后，手动调用它的remove()方法清除数据。</p><p>如果对key的引用为强引用的话，set()，get()方法中对Model的释放就一定不会触发，必然会造成内存泄漏。</p><h3 id="ThreadLocal线程不安全"><a href="#ThreadLocal线程不安全" class="headerlink" title="ThreadLocal线程不安全"></a>ThreadLocal线程不安全</h3><p> 当多个线程的ThreadLocalMap的value保存的是同一个对象实例的引用时，线程通过这个引用对对象实例做修改，也同样会影响了其他线程中引用的这个对象实例。显然要避免ThreadLocal线程不安全就应该让每个线程中的ThreadLocal都应该持有一个新的对象。</p><h2 id="线程间的协作"><a href="#线程间的协作" class="headerlink" title="线程间的协作"></a>线程间的协作</h2><p>是指线程之间相互配合，完成某项工作。如一个线程对对象做了初步处理，另一个线程感知到初步处理完成，然后进行下一步的处理。整个过程开始于一个线程，而继续执行又是另一个线程。相对而言，前者是生产者，后者就是消费者，简单的办法是让消费者线程轮询检查变量是否符合预期，如果条件满足则退出循环，从而完成消费者的工作。但如果要确保及时性就要缩短轮询的间隔，就会不可避免的消耗更多资源。</p><h3 id="等待和通知"><a href="#等待和通知" class="headerlink" title="等待和通知"></a>等待和通知</h3><p> 是指一个线程调用Object的wait()方法后，释放占有的资源进入阻塞态，另一个线程调用Object的notify()或者notifyAll()之后阻塞的线程被唤醒，但notify()和notifyAll()不会立即释放锁，而是等待之后的业务代码执行完之后才会释放锁，阻塞的线程被唤醒之后继续执行后续操作。上述两个线程必须通过一个Object进行操作完成交互，而wait()和notify()用来构建等待方和通知方的通信。</p><ul><li><p>notify()：随机通知一个在对象上等待的线程，使其结束wait()。返回的前提是该线程获取到了对象的锁，没有获得锁的线程重新进入阻塞态。</p></li><li><p>notifyAll()：通知所有等待在该对象上的线程。</p></li><li><p>wait()：调用该方法的线程进入阻塞态，调用wait()方法后,会释放对象的锁。</p></li><li><p>wait(long)：设置一个最大等待时长，如果n毫秒之后没有通知，就会自动唤醒等待锁。</p></li><li><p>wait (long,int)：对于超时时间更细粒度的控制，可以达到纳秒。</p></li></ul><h4 id="等待标准范式"><a href="#等待标准范式" class="headerlink" title="等待标准范式"></a>等待标准范式</h4><pre><code>synchronized(对象){    while(预期不满足){        对象.wait();    }}</code></pre><h4 id="通知标准范式"><a href="#通知标准范式" class="headerlink" title="通知标准范式"></a>通知标准范式</h4><pre><code>synchronized(对象){    //业务逻辑，改变条件    对象.notify()/notifyAll();}</code></pre><p>在调用wait()、notify()系列方法之前，线程必须要获得该对象的对象级别锁，即只能在同步方法或同步块中调用wait()、notify()。进入wait()方法后，当前线程释放锁，在从wait()返回前，线程与其他线程竞争重新获得锁。执行notify()系列方法的线程退出后，释放对象锁，其他线程就回去竞争对象锁。如果其中一个线程获得了该对象锁，它就会继续往下执行，在它退出synchronized代码块，释放锁后，其他的已经被唤醒的线程将会继续竞争获取该锁，一直进行下去，直到所有被唤醒的线程都执行完毕。</p><h4 id="notify和notifyAll应该用谁"><a href="#notify和notifyAll应该用谁" class="headerlink" title="notify和notifyAll应该用谁"></a>notify和notifyAll应该用谁</h4><p>尽可能用notifyAll()，谨慎使用notify()，因为notify()只会唤醒一个线程，我们无法确保被唤醒的这个线程一定就是需要唤醒的线程</p><h4 id="等待超时模式实现-一个连接池"><a href="#等待超时模式实现-一个连接池" class="headerlink" title="等待超时模式实现 一个连接池"></a>等待超时模式实现 一个连接池</h4><p>DBPool.java</p><pre><code>package cn.enjoyedu.ch1.pool;import java.sql.Connection;import java.util.LinkedList;/** *类说明：连接池的实现 */public class DBPool {    /*容器，存放连接*/    private static LinkedList&lt;Connection&gt; pool = new LinkedList&lt;Connection&gt;();    /*限制了池的大小=20*/    public DBPool(int initialSize) {        if (initialSize &gt; 0) {            for (int i = 0; i &lt; initialSize; i++) {                pool.addLast(SqlConnectImpl.fetchConnection());            }        }    }    /*释放连接,通知其他的等待连接的线程*/    public void releaseConnection(Connection connection) {        if (connection != null) {            synchronized (pool){                pool.addLast(connection);                //通知其他等待连接的线程                pool.notifyAll();            }        }    }    /*获取*/    // 在mills内无法获取到连接，将会返回null 1S    public Connection fetchConnection(long mills)            throws InterruptedException {        synchronized (pool){            //永不超时            if(mills&lt;=0){                while(pool.isEmpty()){                    pool.wait();                }                return pool.removeFirst();            }else{                /*超时时刻*/                long future = System.currentTimeMillis()+mills;                /*等待时长*/                long remaining = mills;                while(pool.isEmpty()&amp;&amp;remaining&gt;0){                    pool.wait(remaining);                    /*唤醒一次，重新计算等待时长*/                    remaining = future-System.currentTimeMillis();                }                Connection connection = null;                if(!pool.isEmpty()){                    connection = pool.removeFirst();                }                return connection;            }        }    }}</code></pre><p>DBPoolTest.java</p><pre><code>package cn.enjoyedu.ch1.pool;import java.sql.Connection;import java.util.concurrent.CountDownLatch;import java.util.concurrent.atomic.AtomicInteger;/** *类说明： */public class DBPoolTest {    static DBPool pool  = new DBPool(10);    // 控制器:控制main线程将会等待所有Woker结束后才能继续执行    static CountDownLatch end;    public static void main(String[] args) throws Exception {        // 线程数量        int threadCount = 50;        end = new CountDownLatch(threadCount);        int count = 20;//每个线程的操作次数        AtomicInteger got = new AtomicInteger();//计数器：统计可以拿到连接的线程        AtomicInteger notGot = new AtomicInteger();//计数器：统计没有拿到连接的线程        for (int i = 0; i &lt; threadCount; i++) {            Thread thread = new Thread(new Worker(count, got, notGot),                     &quot;worker_&quot;+i);            thread.start();        }        end.await();// main线程在此处等待        System.out.println(&quot;总共尝试了: &quot; + (threadCount * count));        System.out.println(&quot;拿到连接的次数：  &quot; + got);        System.out.println(&quot;没能连接的次数： &quot; + notGot);    }    static class Worker implements Runnable {        int           count;        AtomicInteger got;        AtomicInteger notGot;        public Worker(int count, AtomicInteger got,                               AtomicInteger notGot) {            this.count = count;            this.got = got;            this.notGot = notGot;        }        public void run() {            while (count &gt; 0) {                try {                    // 从线程池中获取连接，如果1000ms内无法获取到，将会返回null                    // 分别统计连接获取的数量got和未获取到的数量notGot                    Connection connection = pool.fetchConnection(1000);                    if (connection != null) {                        try {                            connection.createStatement();//                            PreparedStatement preparedStatement//                                    = connection.prepareStatement(&quot;&quot;);//                            preparedStatement.execute();                            connection.commit();                        } finally {                            pool.releaseConnection(connection);                            got.incrementAndGet();                        }                    } else {                        notGot.incrementAndGet();                        System.out.println(Thread.currentThread().getName()                                +&quot;等待超时!&quot;);                    }                } catch (Exception ex) {                } finally {                    count--;                }            }            end.countDown();        }    }}</code></pre><h4 id="调用yield-，sleep-，wait-，notify-notifyAll-方法对锁的影响"><a href="#调用yield-，sleep-，wait-，notify-notifyAll-方法对锁的影响" class="headerlink" title="调用yield()，sleep()，wait()，notify()/notifyAll()方法对锁的影响"></a>调用yield()，sleep()，wait()，notify()/notifyAll()方法对锁的影响</h4><p>yield()调用之后只是让出cpu使用权进入就绪态，sleep()不会释放任何资源包括cpu使用权，所以yield()跟sleep()都不会释放锁，wait()方法被调用之后会释放当前线程所持有的所有资源进入阻塞态，等待唤醒，当线程被唤醒之后会去竞争锁，竞争到锁之后才会去继续执行。notify()也不会释放锁，而是等notify()/notifyAll()所在的同步代码块执行完之后才会释放锁，所以notify()/notifyAll()通常在同步代码块的最后一行。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>springboot2+shiro+token认证</title>
    <link href="/2019/12/13/springboot2-shiro-token%E8%AE%A4%E8%AF%81/"/>
    <url>/2019/12/13/springboot2-shiro-token%E8%AE%A4%E8%AF%81/</url>
    
    <content type="html"><![CDATA[<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>从shiro过滤器的源码中可以看到，shiro过滤器拦截请求之后会调用isAccessAllowed()和onAccessDenied()方法，只要其中一个方法返回true，这次请求就会被放行。本文的实现方法是在onAccessDenied()中的执行登录验证即执行executeLogin()方法，这个方法会去执行AuthorizingRealm中的doGetAuthenticationInfo()方法，所以我们只需要在doGetAuthenticationInfo()里实现token的合法性检查，而doGetAuthenticationInfo()中需要AuthenticationToken类，这个类一般是存用户的用户名和密码，所以要重写这个类，把等待验证的token放入这个类，在executeLogin()方法会调用shiro过滤器中的createToken()方法创建AuthenticationToken实例，所以我们只需要重写createToken()方法创建带有token的重写之后的AuthenticationToken类即可。如果验证失败，因为我们是在executeLogin()方法中执行的登录，所以登录失败后会进入shiro过滤器中的onLoginFailure()方法，我们再重写这个方法，将验证失败的结果写入response就可以实现返回json而不是shiro默认的重定向到登录页。</p><p>多点登录限制是借助于redis实现，在用户登录时会将用户id作为键，当前token作为值存入redis中，在验证时获取token中的用户id，然后根据用户id去取redis中的token后对比，如果不同则当前token已经失效，提醒用户重新登录。</p><h2 id="pom文件"><a href="#pom文件" class="headerlink" title="pom文件"></a>pom文件</h2><pre><code>        &lt;!--shiro--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt;            &lt;artifactId&gt;shiro-core&lt;/artifactId&gt;            &lt;version&gt;1.4.0&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt;            &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt;            &lt;version&gt;1.4.0&lt;/version&gt;        &lt;/dependency&gt;        &lt;!--jwt--&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.auth0&lt;/groupId&gt;            &lt;artifactId&gt;java-jwt&lt;/artifactId&gt;            &lt;version&gt;3.3.0&lt;/version&gt;        &lt;/dependency&gt;        &lt;!--redis--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre><h2 id="重写shiro过滤器"><a href="#重写shiro过滤器" class="headerlink" title="重写shiro过滤器"></a>重写shiro过滤器</h2><pre><code>import com.alibaba.fastjson.JSON;import com.minte.english.security.common.utils.JwtUtil;import com.minte.english.security.common.utils.R;import org.apache.commons.lang3.StringUtils;import org.apache.shiro.authc.AuthenticationException;import org.apache.shiro.authc.AuthenticationToken;import org.apache.shiro.web.filter.authc.AuthenticatingFilter;import org.springframework.web.bind.annotation.RequestMethod;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;public class OAuth2Filter extends AuthenticatingFilter {    @Override    protected AuthenticationToken createToken(ServletRequest request, ServletResponse response) throws Exception {        //获取请求token        String token = JwtUtil.getRequestToken((HttpServletRequest) request);        if(StringUtils.isBlank(token)){            return null;        }        return new OAuth2Token(token);    }    @Override    protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) {        if(((HttpServletRequest) request).getMethod().equals(RequestMethod.OPTIONS.name())){            return true;        }        return false;    }    @Override    protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception {        //获取请求token，如果token不存在，直接返回401        String token = JwtUtil.getRequestToken((HttpServletRequest) request);        if(StringUtils.isBlank(token)){            HttpServletResponse httpResponse = (HttpServletResponse) response;            httpResponse.setHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;);            String json = JSON.toJSONString(R.failed(&quot;false&quot;, &quot;获取token信息失败&quot;));            httpResponse.getWriter().print(json);            return false;        }        return executeLogin(request, response);    }    @Override    protected boolean onLoginFailure(AuthenticationToken token, AuthenticationException e, ServletRequest request, ServletResponse response) {        HttpServletResponse httpResponse = (HttpServletResponse) response;        httpResponse.setContentType(&quot;application/json;charset=utf-8&quot;);        try {            //处理登录失败的异常            Throwable throwable = e.getCause() == null ? e : e.getCause();            R r = R.reLogin(throwable.getMessage());            String json = JSON.toJSONString(r);            httpResponse.getWriter().print(json);        } catch (IOException e1) {        }        return false;    }}</code></pre><h2 id="重写AuthorizingRealm"><a href="#重写AuthorizingRealm" class="headerlink" title="重写AuthorizingRealm"></a>重写AuthorizingRealm</h2><pre><code>import com.auth0.jwt.exceptions.TokenExpiredException;import com.minte.english.security.common.utils.JwtUtil;import com.minte.english.security.module.sys.redis.UserRedis;import com.minte.english.security.module.user.pojo.Role;import com.minte.english.security.module.user.pojo.User;import com.minte.english.security.module.user.service.IRoleService;import com.minte.english.security.module.user.service.IUserRoleService;import org.apache.shiro.authc.*;import org.apache.shiro.authc.pam.UnsupportedTokenException;import org.apache.shiro.authz.AuthorizationInfo;import org.apache.shiro.authz.SimpleAuthorizationInfo;import org.apache.shiro.authz.UnauthenticatedException;import org.apache.shiro.realm.AuthorizingRealm;import org.apache.shiro.subject.PrincipalCollection;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import java.io.UnsupportedEncodingException;import java.util.Arrays;import java.util.HashSet;import java.util.Set;@Componentpublic class OAuth2Realm extends AuthorizingRealm {    @Autowired    private IUserRoleService userRoleService;    @Autowired    private IRoleService roleService;    @Autowired    private UserRedis userRedis;    @Override    public boolean supports(AuthenticationToken token) {        return token instanceof OAuth2Token;    }    /**     * 授权(验证权限时调用)     */    @Override    protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) {        User user = (User) principals.getPrimaryPrincipal();        Long userId = user.getId();        Integer roleId = userRoleService.getRoleIdByUserId(userId);        Role role = roleService.getById(roleId);        //用户权限列表        Set&lt;String&gt; permsSet = new HashSet&lt;&gt;(Arrays.asList(role.getPermissions().split(&quot;,&quot;)));        SimpleAuthorizationInfo info = new SimpleAuthorizationInfo();        info.setStringPermissions(permsSet);        return info;    }    /**     * 认证(登录时调用)     */    @Override    protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException {        String accessToken = (String) token.getPrincipal();        // 验证token信息        try {            JwtUtil.verify(accessToken);        } catch (TokenExpiredException e) {            throw new ExpiredCredentialsException();        } catch (UnsupportedEncodingException e) {            throw new UnsupportedTokenException(&quot;token已失效&quot;);        }        // 检测是否在其他设备登录        Long userId = JwtUtil.getUserId(accessToken);        String onlineToken = userRedis.getOnlineUserToken(userId);        if (!onlineToken.equals(accessToken)) {            throw new ConcurrentAccessException(&quot;该账号已在其他设备登录&quot;);        }        // 检查用户授权天数，是否被冻结        User user = userRedis.get(accessToken);        if (user.getValidityDays() &lt;= 0) {            throw new UnauthenticatedException(&quot;授权天数不足&quot;);        }        //账号锁定        if (!user.getEnabled()) {            throw new DisabledAccountException(&quot;该账号已被禁用&quot;);        }        SimpleAuthenticationInfo info = new SimpleAuthenticationInfo(user, accessToken, getName());        return info;    }}</code></pre><h2 id="Config类"><a href="#Config类" class="headerlink" title="Config类"></a>Config类</h2><pre><code>@Configurationpublic class ShiroConfig {    @Bean(&quot;securityManager&quot;)    public SecurityManager securityManager(OAuth2Realm oAuth2Realm) {        DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager();        securityManager.setRealm(oAuth2Realm);        securityManager.setRememberMeManager(null);        return securityManager;    }    /**     * setUsePrefix(false)用于解决一个奇怪的bug。在引入spring aop的情况下。     * 在@Controller注解的类的方法中加入@RequiresRole注解，会导致该方法无法映射请求，导致返回404。 加入这项配置能解决这个bug     * 在使用@Transaction注解时出现无法注入bug解决     *     * @return     */    @Bean    public static DefaultAdvisorAutoProxyCreator getDefaultAdvisorAutoProxyCreator() {        DefaultAdvisorAutoProxyCreator creator = new DefaultAdvisorAutoProxyCreator();        creator.setProxyTargetClass(true);        creator.setUsePrefix(false);        return creator;    }    @Bean(&quot;shiroFilter&quot;)    public ShiroFilterFactoryBean shirFilter(SecurityManager manager) {        ShiroFilterFactoryBean shiroFilterFactory = new ShiroFilterFactoryBean();        shiroFilterFactory.setSecurityManager(manager);        Map&lt;String, Filter&gt; filterMap = shiroFilterFactory.getFilters();        filterMap.put(&quot;oauth2&quot;, new OAuth2Filter());        shiroFilterFactory.setFilters(filterMap);        Map&lt;String, String&gt; filterChainDefinitionMap = new LinkedHashMap&lt;&gt;();        filterChainDefinitionMap.put(&quot;/login&quot;, &quot;anon&quot;);        filterChainDefinitionMap.put(&quot;/actuator&quot;, &quot;anon&quot;);        filterChainDefinitionMap.put(&quot;/actuator/**&quot;, &quot;anon&quot;);        filterChainDefinitionMap.put(&quot;/validate/**&quot;, &quot;anon&quot;);        filterChainDefinitionMap.put(&quot;/user/getByUsername&quot;, &quot;anon&quot;);        filterChainDefinitionMap.put(&quot;/**&quot;, &quot;oauth2&quot;);        shiroFilterFactory.setFilterChainDefinitionMap(filterChainDefinitionMap);        return shiroFilterFactory;    }    @Bean(&quot;lifecycleBeanPostProcessor&quot;)    public LifecycleBeanPostProcessor lifecycleBeanPostProcessor() {        return new LifecycleBeanPostProcessor();    }    @Bean    public AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor(SecurityManager securityManager) {        AuthorizationAttributeSourceAdvisor advisor = new AuthorizationAttributeSourceAdvisor();        advisor.setSecurityManager(securityManager);        return advisor;    }}</code></pre><h2 id="重写AuthenticationToken类"><a href="#重写AuthenticationToken类" class="headerlink" title="重写AuthenticationToken类"></a>重写AuthenticationToken类</h2><pre><code>import org.apache.shiro.authc.AuthenticationToken;/** * token * * @author Mark sunlightcs@gmail.com */public class OAuth2Token implements AuthenticationToken {    private String token;    public OAuth2Token(String token){        this.token = token;    }    @Override    public String getPrincipal() {        return token;    }    @Override    public Object getCredentials() {        return token;    }}</code></pre><h2 id="userRedis的配置"><a href="#userRedis的配置" class="headerlink" title="userRedis的配置"></a>userRedis的配置</h2><pre><code>import com.minte.english.security.common.utils.JwtUtil;import com.minte.english.security.common.utils.RedisKeys;import com.minte.english.security.common.utils.RedisUtil;import com.minte.english.security.module.sys.service.ISysConfigService;import com.minte.english.security.module.user.pojo.User;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;/** * @author zgc * @since 2019/12/5 */@Componentpublic class UserRedis {    @Autowired    private RedisUtil redisUtil;    @Autowired    private ISysConfigService sysConfigService;    public void saveOrUpdate(User user, String token) {        String imgPath = sysConfigService.getValue(&quot;ICON_PATH&quot;) + user.getImagePath();        user.setImagePath(imgPath);        redisUtil.set(RedisKeys.getUserKey(token), user, JwtUtil.getExpiresTime(token));    }    public void delete(String token) {        redisUtil.delete(RedisKeys.getUserKey(token));    }    public User get(String token) {        return redisUtil.get(RedisKeys.getUserKey(token), User.class);    }    public void saveOrUpdateOnlineUser(Long userId, String token) {        redisUtil.set(RedisKeys.getOnlineUserKey(userId), token, JwtUtil.getExpiresTime(token));    }    public String getOnlineUserToken(Long userId) {        return redisUtil.get(RedisKeys.getOnlineUserKey(userId), String.class);    }    public void deleteOnlineUser(Long userId, String token) {        if (getOnlineUserToken(userId).equals(token)) {            redisUtil.delete(RedisKeys.getOnlineUserKey(userId));        }    }    public boolean isOnline(Long userId) {        return userId == null ? false : redisUtil.containsKey(RedisKeys.getOnlineUserKey(userId));    }    public void update(User user) {        Long userId = user.getId();        if (isOnline(userId)) {            String token = getOnlineUserToken(userId);            saveOrUpdate(user, token);        }    }}</code></pre><h2 id="Shiro的异常"><a href="#Shiro的异常" class="headerlink" title="Shiro的异常"></a>Shiro的异常</h2><ul><li>AuthenticationException:身份验证异常<ul><li>CredentitalsException:凭证异常<ul><li>IncorrectCredentialsException:不支持的凭证</li><li>ExpiredCredentialsException:凭证过期</li></ul></li><li>AccountException:账号异常<ul><li>ConcurrentAccessException:并发访问异常</li><li>UnknownAccountException:未知的账号</li><li>ExcessiveAttemptsException:认证次数超限</li><li>DisabledAccountException:账号被禁用</li><li>LockedAccountException:账号被锁定</li></ul></li><li>UnsupportedTokenException:Token异常</li></ul></li><li>AuthorizationException:授权异常<ul><li>UnauthorizedException:抛出以指示请求的操作或对请求的资源的访问是不允许的</li><li>UnanthenticatedException:当尚未完成成功认证时，尝试执行授权操作时引发异常</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>shiro</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>shiro</tag>
      
      <tag>token</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ajax跨域访问shiro问题</title>
    <link href="/2019/12/06/ajax%E8%B7%A8%E5%9F%9F%E8%AE%BF%E9%97%AEshiro%E9%97%AE%E9%A2%98/"/>
    <url>/2019/12/06/ajax%E8%B7%A8%E5%9F%9F%E8%AE%BF%E9%97%AEshiro%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1 id="ajax跨域访问shiro问题"><a href="#ajax跨域访问shiro问题" class="headerlink" title="ajax跨域访问shiro问题"></a>ajax跨域访问shiro问题</h1><p>因为之前的ssm项目要做一次迭代，将前后端不分离改为前后端分离，但是做了跨域设置之后登录可以成功，但其他接口仍然访问不到，前端控制台报错为跨域错误：预请求被重定向。既然登录访问可以成功，说明跨域已经成功，但依然访问不到登录其他接口应该是shiro的问题。查看代码后发现，之前的shiro并没有对预请求进行处理，而且也没有做cookie的跨域，因为shiro所需要的sessionId依赖于cookie或url中的sessionId，但前端没有对sessionId进行处理，cookie也不允许跨域，shiro依然会对登录成功之后的请求进行拦截。所以这次要解决两个问题</p><ol><li>shiro过滤器中放行预请求</li><li>做关于cookie跨域的设置</li></ol><h2 id="ajax参考"><a href="#ajax参考" class="headerlink" title="ajax参考"></a>ajax参考</h2><pre><code>$.ajax({    url:url,    data:{        unitId:&quot;801&quot;    },    // 允许携带cookie跨域    crossDomain: true,     xhrFields:{              withCredentials:true          },    type:&quot;GET&quot;,    success:function(data){        console.log(data);    }})</code></pre><h2 id="后端跨域处理"><a href="#后端跨域处理" class="headerlink" title="后端跨域处理"></a>后端跨域处理</h2><p>因为项目为ssm项目，所以跨域的处理使用filter实现</p><ol><li>添加跨域cookie后，Allow-Origin不能设置为*</li><li>Allow-Method根据情况而定</li></ol><pre><code>@WebFilter(&quot;/*&quot;)public class CORSFilter implements Filter {    public CORSFilter() {    }    public void destroy() {    }    public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException {        //设置跨域请求        response.setHeader(&quot;Access-Control-Allow-Headers&quot;, &quot;x-requested-with&quot;);        response.setHeader(&quot;Access-Control-Allow-Method&quot;, &quot;POST, GET, OPTIONS&quot;);        response.setHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;http://localhost:8090&quot;);        response.setHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;);        filterChain.doFilter(request, response);        chain.doFilter(req, response);    }    public void init(FilterConfig fConfig) throws ServletException {    }}</code></pre><h2 id="重写shiro过滤器"><a href="#重写shiro过滤器" class="headerlink" title="重写shiro过滤器"></a>重写shiro过滤器</h2><p>配置中没有定义自己的shiro过滤器，所以都是默认过滤器</p><table><thead><tr><th>Filter Name</th><th>Class</th></tr></thead><tbody><tr><td>anon</td><td>org.apache.shiro.web.filter.authc.AnonymousFilter</td></tr><tr><td>authc</td><td>org.apache.shiro.web.filter.authc.FormAuthenticationFilter</td></tr><tr><td>authcBasic</td><td>org.apache.shiro.web.filter.authc.BasicHttpAuthenticationFilter</td></tr><tr><td>perms</td><td>org.apache.shiro.web.filter.authz.PermissionsAuthorizationFilter</td></tr><tr><td>port</td><td>org.apache.shiro.web.filter.authz.PortFilter</td></tr><tr><td>rest</td><td>org.apache.shiro.web.filter.authz.HttpMethodPermissionFilter</td></tr><tr><td>roles</td><td>org.apache.shiro.web.filter.authz.RolesAuthorizationFilter</td></tr><tr><td>ssl</td><td>org.apache.shiro.web.filter.authz.SslFilter</td></tr><tr><td>user</td><td>org.apache.shiro.web.filter.authc.UserFilter</td></tr></tbody></table><p>根据以上表格，我们需要重写FormAuthenticationFilter及RolesAuthorizationFilter</p><p>FormAuthenticationFilter</p><pre><code>package com.yaoxx.base.shiro;import java.io.PrintWriter;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.apache.commons.lang3.StringUtils;import org.apache.shiro.web.filter.authc.FormAuthenticationFilter;import org.apache.shiro.web.util.WebUtils;import org.springframework.http.HttpStatus;public class MyAuthenticationFilter extends FormAuthenticationFilter {   @Override   protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) {       boolean allowed = super.isAccessAllowed(request, response, mappedValue);       if (!allowed) {           // 判断请求是否是options请求           String method = WebUtils.toHttp(request).getMethod();           if (StringUtils.equalsIgnoreCase(&quot;OPTIONS&quot;, method)) {               return true;           }       }       return allowed;   }   @Override   protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception {   // 判断是否登录       if (isLoginRequest(request, response)) {          // 判断是否为post访问           if (isLoginSubmission(request, response)) {                return executeLogin(request, response);           } else {               // sessionID已经注册,但是并没有使用post方式提交               return true;           }       } else {           HttpServletRequest req = (HttpServletRequest) request;           HttpServletResponse resp = (HttpServletResponse) response;           String ajaxHeader = req.getHeader(CustomSessionManager.AUTHORIZATION);           if (StringUtils.isNotBlank(ajaxHeader)) {               // 前端Ajax请求，则不会重定向               resp.setHeader(&quot;Access-Control-Allow-Origin&quot;, req.getHeader(&quot;Origin&quot;));               resp.setHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;);               resp.setContentType(&quot;application/json; charset=utf-8&quot;);               resp.setCharacterEncoding(&quot;UTF-8&quot;);               //设置未登录状态码               resp.setStatus(HttpStatus.UNAUTHORIZED.value());               PrintWriter out = resp.getWriter();               String result = &quot;{\&quot;MESSAGE\&quot;:\&quot;未登录用户\&quot;}&quot;;               out.println(result);               out.flush();               out.close();           } else {               // == 如果是普通访问重定向至shiro配置的登录页面 == //               saveRequestAndRedirectToLogin(request, response);           }       }       return false;   }}</code></pre><p>RolesAuthorizationFilter</p><pre><code>package com.yaoxx.base.shiro;import java.io.IOException;import java.io.PrintWriter;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.apache.commons.lang3.StringUtils;import org.apache.shiro.web.filter.authz.RolesAuthorizationFilter;import org.apache.shiro.web.util.WebUtils;import org.springframework.http.HttpStatus;import org.springframework.web.bind.annotation.RequestMethod;public class MyAuthorizationFilter extends RolesAuthorizationFilter {   @Override   public boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue)throws IOException {       boolean allowed =super.isAccessAllowed(request, response, mappedValue);       if (!allowed) {           String method = WebUtils.toHttp(request).getMethod();           if (StringUtils.equalsIgnoreCase(&quot;OPTIONS&quot;, method)) {               return true;           }       }       return allowed;   }   @Override   protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws IOException {       HttpServletRequest req = (HttpServletRequest) request;       HttpServletResponse resp = (HttpServletResponse) response;       // 前端Ajax请求时requestHeader里面带一些参数，用于判断是否是前端的请求       String ajaxHeader = req.getHeader(CustomSessionManager.AUTHORIZATION);       if (StringUtils.isNotBlank(ajaxHeader)) {           // 前端Ajax请求，则不会重定向           resp.setHeader(&quot;Access-Control-Allow-Origin&quot;, req.getHeader(&quot;Origin&quot;));           resp.setHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;);           resp.setContentType(&quot;application/json; charset=utf-8&quot;);           resp.setCharacterEncoding(&quot;UTF-8&quot;);           PrintWriter out = resp.getWriter();           String result = &quot;{\&quot;MESSAGE\&quot;:\&quot;角色，权限不足\&quot;}&quot;;           out.println(result);           out.flush();           out.close();           return false;       }       return super.onAccessDenied(request, response);   }}</code></pre>]]></content>
    
    
    <categories>
      
      <category>shiro</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>shiro</tag>
      
      <tag>bug</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>summernote文本编辑器的使用</title>
    <link href="/2019/08/26/summernote%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2019/08/26/summernote%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>summernote是一款Jquery文本编辑器的插件，本文只是简单的实现文本编辑及图片上传下载功能，更多api请参考<a href="https://summernote.org/getting-started/" target="_blank" rel="noopener">summernote官方文档</a></p><h2 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h2><p>summernote依赖于bootstrap和jquery所以也需要引入bootstrap和jquery</p><pre><code>&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;/assets/css/lib/bootstrap.min.css&quot; &gt;&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;/css/summernote.css&quot;&gt;&lt;script src=&quot;/assets/js/lib/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;/assets/js/lib/bootstrap.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;/js/summernote.js&quot;&gt;&lt;/script&gt;</code></pre><h2 id="html"><a href="#html" class="headerlink" title="html"></a>html</h2><pre><code>&lt;div id=&quot;summernote&quot;&gt;&lt;/div&gt;</code></pre><h2 id="js"><a href="#js" class="headerlink" title="js"></a>js</h2><pre><code>// summernote的初始化方法$(&quot;#summernote&quot;).summernote({    placeholder: &quot;输入内容&quot;,    tabsize: 2,    height: 300,    lang: &#39;zh-CN&#39;,    focus: true,    callbacks: {        onImageUpload: function (files) {                // 上传图片            uploadFile(files[0]);        },        onMediaDelete: function (target){                // 删除图片            deleteFile(target);        }    }});// 上传文件function uploadFile(file){    var imgPath = sendFile(file);    $(&#39;#summernote&#39;).summernote(&#39;insertImage&#39;, imgPath);}// 用于summernote内容回显function getContent(){    var content = $(&#39;#summernote&#39;).summernote(&#39;code&#39;);    if (content==&quot;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&quot;){        return &#39;&#39;;    }    return content;}// 获取summernote的内容function addContent(content){    $(&#39;#summernote&#39;).summernote(&#39;code&#39;, content);}// 上传图片至服务器function sendFile(file) {    if (file == null||file==undefined) {        return null;    }    var formData = new FormData();    formData.append(&quot;file&quot;, file);    console.log(formData);    var filePath = &quot;&quot;;    $.ajax({        url: &quot;/file/upload&quot;,        type: &quot;POST&quot;,        data: formData,        async: false,        contentType: false,        processData: false,        success: function (result) {            filePath = result.data.filePath;        }    });    return filePath;}// 删除服务器图片function deleteFile(filePath) {    $.ajax({        url: &quot;/file/delete&quot;,        type: &quot;POST&quot;,        data: {            &quot;filePath&quot;: filePath        },        success: function (result) {            console.log(result);        }    })}</code></pre><h2 id="java接口"><a href="#java接口" class="headerlink" title="java接口"></a>java接口</h2><pre><code>    @RequestMapping(&quot;/addImg&quot;)    public Map addImg(@RequestParam(&quot;file&quot;) MultipartFile file, HttpServletRequest request) throws IOException {        String fileName = file.getOriginalFilename();        fileName.split(&quot;.&quot;);        System.out.println(&quot;接收到文件:&quot; + fileName);        String fileType = fileName.substring(fileName.lastIndexOf(&quot;.&quot;));        String filePath = new File(&quot;&quot;).getCanonicalFile().getPath() + &quot;/static/images/&quot;;        filePath = filePath + UUID.randomUUID().toString() + fileType;        File dest = new File(filePath);        if (dest.getParentFile() != null) {            dest.getParentFile().mkdirs();        }        try {            file.transferTo(dest);        } catch (IOException e) {            log.warning(&quot;文件上传失败:&quot; + e);            return ResultMap.failed(&quot;文件上传失败&quot;);        }        String path = request.getScheme() + &quot;://&quot; + request.getServerName() + &quot;:&quot;                + request.getServerPort() + request.getContextPath() + &quot;/images/&quot; + dest.getName();        return ResultMap.success(path);    }    @RequestMapping(&quot;deleteImg&quot;)    public Map deleteImg(String imgSrc) {        String fileName = imgSrc.substring(imgSrc.lastIndexOf(&quot;/&quot;) + 1);        System.out.println(fileName);        String filePath = Thread.currentThread().getContextClassLoader().getResource(&quot;&quot;).getPath() + &quot;static/images/&quot;;        filePath = filePath + fileName;        File dest = new File(filePath);        return dest.delete() ? ResultMap.success() : ResultMap.failed();    }</code></pre>]]></content>
    
    
    <categories>
      
      <category>html插件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>html</tag>
      
      <tag>富文本编辑器</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>vim的使用</title>
    <link href="/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="vim介绍"><a href="#vim介绍" class="headerlink" title="vim介绍"></a>vim介绍</h2><p>Vim是从 vi 发展出来的一个文本编辑器。代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。 </p><p>简单的来说， vi 是老式的字处理器，不过功能已经很齐全了，但是还是有可以进步的地方。 vim 则可以说是程序开发者的一项很好用的工具。 </p><p>连 vim 的官方网站 (<a href="http://www.vim.org/" target="_blank" rel="noopener">http://www.vim.org</a>) 自己也说 vim 是一个程序开发工具而不是文字处理软件。（这段是复制来的，不说点啥的话不好看）</p><h2 id="1-vim模式"><a href="#1-vim模式" class="headerlink" title="1. vim模式"></a>1. vim模式</h2><pre><code class="text">正常模式（按Esc或Ctrl+[进入） 左下角显示文件名或为空插入模式（按i进入） 左下角显示--INSERT--可视模式（按v进入） 左下角显示--VISUAL--替换模式（按r或R开始） 左下角显示 --REPLACE--命令行模式（按:或者/或者?开始）ex模式 没用过，有兴趣的同学可以自行了解</code></pre><h2 id="2-打开文件"><a href="#2-打开文件" class="headerlink" title="2. 打开文件"></a>2. 打开文件</h2><pre><code class="text"># 打开单个文件vim file    # 同时打开多个文件vim file1 file2..  # 在vim窗口中打开一个新文件:open [file]       【举个例子】# 当前打开1.txt，做了一些编辑没保存:open!         放弃这些修改，并重新打开未修改的文件# 当前打开1.txt，做了一些编辑并保存:open 2.txt    直接退出对1.txt的编辑，直接打开2.txt编辑，省了退出:wq再重新vim 2.txt的步骤# 打开远程文件，比如ftp或者share folder:e ftp://192.168.10.76/abc.txt:e \qadrive\test\1.txt# 以只读形式打开文件，但是仍然可以使用 :wq! 写入vim -R file # 强制性关闭修改功能，无法使用 :wq! 写入vim -M file</code></pre><h2 id="3-插入命令"><a href="#3-插入命令" class="headerlink" title="3. 插入命令"></a>3. 插入命令</h2><pre><code class="text">i 在当前位置生前插入I 在当前行首插入a 在当前位置后插入A 在当前行尾插入o 在当前行之后插入一行O 在当前行之前插入一行</code></pre><h2 id="4-查找命令"><a href="#4-查找命令" class="headerlink" title="4. 查找命令"></a>4. 查找命令</h2><p>最简单的查找</p><pre><code class="text">/text　　查找text，按n健查找下一个，按N健查找前一个。?text　　查找text，反向查找，按n健查找下一个，按N健查找前一个。vim中有一些特殊字符在查找时需要转义　　.*[]^%/?~$:set ignorecase　　忽略大小写的查找:set noignorecase　　不忽略大小写的查找</code></pre><p>快速查找，不需要手打字符即可查找</p><pre><code class="text">*        向后（下）寻找游标所在处的单词#        向前（上）寻找游标所在处的单词以上两种查找，n,N 的继续查找命令依然可以适用</code></pre><p>精准查找：匹配单词查找</p><p>如果文本中有 <code>hello</code>，<code>helloworld</code>，<code>hellopython</code></p><p>那我使用 /hello ，这三个词都会匹配到。</p><p>有没有办法实现精准查找呢？可以使用</p><pre><code class="text">/hello\&gt;</code></pre><p>精准查找：匹配行首、行末</p><pre><code class="text"># hello位于行首/^hello# world位于行末/world$</code></pre><h2 id="5-替换命令"><a href="#5-替换命令" class="headerlink" title="5. 替换命令"></a>5. 替换命令</h2><pre><code class="text">~  反转游标字母大小写r&lt;字母&gt;           将当前字符替换为所写字母R&lt;字母&gt;&lt;字母&gt;...  连续替换字母cc    替换整行（就是删除当前行，并在下一行插入）cw    替换一个单词（就是删除一个单词，就进入插入模式），前提是游标处于单词第一个字母（可用b定位）C     (大写C)替换至行尾（和D有所区别，D是删除（剪切）至行尾，C是删除至行位并进入插入模式）:s/old/new/    用old替换new，替换当前行的第一个匹配:s/old/new/g   用old替换new，替换当前行的所有匹配:%s/old/new/   用old替换new，替换所有行的第一个匹配:%s/old/new/g  用old替换new，替换整个文件的所有匹配:10,20 s/^/ /g 在第10行至第20行每行前面加四个空格，用于缩进。ddp    交换光标所在行和其下紧邻的一行。</code></pre><h2 id="6-撤销与重做"><a href="#6-撤销与重做" class="headerlink" title="6. 撤销与重做"></a>6. 撤销与重做</h2><pre><code class="text">u 撤销（Undo）U 撤销对整行的操作Ctrl + r 重做（Redo），即撤销的撤销。</code></pre><h2 id="7-删除命令"><a href="#7-删除命令" class="headerlink" title="7. 删除命令"></a>7. 删除命令</h2><p>需要说明的是，vim 其实并没有单纯的删除命令，下面你或许理解为剪切更加准确。</p><p>以字符为单位删除</p><pre><code class="text">x   删除当前字符3x  删除当前字符3次X   删除当前字符的前一个字符。3X  删除当前光标向前三个字符dl  删除当前字符， dl=xdh  删除前一个字符，X=dhD   删除当前字符至行尾。D=d$d$  删除当前字符至行尾d^  删除当前字符之前至行首</code></pre><p>以单词为单位删除</p><pre><code class="text">dw  删除当前字符到单词尾daw 删除当前字符所在单词</code></pre><p>以行为单位删除</p><pre><code class="text">dd  删除当前行dj  删除下一行dk  删除上一行dgg  删除当前行至文档首部d1G  删除当前行至文档首部dG   删除当前行至文档尾部kdgg  删除当前行之前所有行（不包括当前行）jdG   删除当前行之后所有行（不包括当前行）10d     删除当前行开始的10行。:1,10d  删除1-10行:11,$d  删除11行及以后所有的行:1,$d   删除所有行J　　   删除两行之间的空行，实际上是合并两行。</code></pre><h2 id="8-复制粘贴"><a href="#8-复制粘贴" class="headerlink" title="8. 复制粘贴"></a>8. 复制粘贴</h2><p>普通模式中使用y复制</p><pre><code class="text">yy   复制游标所在的整行（3yy表示复制3行）y^   复制至行首，或y0。不含光标所在处字符。y$   复制至行尾。含光标所在处字符。yw   复制一个单词。y2w  复制两个单词。yG   复制至文本末。y1G  复制至文本开头。</code></pre><p>普通模式中使用p粘贴</p><pre><code class="text">p(小写)：代表粘贴至光标后（下边，右边）P(大写)：代表粘贴至光标前（上边，左边）</code></pre><h2 id="9-剪切粘贴"><a href="#9-剪切粘贴" class="headerlink" title="9. 剪切粘贴"></a>9. 剪切粘贴</h2><pre><code class="text">dd    其实就是剪切命令，剪切当前行ddp   剪切当前行并粘贴，可实现当前行和下一行调换位置正常模式下按v（逐字）或V（逐行）进入可视模式然后用jklh命令移动即可选择某些行或字符，再按d即可剪切ndd 剪切当前行之后的n行。利用p命令可以对剪切的内容进行粘贴:1,10d 将1-10行剪切。利用p命令可将剪切后的内容进行粘贴。:1, 10 m 20 将第1-10行移动到第20行之后。</code></pre><h2 id="10-退出保存"><a href="#10-退出保存" class="headerlink" title="10. 退出保存"></a>10. 退出保存</h2><pre><code class="text">:wq 保存并退出ZZ 保存并退出:q! 强制退出并忽略所有更改:e! 放弃所有修改，并打开原来文件。ZZ 保存并退出:sav(eas) new.txt  另存为一个新文件，退出原文件的编辑且不会保存:f(ile) new.txt    新开一个文件，并不保存，退出原文件的编辑且不会保存</code></pre><h2 id="11-移动命令"><a href="#11-移动命令" class="headerlink" title="11. 移动命令"></a>11. 移动命令</h2><p>以字符为单位移动</p><pre><code class="text">h   左移一个字符l   右移一个字符k   上移一个字符j   下移一个字符# 【定位字符】f和Ffx    找到光标后第一个为x的字符3fd   找到光标后第三个为d的字符F   同f，反向查找。</code></pre><p>以行为单位移动</p><pre><code class="text"># 10指代所有数字，可任意指定10h  左移10个字符10l  右移10个字符10k  上移10行10j  下移10行$   移动到行尾 3$  移动到下面3行的行尾</code></pre><p>以单词为单位移动</p><pre><code class="text">w  向前移动一个单词（光标停在单词首部）b  向后移动一个单词e，同w，只不过是光标停在单词尾部ge 同b，光标停在单词尾部。</code></pre><p>以句为单位移动</p><pre><code class="text">(   移动到句首)   移动到句尾</code></pre><p>跳转到文件的首尾</p><pre><code class="text">gg  移动到文件头。 = [[  == ``G   移动到文件尾。 = ]]</code></pre><p>其他移动方法</p><pre><code class="text">^   移动到本行第一个非空白字符上。0   移动到本行第一个字符上(可以是空格)</code></pre><p>使用 <code>具名标记</code> 跳转，个人感觉这个很好用，因为可以跨文件。</p><pre><code class="text">使用 ma ，可以将此处标记为 a，使用 &#39;a 进行跳转使用 :marks 可以查看所有的标记使用 :delm！可以删除所有的标记</code></pre><p>当在查看错误日志时，正常的步骤是，vim打开文件，然后使用 <code>shift+g</code> 再跳转到最后一行，这里有个更简单的操作可以在打开文件时立即跳到最后一行。只要在 vim 和 文件 中间加个 <code>+</code>即可。</p><pre><code class="text">vim + you.log</code></pre><p>举一反三，当你想打开文件立即跳转到指定行时，可以这样</p><pre><code class="text"># 打开文件并跳转到 20 行vim you.log +20</code></pre><p>当你使用 <code>/</code> 搜索定位跳转或者使用 <code>:行号</code> 进行精准跳转时，有时我们想返回到上一次的位置，如何实现？</p><p>只要使用 Ctrl+o 即可返回上一次的位置。</p><h2 id="12-排版功能"><a href="#12-排版功能" class="headerlink" title="12. 排版功能"></a>12. 排版功能</h2><p><strong>缩进</strong></p><pre><code class="text">:set shiftwidth?   查看缩进值:set shiftwidth=4  设置缩进值为4# 缩进相关 最好写到配置文件中  ~/.vimrc:set tabstop=4:set softtabstop=4:set shiftwidth=4:set expandtab&gt;&gt;   向右缩进&lt;&lt;   取消缩进</code></pre><p>如何你要对代码进行缩进，还可以用 <code>==</code> 对当前行缩进，如果要对多行对待缩进，则使用 n<code>==</code>，这种方式要求你所编辑的文件的扩展名是被vim所识别的，比如<code>.py</code>文件。</p><p><strong>排版</strong></p><pre><code class="text">:ce   居中:le   靠左:ri   靠右</code></pre><h2 id="13-注释命令"><a href="#13-注释命令" class="headerlink" title="13. 注释命令"></a>13. 注释命令</h2><p><strong>多行注释</strong></p><pre><code class="text">进入命令行模式，按ctrl + v进入 visual block模式，然后按j, 或者k选中多行，把需要注释的行标记起来按大写字母I，再插入注释符，例如//按esc键就会全部注释了</code></pre><p><strong>取消多行注释</strong></p><pre><code class="text">进入命令行模式，按ctrl + v进入 visual block模式，按字母l横向选中列的个数，例如 // 需要选中2列按字母j，或者k选中注释符号按d键就可全部取消注释</code></pre><p><strong>复杂注释</strong></p><pre><code class="text">:3,5 s/^/#/g 注释第3-5行:3,5 s/^#//g 解除3-5行的注释:1,$ s/^/#/g 注释整个文档:1,$ s/^#//g 取消注释整个文档:%s/^/#/g 注释整个文档，此法更快:%s/^#//g 取消注释整个文档</code></pre><h2 id="14-调整视野"><a href="#14-调整视野" class="headerlink" title="14. 调整视野"></a>14. 调整视野</h2><pre><code class="text">&quot;zz&quot;：命令会把当前行置为屏幕正中央，&quot;zt&quot;：命令会把当前行置于屏幕顶端&quot;zb&quot;：则把当前行置于屏幕底端.Ctrl + e 向下滚动一行Ctrl + y 向上滚动一行Ctrl + d 向下滚动半屏Ctrl + u 向上滚动半屏Ctrl + f 向下滚动一屏Ctrl + b 向上滚动一屏【跳到指定行】：两种方法可以先把行号打开:set nu  打开行号:20    跳到第20行20G    跳到第20行</code></pre><h2 id="15-区域选择"><a href="#15-区域选择" class="headerlink" title="15. 区域选择"></a>15. 区域选择</h2><pre><code class="text">要进行区域选择，要先进入可视模式v   以字符为单位，上下左右选择V   以行为单位，上下选择选择后可进行操作d   剪切/删除y   复制Ctrl+v   如果当前是V(大写)模式，就变成v(小写)         如果当前是v(小写)模式，就变成普通模式。         如果当前是普通模式，就进入v(小写)模式利用这个，可以进行多行缩进。ggVG   选择全文</code></pre><h2 id="16-窗口控制"><a href="#16-窗口控制" class="headerlink" title="16. 窗口控制"></a>16. 窗口控制</h2><p><strong>新建窗口</strong></p><pre><code class="text"># 打开两个文件分属两个窗口vim -o 1.txt 2.txt# 假设现在已经打开了1.txt:sp 2.txt   开启一个横向的窗口，编辑2.txt:vsp 2.txt  开启一个竖向的窗口，编辑2.txt:split        将当前窗口再复制一个窗口出来，内容同步，游标可以不同:split 2.txt  在新窗口打开2.txt的横向窗口# 需要注意：内容同步，但是游标位置是独立的Ctrl-w s    将当前窗口分成水平窗口Ctrl-w v    将当前窗口分成竖直窗口Ctrl-w q    等同:q 结束分割出来的视窗。Ctrl-w q!   等同:q! 结束分割出来的视窗。Ctrl-w o    打开一个视窗并且隐藏之前的所有视窗</code></pre><p><strong>窗口切换</strong></p><pre><code class="text"># 特别说明：Ctrl w &lt;字母&gt; 不需要同时按Ctrl-w h    切换到左边窗口Ctrl-w l    切换到右边窗口Ctrl-w j    切换到下边窗口Ctrl-w k    切换到上边窗口# 特别说明：全屏模式下:n    切换下一个窗口:N    切换上一个窗口:bp   切换上一个窗口# 特别说明：非全屏模式:bn    切换下一个窗口，就当前位置的窗口的内容变了，其他窗口不变:bN    切换上一个窗口，就当前位置的窗口的内容变了，其他窗口不变</code></pre><p><strong>窗口移动</strong></p><pre><code class="text"># 特别说明：Ctrl w &lt;字母&gt; 不需要同时按Ctrl-w J   将当前视窗移至最下面Ctrl-w K   将当前视窗移最上面Ctrl-w H   将当前视窗移至最左边Ctrl-w L   将当前视窗移至最右边Ctrl-ww    按顺序切换窗口</code></pre><p><strong>调整尺寸</strong></p><pre><code class="text"># 友情提示：键盘切记不要处于中文状态Ctrl-w +   增加窗口高度Ctrl-w -   减少窗口高度</code></pre><p><strong>退出窗口</strong></p><pre><code class="text">:close    关闭当前窗口:close!   强制关闭当前窗口:q       退出，不保存:q!      强制退出，不保存:x       保存退出:wq      保存退出:wq!     强制保存退出:w &lt;[路径/]文件名&gt;        另存为:savesa &lt;[路径/]文件名&gt;   另存为ZZ 保存并退出。:only    关闭所有窗口，只保留当前窗口(前提：其他窗口内容有改变的话都要先保存):only!   关闭所有窗口，只保留当前窗口:qall 放弃所有操作并退出:wall 保存所有，:wqall 保存所有并退出。</code></pre><h2 id="17-文档加密"><a href="#17-文档加密" class="headerlink" title="17. 文档加密"></a>17. 文档加密</h2><pre><code class="text">vim -x file_name然后输入密码：确认密码：如果不修改内容也要保存。:wq，不然密码设定不会生效。</code></pre><h2 id="18-录制宏"><a href="#18-录制宏" class="headerlink" title="18. 录制宏"></a>18. 录制宏</h2><p>按q键加任意字母开始录制，再按q键结束录制（这意味着vim中的宏不可嵌套），使用的时候@加宏名，比如qa。。。q录制名为a的宏，@a使用这个宏。</p><h2 id="19-执行命令"><a href="#19-执行命令" class="headerlink" title="19. 执行命令"></a>19. 执行命令</h2><pre><code class="text"># 重复前一次命令. # 执行shell命令:!command# 比如列出当前目录下文件:!ls # 执行脚本:!perl -c script.pl 检查perl脚本语法，可以不用退出vim，非常方便。:!perl script.pl 执行perl脚本，可以不用退出vim，非常方便。:suspend或Ctrl - Z 挂起vim，回到shell，按fg可以返回vim。</code></pre><h2 id="20-帮助命令"><a href="#20-帮助命令" class="headerlink" title="20. 帮助命令"></a>20. 帮助命令</h2><pre><code class="text">在Unix/Linux系统上$ vimtutor# 普通模式下键盘输入vim或F1# 命令行模式下:help     显示整个帮助:help xxx 显示xxx的帮助，比如 :help i, :help CTRL-[（即Ctrl+[的帮助）。:help &#39;number&#39; Vim选项的帮助用单引号括起在Windows系统上:help tutor</code></pre><h2 id="21-配置命令"><a href="#21-配置命令" class="headerlink" title="21. 配置命令"></a>21. 配置命令</h2><p>显示当前设定</p><pre><code class="text">:set或者:se显示所有修改过的配置:set all 显示所有的设定值:set option? 显示option的设定值:set nooption 取消当期设定值:ver   显示vim的所有信息（包括版本和参数等）# 需要注意：全屏模式下:args   查看当前打开的文件列表，当前正在编辑的文件会用[]括起来</code></pre><p>更改设定</p><pre><code class="text">:set nu   显示行号set autoindent(ai)   设置自动缩进set autowrite(aw)    设置自动存档，默认未打开set backup(bk) 设置自动备份，默认未打开set background=dark或light，设置背景风格set cindent(cin) 设置C语言风格缩进:set ts=4   设置tab键转换为4个空格:set ff=unix   # 修改文件dos文件为unix:set shiftwidth?   查看缩进值:set shiftwidth=4  设置缩进值为4:set ignorecase　　忽略大小写的查找:set noignorecase　　不忽略大小写的查找:set paste  # insert模式下，粘贴格式不会乱掉:set ruler?　　查看是否设置了ruler，在.vimrc中，使用set命令设制的选项都可以通过这个命令查看:scriptnames　　查看vim脚本文件的位置，比如.vimrc文件，语法文件及plugin等。:set list 显示非打印字符，如tab，空格，行尾等。如果tab无法显示，请确定用set lcs=tab:&gt;-命令设置了.vimrc文件，并确保你的文件中的确有tab，如果开启了expendtab，那么tab将被扩展为空格。:syntax        列出已经定义的语法项:syntax clear  清除已定义的语法规则:syntax case match    大小写敏感，int和Int将视为不同的语法元素:syntax case ignore   大小写无关，int和Int将视为相同的语法元素，并使用同样的配色方案</code></pre><img src="/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/pic1.png" srcset="/img/loading.gif" class=""><img src="/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/pic2.png" srcset="/img/loading.gif" class=""><img src="/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/pic3.png" srcset="/img/loading.gif" class=""><img src="/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/pic4.png" srcset="/img/loading.gif" class="">]]></content>
    
    
    <categories>
      
      <category>快速开发</category>
      
    </categories>
    
    
    <tags>
      
      <tag>开发技巧</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
