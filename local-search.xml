<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>MySQL的索引与执行计划</title>
    <link href="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/"/>
    <url>/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/</url>
    
    <content type="html"><![CDATA[<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。可以得到索引的本质：<strong>索引是数据结构</strong>。</p><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic1.png" srcset="/img/loading.gif" class=""><p>MySQL默认存储引擎InnoDB只显示支持B-Tree（从技术上来说是B+Tree），在创建创建主键索引时会新增一个节点，当通过主键来查询内容的时候，首先去查索引库快速的定位索引的具体位置。</p><h4 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h4><p>二分查找法（binary search） 也称为折半查找法，用来查找一组有序的记录数组中的某一记录。</p><p>其基本思想是：将记录按有序化（递增或递减）排列，在查找过程中采用跳跃式方式查找，即先以有序数列的中点位置作为比较对象，如果要找的元素值小于该中点元素，则将待查序列缩小为左半部分，否则为右半部分。通过一次比较，将查找区间缩小一半。</p><h4 id="二叉树-Binary-Tree"><a href="#二叉树-Binary-Tree" class="headerlink" title="二叉树(Binary Tree)"></a>二叉树(Binary Tree)</h4><p>每个节点至多只有二棵子树； </p><ul><li><p>二叉树的子树有左右之分，次序不能颠倒； </p></li><li><p>一棵深度为k，且有2的k-1次方个节点，称为满二叉树(Full Tree)； </p></li><li><p>一棵深度为k，且跟节点到k-1层的节点树都达到最大，第k层的所有节点都连续集中在最左边，此时为完全二叉树（Complete Tree）</p></li></ul><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic2.png" srcset="/img/loading.gif" class=""><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic3.png" srcset="/img/loading.gif" class=""><h4 id="平衡二叉树（AVL-树）"><a href="#平衡二叉树（AVL-树）" class="headerlink" title="平衡二叉树（AVL-树）"></a>平衡二叉树（AVL-树）</h4><ul><li>左子树和右子树的高度差绝对值不超过1</li><li>左子树和右子树都是平衡二叉树</li></ul><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic4.png" srcset="/img/loading.gif" class=""><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic5.png" srcset="/img/loading.gif" class=""><h5 id="平衡二叉树的遍历"><a href="#平衡二叉树的遍历" class="headerlink" title="平衡二叉树的遍历"></a>平衡二叉树的遍历</h5><ul><li>前序 ：6 ,3, 2, 5,7, 8（ROOT节点在开头, 中-左-右 顺序）</li><li>中序 ：2, 3, 5, 6,7, 8（中序遍历即为升序，左-中-右 顺序）</li><li>后序 ：2, 5, 3, 8,7, 6 （ROOT节点在结尾，左-右-中 顺序）</li></ul><h5 id="平衡二叉树的旋转"><a href="#平衡二叉树的旋转" class="headerlink" title="平衡二叉树的旋转"></a>平衡二叉树的旋转</h5><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic6.png" srcset="/img/loading.gif" class=""><p>需要通过旋转（左旋，右旋）来维护平衡二叉树的平衡，在添加和删除的时候需要有额外的开销。</p><h4 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h4><h5 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h5><ul><li><p>数据只存储在叶子节点上，非叶子节点只保存索引信息；</p><ul><li>非叶子节点（索引节点）存储的只是一个Flag，不保存实际数据记录； </li><li>索引节点指示该节点的左子树比这个Flag小，而右子树大于等于这个Flag；</li></ul></li><li><p>叶子节点本身按照数据的升序排序进行链接（串联起来）；</p><ul><li>叶子节点中的数据在物理存储上是无序的，仅仅是在逻辑上有序（通过指针串在一起）；</li></ul></li></ul><h5 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h5><ul><li>在块设备上，通过B+树可以有效的存储数据； </li><li>所有记录都存储在叶子节点上，非叶子(non-leaf)存储索引(keys)信息； </li><li>B+树含有非常高的扇出（fanout），通常超过100，在查找一个记录时，可以有效的减少IO操作； </li></ul><h5 id="扇出"><a href="#扇出" class="headerlink" title="扇出"></a>扇出</h5><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic7.png" srcset="/img/loading.gif" class=""><p>扇出是每个索引节点(Non-LeafPage)指向每个叶子节点(LeafPage)的指针，扇出数 = 索引节点(Non-LeafPage)可存储的最大关键字个数 + 1。图例中的索引节点（Non-LeafPage）最大可以存放4个关键字，但实际使用了3个；</p><ul><li>该 B+ 树高度为 2</li><li>每叶子页（LeafPage）4条记录</li><li>扇出数为5 ，</li><li>叶子节点(LeafPage)由小到大（有序）串联在一起</li></ul><h5 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h5><p>B+树的插入必须保证插入后叶子节点中的记录依然排序。 </p><img src="/2020/04/03/MySQL%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92/pic8.png" srcset="/img/loading.gif" class=""><h3 id="索引的分类"><a href="#索引的分类" class="headerlink" title="索引的分类"></a>索引的分类</h3><ul><li><p>普通索引：即一个索引只包含单个列，一个表可以有多个单列索引</p></li><li><p>唯一索引：索引列的值必须唯一，但允许有空值</p></li><li><p>复合索引：即一个索引包含多个列</p></li><li><p>聚簇索引（聚集索引）：并不是一种单独的索引类型，而是一种数据存储方式。将数据存储与索引存储在一起，找到索引也就找到了数据。聚簇索引是唯一的，InnoDB通过聚簇索引保存数据，非聚簇索引一定存储有聚簇索引的列值。</p></li><li><p>非聚簇索引：将数据存储与索引分开存储的结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因。</p></li></ul><h3 id="索引的使用"><a href="#索引的使用" class="headerlink" title="索引的使用"></a>索引的使用</h3><p><strong>查看索引</strong></p><pre><code>SHOW INDEX FROM table_name;</code></pre><p><strong>创建索引</strong></p><pre><code>CREATE [UNIQUE ] INDEX indexName ON mytable(columnname(length));ALTER TABLE 表名 ADD [UNIQUE ] INDEX [indexName] ON (columnname(length));</code></pre><p><strong>删除索引</strong></p><pre><code>DROP INDEX [indexName] ON mytable;</code></pre><h2 id="执行计划"><a href="#执行计划" class="headerlink" title="执行计划"></a>执行计划</h2><p>使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的，分析你的查询语句或是表结构的性能瓶颈。</p><p>执行计划的语法比较简单，只要在SQL查询前加上EXPLAIN关键字就行。</p><p>比如：EXPLAIN select * from table1;</p><h3 id="执行计划详解"><a href="#执行计划详解" class="headerlink" title="执行计划详解"></a>执行计划详解</h3><p>通过执行计划的结果可以分析出以下内容：</p><ul><li>表的读取顺序</li><li>数据读取操作的操作类型</li><li>哪些索引可以使用</li><li>哪些索引被实际使用</li><li>表之间的引用</li><li>每张表有多少行被优化器查询</li></ul><p>通过EXPLAIN关键分析的结果由以下列组成，接下来挨个分析每一个列</p>{% asset_img pic9.png %}<h4 id="id"><a href="#id" class="headerlink" title="id"></a>id</h4><p>描述select查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序</p><p>根据ID的数值结果可以分成一下三种情况</p><ul><li>id相同：执行顺序由上至下</li><li>id不同：如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行</li><li>id相同不同：同时存在</li></ul><h4 id="select-type"><a href="#select-type" class="headerlink" title="select_type"></a>select_type</h4><p>查询类型，主要是用于区别普通查询，联合查询，自查询等的复杂查询</p><table><thead><tr><th>类型</th><th>描述</th></tr></thead><tbody><tr><td>SIMPLE</td><td>简单的select查询，查询中不包含子查询或者UNION</td></tr><tr><td>PRIMARY</td><td>查询中包含任何复杂的子部分，则最外层查询被标记为PRIMARY</td></tr><tr><td>SUBQUERY</td><td>在SELECT或者WHERE列表中包含的子查询</td></tr><tr><td>DERIVED</td><td>在FROM列表中包含的子查询被标记为DERIVED（衍生），MySQL会递归执行这些子查询，把结果放在临时表里。</td></tr><tr><td>UNION</td><td>若第二个SELECT出现在UNION之后，则标记为UNION；若UNION包含在FROM子句的子查询中，外层的SELECT被标记为DEIRIVED</td></tr><tr><td>UNION RESULT</td><td>从UNION表获取结果的SELECT</td></tr></tbody></table><h4 id="table"><a href="#table" class="headerlink" title="table"></a>table</h4><p>所关联的表</p><h4 id="type"><a href="#type" class="headerlink" title="type"></a>type</h4><p>type显示的是访问类型，是较为重要的一个指标，结果值从最好到最坏依次是：</p><p>system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL </p><p>常用的：</p><p>system&gt;const&gt;eq_ref&gt;ref&gt;range&gt;index&gt;ALL</p><p>一般来说，得保证查询至少达到range级别，最好能达到ref。</p><ul><li><p><strong>system</strong>：表只有一行记录（等于系统表），这是const类型的特例，平时不会出现，可以忽略不计</p></li><li><p><strong>const</strong>：表示通过索引一次就找到了，const用于比较primary key 或者 unique索引。因为只需匹配一行数据，所有很快。如果将主键置于where列表中，mysql就能将该查询转换为一个const </p></li><li><p><strong>eq_ref</strong>： 唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描。</p></li><li><p><strong>ref</strong>：非唯一性索引扫描，返回匹配某个单独值的所有行。本质是也是一种索引访问，它返回所有匹配某个单独值的行，然而他可能会找到多个符合条件的行，所以它应该属于查找和扫描的混合体 。</p></li><li><p><strong>range</strong>：只检索给定范围的行，使用一个索引来选择行。key列显示使用了那个索引。一般就是在where语句中出现了bettween、&lt;、&gt;、in等的查询。这种索引列上的范围扫描比全索引扫描要好。只需要开始于某个点，结束于另一个点，不用扫描全部索引 </p></li><li><p><strong>index</strong>：Full Index Scan，index与ALL区别为index类型只遍历索引树。这通常为ALL块，应为索引文件通常比数据文件小。（Index与ALL虽然都是读全表，但index是从索引中读取，而ALL是从硬盘读取） </p></li><li><p><strong>ALL</strong>：Full Table Scan，遍历全表以找到匹配的行</p></li></ul><h4 id="possible-keys与key"><a href="#possible-keys与key" class="headerlink" title="possible_keys与key"></a>possible_keys与key</h4><p>possible_keys：可能使用的索引。</p><p>key：实际使用的索引，如果为NULL，则没事用索引。</p><h4 id="key-len"><a href="#key-len" class="headerlink" title="key_len"></a>key_len</h4><p>Key_len表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。在不损失精确性的情况下，长度越短越好。如果充分用了索引key_len会比没有充分用到索引要长。key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的。</p><ul><li>根据这个值，就可以判断索引使用情况，特别是在组合索引的时候，判断所有的索引字段是否都被查询用到。</li><li>char和varchar跟字符编码也有密切的联系。</li><li>latin1占用1个字节，gbk占用2个字节，utf8占用3个字节。（不同字符编码占用的存储空间不同）</li></ul><h5 id="字符类型key-len计算"><a href="#字符类型key-len计算" class="headerlink" title="字符类型key_len计算"></a>字符类型key_len计算</h5><p>变长字段（varchar）需要额外的2个字节（VARCHAR值保存时只保存需要的字符数，另加一个字节来记录长度（如果列声明的长度超过255，则使用两个字节），所以VARCAHR索引长度计算时候要加2），固定长度字段（char）不需要额外的字节。 </p><p>而如果允许为NULL都需要1个字节的额外空间，所以索引字段最好不要允许为NULL，因为允许为NULL会让统计更加复杂并且需要额外的存储空间。</p><p>复合索引有最左前缀的特性，如果复合索引能全部使用上，则是复合索引字段的索引长度之和，这也可以用来判定复合索引是否部分使用，还是全部使用。</p><h5 id="整数-浮点数-时间类型的索引长度"><a href="#整数-浮点数-时间类型的索引长度" class="headerlink" title="整数/浮点数/时间类型的索引长度"></a>整数/浮点数/时间类型的索引长度</h5><p>整数/浮点数/时间类型的索引长度等于字段本身的字段长度，如果为NULL就等于字段本身的长度+1。</p><p>datetime类型在5.6中字段长度是5个字节，datetime类型在5.5中字段长度是8个字节。</p><h4 id="ref"><a href="#ref" class="headerlink" title="ref"></a>ref</h4><p>显示索引的哪一列被使用了，如果可能的话，是一个常数。哪些列或常量被用于查找索引列上的值</p><h4 id="rows"><a href="#rows" class="headerlink" title="rows"></a>rows</h4><p>根据表统计信息及索引选用情况，大致估算出找到所需的记录所需要读取的行数</p><h4 id="extra"><a href="#extra" class="headerlink" title="extra"></a>extra</h4><p>包含不适合在其他列中显示但十分重要的额外信息。</p><p>Using filesort：文件排序，表示MySQL中无法利用索引完成的排序。当查询的排序规则与复合索引顺序不同时，MySQL会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。。</p><p>Using temporary：表示使用了临时表保存中间结果，常见于排序order by和分组查询group by。</p><p>Using index：表示使用了覆盖索引。覆盖索引表示在获取查询结果时只需要遍历索引树，不需要从硬盘中读取。</p><p>Using where：表示使用了where或者on过滤。</p><p>Using join buffer：表示使用了连接缓存，连接缓存的大小可以使用<code>show VARIABLES like &#39;%join_buffer_size%&#39;</code></p><p>Impossible where：where子句的值总是false，不能用来获取任何元组。</p><h2 id="SQL优化策略"><a href="#SQL优化策略" class="headerlink" title="SQL优化策略"></a>SQL优化策略</h2><p><strong>尽量全值匹配</strong>：如果使用复合索引，应使where条件中尽量包含复合索引的全部列。</p><p><strong>最佳左前缀法则</strong>：复合索引在使用时要遵守最左前缀法则，即查询条件应从从索引最左侧的列开始并且不跳过索引中间的列。</p><p><strong>不在索引列上做任何操作</strong>：索引列上做任何操作（计数、函数、类型转换）会导致索引失效而转向全表扫描。</p><p><strong>进行范围条件查询的列放最后</strong>：如果对复合索引中的列进行范围查询，而且该列处于复合索引的中间位置，会导致符合索引后面的索引列全部失效。</p><p><strong>尽量使用覆盖索引</strong>：尽量使用覆盖索引(只访问索引的查询(索引列和查询列一致))，减少select *</p><p><strong>不等于要慎用</strong>：mysql 在使用不等于（!= 或者&lt;&gt;）的时候会导致索引失效会导致全表扫描，解决方式为使用覆盖索引</p><p><strong>NULL、NOT NULL会影响索引</strong>：在列不允许为空的情况下，使用IS NULL或IS NOT NULL会导致索引失效，在列允许为空的情况下IS NOT NULL会导致索引失效，使用覆盖索引也可以解决这个问题。</p><p><strong>慎用LIKE查询</strong>：如果LIKE以通配符开头（’%abc…’）会导致索引失效变成全表扫描的操作，同样使用覆盖索引也可以解决这个问题。</p><p><strong>字符类型加引号</strong>：字符串不加单引号索引失效。</p><p><strong>OR改为UNION效率高</strong>：OR会导致索引失效，解决方式为使用UNION改写SQL。</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><table><thead><tr><th>where语句</th><th>使用到的索引</th></tr></thead><tbody><tr><td>where a = 3</td><td>a</td></tr><tr><td>where a = 3 and b = 5</td><td>a,b</td></tr><tr><td>where a = 3 and b = 5 and c = 4</td><td>a,b,c</td></tr><tr><td>where b = 3 或者 where b = 3 and c = 4 或者 where c = 5</td><td>空</td></tr><tr><td>where a = 3 and c = 5</td><td>a</td></tr><tr><td>where a = 3 and b &gt;4 and c = 5</td><td>a,b</td></tr><tr><td>where a = 3 and b like ‘kk%’ and c = 4</td><td>a,b,c</td></tr><tr><td>where a = 3 and b like ‘%kk’ and c = 4</td><td>a</td></tr><tr><td>where a = 3 and b like ‘%kk%’ and c = 4</td><td>a</td></tr><tr><td>where a = 3 and b like ‘k%kk%’ and c = 4</td><td>a,b,c</td></tr></tbody></table><h3 id="记忆总结"><a href="#记忆总结" class="headerlink" title="记忆总结"></a>记忆总结</h3><ul><li><p>全值匹配我最爱，最左前缀要遵守；</p></li><li><p>带头大哥不能死，中间兄弟不能断；</p></li><li><p>索引列上少计算，范围之后全失效；</p></li><li><p>LIKE百分写最右，覆盖索引不写*；</p></li><li><p>不等空值还有OR，索引影响要注意；</p></li><li><p>VARCHAR引号不可丢， SQL优化有诀窍。</p></li></ul><h3 id="数据的迁移"><a href="#数据的迁移" class="headerlink" title="数据的迁移"></a>数据的迁移</h3><p>使用前需要确认MySQL是否允许允许导入导出。</p><pre><code>show VARIABLES like &#39;secure_file_priv&#39;</code></pre><ul><li><p>secure_file_priv为NULL时，表示限制MySQL不允许导入或导出。</p></li><li><p>secure_file_priv为/tmp时，表示限制MySQL只能在/tmp目录中执行导入导出，其他目录不能执行。</p></li><li><p>secure_file_priv没有值时，表示不限制MySQL在任意目录的导入导出。</p></li></ul><p>修改方法为将<code>source_file_priv=&#39;&#39;</code>添加到my.cnf文件中。</p><pre><code>select * into OUTFILE &#39;D:\\product.txt&#39; from product_info    -- 将表中的数据迁移到product.txt文件中load data INFILE &#39;D:\\product.txt&#39; into table product_info    -- 将product.txt文件中的数据导入到表中</code></pre>]]></content>
    
    
    <categories>
      
      <category>MySQL进阶</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL的慢查询</title>
    <link href="/2020/04/02/MySQL%E7%9A%84%E6%85%A2%E6%9F%A5%E8%AF%A2/"/>
    <url>/2020/04/02/MySQL%E7%9A%84%E6%85%A2%E6%9F%A5%E8%AF%A2/</url>
    
    <content type="html"><![CDATA[<h2 id="慢查询的配置"><a href="#慢查询的配置" class="headerlink" title="慢查询的配置"></a>慢查询的配置</h2><p>慢查询日志是指MySQL记录所有执行超过long_query_time参数设定的时间阈值的SQL语句的日志。该日志能为SQL语句的优化带来很好的帮助。默认情况下，慢查询日志是关闭的，要使用慢查询日志功能，首先要开启慢查询日志功能。</p><h3 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h3><ul><li>slow_query_log 启动停止技术慢查询日志</li><li>slow_query_log_file 指定慢查询日志得存储路径及文件（默认和数据文件放一起）</li><li>long_query_time 指定记录慢查询日志SQL执行时间得伐值（单位:秒，默认10秒）</li><li>log_queries_not_using_indexes 是否记录未使用索引的SQL</li><li>log_output 日志存放的地方[TABLE][FILE][FILE,TABLE]</li></ul><p>通过下面命令查看下上面的配置：</p><pre><code>show VARIABLES like &#39;%slow_query_log%&#39;show VARIABLES like &#39;%slow_query_log_file%&#39;show VARIABLES like &#39;%long_query_time%&#39;show VARIABLES like &#39;%log_queries_not_using_indexes%&#39;show VARIABLES like &#39;%log_output%&#39;</code></pre><p>通过下面命令设置上面的配置：</p><pre><code>set global long_query_time=5;  -- 默认10秒，这里设置为5秒set GLOBAL slow_query_log = 1; -- 开启慢查询日志set global log_output=&#39;FILE,TABLE&#39; -- 记录在表跟文件中，项目开发中日志只能记录在日志文件中，不能记表中</code></pre><p>设置完成后在datadir中就可以看到慢查询语句，数据库的datadir查看方式为<code>show VARIABLES like &#39;datadir&#39;</code></p><h2 id="慢查询解读"><a href="#慢查询解读" class="headerlink" title="慢查询解读"></a>慢查询解读</h2><pre><code># User@Host: root[root] @ localhost [127.0.0.1]  Id:   10    -- 用户名 、用户的IP信息、线程ID号# Query_time: 0.001042    -- 执行花费的时间【单位：毫秒】# Lock_time:0.000000    -- 执行获得锁的时间# Rows_sent: 2    -- 获得的结果行数# Rows_examined: 2    -- 扫描的数据行数SET timestamp=1535462721;    -- 这SQL执行的具体时间SELECT * FROM mvarchive LIMIT O, 1000;    -- 具体的SQL语句</code></pre><h2 id="慢查询分析"><a href="#慢查询分析" class="headerlink" title="慢查询分析"></a>慢查询分析</h2><p>慢查询的日志记录非常多，要从里面找寻一条查询慢的日志并不是很容易的事情，一般来说都需要一些工具辅助才能快速定位到需要优化的SQL语句，下面介绍两个慢查询辅助工具。</p><h3 id="mysql-dumpslow"><a href="#mysql-dumpslow" class="headerlink" title="mysql dumpslow"></a>mysql dumpslow</h3><p>常用的慢查询日志分析工具，汇总除查询条件外其他完全相同的SQL，并将分析结果按照参数中所指定的顺序输出。</p><p>使用方法：</p><pre><code>mysqldumpslow -s r -t 10 slow-mysql.log-s 排序规则，可选参数[c,t,l,r,at,al,ar]   c:总次数   t:总时间   l:锁的时间   r:总数据行   at,al,ar:平均数[例如：at = 总时间/总次数]-t 选取条数</code></pre><h3 id="pt-query-digest"><a href="#pt-query-digest" class="headerlink" title="pt_query_digest"></a>pt_query_digest</h3><p>是用于分析mysql慢查询的一个工具，与mysqldumpshow工具相比，py-query_digest 工具的分析结果更具体，更完善。但可能因为某些原因如权限不足等，无法在服务器上记录查询。</p><h4 id="安装方式"><a href="#安装方式" class="headerlink" title="安装方式"></a>安装方式</h4><pre><code>安装依赖工具：yum install perl-DBIyum install perl-DBD-MySQLyum install perl-Time-HiResyum install perl-IO-Socket-SSLyum install perl-Digest-MD5下载pt-query-disgest、授权、将其放到/usr/bin下：wget percona.com/get/pt-query-digestchmod u+x pt-query-digestmv /usr/src/pt-query-digest /usr/bin/perl ./pt-query-digest  --explain h=127.0.0.1,u=root,p=root1234%  /usr/local/mysql/data/mysql-slow.log</code></pre><h4 id="语法与重要选项"><a href="#语法与重要选项" class="headerlink" title="语法与重要选项"></a>语法与重要选项</h4><pre><code>pt-query-digest [OPTIONS] [FILES] [DSN]--create-review-table  当使用--review参数把分析结果输出到表中时，如果没有表就自动创建。--create-history-table  当使用--history参数把分析结果输出到表中时，如果没有表就自动创建。--filter  对输入的慢查询按指定的字符串进行匹配过滤后再进行分析--limit限制输出结果百分比或数量，默认值是20,即将最慢的20条语句输出，如果是50%则按总响应时间占比从大到小排序，输出到总和达到50%位置截止。--host  mysql服务器地址--user  mysql用户名--password  mysql用户密码--history 将分析结果保存到表中，分析结果比较详细，下次再使用--history时，如果存在相同的语句，且查询所在的时间区间和历史表中的不同，则会记录到数据表中，可以通过查询同一CHECKSUM来比较某类型查询的历史变化。--review 将分析结果保存到表中，这个分析只是对查询条件进行参数化，一个类型的查询一条记录，比较简单。当下次使用--review时，如果存在相同的语句分析，就不会记录到数据表中。--output 分析结果输出类型，值可以是report(标准分析报告)、slowlog(Mysql slow log)、json、json-anon，一般使用report，以便于阅读。--since 从什么时间开始分析，值为字符串，可以是指定的某个”yyyy-mm-dd [hh:mm:ss]”格式的时间点，也可以是简单的一个时间值：s(秒)、h(小时)、m(分钟)、d(天)，如12h就表示从12小时前开始统计。--until 截止时间，配合—since可以分析一段时间内的慢查询。</code></pre><h4 id="用法示例"><a href="#用法示例" class="headerlink" title="用法示例"></a>用法示例</h4><p>直接分析慢查询文件:</p><pre><code class="bash">#分析slow.log日志，并将分析报告输入到slow_report.log中shell&gt; pt-query-digest  slow.log &gt; slow_report.log</code></pre><p>分析最近12小时内的查询：</p><pre><code class="bash">shell&gt; pt-query-digest  --since=12h  slow.log &gt; slow_report2.log</code></pre><p>分析指定时间范围内的查询：</p><pre><code class="bash">pt-query-digest slow.log --since &#39;2014-04-17 09:30:00&#39; --until &#39;2014-04-17 10:00:00&#39; &gt; slow_report3.log</code></pre><p>分析指含有select语句的慢查询</p><pre><code class="bash">shell&gt; pt-query-digest--filter &#39;$event-&gt;{fingerprint} =~ m/^select/i&#39; slow.log&gt; slow_report4.log</code></pre><p>针对某个用户的慢查询</p><pre><code class="bash">shell&gt; pt-query-digest--filter &#39;($event-&gt;{user} || &quot;&quot;) =~ m/^root/i&#39; slow.log&gt; slow_report5.log</code></pre><p>查询所有所有的全表扫描或full join的慢查询</p><pre><code class="bash">  pt-query-digest--filter &#39;(($event-&gt;{Full_scan} || &quot;&quot;) eq &quot;yes&quot;) ||(($event-&gt;{Full_join} || &quot;&quot;) eq &quot;yes&quot;)&#39; slow.log&gt; slow_report6.log</code></pre><p>把查询保存到query_review表</p><pre><code class="bash">pt-query-digest  --user=root –password=abc123 --review  h=localhost,D=test,t=query_review--create-review-table  slow.log</code></pre><p>把查询保存到query_history表</p><pre><code class="bash">pt-query-digest  --user=root –password=abc123 --review  h=localhost,D=test,t=query_ history--create-review-table  slow.log_20140401pt-query-digest  --user=root –password=abc123--review  h=localhost,D=test,t=query_history--create-review-table  slow.log_20140402</code></pre><p>通过tcpdump抓取mysql的tcp协议数据，然后再分析</p><pre><code class="bash">tcpdump -s 65535 -x -nn -q -tttt -i any -c 1000 port 3306 &gt; mysql.tcp.txtpt-query-digest --type tcpdump mysql.tcp.txt&gt; slow_report9.log</code></pre><p>分析binlog</p><pre><code class="bash">mysqlbinlog mysql-bin.000093 &gt; mysql-bin000093.sqlpt-query-digest  --type=binlog  mysql-bin000093.sql &gt; slow_report10.log</code></pre><p>分析general log</p><pre><code class="bash">pt-query-digest  --type=genlog  localhost.log &gt; slow_report11.log</code></pre><h4 id="报告参数说明"><a href="#报告参数说明" class="headerlink" title="报告参数说明"></a>报告参数说明</h4>{% asset_img pic1.png %}<h5 id="第一部分：总体统计结果"><a href="#第一部分：总体统计结果" class="headerlink" title="第一部分：总体统计结果"></a>第一部分：总体统计结果</h5><ul><li>Overall：总共有多少条查询</li><li>Time range：查询执行的时间范围</li><li>unique：唯一查询数量，即对查询条件进行参数化以后，总共有多少个不同的查询</li><li>total：总计 min：最小 max：最大 avg：平均</li><li>95%：把所有值从小到大排列，位置位于95%的那个数，这个数一般最具有参考价值</li><li>median：中位数，把所有值从小到大排列，位置位于中间那个数</li></ul><pre><code># 该工具执行日志分析的用户时间，系统时间，物理内存占用大小，虚拟内存占用大小# 340ms user time, 140ms system time, 23.99M rss, 203.11M vsz# 工具执行时间# Current date: Fri Nov 25 02:37:18 2016# 运行分析工具的主机名# Hostname: localhost.localdomain# 被分析的文件名# Files: slow.log# 语句总数量，唯一的语句数量，QPS，并发数# Overall: 2 total, 2 unique, 0.01 QPS, 0.01x concurrency # 日志记录的时间范围# Time range: 2016-11-22 06:06:18 to 06:11:40# 属性    总计  最小 最大 平均 95% 标准 中等# Attribute   total  min  max  avg  95% stddev median# ============  ======= ======= ======= ======= ======= ======= =======# 语句执行时间# Exec time    3s 640ms  2s  1s  2s 999ms  1s# 锁占用时间# Lock time   1ms  0  1ms 723us  1ms  1ms 723us# 发送到客户端的行数# Rows sent    5  1  4 2.50  4 2.12 2.50# select语句扫描行数# Rows examine  186.17k  0 186.17k 93.09k 186.17k 131.64k 93.09k# 查询的字符数# Query size   455  15  440 227.50  440 300.52 227.50</code></pre><h5 id="第二部分：查询分组统计结果"><a href="#第二部分：查询分组统计结果" class="headerlink" title="第二部分：查询分组统计结果"></a>第二部分：查询分组统计结果</h5><ul><li>Rank：所有语句的排名，默认按查询时间降序排列，通过–order-by指定</li><li>Query ID：语句的ID，（去掉多余空格和文本字符，计算hash值）</li><li>Response：总的响应时间</li><li>time：该查询在本次分析中总的时间占比</li><li>calls：执行次数，即本次分析总共有多少条这种类型的查询语句</li><li>R/Call：平均每次执行的响应时间</li><li>V/M：响应时间Variance-to-mean的比率</li><li>Item：查询对象</li></ul><pre><code># Profile# Rank Query ID   Response time Calls R/Call V/M Item# ==== ================== ============= ===== ====== ===== ===============# 1 0xF9A57DD5A41825CA 2.0529 76.2%  1 2.0529 0.00 SELECT# 2 0x4194D8F83F4F9365 0.6401 23.8%  1 0.6401 0.00 SELECT wx_member_base</code></pre><h5 id="第三部分：每一种查询的详细统计结果"><a href="#第三部分：每一种查询的详细统计结果" class="headerlink" title="第三部分：每一种查询的详细统计结果"></a>第三部分：每一种查询的详细统计结果</h5><p>由下面查询的详细统计结果，最上面的表格列出了执行次数、最大、最小、平均、95%等各项目的统计。</p><ul><li>ID：查询的ID号，和上图的Query ID对应</li><li>Databases：数据库名</li><li>Users：各个用户执行的次数（占比）</li><li>Query_time distribution ：查询时间分布, 长短体现区间占比，本例中1s-10s之间查询数量是10s以上的两倍。</li><li>Tables：查询中涉及到的表</li><li>Explain：SQL语句</li></ul><pre><code># Query 1: 0 QPS, 0x concurrency, ID 0xF9A57DD5A41825CA at byte 802 # This item is included in the report because it matches --limit.# Scores: V/M = 0.00# Time range: all events occurred at 2016-11-22 06:11:40# Attribute pct total  min  max  avg  95% stddev median# ============ === ======= ======= ======= ======= ======= ======= =======# Count   50  1# Exec time  76  2s  2s  2s  2s  2s  0  2s# Lock time  0  0  0  0  0  0  0  0# Rows sent  20  1  1  1  1  1  0  1# Rows examine 0  0  0  0  0  0  0  0# Query size  3  15  15  15  15  15  0  15# String:# Databases test# Hosts  192.168.8.1# Users  mysql# Query_time distribution# 1us# 10us# 100us# 1ms# 10ms# 100ms# 1s ################################################################# 10s+# EXPLAIN /*!50100 PARTITIONS*/select sleep(2)\G</code></pre>]]></content>
    
    
    <categories>
      
      <category>MySQL进阶</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL的业务设计</title>
    <link href="/2020/04/01/MySQL%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%AE%BE%E8%AE%A1/"/>
    <url>/2020/04/01/MySQL%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%AE%BE%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<h2 id="逻辑设计"><a href="#逻辑设计" class="headerlink" title="逻辑设计"></a>逻辑设计</h2><h3 id="数据库设计的三大范式"><a href="#数据库设计的三大范式" class="headerlink" title="数据库设计的三大范式"></a>数据库设计的三大范式</h3><h4 id="一、要求每一列属性值都不可再分，确保每一列的原子性"><a href="#一、要求每一列属性值都不可再分，确保每一列的原子性" class="headerlink" title="一、要求每一列属性值都不可再分，确保每一列的原子性"></a>一、要求每一列属性值都不可再分，确保每一列的原子性</h4><img src="/2020/04/01/MySQL%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%AE%BE%E8%AE%A1/pic1.png" srcset="/img/loading.gif" class=""><p>这张表的name-age列具有name跟age两个属性，不符合第一个范式，这时候就需要对name-age列进行拆分。</p><img src="/2020/04/01/MySQL%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%AE%BE%E8%AE%A1/pic2.png" srcset="/img/loading.gif" class=""><h4 id="二、必须满足第一范式，并且所有非主属性都完全依赖于主键即不允许有第二主键。"><a href="#二、必须满足第一范式，并且所有非主属性都完全依赖于主键即不允许有第二主键。" class="headerlink" title="二、必须满足第一范式，并且所有非主属性都完全依赖于主键即不允许有第二主键。"></a>二、必须满足第一范式，并且所有非主属性都完全依赖于主键即不允许有第二主键。</h4><img src="/2020/04/01/MySQL%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%AE%BE%E8%AE%A1/pic3.png" srcset="/img/loading.gif" class=""><p>一个订单有多个产品，所以订单的主键为订单ID和产品ID组成的联合主键，这样的设计不符合第二范式，而且产品ID和订单ID没有强关联，所以需要把订单表进行拆分为订单表与订单与商品的中间表</p><img src="/2020/04/01/MySQL%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%AE%BE%E8%AE%A1/pic4.png" srcset="/img/loading.gif" class=""><h4 id="三、必须满足第二范式，并且数据不能存在传递关系，即每个属性都跟主键有直接关系而不是间接关系。"><a href="#三、必须满足第二范式，并且数据不能存在传递关系，即每个属性都跟主键有直接关系而不是间接关系。" class="headerlink" title="三、必须满足第二范式，并且数据不能存在传递关系，即每个属性都跟主键有直接关系而不是间接关系。"></a>三、必须满足第二范式，并且数据不能存在传递关系，即每个属性都跟主键有直接关系而不是间接关系。</h4><img src="/2020/04/01/MySQL%E7%9A%84%E4%B8%9A%E5%8A%A1%E8%AE%BE%E8%AE%A1/pic5.png" srcset="/img/loading.gif" class=""><p>此时，如果客户编号发生改变，用户姓名也会改变，这样不符合第三大范式，应该把客户姓名这一列删除</p><h3 id="反范式设计"><a href="#反范式设计" class="headerlink" title="反范式设计"></a>反范式设计</h3><p>范式设计是为了尽可能的降低数据的冗余，完全符合范式化的设计有时并不能得到良好得SQL查询性能。反范式化是针对范式化而言得，是为了性能而适当得对数据库设计范式得要求进行违反，允许存在少量得冗余，换句话来说反范式化就是使用空间来换取时间。</p><h2 id="物理设计"><a href="#物理设计" class="headerlink" title="物理设计"></a>物理设计</h2><h3 id="命名规范"><a href="#命名规范" class="headerlink" title="命名规范"></a>命名规范</h3><ul><li>可读性原则：使用下划线来格式化的库对象名字以获得良好的可读性</li><li>表意性原则：对象的名字应该能够描述它所表示的对象，对于存储过程，存储过程应该能够体现存储过程的功能。</li><li>长名原则：尽可能少使用或者不使用缩写</li></ul><h3 id="存储引擎的选择"><a href="#存储引擎的选择" class="headerlink" title="存储引擎的选择"></a>存储引擎的选择</h3><table><thead><tr><th><strong>功 能</strong></th><th><strong>MYISAM</strong></th><th><strong>Memory</strong></th><th><strong>InnoDB</strong></th><th><strong>Archive</strong></th></tr></thead><tbody><tr><td>存储限制</td><td>256TB</td><td>RAM</td><td>64TB</td><td>None</td></tr><tr><td>支持事物</td><td>No</td><td>No</td><td>Yes</td><td>No</td></tr><tr><td>支持全文索引</td><td>Yes</td><td>No</td><td>No</td><td>No</td></tr><tr><td>支持数索引</td><td>Yes</td><td>Yes</td><td>Yes</td><td>No</td></tr><tr><td>支持哈希索引</td><td>No</td><td>Yes</td><td>No</td><td>No</td></tr><tr><td>支持数据缓存</td><td>No</td><td>N/A</td><td>Yes</td><td>No</td></tr><tr><td>支持外键</td><td>No</td><td>No</td><td>Yes</td><td>No</td></tr></tbody></table><p>如果要提供提交、回滚、崩溃恢复能力的事物安全（ACID兼容）能力，并要求实现并发控制，InnoDB是一个好的选择。</p><p>如果数据表主要用来插入和查询记录，则MyISAM引擎能提供较高的处理效率。</p><p>如果只是临时存放数据，数据量不大，并且不需要较高的数据安全性，可以选择将数据保存在内存中的Memory引擎，MySQL中使用该引擎作为临时表，存放查询的中间结果。</p><p>如果只有INSERT和SELECT操作，可以选择Archive，Archive支持高并发的插入操作，但是本身不是事务安全的。Archive非常适合存储归档数据，如记录日志信息可以使用Archive。</p><p>使用哪一种引擎需要灵活选择，<strong>一个数据库中多个表可以使用不同引擎以满足各种性能和实际需求</strong>，使用合适的存储引擎，将会提高整个数据库的性能</p><h3 id="数据类型选择"><a href="#数据类型选择" class="headerlink" title="数据类型选择"></a>数据类型选择</h3><p>选择原则</p><ul><li><p><strong>更小的通常更好</strong>：一般情况下选择可以正确存储数据的最小数据类型。越小的数据类型通常更快，占用磁盘，内存和CPU缓存更小。</p></li><li><p><strong>简单就好</strong>：简单的数据类型的操作通常需要更少的CPU周期。例如：整型比字符操作代价要小得多，因为字符集和校对规则(排序规则)使字符比整型比较更加复杂。</p></li><li><p><strong>尽量避免NULL</strong>:尽量制定列为NOT NULL，除非真的需要NULL类型的值。因为可能为NULL列使得索引，索引统计和值比较都更复杂。可为NULL的列会使用更多的存储空间，在MySQL里也需要特殊处理。</p></li></ul><p>当一个列可以选择多种数据类型时</p><ul><li>优先考虑数字类型</li><li>其次是日期、时间类型</li><li>最后是字符类型</li><li>对于相同级别的数据类型，应该优先选择占用空间小的数据类型</li></ul>]]></content>
    
    
    <categories>
      
      <category>MySQL进阶</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL中的锁和事务</title>
    <link href="/2020/03/31/MySQL%E4%B8%AD%E7%9A%84%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/"/>
    <url>/2020/03/31/MySQL%E4%B8%AD%E7%9A%84%E9%94%81%E5%92%8C%E4%BA%8B%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<h2 id="锁的简介"><a href="#锁的简介" class="headerlink" title="锁的简介"></a>锁的简介</h2><h3 id="锁的类型"><a href="#锁的类型" class="headerlink" title="锁的类型"></a>锁的类型</h3><ul><li>表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。</li><li>行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。</li><li>页面锁（gap锁，间隙锁）：开销界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。</li></ul><h3 id="锁的选择"><a href="#锁的选择" class="headerlink" title="锁的选择"></a>锁的选择</h3><p>从锁的角度来说，表级锁更适合以查询为主，只有少量按索引条件更新数据的应用，行级锁更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用。锁的使用需要根据具体应用的特点来确定，不能一概而论。</p><h2 id="MyISAM锁"><a href="#MyISAM锁" class="headerlink" title="MyISAM锁"></a>MyISAM锁</h2><p>MyISAM引擎只支持表锁，表锁又分为表共享读锁（Table Read Lock）和表独占写锁（Table Write Lock）。</p><p>读锁的语法为：<code>lock table 表名 read</code>，写锁的语法为：<code>lock table 表名write</code>，解锁语法为：<code>unlock tables;</code></p><p>当使用读锁锁住MyISAM表时，当前会话对这张表的写操作以及对其他表（如果给这张表起别名MySQL会认为这张表不是被锁住的表）的读写操作都会报错，其他会话对这张表的写操作会被阻塞，对这张表的读操作以及其他表的操作不会被影响，也可以使用读锁锁住这张表，但写锁会被阻塞。</p><p>当使用写锁锁住MyISAM表时，对其他表的读写操作都会报错，其他会话对这张表的读写操作以及对这张表的锁操作会被阻塞，对其他表的操作不会被影响。</p><h2 id="InnnoDB锁"><a href="#InnnoDB锁" class="headerlink" title="InnnoDB锁"></a>InnnoDB锁</h2><p>InnoDB支持多种锁粒度，默认使用行锁，锁粒度最小，锁冲突发生的概率最低，支持的并发度也最高，但系统消耗成本也相对较高。共享锁与排他锁是InnoDB实现的两种标准的行锁。</p><p>InnoDB有三种锁算法——记录锁、gap间隙锁、还有结合了记录锁与间隙锁的next-key锁，InnoDB对于行的查询加锁是使用的是next-key locking这种算法，一定程度上解决了幻读问题。</p><p>共享锁和拍他锁的关系为：</p><ul><li><p>当一个事务对某几行上共享锁时，允许其他事务对这几行进行读操作，但不允许其进行写操作，也不允许其他事务给这几行上排它锁，但允许上读锁。</p></li><li><p>当一个事务对某几个上排它锁时，不允许其他事务写，但允许读。更不允许其他事务给这几行上任何锁。包括写锁。 </p></li></ul><p>共享锁的语法：<code>lock in share mode</code>，例如： <code>select * from 表 where 条件 lock in share mode;</code></p><p>排它锁的写法：<code>for update</code>，例如：<code>select * from 表 where 条件 for update;</code></p><p>注意：</p><ol><li><p>两个事务不能锁同一条数据。</p></li><li><p>insert、delete、update在事务中都会自动默认加上排它锁。</p></li><li><p>行锁必须有索引才能实现，否则会自动锁全表，那么就不是行锁了。</p></li></ol><h2 id="锁的等待问题"><a href="#锁的等待问题" class="headerlink" title="锁的等待问题"></a>锁的等待问题</h2><p>实际开发过程中，你的同事在debug程序的时候可能会锁住一部分数据库的数据，而这个时候再操作这部分数据就可能会超时，这就是锁等待问题的一个体现。</p><p>通过下面这个语句可以查看数据库中锁的情况。</p><pre><code>select * from information_schema.INNODB_LOCKS;</code></pre><p>如果数据库版本为5.7可以通过下面这个指令获取pid，之后使用最下面的kill命令，退出阻塞的SQL</p><pre><code>select * from sys.innodb_lock_waits</code></pre><p>如果不是5.7版本，可以通过下面这条语句来查看阻塞的SQL的线程号</p><pre><code>SELECT  r.trx_id waiting_trx_id,  r.trx_mysql_thread_id waiting_thread,  r.trx_query waiting_query,  b.trx_id blocking_trx_id,  b.trx_mysql_thread_id blocking_threadFROM  information_schema.innodb_lock_waits wINNER JOIN  information_schema.innodb_trx b ON b.trx_id = w.blocking_trx_idINNER JOIN  information_schema.innodb_trx r ON r.trx_id = w.requesting_trx_id;</code></pre><p>得到线程号后就可以通过<code>kill [线程号]</code>这样来退出阻塞的线程。</p><p>不过如果你的同事在进行比较重要的调试，强行kill掉他的SQL可能会影响同事间的关系，如果不是迫不得已这种做法还是少用比较好。</p><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>现在的很多软件都是多用户，多程序，多线程的，对同一个表可能同时有很多人在用，为保持数据的一致性，所以提出了事务的概念，目前只有InnoDB引擎支持事务。</p><h3 id="ACID特性"><a href="#ACID特性" class="headerlink" title="ACID特性"></a>ACID特性</h3><p>事务应该具有4个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为ACID特性。</p><ul><li>原子性（atomicity）：一个事务必须被视为一个不可分割的最小单元，整个事务中的所有操作要么全部提交成功，要么全部失败，对于一个事务来说，不可能只执行其中的一部分操作</li><li>一致性（consistency）：一致性是指事务将数据库从一种一致性转换到另外一种一致性状态，在事务开始之前和事务结束之后数据库中数据的完整性没有被破坏。</li><li>持久性（durability）：一旦事务提交，则其所做的修改就会永久保存到数据库中。此时即使系统崩溃，已经提交的修改数据也不会丢失，如果单纯依靠是数据库，持久性并不能完全解决。</li><li>隔离性（isolation）：一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。</li></ul><h3 id="并发问题"><a href="#并发问题" class="headerlink" title="并发问题"></a>并发问题</h3><p>数据库中共有四种隔离级别：未提交读（READ UNCOMMITED）、已提交读 （READ COMMITED）、可重复读（REPEATABLE READ）、可串行化（SERIALIZABLE）。MySQL默认的事务隔离级别为repeatable-read可以通过<code>show VARIABLES LIKE &#39;%tx_isolation%&#39;;</code>查看数据库目前的隔离级别。</p><p>事务并发引发的问题总共有三种：</p><ul><li><p>脏读：如果在事务B更新数据时，被事务A读取了更新的数据，然后B回滚操作，那么A读取到的数据是脏数据。</p></li><li><p>不可重复读：事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。</p></li><li><p>幻读：系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级，但是系统管理员B就在这个时候插入了一条具体分数的记录，当系统管理员A改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。</p></li></ul><p>不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表</p><p>与隔离级别的对应关系</p><table><thead><tr><th>事务隔离级别</th><th>脏读</th><th>不可重复读</th><th>幻读</th></tr></thead><tbody><tr><td>未提交读（READ UNCOMMITED）</td><td>是</td><td>是</td><td>是</td></tr><tr><td>已提交读 （READ COMMITED）</td><td>否</td><td>是</td><td>是</td></tr><tr><td>可重复读（REPEATABLE READ）</td><td>否</td><td>否</td><td>是</td></tr><tr><td>可串行化（SERIALIZABLE）</td><td>否</td><td>否</td><td>否</td></tr></tbody></table><h3 id="间隙锁（Gap-Lock）"><a href="#间隙锁（Gap-Lock）" class="headerlink" title="间隙锁（Gap Lock）"></a>间隙锁（Gap Lock）</h3><p>间隙锁（Gap Lock）是InnoDB在可重复读提交下为了解决幻读问题时引入的锁机制，间隙锁是一个在索引记录之间的间隙上的锁。</p><p>当使用唯一索引来搜索唯一行的语句时，不需要间隙锁定。如下面语句的id列有唯一索引，此时只会对id值为10的行使用记录锁。</p><pre><code>select * from t where id = 10 for update;// 注意：普通查询是快照读，不需要加锁</code></pre><p>如果上面语句中id列没有建立索引或者是非唯一索引时，则语句会产生间隙锁。</p><p>如果搜索条件里有多个查询条件(即使每个列都有唯一索引)，也是会有间隙锁的。</p><p>需要注意的是，当id列上没有索引时，SQL会走聚簇索引的全表扫描进行过滤，由于过滤是在MySQL Server层面进行的。因此每条记录（无论是否满足条件）都会被加上锁。但是，为了效率考量，MySQL做了优化，对于不满足条件的记录，会在判断后<strong>放锁</strong>，最终持有的，是满足条件的记录上的锁。但是不满足条件的记录上的加锁/放锁动作是不会省略的。所以在没有索引时，不满足条件的数据行会有加锁又放锁的耗时过程。</p><h3 id="事务的使用"><a href="#事务的使用" class="headerlink" title="事务的使用"></a>事务的使用</h3><ul><li><p>开启事务：begin、START TRANSACTION（推荐）、begin work </p></li><li><p>事务回滚：rollback</p></li><li><p>事务提交：commit</p></li><li><p>设置还原点：savepoint [变量名]</p></li><li><p>回退到还原点：rollback to savepoint [变量名]</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>MySQL进阶</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL架构与存储引擎</title>
    <link href="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"/>
    <url>/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/</url>
    
    <content type="html"><![CDATA[<h2 id="MySQL逻辑架构"><a href="#MySQL逻辑架构" class="headerlink" title="MySQL逻辑架构"></a>MySQL逻辑架构</h2><img src="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/pic1.png" srcset="/img/loading.gif" class=""><h3 id="连接层"><a href="#连接层" class="headerlink" title="连接层"></a>连接层</h3><img src="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/pic2.png" srcset="/img/loading.gif" class=""><p>当MySQL启动（MySQL服务器就是一个进程），等待客户端连接，每一个客户端连接请求，服务器都会新建一个线程处理（如果是线程池的话，则是分配一个空的线程），每个线程独立，拥有各自的内存处理空间。</p><p>show VARIABLES like ‘%max_connections%’</p><img src="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/pic3.png" srcset="/img/loading.gif" class=""><p>连接到服务器，服务器需要对其进行验证，也就是用户名、IP、密码验证，一旦连接成功，还需要验证是否具有执行某个特定的查询权限。</p><h3 id="处理层"><a href="#处理层" class="headerlink" title="处理层"></a>处理层</h3><img src="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/pic4.png" srcset="/img/loading.gif" class=""><p>这一层主要功能有：SQL语句的解析、优化，缓存的查询，MySQL内置函数的实现，跨存储引擎功能（所谓跨存储引擎就是说每个引擎都需提供的功能（引擎需对外提供接口）），例如：存储过程、触发器、视图等。</p><pre><code>show variables like &#39;%query_cache_type%&#39;</code></pre><p>大概步骤为：</p><ol><li><p>如果是查询语句（select语句），首先会查询缓存是否已有相应结果，有则返回结果，无则进行下一步（如果不是查询语句，同样调到下一步）</p></li><li><p>解析查询，创建一个内部数据结构（解析树），这个解析树主要用来SQL语句的语义与语法解析；</p></li><li><p>优化：优化SQL语句，例如重写查询，决定表的读取顺序，以及选择需要的索引等。这一阶段用户是可以查询的，查询服务器优化器是如何进行优化的，便于用户重构查询和修改相关配置，达到最优化。这一阶段还涉及到存储引擎，优化器会询问存储引擎，比如某个操作的开销信息、是否对特定索引有查询优化等。</p></li></ol><h4 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h4><pre><code>show variables like  &#39;%query_cache_type%&#39;  -- 查看缓存类型，默认不开启show variables like  &#39;%query_cache_size%&#39;  -- 查看缓存空间大小，默认值1M</code></pre><p>query_cache_type只能在my.cnf文件中修改，使用set修改会报错，缓存只有在两次SQL连接的数据库、协议版本、字符集等因素完全一致时才会起作用。</p><p>具体配置方法：</p><ol><li><p>将query_cache_size设置为具体的大小，具体大小是多少取决于查询的实际情况，但最好设置为1024的倍数，参考值32M。</p></li><li><p>增加一行：query_cache_type=1</p></li><li><p>保存文件后重启MySQL服务。</p></li></ol><p>如：</p><pre><code>query_cache_size=128M query_cache_type=1</code></pre><h4 id="解析查询顺序"><a href="#解析查询顺序" class="headerlink" title="解析查询顺序"></a>解析查询顺序</h4><img src="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/pic5.png" srcset="/img/loading.gif" class=""><h4 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h4><p>SQL编辑器会对SQL语句进行优化，例如重写查询，决定表的读取顺序，以及选择需要的索引等。这一阶段还涉及到存储引擎，优化器会询问存储引擎，比如某个操作的开销信息、是否对特定索引有查询优化等。</p><h3 id="逻辑架构"><a href="#逻辑架构" class="headerlink" title="逻辑架构"></a>逻辑架构</h3><img src="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/pic6.png" srcset="/img/loading.gif" class=""><p>在mysql中schema与oracle schemas其实是不一样的，oracle中schemas的概念可理解为 “多个表（数据库对象）的集合，但在mysql中schema与database等价，只是为了兼容其他数据库，所以也提出了这个。如果通过sql语句删除schema，database也会被删除。</p><h3 id="物理存储结构"><a href="#物理存储结构" class="headerlink" title="物理存储结构"></a>物理存储结构</h3><p>mysql的数据文件都存放在dtadir中，其查看方式为<code>show VARIABLES like &#39;datadir&#39;</code>。当创建一个数据库时，datadir中也会新增一个同名目录，用户建立的表都会在这个目录中，表文件跟具体的存储引擎相关，但都有个后缀为frm的文件用来存放表结构。</p><p>frm文件可以通过安装mysql utilities工具来查看</p><pre><code>tar -zxvf mysql-utilities-1.6.5.tar.gz cd mysql-utilities-1.6.5python ./setup.py buildpython ./setup.py install</code></pre><p>通过以上步骤安装mysql utilities之后，运行以下命令就可以看到表结构</p><pre><code>mysqlfrm --diagnostic /usr/local/mysql/data/mall/account.frm </code></pre><h2 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h2><p>存储引擎是数据库的核心，对于mysql来说，存储引擎是以插件的形式运行的。MySQL允许在一个数据库中使用不同的存储引擎，综合实际需求选择存储引擎可以提升数据库的性能。可以通过<code>show engines;</code>查看数据库的支持的引擎，<code>show variables like &#39;%storage_engine%&#39;;</code>可以查看当前默认的存储引擎。</p><h3 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h3><p>使用这个存储引擎，每个MyISAM在磁盘上存储成三个文件。</p><ol><li><p>frm文件：存储表的定义数据</p></li><li><p>MYD文件：存放表具体记录的数据</p></li><li><p>MYI文件：存储索引</p></li></ol><p>frm和MYI可以存放在不同的目录下。MYI文件用来存储索引，但仅保存记录所在页的指针，索引的结构是B+树结构。这种索引跟数据分开存储的表也被称为堆表。</p><p>MyISAM支持表压缩，但是压缩之后的表就无法进行新增操作，需要再进行解压缩。</p><pre><code>myisampack -b -f /usr/local/mysql/data/mall/testmysam.MYI  -- 压缩myisamchk -r -f /usr/local/mysql/data/mall/testmysam.MYI  -- 解压缩</code></pre><p>MyISAM是不支持事务的，所以他的存储速度相比InnorDB也更快，如果读写操作允许有错误数据，只追求速度的话，可以选择这个存储引擎。不过由于现在innodb越来越强大，MyISAM已经停止维护，绝大多数场景下已经不适合MyISAM。</p><h3 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h3><p>InnoDB是默认的数据库存储引擎，他的主要特点有：</p><ul><li><p>可以通过自动增长列，方法是auto_increment。</p></li><li><p>支持事务。默认的事务隔离级别为可重复度，通过MVCC（并发版本控制）来实现的。</p></li><li><p>使用的锁粒度为行级锁，可以支持更高的并发；</p></li><li><p>支持外键约束；外键约束其实降低了表的查询速度，但是增加了表之间的耦合度。</p></li><li><p>配合一些热备工具可以支持在线热备份；</p></li><li><p>在InnoDB中存在着缓冲管理，通过缓冲池，将索引和数据全部缓存起来，加快查询的速度；</p></li><li><p>对于InnoDB类型的表，其数据的物理组织形式是聚簇表。所有的数据按照主键来组织。数据和索引放在一块，都位于B+数的叶子节点上；</p></li></ul><p>InnoDB的存储表和索引也有下面两种形式：</p><ul><li><p>使用共享表空间存储：所有的表和索引存放在同一个表空间中。</p></li><li><p>使用多表空间存储：表结构放在frm文件，数据和索引放在IBD文件中。分区表的话，每个分区对应单独的IBD文件，分区表的定义可以查看我的其他文章。使用分区表的好处在于提升查询效率。</p></li></ul><p>对于InnoDB来说，最大的特点在于支持事务。但是这是以损失效率来换取的。</p><h3 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h3><p>将数据存在内存，为了提高数据的访问速度，每一个表实际上和一个磁盘文件关联。文件是frm。</p><ul><li><p>支持的数据类型有限制，比如：不支持TEXT和BLOB类型，对于字符串类型的数据，只支持固定长度的行，VARCHAR会被自动存储为CHAR类型；</p></li><li><p>支持的锁粒度为表级锁。所以，在访问量比较大时，表级锁会成为MEMORY存储引擎的瓶颈；</p></li><li><p>由于数据是存放在内存中，一旦服务器出现故障，数据都会丢失；</p></li><li><p>查询的时候，如果有用到临时表，而且临时表中有BLOB，TEXT类型的字段，那么这个临时表就会转化为MyISAM类型的表，性能会急剧降低；</p></li><li><p>默认使用hash索引。</p></li><li><p>果一个内部表很大，会转化为磁盘表。</p></li></ul><img src="/2020/03/30/MySQL%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/pic7.png" srcset="/img/loading.gif" class=""><h3 id="CSV"><a href="#CSV" class="headerlink" title="CSV"></a>CSV</h3><p> CSV引擎类似Oracle的外部表。它将数据存储在“逗号分隔值（CSV）文件”中，但不支持在这种文件上建立相关索引，所有列也不允许为NULL。这种引擎支持从数据库中拷入/拷出CSV文件，比如从电子表格软件输出一个CSV文件，将其存放在MySQL服务器的数据目录中，服务器执行刷新表操作后（<code>flush table</code>），就能够马上读取相关的CSV文件。同样，如果写数据库到一个CSV表，外部程序也可以立刻读取它。在实现某种类型的日志记录时，CSV表作为一种数据交换格式，特别有用。</p><h3 id="Archive"><a href="#Archive" class="headerlink" title="Archive"></a>Archive</h3><p> 从archive单词的解释我们大概可以明白这个存储引擎的用途，这个存储引擎基本上用于数据归档；它的压缩比非常的高，存储空间大概是innodb的10-15分之一所以它用来存储历史数据非常的适合，由于它不支持索引同时也不能缓存索引和数据，所以它不适合作为并发访问表的存储引擎。Archivec存储引擎使用行锁来实现高并发插入操作，但是它不支持事务，而且只允许在自增id列上加索引，其设计目标只是提供高速的插入和压缩功能。</p><h3 id="Ferderated"><a href="#Ferderated" class="headerlink" title="Ferderated"></a>Ferderated</h3><p>Ferderated引擎将数据存储在远程MySQL上，本地只存储表结构和连接信息，相当于提供了一个远程访问MySQL服务器上表的方法。通常使用在统计分析和数据查询中，在游戏行业使用的比较多。</p><p>在MySQL中默认是禁止的，需要在my.ini配置文件中增加federated参数来启用。可以通过<code>show ENGINES</code>查看已经开启的引擎。具体使用如下</p><pre><code>CREATE TABLE `local_fed` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c1` varchar(10) NOT NULL DEFAULT &#39;&#39;, `c2` char(10) NOT NULL DEFAULT &#39;&#39;, PRIMARY KEY (`id`)) ENGINE=federated CONNECTION =&#39;mysql://root:root1234%@127.0.0.1:3306/remote/remote_fed&#39;</code></pre>]]></content>
    
    
    <categories>
      
      <category>MySQL进阶</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL基础</title>
    <link href="/2020/03/25/MySQL%E5%9F%BA%E7%A1%80/"/>
    <url>/2020/03/25/MySQL%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h2 id="MySQL安装"><a href="#MySQL安装" class="headerlink" title="MySQL安装"></a>MySQL安装</h2><p>Linux 使用的版本是centos 7，为方便起见先把防火墙关闭，配置好网络，在安装部分，会分成两部分首先会进行单实例安装，也就是一台服务器上就装一个mysql，接下来就多实例安装，在一个服务器上安装2个甚至多个mysql。</p><h3 id="单实例的安装"><a href="#单实例的安装" class="headerlink" title="单实例的安装"></a>单实例的安装</h3><ol><li><p>解压：将mysql-5.7.9-linux-glibc2.5-x86_64.tar.gz解压到/usr/local/目录下</p><pre><code>cp /soft/mysql-5.7.9-linux-glibc2.5-x86_64.tar.gz  /usr/local/tar -zxvf mysql-5.7.9-linux-glibc2.5-x86_64.tar.gz </code></pre></li><li><p>之后的步骤可以根据解压后目录中的INSTALL-BINARY文件来</p><pre><code>shell&gt; groupadd mysqlshell&gt; useradd -r -g mysql mysqlshell&gt; cd /usr/localshell&gt; tar zxvf /path/to/mysql-VERSION-OS.tar.gzshell&gt; ln -s full-path-to-mysql-VERSION-OS mysqlshell&gt; cd mysqlshell&gt; mkdir mysql-filesshell&gt; chmod 770 mysql-filesshell&gt; chown -R mysql .shell&gt; chgrp -R mysql .shell&gt; bin/mysqld --initialize --user=mysql     # MySQL 5.7.6 and up //这一步会出现数据库密码注意保存shell&gt; bin/mysql_ssl_rsa_setup              # MySQL 5.7.6 and upshell&gt; chown -R root .shell&gt; chown -R mysql data mysql-files //在此之前需要手动创建data目录shell&gt; bin/mysqld_safe --user=mysql &amp; //如果此时报错可以删除etc下的my.cnf文件之后再从bin/mysqld --initialize --user=mysql开始重新执行# Next command is optionalshell&gt; cp support-files/mysql.server /etc/init.d/mysql.server //可选项</code></pre></li><li><p>配置环境变量：</p><p>在<code>/etc/profile</code>中添加<code>export PATH=/usr/local/mysql/bin:$PATH</code></p><p>保存后输入<code>source /etc/profile</code>命令使配置生效</p></li><li><p>配置开启启动</p><p><code>chkconfig mysql.server on</code></p><p><code>chkconfig --list</code></p></li><li><p>登录、修改密码、允许远程登录</p><p><code>mysql -uroot  -p&#39;使用第二步中保存的密码&#39;</code></p><p>成功进入后：</p><p><code>set password = &#39;新密码&#39;;</code></p><p>允许远程登陆</p><p><code>GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;密码&#39;</code></p><p>刷新权限</p><p><code>flush privileges;</code></p></li></ol><h3 id="多实例的安装"><a href="#多实例的安装" class="headerlink" title="多实例的安装"></a>多实例的安装</h3><p>在mysql中已经考虑到了多实例安装的情况。也有相应的脚本命令的支持。</p><p>比如现在装两个mysql端口分别为3307、3308</p><ol><li><p>新建 /etc/my.cnf 配置如下</p><pre><code>[mysqld]sql_mode = &quot;STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION,NO_ZERO_DATE,NO_ZERO_IN_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER&quot;[mysqld_multi]mysqld = /usr/local/mysql/bin/mysqld_safemysqladmin = /usr/local/mysql/bin/mysqladminlog = /var/log/mysqld_multi.log[mysqld1] server-id = 11socket = /tmp/mysql.sock1port = 3307datadir = /data1user = mysqlperformance_schema = offinnodb_buffer_pool_size = 32Mskip_name_resolve = 1log_error = error.logpid-file = /data1/mysql.pid1[mysqld2]server-id = 12socket = /tmp/mysql.sock2port = 3308datadir = /data2user = mysqlperformance_schema = offinnodb_buffer_pool_size = 32Mskip_name_resolve = 1log_error = error.logpid-file = /data2/mysql.pid2</code></pre></li><li><p>创建2个数据目录</p><pre><code>mkdir /data1mkdir /data2</code></pre></li><li><p>初始化MySQL</p><pre><code>chown mysql.mysql /data{1..2}mysqld --initialize --user=mysql --datadir=/data1mysqld --initialize --user=mysql --datadir=/data2cp /usr/local/mysql/support-files/mysqld_multi.server /etc/init.d/mysqld_multid</code></pre></li><li><p>安装perl环境</p><pre><code>yum -y install perl perl-devel</code></pre></li><li><p>查看状态</p><pre><code>mysqld_multi report</code></pre></li><li><p>启动</p><pre><code>mysqld_multi start</code></pre></li><li><p>修改密码，允许远程连接</p><pre><code>mysql -u root -S /tmp/mysql.sock1 -p -P3307mysql -u root -S /tmp/mysql.sock2 -p -P3308set password = &#39;root1234%&#39;;GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;root1234%&#39;;flush privileges;  </code></pre></li></ol><h2 id="MySQL权限"><a href="#MySQL权限" class="headerlink" title="MySQL权限"></a>MySQL权限</h2><p>MySQL的权限简单的理解就是MySQK允许你做权限以内的事情，不可以越界。比如只允许你执行select操作，那么你就不能执行update操作。只允许你从某台机器上连接mysql，那么你就不能从除那台机器以外的其他机器连接mysql。</p><h3 id="简单使用"><a href="#简单使用" class="headerlink" title="简单使用"></a>简单使用</h3><pre><code>grant SELECT on mall.* TO &#39;dev&#39;@&#39;192.168.244.%&#39; IDENTIFIED BY &#39;123&#39; WITH GRANT OPTION;</code></pre><p>以上语可以创建一个拥有mall中所有表进行select操作，用户名为dev，密码为123，允许在网段192.168.0.*连接的用户。</p><pre><code>show grants for &#39;dev&#39;@&#39;192.168.244.%&#39;</code></pre><p>这条命令可以输出刚才创建的dev用户的权限</p><h3 id="用户标识"><a href="#用户标识" class="headerlink" title="用户标识"></a>用户标识</h3><p>在MySQL中的权限不是单纯的赋予给用户的，而是赋予给”用户+IP”的。</p><p>比如dev用户是否能登陆，用什么密码登陆，并且能访问什么数据库等都需要加上IP，这样才算一个完整的用户标识，换句话说 ‘dev’@’192.168.0.168’ 、‘dev’@’127.0.0.1’与‘dev’@’localhost’ 这3个是完全不同的用户标识（哪怕你本机的ip就是192.168.0.168）。</p><h3 id="用户权限所涉及的表"><a href="#用户权限所涉及的表" class="headerlink" title="用户权限所涉及的表"></a>用户权限所涉及的表</h3><p>在mysql库中中存在4个控制权限的表，<code>分别为user表，db表，tables_priv表，columns_priv表</code></p><ul><li>user：存储用户标识</li><li>db：用户对数据库的权限</li><li>table_priv：用户对表的权限</li><li>column_priv：用户对某一列的权限</li></ul><p>MySQL的权限粒度甚至可以细化到某一列上。</p><pre><code>grant select(id,name) on mall.account to &#39;dev&#39;@&#39;192.168.244.%&#39;;</code></pre><p>这条语句可以将mall数据库中account表的id跟name的查询条件给‘dev’@’192.168.244.%’用户，但如果用户之前拥有更高的权限，会以之前权限为准，所以要想生效就需要移除‘dev’@’192.168.244.%’用户之前的权限。</p><pre><code>revoke select on mail.* from &#39;dev&#39;@&#39;192.168.244.%&#39;;</code></pre><p>此时再使用‘dev’@’192.168.244.%’用户查看表account时可能会报错，此时可以用过以下语句查看是否设置成功。</p><pre><code>select id,name from account;</code></pre><h2 id="MySQL的角色"><a href="#MySQL的角色" class="headerlink" title="MySQL的角色"></a>MySQL的角色</h2><p> MySql基于”用户+IP”的这种授权模式在设置给多个用户设置相同权限时会比较繁琐。所以MySQL官方在5.7之后推出“Role Like”功能来实现类似角色的功能，更加方便管理多个同样权限的账户。</p><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><ol><li><p>检查是否开启角色功能</p><pre><code>show variables like &quot;%proxy%&quot;</code></pre></li><li><p><code>check_proxy_users</code>，<code>mysql_native_password_proxy_users</code>这两个变量需要设置成true</p><pre><code>set GLOBAL check_proxy_users =1;set GLOBAL mysql_native_password_proxy_users = 1;</code></pre></li></ol><h3 id="简单使用-1"><a href="#简单使用-1" class="headerlink" title="简单使用"></a>简单使用</h3><ol><li><p>创建一个dev_role用户</p><pre><code>create USER &#39;dev_role&#39;</code></pre></li><li><p>在创建两个用户</p><pre><code>create USER &#39;test1&#39;create USER &#39;test2&#39;</code></pre></li><li><p>把两个用户加到组里面</p><pre><code>grant proxy on &#39;dev_role&#39; to &#39;test1&#39;grant proxy on &#39;dev_role&#39; to &#39;test2&#39;</code></pre></li><li><p>如果是远程连接需要给远程连接的ROOTGRANT权限</p><pre><code>GRANT PROXY ON &#39;&#39;@&#39;&#39; TO &#39;root&#39;@&#39;%&#39; WITH GRANT OPTION;</code></pre></li><li><p>给<code>dev_role</code>设置权限</p><pre><code>grant select(id,name) on mall.account to &#39;dev_role&#39;</code></pre></li></ol><h2 id="MySQL的数据类型"><a href="#MySQL的数据类型" class="headerlink" title="MySQL的数据类型"></a>MySQL的数据类型</h2><h3 id="int类型"><a href="#int类型" class="headerlink" title="int类型"></a>int类型</h3><table><thead><tr><th><strong>类型</strong></th><th><strong>字节</strong></th><th><strong>最小值</strong>（有符号/无符号）</th><th><strong>最大值</strong>（有符号/无符号）</th></tr></thead><tbody><tr><td>TINYINT</td><td>1</td><td>-128 / 0</td><td>127 / 255</td></tr><tr><td>SMALLINT</td><td>2</td><td>-32768 / 0</td><td>32767/65535</td></tr><tr><td>MEDIUMINT</td><td>3</td><td>-8388608 / 0</td><td>8388607/16777215</td></tr><tr><td>INT</td><td>4</td><td>-2147483648 / 0</td><td>2147483647/4294967295</td></tr><tr><td>BIGINT</td><td>8</td><td>-9223372036854775808 / 0</td><td>9223372036854775807/18446744073709551615</td></tr></tbody></table><p>注：</p><ul><li>项目中通常使用有符号的BIGINT。</li><li>int(N)中N是指显示宽度，并不是最大存储长度，如果开启zerofill（填充0），在数据长度未达到N时会在左侧填充数字0至N（可视化工具中可能会将左侧的0屏蔽）。</li><li>自动增长只能用于主键，且只有主键类型为NULL时会触发。</li></ul><h3 id="字符类型"><a href="#字符类型" class="headerlink" title="字符类型"></a>字符类型</h3><table><thead><tr><th>类型</th><th>说明</th><th>N的含义</th><th>是否有字符集</th><th>最大长度</th></tr></thead><tbody><tr><td>CHAR(N)</td><td>定长字符</td><td>字符</td><td>是</td><td>255</td></tr><tr><td>VARCHAR(N)</td><td>变长字符</td><td>字符</td><td>是</td><td>16384</td></tr><tr><td>BINARY(N)</td><td>定长二进制字节</td><td>字节</td><td>否</td><td>255</td></tr><tr><td>VARBINARY(N)</td><td>变长二进制字节</td><td>字节</td><td>否</td><td>16384</td></tr><tr><td>TINYBLOB(N)</td><td>二进制大对象</td><td>字节</td><td>否</td><td>256</td></tr><tr><td>BLOB(N)</td><td>二进制大对象</td><td>字节</td><td>否</td><td>16K</td></tr><tr><td>MEDIUMBLOB(N)</td><td>二进制大对象</td><td>字节</td><td>否</td><td>16M</td></tr><tr><td>LONGBLOB(N)</td><td>二进制大对象</td><td>字节</td><td>否</td><td>4G</td></tr><tr><td>TINYTEXT(N)</td><td>大对象</td><td>字节</td><td>是</td><td>256</td></tr><tr><td>TEXT(N)</td><td>大对象</td><td>字节</td><td>是</td><td>16K</td></tr><tr><td>MEDIUMTEXT(N)</td><td>大对象</td><td>字节</td><td>是</td><td>16M</td></tr><tr><td>LONGTEXT(N)</td><td>大对象</td><td>字节</td><td>是</td><td>4G</td></tr></tbody></table><p>注：</p><ul><li>排序规则中_ci为不区分大小写比较，_cs为区分大小写比较，_bin为使用二进制编码比较。</li><li>utf8_unicode_ci和utf8_general_ci对中、英文来说没有实质的差别。utf8_general_ci校对速度快，但准确度稍差，utf8_unicode_ci准确度高，但校对速度稍慢。如果你的应用有德语、法语或者俄语，请一定使用utf8_unicode_ci，其余情况下utf8_general_ci就够了。</li><li>除char，varchar中的N表示字符长度外，其余类型中的N均表示字节长度。</li></ul><h3 id="时间类型"><a href="#时间类型" class="headerlink" title="时间类型"></a>时间类型</h3><table><thead><tr><th>日期类型</th><th>占用空间</th><th>表示范围</th></tr></thead><tbody><tr><td>DATETIME</td><td>8</td><td>1000-01-01 00:00:00 ~ 9999-12-31 23:59:59</td></tr><tr><td>DATE</td><td>3</td><td>1000-01-01 ~ 9999-12-31</td></tr><tr><td>TIMESTAMP</td><td>4</td><td>1970-01-01 00:00:00UTC ~ 2038-01-19 03:14:07UTC</td></tr><tr><td>YEAR</td><td>1</td><td>YEAR(2):1970-2070, YEAR(4):1901-2155</td></tr><tr><td>TIME</td><td>3</td><td>-838:59:59 ~ 838:59:59</td></tr></tbody></table><p>注：datetime与timestamp区别在于，再修改时区后timestamp会相应的变化，datetime不会。</p><h3 id="JSON类型"><a href="#JSON类型" class="headerlink" title="JSON类型"></a>JSON类型</h3><p>MySQK5.7开始引入JSON数据类型用来保存JSON类型的数据，与varchar的区别在于</p><ul><li>MySQL提供了一组操作JSON数据的内置函数。</li></ul><ul><li>JSON数据类型会自动校验数据是否为JSON格式，如果不是JSON格式数据，则会报错。</li><li>存储在JSON列中的JSON数据被转换成内部的存储格式，允许快速读取。</li><li>可以修改特定的键值</li></ul><h3 id="相关的内置函数"><a href="#相关的内置函数" class="headerlink" title="相关的内置函数"></a>相关的内置函数</h3><ul><li><p>json_type：显示当前JSON字符串的类型，如<code>select json_type(&#39;[&quot;test1&quot;,&quot;test2&quot;,&quot;test3&quot;]&#39;);</code>输出结果为：<code>ARRAY</code></p></li><li><p>json_array：将数组对象转为JSON数组，如<code>select json_array(1,now(),&quot;test&quot;);</code>输出结果为：<code>[1, &quot;2020-03-29 20:44:41.000000&quot;, &quot;test1&quot;]</code></p></li><li><p>json_object：将对象转为JSON格式数据，如<code>select json_object(&quot;name&quot;, &quot;enjoy&quot;, &quot;email&quot;, &quot;enjoy.com&quot;, &quot;age&quot;,35);</code>输出结果为：<code>{&quot;age&quot;: 35, &quot;name&quot;: &quot;enjoy&quot;, &quot;email&quot;: &quot;enjoy.com&quot;}</code></p></li><li><p>json_extract：可以提取JSON格式中的属性，如<code>select json_extract(&#39;[10, 20, [30, 40]]&#39;, &#39;$[1]&#39;);</code>输出结果为：<code>20</code></p></li><li><p>json_insert：向JSON中插入数据，如果已存在则不会修改，如</p><pre><code> set @json = &#39;{ &quot;a&quot;: 1, &quot;b&quot;: [2, 3]}&#39;; select json_insert(@json, &#39;$.a&#39;, 10, &#39;$.c&#39;, &#39;[true, false]&#39;);</code></pre><p>输出结果为：<code>{&quot;a&quot;: 1, &quot;b&quot;: [2, 3], &quot;c&quot;: &quot;[true, false]&quot;}</code></p></li><li><p>json_merge：合并数据并返回，如<code>select json_merge(&#39;{&quot;name&quot;: &quot;enjoy&quot;}&#39;, &#39;{&quot;id&quot;: 47}&#39;);</code>输出结果为：<code>{&quot;id&quot;: 47, &quot;name&quot;: &quot;enjoy&quot;}</code></p></li></ul><p><a href="https://dev.mysql.com/doc/refman/5.7/en/json-function-reference.html" target="_blank" rel="noopener">其他函数</a></p><h3 id="JSON类型的索引"><a href="#JSON类型的索引" class="headerlink" title="JSON类型的索引"></a>JSON类型的索引</h3><p>由于JSON类型数据本身无法直接创建索引，所以将要建立索引的JSON数据中的字段，重新生成虚拟字段（Virtual Columns）之后，再对该字段进行索引。</p><pre><code>create table test( data json, gen_col varchar(10) generated always as (data-&gt;&gt;&#39;$.name&#39;),  index idx (gen_col) );</code></pre><p>上面的语句将为test表中data字段中的name属性创建名为gen_col的虚拟字段，再为gen_col创建名为idx的索引。</p>]]></content>
    
    
    <categories>
      
      <category>MySQL进阶</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>编写高效优雅的Java代码</title>
    <link href="/2020/03/24/%E7%BC%96%E5%86%99%E9%AB%98%E6%95%88%E4%BC%98%E9%9B%85%E7%9A%84Java%E4%BB%A3%E7%A0%81/"/>
    <url>/2020/03/24/%E7%BC%96%E5%86%99%E9%AB%98%E6%95%88%E4%BC%98%E9%9B%85%E7%9A%84Java%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<h3 id="避免过多的构造器参数"><a href="#避免过多的构造器参数" class="headerlink" title="避免过多的构造器参数"></a>避免过多的构造器参数</h3><p>如果参数过多，会导致构造方法非常复杂、拓展性差、难以理解。</p><p>可以使用get()、set()方法对非必须的属性进行设置，构造方法中只包含必须的属性，将原本的一行代码转为多行代码。</p><p>还可以使用建造者模式，一般有</p><ol><li>抽象建造者：一般来说是个接口，包含1）建造方法，建造部件的方法（不止一个），2）返回产品的方法</li><li>具体建造者</li><li>导演者，调用具体的建造者，创建产品对象</li><li>产品，需要建造的复杂对象</li></ol><p>使用时需要创建导演者和具体建造者，并把具体建造者交给导演者，然后通知导演者操纵建造者进行产品的创建。在实际的应用过程中，有时会省略抽象建造者和导演者。建造者模式的代码易于阅读和编写，相对于上一种方式更加安全。</p><pre><code>/** * 建造者模式（简单版） */public class BoxBuilder {    //required必须参数    private  final String name;//礼盒名称    private  final int price;//礼盒价格    //optional可选参数    private   int zz;//粽子    private   int xyd;//咸鸭蛋    private   int ldg;//绿豆糕    private   int yb;//月饼    private   int jg;//坚果    //具体建造者    public static class Builder{        //required必须参数        private  final String name;//礼盒名称        private  final int price;//礼盒价格        //optional可选参数        private   int zz;//粽子        private   int xyd;//咸鸭蛋        private   int ldg;//绿豆糕        private   int yb;//月饼        private   int jg;//坚果        //构造方法        public Builder(String name, int price) {            super();            this.name = name;            this.price = price;        }        //建造方法        public BoxBuilder builder(){            return new BoxBuilder(this);        }        public Builder zz(int value){            this.zz=value;            return this;        }        public Builder xyd(int value){            this.xyd=value;            return this;        }        //......    }    private BoxBuilder (Builder builder){        name = builder.name;        price =builder.price;        zz =builder.zz;        xyd =builder.xyd;        ldg=builder.ldg;        yb=builder.yb;        jg=builder.jg;    }    public static void main(String[] args) {        BoxBuilder box1 = new Builder(&quot;端午节礼盒1&quot;,120)                .zz(8)                .xyd(4)                .builder();    }}</code></pre><h3 id="类构造器私有化"><a href="#类构造器私有化" class="headerlink" title="类构造器私有化"></a>类构造器私有化</h3><p>一些不需要实例化的类比如工具类，这些类是不应该提供具体实例的，此时可以将构造函数私有化，防止使用者new出实例。</p><h4 id="不要创建不必要的对象"><a href="#不要创建不必要的对象" class="headerlink" title="不要创建不必要的对象"></a>不要创建不必要的对象</h4><ol><li><p>避免无意中创建的对象，如自动装箱，<code>String a = new String(&quot;a&quot;)</code>等</p></li><li><p>尽量重用不可变的对象，以及不会被修改的对象。</p></li><li><p>使用静态工厂替代构造方法可以避免过多的创建对象。</p></li><li><p>通过维护对象池（pool）来避免创建对象并不是一种好的做法，除非是重量级的对象，比如数据库的连接等。</p></li></ol><h3 id="避免使用终结方法"><a href="#避免使用终结方法" class="headerlink" title="避免使用终结方法"></a>避免使用终结方法</h3><p>jdk不能保证finalizer方法何时执行，也不能保证一定会执行，如果需要释放资源可以使用try/finally。</p><h3 id="使类和成员的可访问性最小化"><a href="#使类和成员的可访问性最小化" class="headerlink" title="使类和成员的可访问性最小化"></a>使类和成员的可访问性最小化</h3><p>模块对外部其他模块来说，隐藏其内部数据和其他实现细节–封装</p><p>编写程序和设计架构，最重要的目标之一就是模块之间的解耦。使类和成员的可访问性最小化无疑是有效的途径之一。让每个类或成员尽可能的不可访问，即使用尽可能低的实现细节，避免公开公共类的成员，在仔细设计类公共方法之后，让所有成员设计为私有的。 只有当同一个包中的其他类真的需要访问成员时，再去修改私有修饰符，从而使成员包成为包级私有的。</p><p>对于成员(属性、方法、嵌套类和嵌套接口)，有四种可能的访问级别，在这里，按照可访问性从小到大列出：</p><ul><li><p>private：该成员只能在声明它的顶级类内访问。</p></li><li><p>package-private：成员可以从被声明的包中的任何类中访问。从技术上讲，如果没有指定访问修饰符(接口成员除外，它默认是公共的)，这是默认访问级别。</p></li><li><p>protected：成员可以从被声明的类的子类中访问(受一些限制，JLS，6.6.2)，以及它声明的包中的任何类。</p></li><li><p>public：该成员可以从任何地方被访问。</p></li></ul><h3 id="使可变性最小"><a href="#使可变性最小" class="headerlink" title="使可变性最小"></a>使可变性最小</h3><p>不可变类只是其实例不能被修改的类。每个实例中包含的所有信息都必须在创建该实例的时候就提供，并在对象的整个生命周期内固定不变。Java平台类库中包含许多不可变的类，其中有String、基本类型的包装类、BigInteger和BigDecimal。存在不可变的类有许多理由：不可变的类比可变的泪更加易于设计、实现和使用。他们不容易出错，且更加安全。</p><p>为了使类成为不可变，要遵循下面五条规则：</p><ul><li><p>不要提供任何会修改对象状态的方法。</p></li><li><p>保证类不会被扩展。为了防止子类化，一般做法是使这个类成为final的 。</p></li><li><p>使所有的域都是final的。一是为了表明意图，二是为了在多线程间确保对对象使用正确的行为。</p></li><li><p>使所有的域都成为私有的。这样可以防止客户端获得访问被域引用的可变对象的权限，并防止客户端直接修改这些对象。</p></li><li><p>确保对于任何可变组件的互斥访问。如果类具有指向可变对象的域，则必须确保该类的使用者无法获得指向这些对象的引用。并且，永远不要对使用者提供的对象引用来初始化这样的域，也不要从任何方法中返回该对象引用。</p></li></ul><h3 id="复合优先于继承"><a href="#复合优先于继承" class="headerlink" title="复合优先于继承"></a>复合优先于继承</h3><p>你永远不知道你的用户是如何使用你写的产品，同样使用继承拓展一个其他人的类也是危险的。父类的具体实现很容易影响子类的正确性。尽量不使用继承扩展现有的类，而是在新类中引用现有的类，这种设计称为复合（Composition）。</p><h3 id="接口优于抽象类"><a href="#接口优于抽象类" class="headerlink" title="接口优于抽象类"></a>接口优于抽象类</h3><p>由于Java只允许单继承的，当发生业务变化需要新增业务方法时，使用抽象类有可能导致不需要变化的其他子类也不得不实现新增的业务方法，如果使用接口，只需要在实现中增加新创建的接口即可。</p><p>JDK源码通常声明一个抽象的骨架类实现接口，骨架类类实现通用的方法，实际业务类可以同时实现接口又继承骨架类，也可以只实现接口。如HashSet实现了Set接口 但是继承AbstractSet类，而AbstractSet本身也实现了Set接口。其他如Map，List都是这样的设计的。</p><h3 id="慎用可变参数"><a href="#慎用可变参数" class="headerlink" title="慎用可变参数"></a>慎用可变参数</h3><p>在定义参数数目不定的方法时，可变参数方法是一种很方便的方式，但是他们不应该被过渡滥用。如果使用不当，会产生混乱的结果。</p><p>可变参数的机制原理：</p><ol><li><p>创建一个array[]，它的size就是所传参数的个数；</p></li><li><p>将参数放入到array[]中；</p></li><li><p>将array[]传给方法。</p></li></ol><p>可变参数方法是允许传入0个参数或者null的，而且编译时正常但会在运行时失败。可变参数方法的每次调用都会进行一次数组分配和初始化，对系统性能有一定影响。</p><h3 id="返回空的数组或集合，不要返回null"><a href="#返回空的数组或集合，不要返回null" class="headerlink" title="返回空的数组或集合，不要返回null"></a>返回空的数组或集合，不要返回null</h3><p>如果方法的结果返回null，会导致开发者的要单独处理为null的情况。这样的方法比较难以使用，更容易出错，并且没有性能优势。而返回零长度，调用方可以统一处理，如使用foreach即可。</p><p>JDK提供的空集合：<code>Collections.emptyList()</code>、<code>Collections.emptySet()</code>、<code>Collections.emptyMap</code></p><h3 id="优先使用标准的异常"><a href="#优先使用标准的异常" class="headerlink" title="优先使用标准的异常"></a>优先使用标准的异常</h3><p>代码重用是值得提倡的，这是一条通用的规则，异常也不例外。Java平台类库提供了一组基本的未受检的异常，他们满足了绝大多数API的异常抛出需要。</p><p>常用的异常：</p><ul><li><p>IllegalArgumentException：调用者传递的参数不合适</p></li><li><p>IllegalStateException：接收的对象状态不对，</p></li><li><p>NullPointerException：对象为空</p></li><li><p>UnsupportedOperationException：不支持的操作</p></li><li><p>ConcurrentModificationExccetion：禁止并发修改时，监测到对象的并发修改</p></li></ul><p>重用现有的异常有多方面的好处。其中最主要的好处是使代码更加易于学习和使用，现有异常大多是是开发者已知的，他们的可读性会更好。还有就是异常类越少，意味着需要加载的类越少，装载这些类的时间开销也越少。</p><h3 id="用枚举代替int常量"><a href="#用枚举代替int常量" class="headerlink" title="用枚举代替int常量"></a>用枚举代替int常量</h3><p>针对int常量以下不足： </p><ol><li>在类型安全方面，使用相同的常量值的两个常量，编译器并不能检测出错误； </li><li>因为int常量是编译时常量，被编译到使用它们class文件中。若常量发生变化，相关类必须重新编译，否则它们的行为就不确定； </li><li>想要描述常量是比较困难的。</li></ol><p>枚举高级用法：</p><ul><li><p>枚举常量与数据关联：枚举常量可以与数据相关，可以在其构造方法中加入逻辑代码，然后在枚举中提供新的属性以存放和返回结果信息。</p></li><li><p>枚举常量与行为关联：枚举常量还可以与行为关联，如实现四则运算</p><pre><code>public enum Operation {  PLUS(&quot;+&quot;) {    @Override    double apply(double x, double y) {      return x + y;    }  },  MINUS(&quot;-&quot;) {    @Override    double apply(double x, double y) {      return x - y;    }  },  TIMES(&quot;*&quot;) {    @Override    double apply(double x, double y) {      return x * y;    }  },  DIVIDE(&quot;/&quot;) {    @Override    double apply(double x, double y) {      return x / y;    }  };  private String symbol;  Operation(String symbol) {    this.symbol = symbol;  }  @Override  public String toString() {    return symbol;  }  abstract double apply(double x, double y);}</code></pre></li><li><p>枚举策略模式：以下代码是计算工人工资。平时工作8小时，超过8小时，以加班工资方式另外计算，如果是双休日，都按照加班方式处理工资。</p><pre><code>public enum PayRoll {  MONDY(PayType.WEEKDAY),  TUESDAY(PayType.WEEKDAY),  WEDNESDAY(PayType.WEEKDAY),  THURSDAY(PayType.WEEKDAY),  FRIDAY(PayType.WEEKDAY),  SATURDAY(PayType.WEEKEND),  SUNDAY(PayType.WEEKEND);  private final PayType payType;  PayRoll(PayType payType) {    this.payType = payType;  }  double pay(double hoursWorked, double payRate) {    return payType.pay(hoursWorked, payRate);  }  private enum PayType {    WEEKDAY {      @Override      double overtimePay(double hoursWorked, double payRate) {        double overtime = hoursWorked - HOURS_PER_SHIFT;        return overtime &lt;= 0 ? 0 : overtime * payRate / 2;      }    },    WEEKEND {      @Override      double overtimePay(double hoursWorked, double payRate) {        return hoursWorked * payRate / 2;      }    };    private static final int HOURS_PER_SHIFT = 8;    abstract double overtimePay(double hoursWorked, double payRate);    double pay(double hoursWorked, double payRate) {      double basePay = hoursWorked * payRate;      return basePay + overtimePay(hoursWorked, payRate);    }  }}</code></pre></li></ul><h3 id="将局部变量的作用域最小化"><a href="#将局部变量的作用域最小化" class="headerlink" title="将局部变量的作用域最小化"></a>将局部变量的作用域最小化</h3><p>将局部变量的作用域最小化，可以增强代码的可读性和可维护性，并降低出错的可能性。</p><ul><li>使一个局部变量的作用域最小化，最有力的技术是在第一次使用它的地方声明。如果变量在使用之前进行声明，这只会造成混乱————对于试图理解程序功能的读者来说，这又多了一种只会分散他们注意力的因素。等到用到该变量的时候，读者可能已经记不起该变量的类型或者初始值了。</li><li>尽量使局部变量的声明都包含一个初始化表达式，如果初始化条件不满足，就需要推迟声明。</li><li>使方法体尽可能小而集中 ，如果把两个操作（activity）合并到同一个方法中，与其中一个操作相关的局部变量就有可能会出现在执行另一个操作的代码范围之内。此时可以把这个方法分成两个，每个方法各执行一个操作。</li></ul><h3 id="精确计算，避免使用float和double"><a href="#精确计算，避免使用float和double" class="headerlink" title="精确计算，避免使用float和double"></a>精确计算，避免使用float和double</h3><p>float和double主要为了科学计算和工程计算而设计，执行二进制浮点运算，这是为了在广泛的数值范围上提供较为精确的快速近似计算而精心设计的。然而，它们没有提供完全精确的结果，所以不适合用于需要精确结果的场合，尤其是货币计算。</p><p>可以使用BigDecimal来解决这个问题，BigDecimal还提供了八种舍入模式来让开发者完全控制舍入，然而使用BigDecimal有两个缺点：与使用基本运算类型相比，这样做很不方便，而且很慢。</p><p>除了使用BigDecimal之外，还有一种办法是使用int或者long，到底选用int或者long，到底选用int或者long要取决于所涉及数值的大小，同时要自己处理十进制小数点。</p><h3 id="当心字符串连接的性能"><a href="#当心字符串连接的性能" class="headerlink" title="当心字符串连接的性能"></a>当心字符串连接的性能</h3><p>在存在大量字符串拼接或者大型字符串拼接的时候，尽量使用StringBuilder和StringBuffer，不要使用字符串连接操作符来合并多个字符串，除非性能无关紧要。</p><h3 id="控制方法的大小"><a href="#控制方法的大小" class="headerlink" title="控制方法的大小"></a>控制方法的大小</h3><p>尽量将方法长度控制的尽量小，方法复杂度&gt;=代码行数^2，当代码超过10行以上时，方法的复杂度就会大幅攀升，超过500行的代码可维护性就会大打折扣。</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>JVM</tag>
      
      <tag>Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入了解性能优化</title>
    <link href="/2020/03/23/%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    <url>/2020/03/23/%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="虚拟机优化技术-逃逸分析"><a href="#虚拟机优化技术-逃逸分析" class="headerlink" title="虚拟机优化技术-逃逸分析"></a>虚拟机优化技术-逃逸分析</h2><p>逃逸分析（Escape Analysis）是目前JVM中比较前沿的优化技术，它不是直接的优化手段而是为其他优化手段提供依据的分析技术，逃逸分析的基本行为就是分析对象动态作用域。简单来讲就是，Java Hotspot 虚拟机可以分析新创建对象的使用范围，并决定是否在 Java 堆上分配内存的一项技术。</p><p><strong>相关的JVM参数：</strong></p><ul><li><p>-XX:+DoEscapeAnalysis：启用逃逸分析(默认打开)</p></li><li><p>-XX:-DoEscapeAnalysis：关闭逃逸分析</p></li><li><p>-XX:+PrintEscapeAnalysis：显示分析结果</p></li><li><p>-XX:+EliminateAllocations：标量替换(默认打开) </p></li><li><p>-XX:+UseTLAB 本地线程分配缓冲(默认打开) </p></li></ul><p>开启逃逸分析创建的对象可以在栈上分配，对象的生命周期就跟随线程，不需要进行垃圾回收，在频繁的调用方法的情况下可以得到很大的性能提高。但由于线程私有的分配缓冲比较小，约为Eden的百分之一，所以大对象的分配还是会在堆中进行。</p><p>使用了逃逸分析时对象在栈上分配：</p><img src="/2020/03/23/%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic1.png" srcset="/img/loading.gif" class=""><p>没有使用逃逸分析时对象都在堆上分配（触发频次GC，加重负担）：</p><img src="/2020/03/23/%E6%B7%B1%E5%85%A5%E4%BA%86%E8%A7%A3%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic2.png" srcset="/img/loading.gif" class=""><h2 id="常用的性能评价-测试指标"><a href="#常用的性能评价-测试指标" class="headerlink" title="常用的性能评价/测试指标"></a>常用的性能评价/测试指标</h2><p>一个web应用不是一个孤立的个体，它是一个系统的部分，系统中的每一部分都会影响整个系统的性能</p><p><strong>响应时间</strong></p><p>提交请求和返回该请求的响应之间使用的时间，一般比较关注平均响应时间。</p><p>常用操作的响应时间列表：</p><table><thead><tr><th>操作</th><th>响应时间</th></tr></thead><tbody><tr><td>打开一个站点</td><td>几秒</td></tr><tr><td>数据库查询一条记录（有索引）</td><td>十几毫秒</td></tr><tr><td>机械磁盘一次寻址定位</td><td>4毫秒</td></tr><tr><td>从机械磁盘顺序读取1M数据</td><td>2毫秒</td></tr><tr><td>从SSD磁盘顺序读取1M数据</td><td>0.3毫秒</td></tr><tr><td>从远程分布式换成Redis读取一个数据</td><td>0.5毫秒</td></tr><tr><td>从内存读取1M数据</td><td>十几微妙</td></tr><tr><td>Java程序本地方法调用</td><td>几微妙</td></tr><tr><td>网络传输2Kb数据</td><td>1微妙</td></tr></tbody></table><p><strong>并发数</strong></p><p>同一时刻，对服务器有实际交互的请求数。</p><p>和网站在线用户数的关联：1000个同时在线用户数，可以估计并发数在5%到15%之间，也就是同时并发数在50~150之间。</p><p><strong>吞吐量</strong></p><p>对单位时间内完成的工作量（请求）的量度</p><p><strong>关系</strong></p><p>系统吞吐量和系统并发数以及响应时间的关系：</p><p>吞吐量可以理解为单位时间内响应请求的次数，并发数是同一时刻的请求数。</p><p>响应时间是车速。</p><p>当请求数很少时，响应速度比较快，但是单位时间的响应也比较少，所以吞吐量也比较少，。随着请求数的增多，响应速度会收到影响，但是吞吐量会增加的很快；请求数的继续增加，响应速度影响比较大，单位时间内完成的请求次数会受到影响，会进一步影响到吞吐量；</p><p>如果请求数继续增加，导致系统资源耗尽，系统将会无法完成响应。</p><h2 id="常用的性能优化手段"><a href="#常用的性能优化手段" class="headerlink" title="常用的性能优化手段"></a>常用的性能优化手段</h2><p><strong>避免过早优化</strong></p><p>项目初期，我们应该着重于编写清晰，直接，易读和易理解高效优雅的代码，真正的优化应该留到以后，等到性能分析表明优化措施有巨大的收益时再进行。</p><p><strong>不应该把大量的时间耗费在小的性能改进上，过早考虑优化是所有噩梦的根源。</strong></p><p><strong>进行系统性能测试</strong></p><p>所有的性能调优，都有应该建立在性能测试的基础上，直觉很重要，但是要用数据说话，可以推测，但是要通过测试求证。</p><p><strong>寻找系统瓶颈，分而治之，逐步优化</strong></p><p>性能测试后，对整个请求经历的各个环节进行分析，排查出现性能瓶颈的地方，定位问题，分析影响性能的的主要因素，如内存、磁盘IO、网络、CPU、代码问题、架构设计、系统资源等。</p><h3 id="前端优化常用手段（了解即可）"><a href="#前端优化常用手段（了解即可）" class="headerlink" title="前端优化常用手段（了解即可）"></a>前端优化常用手段（了解即可）</h3><ul><li><p><strong>合并请求</strong></p><p>合并CSS，Js，图片请求，使用http中的keep-alive减少连接消耗（http1.1中默认开启，包括nginx）</p></li><li><p><strong>使用客户端缓冲</strong></p><p>将静态资源文件（css、图标等）缓存在浏览器中，可以通过Cache-Control（相对时间）和Expires设置相关的属性，如果文件发生了变化，需要更新，则通过改变文件名来解决。</p></li><li><p><strong>启用压缩</strong></p><p>使用压缩可以减少网络传输量，但也会给浏览器和服务器带来性能的压力，需要权衡使用。</p></li><li><p><strong>资源文件加载顺序</strong></p><p>css放在页面前，js放在页面后，JS只要加载后就会立刻执行，有些JS可能执行时间比较长影响css加载速度，浏览器在加载完CSS才会对页面进行渲染。</p></li><li><p><strong>减少Cookie传输</strong></p><p>cookie包含在每次的请求和响应中，因此哪些数据写入cookie需要慎重考虑（静态资源不需要放入cookie）</p></li><li><p><strong>友好的提示（非技术手段）</strong></p><p>有时候在给用户一个提示，就能收到良好的效果。</p></li><li><p><strong>CDN加速</strong></p><p>CDN，又称内容分发网络，本质是一个缓存，而且是将数据缓存在用户最近的地方。无法自行实现CDN的时候，可以根据经济实力考虑商用CDN服务。</p></li><li><p><strong>反向代理缓存（动静分离）</strong></p><p>将静态资源文件缓存在反向代理服务器上，一般是Nginx。</p></li><li><p><strong>WEB组件分离</strong></p><p>将js，css和图片文件放在不同的域名下。可以提高浏览器在下载web组件的并发数。因为浏览器在下载同一个域名的的数据存在并发数限制。</p></li></ul><h3 id="应用服务性能优化"><a href="#应用服务性能优化" class="headerlink" title="应用服务性能优化"></a>应用服务性能优化</h3><h4 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h4><p>网站性能优化第一定律：优先考虑使用缓存优化性能</p><h5 id="缓存的基本原理和本质"><a href="#缓存的基本原理和本质" class="headerlink" title="缓存的基本原理和本质"></a>缓存的基本原理和本质</h5><p>缓存是将数据存在访问速度较高的介质中，减少数据访问的时间，同时避免重复计算。</p><h5 id="合理使用缓存的准则"><a href="#合理使用缓存的准则" class="headerlink" title="合理使用缓存的准则"></a>合理使用缓存的准则</h5><ul><li><p>频繁修改的数据，尽量不要缓存，读写比2:1以上才有缓存的价值。</p></li><li><p>缓存一定是热点数据。</p></li><li><p>应用能够容忍一定时间的数据不一致。</p></li><li><p>缓存可用性问题，一般通过热备或者集群来解决。 </p></li></ul><h5 id="分布式缓存"><a href="#分布式缓存" class="headerlink" title="分布式缓存"></a>分布式缓存</h5><p>以集群的方式提供缓存服务，有两种实现；</p><ol><li><p>需要更新同步的分布式缓存，所有的服务器保存相同的缓存数据，带来的问题就是，缓存的数据量受限制，其次，数据要在所有的机器上同步，代价很大。</p></li><li><p>每台机器只缓存一部分数据，然后通过一定的算法选择缓存服务器。常见的余数hash算法存在当有服务器上下线的时候，大量缓存数据重建的问题。所以提出了一致性哈希算法。</p></li></ol><h5 id="哈希一致性"><a href="#哈希一致性" class="headerlink" title="哈希一致性"></a>哈希一致性</h5><ol><li><p>首先求出服务器（节点）的哈希值，并将其配置到0～2的32次方的圆（continuum）上。</p></li><li><p>然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。</p></li><li><p>然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过232仍然找不到服务器，就会保存到第一台服务器上。</p></li></ol><p>哈希一致性算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。</p><h5 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h5><p>一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题，此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器ip或主机名的后面增加编号来实现。例如，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点：同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。</p><h5 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h5><p>可以很好的将用户的请求分配到多个机器处理，对总体性能有很大的提升</p><h4 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h4><h5 id="同步和异步、阻塞和非阻塞"><a href="#同步和异步、阻塞和非阻塞" class="headerlink" title="同步和异步、阻塞和非阻塞"></a>同步和异步、阻塞和非阻塞</h5><p><strong>同步和异步关注的是结果消息的通信机制</strong></p><p><strong>同步</strong>：同步的意思就是调用方需要主动等待结果的返回</p><p><strong>异步</strong>：异步的意思就是不需要主动等待结果的返回，而是通过其他手段比如，状态通知，回调函数等。</p><p><strong>阻塞和非阻塞主要关注的是等待结果返回的调用方的状态</strong></p><p><strong>阻塞</strong>：是指结果返回之前，当前线程被挂起，不做任何事</p><p><strong>非阻塞</strong>：是指结果在返回之前，线程可以做一些其他事，不会被挂起。</p><p><strong>同步阻塞</strong>：同步阻塞基本也是编程中最常见的模型，比如说同步队列的take()方法，如果队列中没有元素，当前线程会一直阻塞直到获取到元素，BIO也属于同步阻塞。</p><p><strong>同步非阻塞</strong>：同步非阻塞在编程中可以抽象为一个轮询模式，比如说同步队列的poll()方法，如果队列中没有元素会返回null，此时我们可以执行其他的逻辑，在此期间会不断调用poll()方法直到不为null，jdk里的NIO就属于 同步非阻塞。</p><p><strong>异步阻塞</strong>：异步阻塞这个编程里面用的较少，如果在线程池中提交有返回值的任务之后，马上调用future.get()，此时线程会马上被阻塞，直到任务之行结束。所以这个模式有点憨，与同步阻塞的效果相同，但还需要调用资源开辟线程。</p><p><strong>异步非阻塞</strong>：例如jdk提供的CompletableFuture，它采用了观察者设计模式，可以完成异步非阻塞的计算，弥补了future阻塞式获取结果的不足，jdk里的AIO就属于异步。</p><h5 id="常见异步的手段"><a href="#常见异步的手段" class="headerlink" title="常见异步的手段"></a>常见异步的手段</h5><ul><li><p>Servlet异步</p></li><li><p>多线程</p></li><li><p>消息队列</p></li></ul><h4 id="代码优化"><a href="#代码优化" class="headerlink" title="代码优化"></a>代码优化</h4><p>一个应用的性能归根结底取决于代码是如何编写的。</p><ul><li><p><strong>选择合适的数据结构</strong></p><p>比如ArrayList和LinkedList的选择，LinkedList在进行add()操作时不需要进行扩容，而ArrayList内部是数组实现，数据量较大时会进行扩容，扩容时的数据复制会比较耗费时间。</p></li><li><p><strong>选择更优的算法</strong></p></li><li><p><strong>编写更少的代码</strong></p></li><li><p><strong>并发编程</strong></p></li><li><p><strong>资源的复用</strong></p><p>目的是减少开销很大的系统资源的创建和销毁，比如数据库连接，网络通信连接，线程资源等等。</p></li><li><p><strong>单例模式</strong></p><p>Spring中的bean</p></li><li><p><strong>池化技术</strong></p></li></ul><h4 id="存储性能优化"><a href="#存储性能优化" class="headerlink" title="存储性能优化"></a>存储性能优化</h4><ul><li><p><strong>尽量使用SSD</strong></p></li><li><p><strong>定时清理数据或者按数据的性质分开存放</strong></p></li><li><p><strong>结果集处理</strong></p><p>用setFetchSize控制jdbc每次从数据库中返回多少数据。</p></li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>调优是个很复杂、很细致的过程，要根据实际情况调整，不同的机器、不同的应用、不同的性能要求调优的手段都是不同的。也没有一个放之四海而皆准的配置或者公式。King老师也无法告诉大家全部与性能相关的知识，即使是jvm参数也是如此，再比如说性能有关的操作系统工具，和操作系统本身相关的所谓大页机制，都需要大家平时去积累，去观察，去实践。</p><p>king老师在这个专题上告诉大家的除了各种java虚拟机基础知识、内部原理，也告诉大家一个性能优化的一个基本思路和着手的方向。</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>JVM</tag>
      
      <tag>Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JVM性能优化</title>
    <link href="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    <url>/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="内存溢出"><a href="#内存溢出" class="headerlink" title="内存溢出"></a>内存溢出</h2><p>程序在申请内存时，没有足够的内存空间就会发生内存溢出。</p><p>内存溢出的几种方式：</p><ul><li><p><strong>栈溢出</strong>：方法死循环递归调用即线程内的栈空间不足：<strong>StackOverflowError</strong>，不断建立线程即JVM栈空间不足：<strong>StackOutOfMemoryError</strong></p></li><li><p><strong>堆溢出</strong>：不断创建对象导致垃圾回收线程占用了超过98%的资源，但是回收效率小于2%时：<strong>OutOfMemoryError</strong>:GC overhead limit exceeded，分配对象大于最大堆的大小：<strong>OutOfMemoryError</strong>:Java heap space</p></li><li><p><strong>方法区溢出</strong>：由于方法区GC效率低，动态语言、CGLB、JSP、OSGI会加载在方法区，如果方法区大小不足，会造成方法区溢出。</p></li><li><p><strong>直接内存溢出</strong>：分配的本机直接内存（NIO使用的就是本机直接内存）大小大于JVM对直接内存的限制：<strong>OutOfMemoryError</strong>:Direct buffer memory</p></li></ul><h2 id="内存泄漏"><a href="#内存泄漏" class="headerlink" title="内存泄漏"></a>内存泄漏</h2><p>程序在申请内存后不再使用，但由于与GC Roots仍存在关联，在垃圾回收时无法释放已申请的内存空间，导致内存长期被占用。</p><p>内存泄露的几种原因：</p><ul><li><p><strong>长生命周期的对象持有短生命周期对象的引用</strong>：例如将ArrayList设置为静态变量，则容器中的对象在程序结束之前将不能被释放，从而造成内存泄漏</p></li><li><p><strong>连接未关闭</strong>：如数据库连接、网络连接和IO连接等，只有连接被关闭后，垃圾回收器才会回收对应的对象。</p></li><li><p><strong>变量作用域不合理</strong>：例如：变量的定义的作用范围大于其使用范围、没有及时地把对象设置为null等</p></li><li><p><strong>内部类持有外部类</strong>：Java的非静态内部类的创建方式，会隐式地持有外部类的引用，而且默认情况下这个引用是强引用，如果内部类的生命周期长于外部类的生命周期，程序很容易就产生内存泄漏（主观上垃圾回收器会回收掉外部类的实例，但由于内部类持有外部类的引用，实际上外部类并没有被回收）</p><p>解决方法：内部类尽量定义为静态，或者在内部类的内部显式持有一个外部类的软引用(或弱引用)，并通过构造方法的方式传递进来，在内部类的使用过程中，先判断一下外部类是否被回收；</p></li><li><p><strong>Hash值改变</strong>：在集合中，如果修改了对象中的参与计算哈希值的字段，会导致无法从集合中单独删除当前对象，造成内存泄露</p></li></ul><h2 id="内存泄漏和内存溢出辨析"><a href="#内存泄漏和内存溢出辨析" class="headerlink" title="内存泄漏和内存溢出辨析"></a>内存泄漏和内存溢出辨析</h2><ul><li><p><strong>产生原因</strong>：内存溢出是由于内存空间不足导致，而且内存泄漏是由于应该释放的对象没有释放，导致可使用内存的缩小。</p></li><li><p><strong>如何避免：</strong>内存溢出可以通过检查代码问题以及调整虚拟机参数设置足够的空间来解决，内存泄漏一定是代码的问题，所以只能通过检查代码问题来解决，很多情况下内存溢出是内存泄漏导致的。</p></li></ul><h2 id="MAT"><a href="#MAT" class="headerlink" title="MAT"></a>MAT</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>MAT是Eclipse Memory Analyzer的简称，是一个快速且功能丰富的Java堆分析器，可以用于查找内存泄露以及查看内存消耗情况。使用Memory Analyzer分析具有数亿个对象的高效堆转储，快速计算对象的保留大小，查看谁阻止垃圾收集器收集对象，运行报告以自动提取泄漏嫌疑者。可以在<a href="http://www.eclipse.org/mat/下载并使用MAT。" target="_blank" rel="noopener">http://www.eclipse.org/mat/下载并使用MAT。</a></p><h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><p>模拟内存溢出错误并导出dump文件</p><pre><code>public class OOMTest {    public static void main(String[] args) {        List&lt;Object&gt; list = new LinkedList&lt;&gt;();        int i = 0;        while (true) {            i++;            if (i % 10000 == 0) {                System.out.println(&quot;i=&quot; + i);            }            list.add(new Object());        }    }}</code></pre><p>加入vm参数-Xms30m -Xmx30m  -XX:+PrintGCDetails -XX:+HeapDumpOnOutOfMemoryError</p><p>栈溢出时会在项目目录下生成*.hprof文件</p><p>使用MAT打开文件 File-&gt;Open Heap Dump-&gt;Leak Suspects Report-&gt;Finash</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic1.png" srcset="/img/loading.gif" class=""><p>在<strong>Problem Supect</strong>中显示主线程占用了97.88%的空间，点击Details后可以看到更加具体的分析。</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic2.png" srcset="/img/loading.gif" class=""><p>其中</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic3.png" srcset="/img/loading.gif" class=""><p><strong>浅堆</strong>（Shallow Heap）：分配一个对象所消耗的内存</p><p><strong>深堆</strong>（Retained Heap）：深堆大小是对象直接或间接引用到的所有对象的浅堆大小之，即GC回收时真实可回收的内存大小。</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic4.png" srcset="/img/loading.gif" class=""><p>例如：对象A引用了C和D，对象B引用了E。那么对象A的浅堆大小只是A本身，而如果A被回收，那么C和D都会被回收(可达性分析算法)，所以A的深堆大小为A+C+D之和，同时由于对象E还可以通过对象B访问到，因此不在对象A的深堆范围内。</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic5.png" srcset="/img/loading.gif" class=""><p><strong>incoming</strong>：当前对象引用的对象</p><p><strong>outgoing</strong>：当前对象在哪些对象中被引用</p><h2 id="JVM工具"><a href="#JVM工具" class="headerlink" title="JVM工具"></a>JVM工具</h2><h3 id="命令行工具"><a href="#命令行工具" class="headerlink" title="命令行工具"></a>命令行工具</h3><ul><li><p><strong>jps</strong></p><p>列出当前机器上正在运行的虚拟机进程，JPS从操作系统的临时目录上去找。</p><p>-q:仅仅显示进程号</p><p>-m:输出主函数传入的参数</p><p>-l:输出应用程序主类完整package名称或jar完整名称</p><p>-v:列出jvm参数</p></li><li><p><strong>jstat</strong></p><p>是用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据，在没有GUI图形界面，只提供了纯文本控制台环境的服务器上，它将是运行期定位虚拟机性能问题的首选工具。</p><p>例如：jstat-gc 13616 250 10:每250毫秒查询一次进程13616垃圾收集状况，一共查询10次</p><p>-class (类加载器) </p><p>-compiler (JIT) </p><p>-gc (GC堆状态) </p><p>-gccapacity (各区大小) </p><p>-gccause (最近一次GC统计和原因) </p><p>-gcnew (新区统计)</p><p>-gcnewcapacity (新区大小)</p><p>-gcold (老区统计)</p><p>-gcoldcapacity (老区大小)</p><p>-gcpermcapacity (永久区大小)</p><p>-gcutil (GC统计汇总)</p><p>-printcompilation (HotSpot编译统计)</p></li><li><p><strong>jinfo</strong> </p><p>查看和修改虚拟机的参数。</p><p>jinfo –sysprops 可以查看由System.getProperties()取得的参数</p><p>jinfo –flag 未被显式指定的参数的系统默认值</p><p>jinfo –flags（注意s）显示虚拟机的参数</p><p>jinfo –flag +[参数] 增加参数</p><p>由于虚拟机的限制，只有输入java -XX:+PrintFlagsFinal –version命令后，查询结果最后一列为manageable的参数可以增加。</p><p>jinfo –flag -[参数] 去除参数</p></li><li><p><strong>jmap</strong></p><p>用于生成堆转储快照（一般称为heapdump或dump文件）。jmap的作用并不仅仅是为了获取dump文件，它还可以查询finalize执行队列、Java堆和永久代的详细信息，如空间使用率、当前用的是哪种收集器等。和jinfo命令一样，jmap有不少功能在Windows平台下都是受限的，除了生成dump文件的-dump选项和用于查看每个类的实例、空间占用统计的-histo选项在所有操作系统都提供之外，其余选项都只能在Linux/Solaris下使用。</p><p>jmap -dump:live,format=b,file=heap.bin &lt;pid&gt;</p><p>Sun JDK提供jhat（JVM Heap Analysis Tool）命令与jmap搭配使用，来分析jmap生成的堆转储快照。</p></li><li><p><strong>jhat</strong></p><p>jhat dump文件名</p><p>使用jhat可以在服务器上生成堆转储文件分析（一般不推荐，毕竟占用服务器的资源，比如一个文件就有1个G）</p><p>后屏幕显示“Server is ready.”的提示后，用户在浏览器中键入<a href="http://localhost:7000/就可以访问详情。" target="_blank" rel="noopener">http://localhost:7000/就可以访问详情。</a></p></li><li><p><strong>jstack</strong></p><p>（Stack Trace for Java）命令用于生成虚拟机当前时刻的线程快照。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等都是导致线程长时间停顿的常见原因。</p><p>在代码中可以用java.lang.Thread类的getAllStackTraces（）方法用于获取虚拟机中所有线程的StackTraceElement对象。使用这个方法可以通过简单的几行代码就完成jstack的大部分功能，在实际项目中不妨调用这个方法做个管理员页面，可以随时使用浏览器来查看线程堆栈。</p></li></ul><h3 id="可视化工具"><a href="#可视化工具" class="headerlink" title="可视化工具"></a>可视化工具</h3><p>JMX（Java Management Extensions，即Java管理扩展）是一个为应用程序、设备、系统等<a href="https://baike.baidu.com/item/%E6%A4%8D%E5%85%A5/7958584" target="_blank" rel="noopener">植入</a>管理功能的框架。JMX可以跨越一系列异构操作系统平台、<a href="https://baike.baidu.com/item/%E7%B3%BB%E7%BB%9F%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/6842760" target="_blank" rel="noopener">系统体系结构</a>和<a href="https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE/332131" target="_blank" rel="noopener">网络传输协议</a>，灵活的开发无缝集成的系统、网络和服务管理应用。</p><p><strong>远程连接生产环境需要在启动参数中增加：</strong></p><p>-Djava.rmi.server.hostname=…..</p><p>-Dcom.sun.management.jmxremote</p><p>-Dcom.sun.management.jmxremote.port=8888</p><p>-Dcom.sun.management.jmxremote.authenticate=false</p><p>-Dcom.sun.management.jmxremote.ssl=false</p><h4 id="Jconsole"><a href="#Jconsole" class="headerlink" title="Jconsole"></a>Jconsole</h4><p>java监视与管理控制台</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic7.png" srcset="/img/loading.gif" class=""><h4 id="Jvisualvm"><a href="#Jvisualvm" class="headerlink" title="Jvisualvm"></a>Jvisualvm</h4><p>多合一故障处理工具，一般来说用于本机调试用，如果需要用于生产环境必须启用远程连接</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic6.png" srcset="/img/loading.gif" class=""><p>插件中心地址</p><p><a href="https://visualvm.github.io/archive/uc/8u40/updates.xml.gz" target="_blank" rel="noopener">https://visualvm.github.io</a></p><p>但是注意版本问题，不同的JDK所带的visualvm是不一样的，下载插件时需要下对应的版本。</p><h2 id="GC调优"><a href="#GC调优" class="headerlink" title="GC调优"></a>GC调优</h2><p>JVM调优并不能显著的提高系统性能，主要提升的是系统稳定性。如果系统出现了频繁的垃圾回收，这时候系统是不稳定的，所以需要进行JVM调优，调整垃圾回收的频次。</p><h3 id="GC调优原则"><a href="#GC调优原则" class="headerlink" title="GC调优原则"></a>GC调优原则</h3><ol><li>大多数的java应用不需要GC调优</li><li>大多数需要GC调优的情况是由于代码问题引起的</li><li>优化GC参数是最后的手段</li></ol><h3 id="GC调优指标"><a href="#GC调优指标" class="headerlink" title="GC调优指标"></a>GC调优指标</h3><ul><li><p><strong>GC的时间</strong></p><p>参考性指标：</p><ul><li>Minor GC执行时间在50ms内</li><li>Full GC执行时间在1000ms内</li></ul></li><li><p><strong>GC的频率</strong></p><p>参考性指标：</p><ul><li>Minor GC执行大于10秒一次</li><li>Full GC执行频率大于10分钟1次</li></ul></li></ul><p>即：如果满足下面的指标，则一般不需要进行GC调优</p><ul><li><p>Minor GC执行时间不到50ms；</p></li><li><p>Minor GC执行不频繁，约10秒一次；</p></li><li><p>Full GC执行时间不到1s</p></li><li><p>Full GC执行频率不算频繁，不低于10分钟1次；</p></li></ul><h3 id="GC调优步骤"><a href="#GC调优步骤" class="headerlink" title="GC调优步骤"></a>GC调优步骤</h3><ol><li><p><strong>监控GC的状态：使用各种JVM工具</strong>，查看当前日志，分析当前JVM参数设置，并且分析当前堆内存快照和GC日志，根据实际的各区域内存划分和GC执行时间，决定是否进行优化。</p></li><li><p><strong>分析结果，判断是否需要优化</strong>：如果各项参数设置合理，系统没有超时日志出现，GC频率不高，GC耗时不高，那么没有必要进行GC优化；如果GC时间超过1-3秒，或者频繁GC，则必须优化；</p></li><li><p><strong>调整GC类型和内存分配</strong>：如果内存分配过大或过小，或者采用的GC收集器比较慢，则应该优先调整这些参数，并且先找1台或几台机器进行beta，然后比较优化过的机器和没有优化的机器的性能对比，并有针对性的做出最后选择；</p></li><li><p><strong>不断的分析和调整</strong>：通过不断的试验和试错，分析并找到最合适的参数</p></li><li><p><strong>全面应用参数</strong>：如果找到了最合适的参数，则将这些参数应用到所有服务器，并进行后续跟踪。</p></li></ol><h3 id="GC调优实战"><a href="#GC调优实战" class="headerlink" title="GC调优实战"></a>GC调优实战</h3><h4 id="如何阅读GC日志"><a href="#如何阅读GC日志" class="headerlink" title="如何阅读GC日志"></a>如何阅读GC日志</h4><p>主要关注MinorGC和FullGC 的回收效率（回收前大小和回收比较）、回收的时间。</p><p>以参数<strong>-Xms5m -Xmx5m -XX:+PrintGCDetails -XX:+UseSerialGC</strong>为例：</p><p>[DefNew: 1855K-&gt;1855K(1856K), 0.0000148 secs][Tenured: 2815K-&gt;4095K(4096K), 0.0134819 secs] 4671K</p><p>DefNew指明了收集器类型，而且说明了收集发生在新生代。</p><p>1855K-&gt;1855K(1856K)表示，回收前 新生代占用1855K，回收后占用1855K，新生代大小1856K。</p><p>0.0000148 secs 表明新生代回收耗时。</p><p>Tenured表明收集发生在老年代</p><p>2815K-&gt;4095K(4096K), 0.0134819 secs：含义同新生代</p><p>最后的4671K指明堆的大小。</p><p>收集器参数变为<strong>-XX:+UseParNewGC</strong>，日志变为：</p><p>[ParNew: 1856K-&gt;1856K(1856K), 0.0000107 secs][Tenured: 2890K-&gt;4095K(4096K), 0.0121148 secs]</p><p>收集器参数变为-<strong>XX:+ UseParallelGC或UseParallelOldGC</strong>，日志变为：</p><p>[PSYoungGen: 1024K-&gt;1022K(1536K)] [ParOldGen: 3783K-&gt;3782K(4096K)] 4807K-&gt;4804K(5632K),</p><p>当收集器参数变为：<strong>-XX:+UseConcMarkSweepGC</strong>、<strong>-XX:+UseG1GC</strong>时，CMS收集器和G1收集器会有明显的相关字样</p><h4 id="项目启动时的GC优化"><a href="#项目启动时的GC优化" class="headerlink" title="项目启动时的GC优化"></a>项目启动时的GC优化</h4><ol><li>开启日志分析 -XX:+PrintGCDetails 发现有7次Minor GC，2次Full GC，执行FullGC的原因是Metaspace空间不足。</li><li>调整Metadata空间-XX:MetaspaceSize=64m，调整后FullGC不再出现。</li><li>调整堆空间-Xms500m，调整后Minor GC次数减少至4次</li><li>继续调整堆空间-Xms1000m，调整后Minor GC减少至2次</li><li>调整新生代空间-Xmn900m，调整后Minor GC减少至1次</li><li>继续调整新生代空间-Xms2000m -Xmn1800m，调整后Minor GC次数没有变化，这次的调整时没有意义的，反而会造成资源浪费。</li></ol><h4 id="项目运行GC优化"><a href="#项目运行GC优化" class="headerlink" title="项目运行GC优化"></a>项目运行GC优化</h4><p>使用jmeter同时访问三个接口，index、time、noblemetal</p><p>使用40个线程，循环2500次进行压力测试，观察并发的变化</p><p>使用单线程GC -XX:+UseSerialGC</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic8.png" srcset="/img/loading.gif" class=""><p>使用多线程GC -XX:+UseParNewGC</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic9.png" srcset="/img/loading.gif" class=""><p>可以看到吞吐量有一定的上升</p><p>使用CMS -XX:+UseConcMarkSweepGC</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic10.png" srcset="/img/loading.gif" class=""><p>CMS采用了并发收集，所以STW的时间较小，吞吐量较单线程GC有一定提高，最大请求时间有明显的下降。</p><p>使用G1 -XX:+UseG1GC</p><img src="/2020/03/21/JVM%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic11.png" srcset="/img/loading.gif" class=""><p>此时的吞吐量是最大的，最大请求时间有明显的下降。</p><h4 id="推荐策略"><a href="#推荐策略" class="headerlink" title="推荐策略"></a>推荐策略</h4><h5 id="堆空间的设置"><a href="#堆空间的设置" class="headerlink" title="堆空间的设置"></a>堆空间的设置</h5><p>可以将新生代尽可能的设置的大一些，减少MinorGC的次数。如果新生代设置的过小会导致对象直接进入老年代，如果此时老年代满了，会触发FullGC.。</p><h5 id="垃圾收集器的选择"><a href="#垃圾收集器的选择" class="headerlink" title="垃圾收集器的选择"></a>垃圾收集器的选择</h5><p>响应时间优先的应用：老年代尽量使用并发收集器，大小需要小心设置一般要考虑并发会话率和会话持续时间等一些参数。如果堆设置小了,可能会造成内存碎片，高回收频率以及应用暂停而使用传统的标记清除方式。如果堆大了，则需要较长的收集时间。最优化的方案,一般需要参考以下数据获得：</p><ul><li>并发垃圾收集信息</li><li>持久代并发收集次数</li><li>传统GC信息</li><li>新生代和老年代回收上的时间比例。</li></ul><p>吞吐量优先的应用：一般吞吐量优先的应用都有一个很大的新生代和一个较小的老年代。这样可以尽可能回收掉大部分短期对象，减少中期的对象，而老年代可以尽量存放长期存活对象。</p><p>GC调优是个很复杂、很细致的过程，要根据实际情况调整，不同的机器、不同的应用、不同的性能要求调优的手段都是不同的，king老师也无法告诉大家全部，即使是jvm参数也是如此，比如说性能有关的操作系统工具，和操作系统本身相关的所谓大页机制，都需要大家平时去积累，去观察，去实践，king老师在这个专题上告诉大家的除了各种java虚拟机基础知识和内部原理，也告诉大家一个性能优化的一个基本思路和着手的方向。</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>JVM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JVM的执行子系统</title>
    <link href="/2020/03/12/JVM%E7%9A%84%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F/"/>
    <url>/2020/03/12/JVM%E7%9A%84%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="Class文件结构"><a href="#Class文件结构" class="headerlink" title="Class文件结构"></a>Class文件结构</h2><h3 id="Jvm的无关性"><a href="#Jvm的无关性" class="headerlink" title="Jvm的无关性"></a>Jvm的无关性</h3><p><strong>平台无关性</strong>是建立在操作系统上，虚拟机厂商提供了许多可以运行在各种不同平台的虚拟机，它们都可以载入和执行字节码，从而实现程序的“一次编写，到处运行”</p><p>各种不同平台的虚拟机与所有平台都统一使用的程序存储格式——字节码（ByteCode）是构成平台无关性的基石，也是<strong>语言无关性</strong>的基础。Java虚拟机不和包括Java在内的任何语言绑定，它只与“Class文件”这种特定的二进制文件格式所关联，Class文件中包含了Java虚拟机指令集和符号表以及若干其他辅助信息。</p><h3 id="Class类文件（字节码）"><a href="#Class类文件（字节码）" class="headerlink" title="Class类文件（字节码）"></a>Class类文件（字节码）</h3><p>整个Class文件中存储的内容几乎全部是程序运行的必要数据，没有空隙存在，各个数据严格按照顺序紧凑地排列，中间没有添加任何分隔符。Class文件是一组以8位字节为基础单位的二进制流，由于它没有任何分隔符号，所以在其中的数据项，无论是顺序还是数量，都是被严格限定的，哪个字节代表什么含义，长度是多少，先后顺序如何，都不允许改变。</p><p>Class文件格式采用一种类似于C语言结构体的伪结构来存储数据，这种伪结构中只有两种数据类型：无符号数和表。</p><p>无符号数属于基本的数据类型，以u1、u2、u4、u8来分别代表1个字节、2个字节、4个字节和8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8编码构成字符串值。</p><p>表是由多个无符号数或者其他表作为数据项构成的复合数据类型，所有表都习惯性地以“_info”结尾。表用于描述有层次关系的复合结构的数据，整个Class文件本质上就是一张表。</p><p>按顺序包括：</p><ol><li><p><strong>魔数与Class文件的版本</strong></p><p>每个Class文件的头4个字节称为魔数（Magic Number），它的唯一作用是确定这个文件是否为一个能被虚拟机接受的Class文件。使用魔数而不是扩展名来进行识别主要是基于安全方面的考虑，因为文件扩展名可以随意地改动。文件格式的制定者可以自由地选择魔数值，只要这个魔数值还没有被广泛采用过同时又不会引起混淆即可。紧接着魔数的4个字节存储的是Class文件的版本号：第5和第6个字节是次版本号（MinorVersion），第7和第8个字节是主版本号（Major Version）。Java的版本号是从45开始的，JDK 1.1之后的每个JDK大版本发布主版本号向上加1高版本的JDK能向下兼容以前版本的Class文件，但不能运行以后版本的Class文件，即使文件格式并未发生任何变化，虚拟机也必须拒绝执行超过其版本号的Class文件。</p></li><li><p><strong>常量池</strong></p><p>常量池中常量的数量是不固定的，所以在常量池的入口需要放置一项u2类型的数据，代表常量池容量计数值（constant_pool_count）。与Java中语言习惯不一样的是，这个容量计数是从1而不是0开始的</p><p>常量池中主要存放两大类常量：字面量（Literal）和符号引用（Symbolic References）。</p><p>字面量比较接近于Java语言层面的常量概念，如文本字符串、声明为final的常量值等。</p><p>而符号引用则属于编译原理方面的概念，包括了下面三类常量：</p><ul><li>类和接口的全限定名（Fully Qualified Name）</li><li>字段的名称和描述符（Descriptor）</li><li>方法的名称和描述符</li></ul></li><li><p><strong>访问标志</strong></p><p>用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口；是否定义为public类型；是否定义为abstract类型；如果是类的话，是否被声明为final等</p></li><li><p><strong>类索引、父类索引与接口索引集合</strong></p><p>这三项数据来确定这个类的继承关系。类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名。由于Java语言不允许多重继承，所以父类索引只有一个，除了java.lang.Object之外，所有的Java类都有父类，因此除了java.lang.Object外，所有Java类的父类索引都不为0。接口索引集合就用来描述这个类实现了哪些接口，这些被实现的接口将按implements语句（如果这个类本身是一个接口，则应当是extends语句）后的接口顺序从左到右排列在接口索引集合中</p></li><li><p><strong>字段表集合</strong></p><p>描述接口或者类中声明的变量。字段（field）包括类级变量以及实例级变量。而字段叫什么名字、字段被定义为什么数据类型，这些都是无法固定的，只能引用常量池中的常量来描述。</p><p>字段表集合中不会列出从超类或者父接口中继承而来的字段，但有可能列出原本Java代码之中不存在的字段，譬如在内部类中为了保持对外部类的访问性，会自动添加指向外部类实例的字段。</p></li><li><p><strong>方法表集合</strong></p><p>描述了方法的定义，但是方法里的Java代码，经过编译器编译成字节码指令后，存放在属性表集合中的方法属性表集合中一个名为“Code”的属性里面。</p><p>与字段表集合相类似的，如果父类方法在子类中没有被重写（Override），方法表集合中就不会出现来自父类的方法信息。但同样的，有可能会出现由编译器自动添加的方法，最典型的便是类构造器“＜clinit＞”方法和实例构造器“＜init＞”</p></li><li><p><strong>属性表集合</strong></p><p>存储Class文件、字段表、方法表都自己的属性表集合，以用于描述某些场景专有的信息。如方法的代码就存储在Code属性表中。</p></li></ol><h2 id="字节码指令"><a href="#字节码指令" class="headerlink" title="字节码指令"></a>字节码指令</h2><p>Java虚拟机的指令由一个字节长度的、代表着某种特定操作含义的数字（称为操作码，Opcode）以及跟随其后的零至多个代表此操作所需参数（称为操作数，Operands）而构成。</p><p>由于限制了Java虚拟机操作码的长度为一个字节（即0～255），这意味着指令集的操作码总数不可能超过256条。</p><p>大多数的指令都包含了其操作所对应的数据类型信息。例如：</p><p>iload指令用于从局部变量表中加载int型的数据到操作数栈中，而fload指令加载的则是float类型的数据。</p><p>大部分的指令都没有支持整数类型byte、char和short，甚至没有任何指令支持boolean类型。大多数对于boolean、byte、short和char类型数据的操作，实际上都是使用相应的int类型作为运算类型</p><p>常见指令一般有：</p><ul><li><p><strong>加载和存储指令</strong></p><p>用于将数据在栈帧中的局部变量表和操作数栈之间来回传输，这类指令包括如下内容。</p><p>将一个局部变量加载到操作栈：iload、iload_＜n＞、lload、lload_＜n＞、fload、fload_＜n＞、dload、dload_＜n＞、aload、aload_＜n＞。_</p><p>将一个数值从操作数栈存储到局部变量表：istore、istore_＜n＞、lstore、lstore_＜n＞、fstore、fstore_＜n＞、dstore、dstore_＜n＞、astore、astore_＜n＞。_</p><p>将一个常量加载到操作数栈：bipush、sipush、ldc、ldc_w、ldc2_w、aconst_null、iconst_m1、iconst_＜i＞、lconst_＜l＞、fconst_＜f＞、dconst_＜d＞。</p><p>扩充局部变量表的访问索引的指令：wide。</p></li><li><p><strong>运算或算术指令</strong></p><p>用于对两个操作数栈上的值进行某种特定运算，并把结果重新存入到操作栈顶。</p><p>加法指令：iadd、ladd、fadd、dadd。</p><p>减法指令：isub、lsub、fsub、dsub。</p><p>乘法指令：imul、lmul、fmul、dmul等等</p></li><li><p><strong>类型转换指令</strong></p><p>可以将两种不同的数值类型进行相互转换，</p><p>Java虚拟机直接支持以下数值类型的宽化类型转换（即小范围类型向大范围类型的安全转换）：</p><ul><li>int类型到long、float或者double类型。</li><li>long类型到float、double类型。</li><li>float类型到double类型。</li></ul><p>处理窄化类型转换（Narrowing Numeric Conversions）时，必须显式地使用转换指令来完成，这些转换指令包括：i2b、i2c、i2s、l2i、f2i、f2l、d2i、d2l和d2f。</p></li><li><p><strong>创建类实例的指令</strong></p><p>new</p></li><li><p><strong>创建数组的指令</strong></p><p>newarray、anewarray、multianewarray。</p></li><li><p><strong>访问字段指令</strong></p><p>getfield、putfield、getstatic、putstatic。</p></li><li><p><strong>数组存取相关指令</strong></p><p>把一个数组元素加载到操作数栈的指令：baload、caload、saload、iaload、laload、faload、daload、aaload。</p><p>将一个操作数栈的值存储到数组元素中的指令：bastore、castore、sastore、iastore、fastore、dastore、aastore。</p></li><li><p><strong>取数组长度的指令</strong></p><p>arraylength</p></li><li><p><strong>检查类实例类型的指令</strong></p><p>instanceof、checkcast。</p></li><li><p><strong>操作数栈管理指令</strong></p><p>如同操作一个普通数据结构中的堆栈那样，Java虚拟机提供了一些用于直接操作操作数栈的指令，包括：将操作数栈的栈顶一个或两个元素出栈：pop、pop2。</p><p>复制栈顶一个或两个数值并将复制值或双份的复制值重新压入栈顶：dup、dup2、dup_x1、dup2_x1、dup_x2、dup2_x2。</p><p>将栈最顶端的两个数值互换：swap。</p></li><li><p><strong>控制转移指令</strong></p><p>控制转移指令可以让Java虚拟机有条件或无条件地从指定的位置指令而不是控制转移指令的下一条指令继续执行程序，从概念模型上理解，可以认为控制转移指令就是在有条件或无条件地修改PC寄存器的值。控制转移指令如下。</p><ul><li>条件分支：ifeq、iflt、ifle、ifne、ifgt、ifge、ifnull、ifnonnull、if_icmpeq、if_icmpne、if_icmplt、if_icmpgt、if_icmple、if_icmpge、if_acmpeq和if_acmpne。</li><li>复合条件分支：tableswitch、lookupswitch。</li><li>无条件分支：goto、goto_w、jsr、jsr_w、ret。</li></ul></li><li><p><strong>方法调用指令</strong></p><p>invokevirtual指令用于调用对象的实例方法，根据对象的实际类型进行分派（虚方法分派），这也是Java语言中最常见的方法分派方式。</p><p>invokeinterface指令用于调用接口方法，它会在运行时搜索一个实现了这个接口方法的对象，找出适合的方法进行调用。</p><p>invokespecial指令用于调用一些需要特殊处理的实例方法，包括实例初始化方法、私有方法和父类方法。</p><p>invokestatic指令用于调用类方法（static方法）。</p><p>invokedynamic指令用于在运行时动态解析出调用点限定符所引用的方法，并执行该方法，前面4条调用指令的分派逻辑都固化在Java虚拟机内部，而invokedynamic指令的分派逻辑是由用户所设定的引导方法决定的。</p><p>方法调用指令与数据类型无关。</p></li><li><p><strong>方法返回指令</strong></p><p>是根据返回值的类型区分的，包括ireturn（当返回值是boolean、byte、char、short和int类型时使用）、lreturn、freturn、dreturn和areturn，另外还有一条return指令供声明为void的方法、实例初始化方法以及类和接口的类初始化方法使用。</p></li><li><p><strong>异常处理指令</strong></p><p>在Java程序中显式抛出异常的操作（throw语句）都由athrow指令来实现</p></li><li><p><strong>同步指令</strong></p><p>有monitorenter和monitorexit两条指令来支持synchronized关键字的语义</p></li></ul><h2 id="栈帧详解"><a href="#栈帧详解" class="headerlink" title="栈帧详解"></a>栈帧详解</h2><p>当前栈帧：一个线程的方法调用链可能会很长，这意味着虚拟机栈会被压入很多栈帧，但在线程执行的某个时间点只有位于栈顶的栈帧才是有效的，该栈帧称为“当前栈帧”，与这个栈帧相关联的方法称为“当前方法”。</p><img src="/2020/03/12/JVM%E7%9A%84%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F/pic1.png" srcset="/img/loading.gif" class=""><ul><li><p><strong>局部变量表</strong></p><p>局部变量表的容量以变量槽（Variable Slot，下称 Slot）为最小单位，虚拟机规范中导向性地说到每个 Slot 都应该能存放一个 boolean、byte、char、short、int、float、double、long 8 种数据类型和reference ，可以使用 32 位或更小的物理内存来存放。</p><p>对于 64 位的数据类型，虚拟机会以高位对齐的方式为其分配两个连续的 Slot 空间。Java 语言中明确的（reference 类型则可能是 32 位也可能是 64 位）64 位的数据类型只有 long 和 double 两种。</p></li><li><p><strong>操作数栈</strong></p><p>操作数栈（Operand Stack）也常称为操作栈，它是一个先进后出（First In Last Out,FILO）栈。 同局部变量表一样， 操作数栈的每一个元素可以是任意的Java数据类型，包括long和double。 32位数据类型所占的栈容量为1，64位数据类型所占的栈容量为2。 </p><p>当一个方法刚刚开始执行的时候，这个方法的操作数栈是空的，在方法的执行过程中，会有各种字节码指令往操作数栈中写入和提取内容，也就是出栈/入栈操作。 例如，在做算术运算的时候是通过操作数栈来进行的，又或者在”调用其他方法的时候是通过操作数栈来进行参数传递的”。</p><p>java虚拟机的解释执行引擎称为“基于栈的执行引擎”，其中所指的“栈”就是操作数栈。</p></li><li><p><strong>数据重叠优化</strong></p><p>虚拟机概念模型中每二个栈帧都是相互独立的，但在实际应用是我们知道一个方法调用另一个方法时，往往存在参数传递，这种做法在虚拟机实现过程中会做一些优化，具体做法如下：令两个栈帧出现一部分重叠。让下面栈帧的一部分操作数栈与上面栈帧的部分局部变量表重叠在一起，进行方法调用时就可以共用一部分数据，无须进行额外的参数复制传递。</p><img src="/2020/03/12/JVM%E7%9A%84%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F/pic2.png" srcset="/img/loading.gif" class=""></li><li><p><strong>动态连接</strong></p><p>栈帧执行方法是哪个方法，栈帧中会持有一个符号引用，该引用指向某个具体方法。</p><p>符号引用是一个地址位置的代号，在编译的时候我们是不知道某个方法在运行的时候是放到哪里的，这时我用代号com/enjoy/pojo/User.Say:()V指代某个类的方法，将来可以把符号引用转换成直接引用进行真实的调用。</p><p>用符号引用转化成直接引用的解析时机，把解析分为两大类 </p><ul><li><p><strong>静态解析</strong>：符号引用在类加载阶段或者第一次使用的时候就直接转换成直接引用。</p></li><li><p><strong>动态连接</strong>：符号引用在每次运行期间转换为直接引用，即每次运行都重新转换。</p></li></ul></li><li><p><strong>方法返回地址</strong></p><p>方法退出方式有：正常退出与异常退出</p><p>理论上，执行完当前栈帧的方法，需要返回到当前方法被调用的位置，所以栈帧需要记录一些信息，用来恢复上层方法的执行状态。正常退出：上层方法的PC计数器可以做为当前方法的返回地址，被保存在当前栈帧中。异常退出时：通过异常处理器表来确定返回地址。</p><p>方法退出时会做的操作：恢复上次方法的局部变量表、操作数栈，把当前方法的返回值，压入调用者栈帧的操作数栈中，使用当前栈帧保存的返回地址调整PC计数器的值，当前栈帧出栈，随后，执行PC计数器指向的指令。</p></li><li><p><strong>附加信息</strong></p><p>虚拟机规范允许实现虚拟机时增加一些额外信息，例如与调试相关的信息。</p><p>一般把动态连接、方法返回地址、其他额外信息归成一类，称为栈帧信息。</p></li></ul><h2 id="字节码执行引擎"><a href="#字节码执行引擎" class="headerlink" title="字节码执行引擎"></a>字节码执行引擎</h2><p>Java编译器输出的指令流基本上是一种基于栈的指令集架构，指令流中的指令大部分都是零地址指令，它们依赖操作数栈进行工作。</p><p>基于寄存器的指令集，最典型的就是x86的二地址指令集，说得通俗一些，就是现在我们主流PC机中直接支持的指令集架构，这些指令依赖寄存器进行工作。</p><p>举个最简单的例子，分别使用这两种指令集计算“1+1”的结果，基于栈的指令集会是这样子的：</p><p>iconst_1</p><p>iconst_1</p><p>iadd</p><p>istore_0</p><p>两条iconst_1指令连续把两个常量1压入栈后，iadd指令把栈顶的两个值出栈、相加，然后把结果放回栈顶，最后istore_0把栈顶的值放到局部变量表的第0个Slot中。</p><p>如果基于寄存器，那程序可能会是这个样子：</p><p>mov eax，1</p><p>add eax，1</p><p>mov指令把EAX寄存器的值设为1，然后add指令再把这个值加1，结果就保存在EAX寄存器里面。</p><p>基于栈的指令集主要的优点就是可移植，寄存器由硬件直接提供，程序直接依赖这些硬件寄存器则不可避免地要受到硬件的约束。栈架构指令集的主要缺点是执行速度相对来说会稍慢一些。所有主流物理机的指令集都是寄存器架构也从侧面印证了这一点。</p><h2 id="方法调用详解"><a href="#方法调用详解" class="headerlink" title="方法调用详解"></a>方法调用详解</h2><p>在Java语言中符合“编译期可知，运行期不可变”这个要求的方法，主要包括静态方法和私有方法两大类，前者与类型直接关联，后者在外部不可被访问，这两种方法各自的特点决定了它们都不可能通过继承或别的方式重写其他版本，因此它们都适合在类加载阶段进行解析。</p><h3 id="静态分派"><a href="#静态分派" class="headerlink" title="静态分派"></a>静态分派</h3><pre><code>public class StaticDispatch{    static abstract class Human{}    static class Man extends Human{    }    static class Woman extends Human{}    public void sayHello(Human guy){        System.out.println(&quot;hello,guy！&quot;);    }    public void sayHello(Man guy){        System.out.println(&quot;hello,gentleman！&quot;);    }    public void sayHello(Woman guy){        System.out.println(&quot;hello,lady！&quot;);    }    public static void main(String[]args){        Human h1 = new Man();        Human h2 = new Woman();        StaticDispatch sr = new StaticDispatch();        sr.sayHello(h1);        sr.sayHello(h2);        //实际类型变化        Human man=new Man();        //静态类型变化        sr.sayHello((Man)man);        man=new Woman();        sr.sayHello((Woman)man);    }}</code></pre><p>输出结果</p><pre><code>hello,guyhello,guy</code></pre><p>“Human”称为变量的静态类型（Static Type），或者叫做的外观类型（Apparent Type），后面的“Man”则称为变量的实际类型（Actual Type），静态类型和实际类型在程序中都可以发生一些变化，区别是静态类型的变化仅仅在使用时发生，变量本身的静态类型不会被改变，并且变量本身的静态类型是在编译期可知的；而实际类型变化的结果在运行期才可确定，编译器在编译程序的时候并不知道一个对象的实际类型是什么。</p><p>代码中定义了两个静态类型相同但实际类型不同的变量，但虚拟机（准确地说是编译器）在重载时是通过参数的静态类型而不是实际类型作为判定依据的。并且静态类型是编译期可知的，因此，在编译阶段，Javac编译器会根据参数的静态类型决定使用哪个重载版本，所以选择了sayHello（Human）作为调用目标。所有依赖静态类型来定位方法执行版本的分派动作称为静态分派。静态分派的典型应用是方法重载。静态分派发生在编译阶段，因此确定静态分派的动作实际上不是由虚拟机来执行的。</p><h3 id="动态分派"><a href="#动态分派" class="headerlink" title="动态分派"></a>动态分派</h3><pre><code>public class DynamicDispatch {    static abstract class Human{        protected abstract void sayHello();    }    static class Man extends Human{        @Override        protected void sayHello() {            System.out.println(&quot;hello,gentleman！&quot;);        }    }    static class Woman extends Human{        @Override        protected void sayHello() {            System.out.println(&quot;hello,lady！&quot;);        }    }    public static void main(String[]args){        Human h1 = new Man();        Human h2 = new Woman();        h1.sayHello();        h2.sayHello();        h1 = new Woman();        h1.sayHello();    }}</code></pre><p>输出结果</p><pre><code>hello,gentleman！hello,lady！hello,lady！</code></pre><p>上述代码的静态类型同样都是Human的两个变量h1和h2，但在调用sayHello()方法时执行了不同的行为，并且变量好在两次调用中执行了不同的方法。导致这个现象的原因很明显，是这两个变量的实际类型不同。</p><img src="/2020/03/12/JVM%E7%9A%84%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F/pic3.png" srcset="/img/loading.gif" class=""><p>动态分派最常用的实现手段就是为类在方法区中建立一个虚方法表。虚方法表中存放着各个方法的实际入口地址。如果某个方法在子类中没有被重写，那子类的虚方法表里面的地址入口和父类相同方法的地址入口是一致的，都指向父类的实现入口。如果子类中重写了这个方法，子类方法表中的地址将会替换为指向子类实现版本的入口地址。图中，Son重写了来自Father的全部方法，因此Son的方法表没有指向Father类型数据的箭头。但是Son和Father都没有重写来自Object的方法，所以它们的方法表中所有从Object继承来的方法都指向了Object的数据类型。</p><h2 id="类加载机制"><a href="#类加载机制" class="headerlink" title="类加载机制"></a>类加载机制</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（Unloading）7个阶段。其中验证、准备、解析3个部分统称为连接（Linking）</p><h3 id="加载阶段"><a href="#加载阶段" class="headerlink" title="加载阶段"></a>加载阶段</h3><p>虚拟机需要完成以下3件事情：</p><ol><li><p>通过一个类的全限定名来获取定义此类的二进制字节流。</p></li><li><p>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。</p></li><li><p>在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。</p></li></ol><h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><p>是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。但从整体上看，验证阶段大致上会完成下面4个阶段的检验动作：文件格式验证、元数据验证、字节码验证、符号引用验证。</p><h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><p>是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。这个阶段中有两个容易产生混淆的概念需要强调一下，首先，这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。其次，这里所说的初始值通常情况下是数据类型的零值，假设一个类变量的定义为：</p><p>public static int value=123；</p><p>那变量value在准备阶段过后的初始值为0而不是123，因为这时候尚未开始执行任何Java方法，而把value赋值为123的putstatic指令是程序被编译后，存放于类构造器＜clinit＞()方法之中，所以把value赋值为123的动作将在初始化阶段才会执行。假设上面类变量value的定义变为：public static final int value=123；</p><p>编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为123。</p><h3 id="解析阶段"><a href="#解析阶段" class="headerlink" title="解析阶段"></a>解析阶段</h3><p>是虚拟机将常量池内的符号引用替换为直接引用的过程。</p><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>是类加载过程的最后一步，前面的类加载过程中，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制。到了初始化阶段，才真正开始执行类中定义的Java程序代码。在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则根据程序员通过程序制定的主观计划去初始化类变量和其他资源，或者可以从另外一个角度来表达：初始化阶段是执行类构造器＜clinit＞()方法的过程。＜clinit＞()方法是由编译器自动收集类中的所有类变量的赋值动作和静态代码块中的语句合并产生的，编译器收集的顺序是由语句在源文件中出现的顺序所决定的。</p><p>＜clinit＞()方法对于类或接口来说并不是必需的，如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生成＜clinit＞()方法。</p><h4 id="触发类初始化的五种情况"><a href="#触发类初始化的五种情况" class="headerlink" title="触发类初始化的五种情况"></a>触发类初始化的五种情况</h4><p>初始化阶段，虚拟机规定有且只有5种情况必须立即对类进行初始化（而加载、验证、准备需要在此之前开始）：</p><ol><li><p>遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。</p></li><li><p>使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。</p></li><li><p>当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。</p></li><li><p>当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。</p></li><li><p>当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。</p></li></ol><h4 id="初始化时的几种特殊情况"><a href="#初始化时的几种特殊情况" class="headerlink" title="初始化时的几种特殊情况"></a>初始化时的几种特殊情况</h4><ol><li><p>对于静态字段，只有直接定义这个字段的类才会被初始化，当通过其子类来引用父类中定义的静态字段时，只会触发父类的初始化而不会触发子类的初始化。</p></li><li><p>数组形式的new(而不是构造方法)不会触发类初始化</p></li><li><p>直接打印类的常量会不会触发类的初始化</p><p>坑：如果常量发生变化，使用这个常量的其他类中不重新编译就会还是原来的值。其实在编译阶段通过常量传播优化，就已经将常量的值存储到了本类的常量池中，以后对其他类中常量的引用实际都已被转化为对自身常量的引用了。就是说，实际上当前类的Class文件之中并不存在常量所在类的符号引用入口，这两个类在编译成Class之后就不存在任何联系了。</p></li><li><p>如果使用常量去引用另外一个常量，这个时候编译阶段无法进行优化，也会触发类的初始化。</p></li></ol><h4 id="初始化的线程安全"><a href="#初始化的线程安全" class="headerlink" title="初始化的线程安全"></a>初始化的线程安全</h4><p>虚拟机会保证一个类的＜clinit＞()方法在多线程环境中被正确地加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的＜clinit＞()方法，其他线程都需要阻塞等待，直到活动线程执行＜clinit＞()方法完毕。如果在一个类的＜clinit＞()方法中有耗时很长的操作，就可能造成多个进程阻塞。所以类的初始化是线程安全的，项目中可以利用这点。</p><h2 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h2><p>类在JVM中的的唯一性是由它的类加载器及全限定名确定的。每一个类加载器都拥有一个独立的类名称空间，所以比较两个类是否“相等”的前提是这两个类是由同一个类加载器加载，否则，即使这两个类来源于同一个Class文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。</p><p>这里所指的“相等”，包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法的返回结果，也包括使用instanceof关键字做对象所属关系判定等情况。</p><h3 id="类加载器分类"><a href="#类加载器分类" class="headerlink" title="类加载器分类"></a>类加载器分类</h3><ul><li><p><strong>启动类加载器（Bootstrap ClassLoader）</strong>：这个类加载器使负责将存放在＜JAVA_HOME＞\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器，那直接使用null代替即可。</p></li><li><p><strong>扩展类加载器（Extension ClassLoader）</strong>：这个加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载＜JAVA_HOME＞\lib\ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。</p></li><li><p><strong>应用程序类加载器（Application ClassLoader）</strong>：这个类加载器由sun.misc.Launcher$App-ClassLoader实现。由于这个类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，所以一般也称它为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。</p></li></ul><p>但从JVM的角度来讲，只存在两种不同的类加载器，启动类加载器（Bootstrap ClassLoader）和所有其他的类加载器，启动类加载器用C++语言实现，是虚拟机自身的一部分，另一种所有其他的类加载器，使用java语言实现，独立于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader。</p><h3 id="双亲委派模型"><a href="#双亲委派模型" class="headerlink" title="双亲委派模型"></a>双亲委派模型</h3><p>我们的应用程序都是由这3种类加载器互相配合进行加载的，如果有必要，还可以加入自己定义的类加载器。</p><p>双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。这里类加载器之间的父子关系一般不会以继承（Inheritance）的关系来实现，而是都使用组合（Composition）关系即在代码中保存一个父加载器来复用父加载器的代码。</p><img src="/2020/03/12/JVM%E7%9A%84%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F/pic4.png" srcset="/img/loading.gif" class=""><p>某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父类加载器，依次递归，如果父类加载器可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载任务时，才自己去加载。</p><p>使用双亲委派模型来组织类加载器之间的关系，有一个显而易见的好处就是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，保证java程序稳定运行。例如用户自己编写了一个称为java.lang.Object的类，并放在程序的ClassPath中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都是同一个类，即rt.jar中的Object类，用户编写的这个类不会被再次加载。相反，如果没有使用双亲委派模型，由各个类加载器自行去加载的话，系统中将会出现多个不同的Object类，Java类型体系中最基础的行为也就无法保证，应用程序也将会变得一片混乱。</p><h3 id="自定义类加载器"><a href="#自定义类加载器" class="headerlink" title="自定义类加载器"></a>自定义类加载器</h3><p>ClassLoader中的loadClass方法中的代码逻辑就是双亲委派模型：</p><p>在自定义ClassLoader的子类时候，我们常见的会有两种做法，一种是重写<strong>loadClass</strong>方法，另一种是重写<strong>findClass</strong>方法。其实这两种方法本质上差不多，毕竟loadClass也会调用findClass，但是从逻辑上讲最好不要直接修改loadClass的内部逻辑。建议的做法是只在findClass里重写自定义类的加载方法。<br> loadClass这个方法是实现双亲委托模型逻辑的地方，擅自修改这个方法会导致模型被破坏，容易造成问题。因此最好是在双亲委托模型框架内进行小范围的改动，不破坏原有的稳定结构。同时，也避免了自己重写loadClass方法的过程中必须写双亲委托的重复代码，从代码的复用性来看，不直接修改这个方法始终是比较好的选择。</p><h3 id="Tomcat类加载机制"><a href="#Tomcat类加载机制" class="headerlink" title="Tomcat类加载机制"></a>Tomcat类加载机制</h3><p>Tomcat本身也是一个java项目，因此其也需要被JDK的类加载机制加载，也就必然存在引导类加载器、扩展类加载器和应用(系统)类加载器。</p><p>当tomcat启动时，会创建几种类加载器：</p><ol><li><p><strong>Bootstrap 引导类加载器</strong>：加载JVM启动所需的类，以及标准扩展类（位于jre/lib/ext下）</p></li><li><p><strong>System系统类加载器</strong>：加载tomcat启动的类，比如bootstrap.jar，通常在catalina.bat或者catalina.sh中指定。位于CATALINA_HOME/bin下。</p></li><li><p><strong>Common通用类加载器</strong>：加载tomcat使用以及应用通用的一些类，位于CATALINA_HOME/lib下，比如servlet-api.jar</p></li><li><p><strong>webapp应用类加载器</strong>：每个应用在部署后，都会创建一个唯一的类加载器。该类加载器会加载位于 WEB-INF/lib下的jar文件中的class 和 WEB-INF/classes下的class文件。</p></li></ol><img src="/2020/03/12/JVM%E7%9A%84%E6%89%A7%E8%A1%8C%E5%AD%90%E7%B3%BB%E7%BB%9F/pic5.png" srcset="/img/loading.gif" class=""><p><strong>Common ClassLoader</strong>作为<strong>Catalina ClassLoader</strong>和<strong>Shared ClassLoader</strong>的parent，而<strong>Shared ClassLoader</strong>又可能存在多个children类加载器<strong>WebApp ClassLoader</strong>，一个<strong>WebApp ClassLoader</strong>实际上就对应一个Web应用，那Web应用就有可能存在Jsp页面，这些Jsp页面最终会转成class类被加载，因此也需要一个Jsp的类加载器。</p><p>需要注意的是，在代码层面<strong>Catalina ClassLoader</strong>、<strong>Shared ClassLoader</strong>、<strong>Common ClassLoader</strong>对应的实体类实际上都是<strong>URLClassLoader</strong>或者<strong>SecureClassLoader</strong>，一般我们只是根据加载内容的不同和加载父子顺序的关系，在逻辑上划分为这三个类加载器；而<strong>WebApp ClassLoader</strong>和<strong>JasperLoader</strong>都是存在对应的类加载器类的。</p><p>还需要注意的是：<strong>WebApp ClassLoadder</strong>中的<strong>loadClass</strong>方法已经被重写，重写后的<strong>loadClass</strong>方法不再维护<strong>双亲委派机制</strong>，这样就保证了不Tomcat容器下两个应用间类的隔离。</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>JVM</tag>
      
      <tag>Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>垃圾回收算法与垃圾回收器</title>
    <link href="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/"/>
    <url>/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="垃圾回收的区域"><a href="#垃圾回收的区域" class="headerlink" title="垃圾回收的区域"></a>垃圾回收的区域</h2><p>1、面试需要</p><p>2、GC对应用的性能是有影响的；</p><p>3、写代码有好处</p><p>栈中的生命周期是跟随线程，所以一般不需要关注，堆中的对象是垃圾回收的重点，方法区/元空间也会发生垃圾回收，不过这块的效率比较低，一般不是我们关注的重点</p><h2 id="GC判断对象的存活"><a href="#GC判断对象的存活" class="headerlink" title="GC判断对象的存活"></a>GC判断对象的存活</h2><h3 id="引用计数法"><a href="#引用计数法" class="headerlink" title="引用计数法"></a>引用计数法</h3><p>给对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。（Python在用，但主流虚拟机没有使用）</p><p>优点：快，方便，实现简单。</p><p>缺陷：对象相互引用时（A.instance=B同时B.instance=A），很难判断对象是否该回收。</p><h3 id="可达性分析"><a href="#可达性分析" class="headerlink" title="可达性分析"></a>可达性分析</h3><p>这个算法的基本思路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。</p><p>作为GC Roots的对象包括下面几种：</p><ul><li><p>当前虚拟机栈中局部变量表中的引用的对象</p></li><li><p>当前本地方法栈中局部变量表中的引用的对象</p></li><li><p>方法区中类静态属性引用的对象</p></li><li><p>方法区中的常量引用的对象</p></li></ul><p>注意：当垃圾回收器将要回收对象所占内存之前会调用finalize()方法，让此对象处理它生前的最后事情（这个对象可以趁这个时机挣脱死亡的命运）。finalize()可以完成对象的拯救，但是JVM不保证一定能执行。</p><h2 id="引用（Reference）"><a href="#引用（Reference）" class="headerlink" title="引用（Reference）"></a>引用（Reference）</h2><p>传统定义：Reference中存储的数据代表的是一块内存的起始地址。</p><h3 id="强引用"><a href="#强引用" class="headerlink" title="强引用"></a>强引用</h3><p>即使内存不足，垃圾回收器也绝对不会回收GC Roots的强引用对象。</p><p>一般的Object obj = new Object() ，就属于强引用。</p><h3 id="软引用（SoftReference）"><a href="#软引用（SoftReference）" class="headerlink" title="软引用（SoftReference）"></a>软引用（SoftReference）</h3><p>垃圾回收器在内存充足的时候不会回收GC Roots 的软引用对象，而在内存不足时才会回收。</p><p>软引用非常适合于创建缓存。当系统内存不足的时候，缓存中的内容是可以被释放的。例如，一个程序用来处理用户提供的图片。如果将所有图片读入内存，这样虽然可以很快的打开图片，但内存空间使用巨大，一些使用较少的图片浪费内存空间，需要手动从内存中移除。如果每次打开图片都从磁盘文件中读取到内存再显示出来，虽然内存占用较少，但一些经常使用的图片每次打开都要访问磁盘，代价巨大。这个时候就可以用软引用构建缓存。</p><p>用软引用关联的对象，系统将要发生OOM之前，这些对象就会被回收。参见代码：</p><p>VM参数 -Xms10m -Xmx10m -XX:+PrintGC</p><pre><code>public class TestSoftRef {    //对象    public static class User{        public int id = 0;        public String name = &quot;&quot;;        public User(int id, String name) {            super();            this.id = id;            this.name = name;        }        @Override        public String toString() {            return &quot;User [id=&quot; + id + &quot;, name=&quot; + name + &quot;]&quot;;        }    }    //    public static void main(String[] args) {        User u = new User(1,&quot;King&quot;); //new是强引用        SoftReference&lt;User&gt; userSoft = new SoftReference&lt;User&gt;(u);        u = null;//干掉强引用，确保这个实例只有userSoft的软引用        System.out.println(userSoft.get()); //看一下这个对象是否还在        System.gc();//进行一次GC垃圾回收  千万不要写在业务代码中。        System.out.println(&quot;After gc&quot;);        System.out.println(userSoft.get());        //往堆中填充数据，导致OOM        List&lt;byte[]&gt; list = new LinkedList&lt;&gt;();        try {            for(int i=0;i&lt;100;i++) {                System.out.println(&quot;*************&quot;+userSoft.get());                list.add(new byte[1024*1024*1]); //1M的对象            }        } catch (Throwable e) {            //抛出了OOM异常时打印软引用对象            System.out.println(&quot;Exception*************&quot;+userSoft.get());        }    }}</code></pre><p>运行结果</p><img src="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/pic1.png" srcset="/img/loading.gif" class=""><h3 id="弱引用-WeakReference"><a href="#弱引用-WeakReference" class="headerlink" title="弱引用 WeakReference"></a>弱引用 WeakReference</h3><p>垃圾回收器在扫描到弱引用的对象时，无论内存充足与否，都会回收该对象的内存。</p><p>一些有用（程度比软引用更低）但是并非必需，用弱引用关联的对象，只能生存到下一次垃圾回收之前，GC发生时，不管内存够不够都会被回收。</p><p>参看代码：</p><pre><code>public class TestWeakRef {    public static class User{        public int id = 0;        public String name = &quot;&quot;;        public User(int id, String name) {            super();            this.id = id;            this.name = name;        }        @Override        public String toString() {            return &quot;User [id=&quot; + id + &quot;, name=&quot; + name + &quot;]&quot;;        }    }    public static void main(String[] args) {        User u = new User(1,&quot;King&quot;);        WeakReference&lt;User&gt; userWeak = new WeakReference&lt;User&gt;(u);        u = null;//干掉强引用，确保这个实例只有userWeak的弱引用        System.out.println(userWeak.get());        System.gc();//进行一次GC垃圾回收        System.out.println(&quot;After gc&quot;);        System.out.println(userWeak.get());    }}</code></pre><p><strong>注意：</strong>软引用 SoftReference和弱引用 WeakReference，可以用在内存资源紧张的情况下或者创建不是很重要的数据缓存。JDK中WeakHashMap和ThreadLocal中的key使用的就是弱引用。</p><h3 id="虚引用-PhantomReference"><a href="#虚引用-PhantomReference" class="headerlink" title="虚引用 PhantomReference"></a>虚引用 PhantomReference</h3><p>虚引用也被称为幽灵引用，是最弱的引用类型，在被垃圾回收的时候可以收到一个通知，主要被用来跟踪对象被垃圾回收器回收的活动。如果一个对象只具有虚引用，那么它和没有任何引用一样，任何时候都可能被回收。</p><h2 id="GC（Garbage-Collection）"><a href="#GC（Garbage-Collection）" class="headerlink" title="GC（Garbage Collection）"></a>GC（Garbage Collection）</h2><h3 id="Minor-GC"><a href="#Minor-GC" class="headerlink" title="Minor GC"></a>Minor GC</h3><p><strong>特点</strong>：发生在新生代上，发生的较频繁，执行速度较快</p><p>触发条件： Eden区空间不足，空间分配担保成功</p><h3 id="Full-GC"><a href="#Full-GC" class="headerlink" title="Full GC"></a>Full GC</h3><p><strong>特点</strong>： 主要发生在老年代上（新生代也会回收），较少发生，执行速度较慢</p><p><strong>触发条件</strong>： </p><ul><li><p>调用 System.gc()</p></li><li><p>老年代区域空间不足</p></li><li><p>空间分配担保失败</p></li><li><p>JDK 1.7 及以前的永久代(方法区)空间不足</p></li><li><p>CMS GC处理浮动垃圾申请预留空间时，如果新生代空间不足，则采用空间分配担保机制，如果老年代空间不足，则触发Full GC</p></li></ul><h2 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h2><h3 id="复制算法（Copying）"><a href="#复制算法（Copying）" class="headerlink" title="复制算法（Copying）"></a>复制算法（Copying）</h3><p>将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。这块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间全部清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半。</p><p>新生代中的对象98%是“朝生夕死”的，所以一般来说回收占据10%的空间够用了，所以并不需要按照1:1的比例来划分内存空间，而是将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。</p><p>HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的内存会被“浪费”。</p><h3 id="标记-清除算法（Mark-Sweep）"><a href="#标记-清除算法（Mark-Sweep）" class="headerlink" title="标记-清除算法（Mark-Sweep）"></a>标记-清除算法（Mark-Sweep）</h3><p>首先标记所有需要回收的对象 ，之后统一回收被标记的对象。缺点是相对于复制算法标记和清除效率都不高，而且会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。</p><h3 id="标记-整理算法（Mark-Compact）"><a href="#标记-整理算法（Mark-Compact）" class="headerlink" title="标记-整理算法（Mark-Compact）"></a>标记-整理算法（Mark-Compact）</h3><p>首先标记出所有需要回收的对象，在标记完成后，后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。缺点是效率相对标记-清除会更低一点。</p><h2 id="垃圾回收器"><a href="#垃圾回收器" class="headerlink" title="垃圾回收器"></a>垃圾回收器</h2><h3 id="分代收集"><a href="#分代收集" class="headerlink" title="分代收集"></a>分代收集</h3><p>根据各个年代的特点选取不同的垃圾收集算法：新生代使用复制算法，老年代使用标记-整理或者标记-清除算法。</p><p>在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。</p><p>而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。</p><h3 id="各种垃圾回收器"><a href="#各种垃圾回收器" class="headerlink" title="各种垃圾回收器"></a>各种垃圾回收器</h3><h4 id="Serial-Serial-Old"><a href="#Serial-Serial-Old" class="headerlink" title="Serial/Serial Old"></a>Serial/Serial Old</h4><p>最古老、成熟的单线程（独占式）收集器，适用于单CPU 服务器。</p><p>Serial采用<strong>复制算法</strong>回收区域为新生代，Serial Old使用<strong>标记整理算法</strong>回收区域为老年代。</p><h4 id="ParNew"><a href="#ParNew" class="headerlink" title="ParNew"></a>ParNew</h4><p>和Serial基本没区别，唯一的区别在于ParNew是并行收集器，停顿时间比Serial少。</p><p>并行是指垃圾收集的多线程的同时进行。</p><p>ParNew回收区域为<strong>新生代</strong>，算法为<strong>复制算法</strong>。</p><h4 id="Parallel-Scavenge（ParallerGC）-Parallel-Old"><a href="#Parallel-Scavenge（ParallerGC）-Parallel-Old" class="headerlink" title="Parallel Scavenge（ParallerGC）/Parallel Old"></a>Parallel Scavenge（ParallerGC）/Parallel Old</h4><p>注重于吞吐量的并行收集器，高吞吐量可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台计算为主没有太多交互的任务。</p><p>吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。</p><p>Parallel Scavenge（ParallerGC）采用<strong>复制算法</strong>，回收的区域为新生代、Parallel Old采用<strong>标记整理算法</strong>，回收区域为老年代。</p><h4 id="Concurrent-Mark-Sweep-（CMS）"><a href="#Concurrent-Mark-Sweep-（CMS）" class="headerlink" title="Concurrent Mark Sweep （CMS）"></a>Concurrent Mark Sweep （CMS）</h4><p>以获取最短回收停顿时间为目标的并行与并发收集器。</p><p>并发是指垃圾收集的多线程和应用的多线程同时进行，不支持并发的收集器在回收时会暂停所有用户线程（STW -Stop the world）。</p><p>目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。</p><p>从名字（包含“Mark Sweep”）上就可以看出，CMS收集器是基于<strong>标记清除算法</strong>实现的，但它的运作过程相对于前面几种收集器来说更复杂一些，回收区域为<strong>老年代</strong>。</p><p><strong>收集过程</strong>：</p><ul><li><strong>初始标记：</strong>标记 GC Roots的直接关联到的对象，速度很快，需要暂停所有用户线程（STW -Stop the world）。</li><li><strong>并发标记：</strong>从GC Roots的直接关联的对象开始进行可达性分析，找到存活对象，它在整个回收过程中耗时最长，不需要停顿。</li><li><strong>重新标记：</strong>由于并发标记期间用户线程继续运作而导致部分对象的标记记录产生变动，需要停顿(STW)来修正这部分标记记录。停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短。</li><li><strong>并发清除：</strong>不需要停顿。</li></ul><img src="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/pic3.png" srcset="/img/loading.gif" class=""><p>在整个过程中耗时最长的并发标记、并发清除，收集器线程可以与用户线程一起工作，所以总体上说CMS收集器的内存回收过程是与用户线程一起并发执行的。</p><p>由于采用标记 - 清除算法会导致产生不连续的空间碎片</p><p>在并发阶段多线程占据会占据比较多的CPU资源，如果CPU资源不足，效率会明显降低。</p><p>在CMS并发清理之前，标记过程之后用户线程继续运行产生的垃圾，CMS无法在当次收集中处理掉，只好留待下一次GC时再清理掉，这一部分垃圾就称为“浮动垃圾”。</p><p>由于浮动垃圾的存在，需要预留出一部分内存，这就意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。</p><p>在1.6的版本中老年代空间使用率阈值为92%</p><p>如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。</p><h4 id="G1（Garbage-First）垃圾回收器"><a href="#G1（Garbage-First）垃圾回收器" class="headerlink" title="G1（Garbage First）垃圾回收器"></a>G1（Garbage First）垃圾回收器</h4><p>G1（Garbage First）收集器是当今垃圾回收技术最前沿的成果之一。同CMS收集器一样，G1也是关注最小时延的<strong>并行与并发收集器</strong>，也同样适合大尺寸堆内存的垃圾收集，官方也推荐使用G1来代替选择CMS。</p><p>G1最大的特点是引入分区的思路，弱化了分代的概念，合理利用垃圾收集各个周期的资源，解决了其他收集器甚至CMS的众多缺陷。</p><p>G1 把堆划分成多个大小相等的独立区域（Region），每个独立区域会被标记为Eden/Survivor/Old/Humongous（用于存储大对象）中的一个，并使用标记—整理 （humongous） 和复制回收算法(survivor)，避免产生内存碎片。</p><img src="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/pic4.png" srcset="/img/loading.gif" class=""><p>G1可以将可以将停顿（STW）的时间尽可能的控制在设置的时间之内。</p><p>G1收集器之所以能建立可控制的停顿时间模型，是因为它可以避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。</p><h5 id="G1-GC模式"><a href="#G1-GC模式" class="headerlink" title="G1 GC模式"></a>G1 GC模式</h5><h6 id="Young-GC"><a href="#Young-GC" class="headerlink" title="Young GC"></a>Young GC</h6><p>选定所有年轻代里的Region。通过控制年轻代的region个数，即年轻代内存大小，来控制young GC（复制回收算法）的时间开销。</p><h6 id="Mixed-GC"><a href="#Mixed-GC" class="headerlink" title="Mixed GC"></a>Mixed GC</h6><p>选定所有年轻代里的Region，外加根据全局并发标记（global concurrent marking）统计得出收集收益高的若干老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。</p><p>Mixed GC不是full GC，它只能回收部分老年代的Region。如果mixed GC实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行Mixed GC，就会使用serial old GC（full GC）来收集整个GC heap。所以我们可以知道，G1是不提供full GC的。</p><h5 id="全局并发标记（global-concurrent-marking）"><a href="#全局并发标记（global-concurrent-marking）" class="headerlink" title="全局并发标记（global concurrent marking）"></a>全局并发标记（global concurrent marking）</h5><p><strong>初始标记：</strong>仅仅只是标记一下GC Roots 能直接关联到的对象，并且修改TAMS（Nest Top Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可以的Region中创建对象，此阶段需要停顿线程(STW)，但耗时很短。</p><p><strong>并发标记：</strong>对堆中直接关联到GC Roots之外的所有对象进行可达性分析，找到存活对象，此阶段耗时较长，但可与用户程序并发执行。</p><p><strong>最终标记：</strong>为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程(STW)，可并行执行。</p><p><strong>筛选回收：</strong>首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。</p><img src="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/pic5.png" srcset="/img/loading.gif" class=""><h5 id="G1-GC主要的参数"><a href="#G1-GC主要的参数" class="headerlink" title="G1 GC主要的参数"></a>G1 GC主要的参数</h5><table><thead><tr><th><strong>参数</strong></th><th><strong>含义</strong></th></tr></thead><tbody><tr><td>-XX:G1HeapRegionSize=n</td><td>设置Region大小，并非最终值</td></tr><tr><td>-XX:MaxGCPauseMillis</td><td>设置G1收集过程目标时间，默认值200ms，不是硬性条件</td></tr><tr><td>-XX:G1NewSizePercent</td><td>新生代最小值，默认值5%</td></tr><tr><td>-XX:G1MaxNewSizePercent</td><td>新生代最大值，默认值60%</td></tr><tr><td>-XX:ParallelGCThreads</td><td>STW期间，并行GC线程数</td></tr><tr><td>-XX:ConcGCThreads=n</td><td>并发标记阶段，并行执行的线程数</td></tr><tr><td>-XX:InitiatingHeapOccupancyPercent</td><td>设置触发标记周期的 Java 堆占用率阈值。默认值是45%。这里的java堆占比指的是non_young_capacity_bytes，包括old+humongous</td></tr></tbody></table><h4 id="新一代垃圾回收器-ZGC"><a href="#新一代垃圾回收器-ZGC" class="headerlink" title="新一代垃圾回收器-ZGC"></a>新一代垃圾回收器-ZGC</h4><p>Java 11推出了一个全新的垃圾收集器ZGC，它是由Oracle开发的，为实现以下几个目标而诞生的垃圾回收器：</p><ul><li>停顿时间不超过10ms</li><li>停顿时间不会因堆变大而变长</li><li>堆大小范围可支持几G到几T</li></ul><p>为了实现其目标（暂停时间和性能影响），ZGC使用了两种新的热点垃圾收集器技术：指针着色和负载屏障。</p><h5 id="指针着色"><a href="#指针着色" class="headerlink" title="指针着色"></a>指针着色</h5><p>指针表示虚拟内存中字节的位置。 但是，我们不一定要使用指针的所有位来执行此操作 - 某些位可以表示指针的属性。 这就是我们所说的指针着色。</p><p>使用32位，我们可以处理4GB字节（2的32次方）。 由于现在配置的内存已经远远超过了这个数量，我们显然不能使用32位。 因此，ZGC使用64位指针， 这意味着ZGC仅适用于64位平台：</p><img src="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/pic1.png" srcset="/img/loading.gif" class=""><p>ZGC指针使用42位来表示地址本身。 因此，ZGC指针可以处理4TB的内存空间（2的42次方）。</p><p>最重要的是，我们有4位来存储指针状态：</p><ul><li>finalizable bit：该对象只能通过终结器来访问</li><li>重映射位：参考指向对象的当前地址（下面的重定位）</li><li>marked0和marked1位：这些用于标记可到达的对象，我们还将这些位称为元数据位。</li></ul><h5 id="多重映射"><a href="#多重映射" class="headerlink" title="多重映射"></a>多重映射</h5><p>多重映射意味着我们将多个虚拟内存范围映射到物理内存。 在ZGC中，这些范围仅在前面提到的元数据位中不同。</p><p>指针着色使解除引用开销更加昂贵，因为我们必须屏蔽有用的位来访问地址本身。 但是，ZGC绕过这个成本，因为四个元数据位中只有一个是1。这样我们只有四个范围要映射，映射由操作系统处理。 此外，我们只使用其中三个范围，因为我们从不想取消引用可终结指针：</p><h5 id="负载屏障"><a href="#负载屏障" class="headerlink" title="负载屏障"></a>负载屏障</h5><p>负载屏障是一个代码片段，它在线程从堆加载引用时运行，例如，当我们访问对象的非基本字段时。</p><img src="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/pic2.png" srcset="/img/loading.gif" class=""><p>在上面的代码中，第一行（String name = person.name;）这行会对堆中对象数据的Person引用之后，然后加载对其所包含名称的引用，这时会触发负载屏障。</p><p>第二行触发打印到屏幕，不会直接导致负载屏障触发，因为引用名称(name)是局部变量，因此没有从堆加载引用。</p><p>在ZGC中，负载障碍检查引用的元数据位。 根据这些位，ZGC可能会在我们获得它之前对引用执行一些处理。 因此，它可能产生完全不同的引用。</p><h5 id="标记"><a href="#标记" class="headerlink" title="标记"></a>标记</h5><p>标记是垃圾收集器确定我们可以到达哪些对象的过程。 我们无法达到的被认为是垃圾。 ZGC将标记分为三个阶段：</p><ul><li><p>第一阶段是Stop The World阶段。 在这个阶段，我们寻找根引用并标记它们。 根引用是到达堆中对象的起点，例如，局部变量或静态字段。 由于根引用的数量通常较小，因此该阶段很短。</p></li><li><p>下一阶段是并发阶段。 在这个阶段，我们从根引用开始遍历对象图。 我们标记我们到达的每个对象。 此外，当负载屏障检测到未标记的引用时，也会进行标记。</p></li><li><p>最后阶段也是Stop The World阶段，用来处理一些边缘情况，比如弱引用。</p></li></ul><p>这几个阶段完成后，我们就知道哪些对象可达，哪些对象不可达。</p><p>ZGC使用marked0和marked1元数据位进行标记。</p><h5 id="重定位"><a href="#重定位" class="headerlink" title="重定位"></a>重定位</h5><p>当我们必须为新对象分配内存时，我们可以遵循两种策略。</p><p>首先，我们可以扫描内存中的可用空间，直到有空间间足以容纳我们的对象。但是扫描内存是一项昂贵的操作，此外，内存将变得碎片化。如果我们想要减小碎片化，让内存变得更紧凑，将消耗更多的CPU处理能力。</p><p>另一种策略是频繁地将碎片存储区域中的对象以更紧凑的格式重定位到空闲区域。为了更有效，我们将内存空间分成块。我们要么将所有对象重新定位到一个块中的或者一个块不存在一个对象。这样，内存分配会更快，因为我们知道内存中有整个空块。</p><p>在ZGC，重定位也包括三个阶段。</p><ul><li>并发阶段查找我们要重定位的块并将它们放入重定位集中。</li><li>Stop The World阶段将重定位集中的所有根引用进行重定位并更新其引用。</li><li>并发阶段将重定位集中的所有剩余对象进行重定位，并在转发表中存储旧地址和新地址之间的映射。</li></ul><h5 id="重新映射"><a href="#重新映射" class="headerlink" title="重新映射"></a>重新映射</h5><p>请注意，在重定位阶段，我们没有重写对重定位对象的所有引用。 因此，使用这些引用，我们将无法访问我们想要的对象。 更糟糕的是，我们会访问到垃圾对象。</p><p>ZGC使用负载屏障来解决这个问题。 负载屏障使用称为重新映射的技术来修复指向重定位对象的引用。</p><h5 id="如何启用ZGC？"><a href="#如何启用ZGC？" class="headerlink" title="如何启用ZGC？"></a>如何启用ZGC？</h5><p>运行我们的应用程序时，我们可以使用以下命令行选项启用ZGC：</p><p>-XX：+ UnlockExperimentalVMOptions -XX：+ UseZGC 请注意，目前ZGC是一个实验性GC，在生产平台上使用，还需要再考察。</p><h3 id="垃圾回收器之间的对应关系"><a href="#垃圾回收器之间的对应关系" class="headerlink" title="垃圾回收器之间的对应关系"></a>垃圾回收器之间的对应关系</h3><img src="/2020/03/09/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%E4%B8%8E%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/pic2.png" srcset="/img/loading.gif" class=""><h3 id="垃圾回收器的重要参数"><a href="#垃圾回收器的重要参数" class="headerlink" title="垃圾回收器的重要参数"></a>垃圾回收器的重要参数</h3><table><thead><tr><th><strong>参数</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>-XX:UseSerialGC</td><td>虚拟机运行在Client模式下的默认值，打开此开关后，使用 Serial+Serial Old 的收集器组合进行内存回收</td></tr><tr><td>-XX:UseParNewGC</td><td>打开此开关后，使用 ParNew + Serial Old 的收集器组合进行内存回收</td></tr><tr><td>-XX:UseConcMarkSweepGC</td><td>打开此开关后，使用 ParNew + CMS + Serial Old 的收集器组合进行内存回收。Serial Old 收集器将作为 CMS 收集器出现 Concurrent Mode Failure 失败后的后备收集器使用</td></tr><tr><td>-XX:UseParallelGC</td><td>虚拟机运行在 Server 模式下的默认值，打开此开关后，使用 Parallel Scavenge + Serial Old(PS MarkSweep) 的收集器组合进行内存回收</td></tr><tr><td>-XX:UseParallelOldGC</td><td>打开此开关后，使用 Parallel Scavenge + Parallel Old 的收集器组合进行内存回收</td></tr><tr><td>-XX:SurvivorRatio</td><td>新生代中 Eden 区域与 Survivor 区域的容量比值，默认为8，代表 Eden : Survivor = 8 : 1</td></tr><tr><td>-XX:PretenureSizeThreshold</td><td>直接晋升到老年代的对象大小，设置这个参数后，大于这个参数的对象将直接在老年代分配</td></tr><tr><td>-XX:MaxTenuringThreshold</td><td>晋升到老年代的对象年龄，每个对象在坚持过一次 Minor GC 之后，年龄就增加1，当超过这个参数值时就进入老年代</td></tr><tr><td>-XX:UseAdaptiveSizePolicy</td><td>动态调整 Java 堆中各个区域的大小以及进入老年代的年龄</td></tr><tr><td>-XX:HandlePromotionFailure</td><td>是否允许分配担保失败，即老年代的剩余空间不足以应付新生代的整个 Eden 和 Survivor 区的所有对象都存活的极端情况</td></tr><tr><td>-XX:ParallelGCThreads</td><td>设置并行GC时进行内存回收的线程数</td></tr><tr><td>-XX:GCTimeRatio</td><td>GC 时间占总时间的比率，默认值为99，即允许 1% 的GC时间，仅在使用 Parallel Scavenge 收集器生效</td></tr><tr><td>-XX:MaxGCPauseMillis</td><td>设置 GC 的最大停顿时间，仅在使用 Parallel Scavenge 收集器时生效</td></tr><tr><td>-XX:CMSInitiatingOccupancyFraction</td><td>设置 CMS 收集器在老年代空间被使用多少后触发垃圾收集，默认值为 68%，仅在使用 CMS 收集器时生效</td></tr><tr><td>-XX:UseCMSCompactAtFullCollection</td><td>设置 CMS 收集器在完成垃圾收集后是否要进行一次内存碎片整理，仅在使用 CMS 收集器时生效</td></tr><tr><td>-XX:CMSFullGCsBeforeCompaction</td><td>设置 CMS 收集器在进行若干次垃圾收集后再启动一次内存碎片整理，仅在使用 CMS 收集器时生效</td></tr></tbody></table><p>使用jps -v可以查看当前虚拟机参数</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>JVM</tag>
      
      <tag>Java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JVM中的对象</title>
    <link href="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/"/>
    <url>/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/</url>
    
    <content type="html"><![CDATA[<h2 id="对象的分配"><a href="#对象的分配" class="headerlink" title="对象的分配"></a>对象的分配</h2><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic1.png" srcset="/img/loading.gif" class=""><h3 id="检查加载"><a href="#检查加载" class="headerlink" title="检查加载"></a>检查加载</h3><p>先检查对应的类是否已经加载。如果没有，则进行类加载</p><h3 id="分配内存"><a href="#分配内存" class="headerlink" title="分配内存"></a>分配内存</h3><p>虚拟机将为新生对象分配内存。为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来，内存的大小由方法区的信息确定</p><h4 id="内存的分配方式"><a href="#内存的分配方式" class="headerlink" title="内存的分配方式"></a>内存的分配方式</h4><ul><li><p><strong>指针碰撞</strong>：如果Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“<strong>指针碰撞</strong>”。    </p></li><li><p><strong>空闲列表</strong>：如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“<strong>空闲列表</strong>”。</p></li></ul><p>选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。</p><h4 id="并发安全"><a href="#并发安全" class="headerlink" title="并发安全"></a>并发安全</h4><p>对象创建在虚拟机中是非常频繁的行为，修改指针的指向位置可能存在线程安全问题。可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。</p><p>解决这个问题有两种方案一种是使用<strong>CAS机制</strong>及失败重试的方法保证分配内存空间的动作的线程安全。另一种是使用<strong>分配缓冲（Thread Local Allocation Buffer,TLAB）</strong>，即为每个线程在Java堆中预先分配一块大小约为Eden1%的私有内存，让线程在为新对象分配内存空间时使用自己专属的分配指针来分配空间，减少同步开销。</p><p>TLAB只是让每个线程有私有的分配指针，对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。当一个TLAB用满（分配指针top撞上分配极限end了），就需要重新从Eden区域申请。</p><h3 id="内存空间初始化"><a href="#内存空间初始化" class="headerlink" title="内存空间初始化"></a>内存空间初始化</h3><p>内存分配完成后，虚拟机需要将分配到的内存空间初始化为零值，这一步操作保证了对象的实例字段不赋初始值也可以访问对应的零值(如int值为0，boolean值为false，对象类型为null等)。</p><h3 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h3><p>接下来，虚拟机要对对象头的信息进行必要的设置，例如这个对象的hashcode、GC分代年龄、锁标志状态、线程持有的锁、偏向线程ID、偏向时间戳、对应的类的实例、类的元数据信息等。</p><h3 id="对象初始化"><a href="#对象初始化" class="headerlink" title="对象初始化"></a>对象初始化</h3><p>在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从程序的角度来看，对象创建才刚刚开始，所有的字段都还为零值。</p><h4 id="对象的内存布局"><a href="#对象的内存布局" class="headerlink" title="对象的内存布局"></a>对象的内存布局</h4><p>在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。</p><p>对象头包括两部分信息</p><ul><li><p>一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。</p></li><li><p>另外一部分是类型指针，即指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。</p></li></ul><p>实例数据就是指实际的数据，如int类型为1，String类型为字符串等</p><p>对齐填充这部分信息不一定存在，也没有特别的含义，仅仅起着占位符的作用。由于HotSpot VM的内存管理系统要求对对象的大小必须是8字节的整数倍，而对象正好是9字节的整数，所以当对象其他数据部分（对象实例数据）没有对齐时，就需要通过对齐填充来补全。</p><h2 id="对象的访问方式"><a href="#对象的访问方式" class="headerlink" title="对象的访问方式"></a>对象的访问方式</h2><p>建立对象是为了使用对象，我们的Java程序需要通过栈上的引用（reference）数据来操作堆上的具体对象。目前主流的访问方式有使用句柄和直接指针两种。</p><h3 id="句柄"><a href="#句柄" class="headerlink" title="句柄"></a>句柄</h3><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic2.png" srcset="/img/loading.gif" class=""><p>句柄是一种特殊的智能指针 。句柄与普通指针的区别在于，指针包含的是引用对象的内存地址，而句柄则是由系统所管理的引用标识，该标识可以被系统重新定位到一个内存地址上。</p><p>如果使用句柄访问的话，那么Java堆中将会划分出一块内存来作为句柄池，引用（reference）中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。</p><p>使用句柄来访问的最大好处就是引用（reference）中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而引用（reference）本身不需要修改。</p><h3 id="直接指针"><a href="#直接指针" class="headerlink" title="直接指针"></a>直接指针</h3><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic3.png" srcset="/img/loading.gif" class=""><p>如果使用直接指针访问， 引用（reference）中存储的直接就是对象地址。</p><p>使用直接指针访问方式的最大好处就是速度更快，它节省了一次指针定位的时间开销，由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是一项非常可观的执行成本。</p><p>HotSpot是使用直接指针访问方式进行对象访问的。</p><h2 id="堆内存分配策略"><a href="#堆内存分配策略" class="headerlink" title="堆内存分配策略"></a>堆内存分配策略</h2><h3 id="堆内存的划分"><a href="#堆内存的划分" class="headerlink" title="堆内存的划分"></a>堆内存的划分</h3><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic4.png" srcset="/img/loading.gif" class=""><p>在 Java 中，堆被划分成两个不同的区域：<strong>新生代 ( Young )</strong>、<strong>老年代 ( Old )</strong>。新生代 ( Young ) 又被划分为三个区域：<strong>Eden</strong>、<strong>From Survivor</strong>、<strong>To Survivor</strong>。 </p><p>参数设置</p><ul><li><p>-Xmn20m 表示新生代大小为20m（初始容量和最大容量）</p></li><li><p>-XX:SurvivorRatio=8 表示Eden和Survivor的比值，缺省为8 表示 Eden:From:To= 8:1:1，如果设置为2则表示 Eden:From:To= 2:1:1</p></li><li><p>-XX:PretenureSizeThreshold=4m 表示如果对象大小超过该数值将进入老年代</p></li><li><p>-XX:+PrintGCDetails 表示打印GC详细信息</p></li><li><p>-XX:+UseSerialGC</p></li><li><p>-XX:TargetSurvivorRatio=50% 设定survivor区的目标使用率，默认为50%（分配策略中会有详细解释）</p></li><li><p>-XX:MaxTenuringThreshold=15 晋升年龄最大阈值，默认15</p></li></ul><h3 id="分配策略"><a href="#分配策略" class="headerlink" title="分配策略"></a>分配策略</h3><ul><li><p><strong>对象优先在Eden分配</strong></p><p>大多数情况下，对象在新生代Eden区中分配。当Eden区没有足够空间分配时，虚拟机将发起一次Minor GC。</p></li><li><p><strong>大对象直接进入老年代</strong></p><p>如果对象的大小超过<strong>PretenureSizeThreshold</strong>的数值将直接进入老年代。</p></li><li><p><strong>长期存活的对象将进入老年代</strong></p><p>Minor GC进行回收后，新生代中所有区域存活对象的年龄会加1，Eden区域中存活的对象将进入Survivor(from)区或Survivor(to)区，Survivor(from)区的存活对象会进入Survivor(to)区，Survivor(to)区存活的对象会进入Survivor(from)区，当多次回收、对象的年龄达到<strong>MaxTenuringThreshold</strong>之后就会进入老年代。Survivor(to)区，Survivor(to)区的对象会频繁交换，这也是Survivor(from)区、Survivor(to)区使用复制回收算法的原因。</p></li><li><p><strong>动态对象年龄判定</strong></p><p>Survivor将区域的年龄从小到大进行累加，当加入某个年龄段后，累加和超过survivor区域<strong>*TargetSurvivorRatio</strong>的时候，就从这个年龄段往上的年龄的对象进入到老年代。</p></li><li><p><strong>空间分配担保</strong></p><p>在发生minor gc之前，虚拟机会检测老年代的连续空间是否大于新生代对象总大小，如果满足就会进行minor gc，如果不满足虚拟机查看HandlePromotionFailure参数是否允许担保失败，如果允许担保失败，会继续检测老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小。若大于，将尝试进行一次minor gc，如果minor gc失败，则重新进行一次full gc，若小于或者不允许担保，那这时也要改为进行一次Full GC。</p><p>JDK 6 Update 24之后HandlePromotionFailure参数不会再影响到虚拟机的空间分配担保策略，虽然源码中还定义了HandlePromotionFailure参数，但是在代码中已经不会再使用它。规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小就会进行Minor GC，否则将进行Full GC。</p></li></ul><h2 id="Java中的泛型"><a href="#Java中的泛型" class="headerlink" title="Java中的泛型"></a>Java中的泛型</h2><h3 id="泛型是什么"><a href="#泛型是什么" class="headerlink" title="泛型是什么"></a>泛型是什么</h3><p>泛型，即“参数化类型”。将所需类型由具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。</p><p>泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。</p><h4 id="泛型类"><a href="#泛型类" class="headerlink" title="泛型类"></a>泛型类</h4><p>引入一个类型变量T（其他大写字母都可以，不过常用的就是T，E，K，V等等），并且用&lt;&gt;括起来，并放在类名的后面。泛型类是允许有多个类型变量的。</p><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic5.png" srcset="/img/loading.gif" class=""><h4 id="泛型接口"><a href="#泛型接口" class="headerlink" title="泛型接口"></a>泛型接口</h4><p>泛型接口与泛型类的定义基本相同。</p><h4 id="泛型方法"><a href="#泛型方法" class="headerlink" title="泛型方法"></a>泛型方法</h4><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic7.png" srcset="/img/loading.gif" class=""><p>泛型方法，是在调用方法的时候指明泛型的具体类型 ，泛型方法可以在任何地方和任何场景中使用，包括普通类和泛型类。</p><h4 id="为什么我们需要泛型？"><a href="#为什么我们需要泛型？" class="headerlink" title="为什么我们需要泛型？"></a>为什么我们需要泛型？</h4><p>实际开发中，经常有数值类型求和的需求，例如实现int类型、long类型、double类型的求和，重新在重载三次add方法。所以范型的好处是：</p><ul><li>适用于多种数据类型执行相同的代码</li><li>泛型中的类型在使用时指定，不需要强制类型转换</li></ul><h4 id="虚拟机是如何实现泛型的？"><a href="#虚拟机是如何实现泛型的？" class="headerlink" title="虚拟机是如何实现泛型的？"></a>虚拟机是如何实现泛型的？</h4><p>泛型只在程序源码中存在，在编译后的字节码文件中，就已经替换为原来的类型了，并且在相应的地方插入了强制转型代码，因此，对于运行期的Java语言来说，ArrayList＜int＞与ArrayList＜String＞就是同一个类，所以泛型技术实际上是Java语言的一颗语法糖。</p><p>Java语言中的泛型实现方法称为类型擦除，基于这种方法实现的泛型称为伪泛型。</p><p>将一段Java代码编译成Class文件，然后再用字节码反编译工具进行反编译后，将会发现泛型都不见了，程序又变回了Java泛型出现之前的写法，泛型类型都变回了原生类型（因为）</p><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic8.png" srcset="/img/loading.gif" class=""><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic9.png" srcset="/img/loading.gif" class=""><h4 id="使用泛型注意事项"><a href="#使用泛型注意事项" class="headerlink" title="使用泛型注意事项"></a>使用泛型注意事项</h4><img src="/2020/03/07/JVM%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/pic10.png" srcset="/img/loading.gif" class=""><p>上面这段代码是不能被编译的，因为参数List＜Integer＞和List＜String＞编译之后都被擦除了，变成了一样的原生类型List＜E＞，导致这两种方法的特征签名变得一模一样（在IDEA中不能通过，但是jdk的编译器是可以，因为jdk是根据方法返回值+方法名+参数）。</p><p>JVM版本兼容性问题：JDK1.5以前，为了确保泛型的兼容性，JVM除了擦除其实还是保留了泛型信息（Signature是其中最重要的一项属性，它的作用就是存储一个方法在字节码层面的特征签名，这个属性中保存的参数类型并不是原生类型，而是包括了参数化类型的信息）-弱记忆。</p><p>另外，从Signature属性的出现我们还可以得出结论，擦除仅仅是对方法的Code属性中的字节码进行擦除，实际上元数据中还是保留了泛型信息，这也是我们能通过反射手段取得参数化类型的根本依据。</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>JVM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入理解JVM内存区域</title>
    <link href="/2020/03/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/"/>
    <url>/2020/03/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="Java-SE体系架构"><a href="#Java-SE体系架构" class="headerlink" title="Java SE体系架构"></a>Java SE体系架构</h2><p>JavaSE，Java平台标准版，为Java EE和Java ME提供了基础。</p><p>JDK：Java开发工具包，JDK是JRE的超集，包含JRE中的所有内容，以及开发程序所需的编译器和调试程序等工具。</p><p>JRE：Java SE运行时环境 ，提供库、Java虚拟机和其他组件来运行用Java编程语言编写的程序。主要类库，包括：程序部署发布、用户界面工具类、继承库、其他基础库，语言和工具基础库</p><p>JVM：java虚拟机，负责JavaSE平台的硬件和操作系统无关性、编译执行代码（字节码）和平台安全性</p><img src="/2020/03/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/pic1.png" srcset="/img/loading.gif" class=""><h2 id="虚拟机的历史"><a href="#虚拟机的历史" class="headerlink" title="虚拟机的历史"></a>虚拟机的历史</h2><p>虚拟机的区别主要在于字节码的执行的方式，目前主要的执行方式有解释执行和编译执行（针对字节码的执行），解释执行就是边翻译为机器码边执行，编译执行（即时编译）就是先将一个方法中的所有字节码全部编译成机器码之后再执行。</p><h3 id="HotSpot-VM-SUN"><a href="#HotSpot-VM-SUN" class="headerlink" title="HotSpot VM(SUN)"></a>HotSpot VM(SUN)</h3><p>以前使用最广的Java虚拟机，采用的是先解释执行，到了一定时机后热点代码（多次执行、循环等）再翻译成机器码，具有热点代码探测技术（通过执行计数器找到最有编译价值的代码，如果代码用得非常频繁，就会把这些代码编译成本地代码）。</p><h3 id="JRcokit-VM-BEA"><a href="#JRcokit-VM-BEA" class="headerlink" title="JRcokit VM(BEA)"></a>JRcokit VM(BEA)</h3><p>号称“世界上最快的Java虚拟机 ”，JRockit采取的方法是在执行class时直接编译为机器码（Java程序启动速度会比较慢）。</p><h3 id="J9-VM-IBM"><a href="#J9-VM-IBM" class="headerlink" title="J9 VM(IBM)"></a>J9 VM(IBM)</h3><p>J9和Hotspot比较接近，主要是用在IBM产品（IBM WebSphere和IBM的AIX平台上），华为有的项目用的J9。</p><h3 id="Dalvik-VM-Google"><a href="#Dalvik-VM-Google" class="headerlink" title="Dalvik VM(Google)"></a>Dalvik VM(Google)</h3><p>Google Android Dalivk VM：谷歌移动端的虚拟机，使用的寄存器架构，执行dex（Dalvik Executable）通过class转化而来。</p><h3 id="HotSpot-VM-ORACLE"><a href="#HotSpot-VM-ORACLE" class="headerlink" title="HotSpot VM(ORACLE)"></a>HotSpot VM(ORACLE)</h3><p>目前使用范围最广的Java虚拟机，由ORACLE公司收购HotSpot VM(SUN)和JRcokit VM(BEA)之后合并而来。</p><h2 id="未来的Java发展"><a href="#未来的Java发展" class="headerlink" title="未来的Java发展"></a>未来的Java发展</h2><p><strong>模块化：</strong>OSGI（动态化、模块化），应用层面就是微服务，互联网的发展方向</p><p><strong>混合语言</strong>：多个语言都可以运行在JVM中，google的Kotlin 成为了 Android 的官方语言。Scala(Kafka)</p><p><strong>多核并行</strong>：CPU从高频次转变为多核心，多核时代。JDK1.7引入了Fork/Join，JDK1.8提出lambda表达式(函数式编程天生适合并行运行)</p><p><strong>丰富语法：</strong>JDK5提出自动装箱、泛型(并发编程讲到)、动态注解等语法。JDK7二进制原生支持。try-catch-finally 至try-with-resource</p><p><strong>64位：</strong>虽然同样的程序64位内存消耗比32位要多一点，但是支持内存大，所以虚拟机都会完全过渡到64位，32位的JVM有4G的堆大小限制。</p><p><strong>更强的垃圾回收器（现在主流CMS、G1）</strong>：JDK11 –ZGC（暂停时间不超过10毫秒，且不会随着堆的增加而增加，TB级别的堆回收））：有色指针、加载屏障。JDK12支持并发类卸载，进一步缩短暂停时间 JDK13(计划于2019年9月)将最大堆大小从4TB增加到16TB</p><h2 id="JVM的整体介绍"><a href="#JVM的整体介绍" class="headerlink" title="JVM的整体介绍"></a>JVM的整体介绍</h2><img src="/2020/03/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/pic2.png" srcset="/img/loading.gif" class=""><p>JDK将代码编译为class文件后经过类加载存储在JVM的运行时数据区（内存），执行时会由执行引擎使用c++语言去执行对应的机器码。</p><h3 id="运行时数据区域"><a href="#运行时数据区域" class="headerlink" title="运行时数据区域"></a>运行时数据区域</h3><p>JVM在运行过程中会把它管理的内存划分成不同的数据区域。</p><img src="/2020/03/05/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/pic3.png" srcset="/img/loading.gif" class=""><p>线程私有：程序计数器，虚拟机栈，本地方法栈，这部分区域会随着线程产生和消亡，不用担心内存回收问题</p><p>线程共享：堆、方法区</p><p>计算机的运行由指令和数据组成，线程私有的区域主要与指令的执行有关，线程共享区域通常用来存储共享数据。</p><h4 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h4><p>程序计数器是一个较小的内存空间，指向当前线程正在执行的字节码指令的地址。</p><p>由于java是多线程的存在线程切换的情况、当前线程在执行过程中可能会被挂起，所以JVM需要通过程序计数器记录当前线程的执行情况。</p><h4 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h4><p>以栈帧的方式存储<strong>当前线程</strong>运行方法所需的数据指令和返回地址，以及方法调用过程中变量，大小缺省为1M，可用参数 –Xss调整大小，例如-Xss256k。java.lang.StackOverflowError 一般的方法调用是很难出现的，如果出现了要考虑是否有无限递归。</p><p>每个方法在执行的同时都会创建一个<strong>栈帧</strong>并将其入栈，当前线程正在执行的方法就是其虚拟机栈顶的栈桢。</p><p>栈帧中主要包括：</p><ul><li><p><strong>局部变量表：</strong>用于存储方法中的变量（方法入参等）。如果是Java的八大基础数据类型可以直接存储，如果是对象则存放它的引用地址。大小在代码编译时就已经写入到方法表的Code属性，之后不会改变，仅仅取决于具体虚拟机的实现。</p></li><li><p><strong>操作数据栈</strong>：用于执行方法中对数据的操作，操作的的数据可以是任意的java数据类型。</p></li><li><p><strong>动态连接：</strong>提供符号引用和直接引用在运行时进行解析和链接。</p></li><li><p><strong>返回地址：</strong>记录方法执行完成后返回的位置。</p></li></ul><p>使用javap -v JavaStack.class &gt; a.txt之后可以得到字节码文件反编译后的汇编代码，通过汇编代码我们可以深入的了解java代码的工作机制。</p><p>例如将</p><pre><code>public void sub(int num){    num = num - 100;}</code></pre><p>反编译后</p><pre><code>public void sub(int);    descriptor: (I)V    flags: ACC_PUBLIC    Code:      stack=2, locals=2, args_size=2         0: iload_1    // 冒号前的数字表示字节码指令的地址行号，iload_1:下标为1的局部变量表入栈         1: bipush        100    // 将一个byte类型的常量入栈         3: isub    // 将栈顶的两个int的数据出栈、相减，结果入栈         4: istore_1  // 栈顶的int类型存入局部变量表1的位置         5: return      LineNumberTable:        line 9: 0        line 10: 5      LocalVariableTable:    //        Start  Length  Slot  Name   Signature            0       6     0  this   Lcom/jvm/ch01/JavaStack1;            0       6     1   num   I</code></pre><h4 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h4><p>本地方法栈保存的是native方法的信息，当一个JVM创建的线程调用native方法后，JVM不再为其在虚拟机栈中创建栈帧，JVM只是简单地动态链接并直接调用native方法。</p><p>虚拟机规范无强制规定，各版本虚拟机自由实现HotSpot直接把本地方法栈和虚拟机栈合二为一</p><h4 id="方法区（永久代（JDK1-7及以前）、元空间（JDK1-8））"><a href="#方法区（永久代（JDK1-7及以前）、元空间（JDK1-8））" class="headerlink" title="方法区（永久代（JDK1.7及以前）、元空间（JDK1.8））"></a>方法区（永久代（JDK1.7及以前）、元空间（JDK1.8））</h4><p>用于存储：</p><ul><li>类信息：包括类名、修饰符、变量名、方法名、方法代码、返回值、直接接口的有序列表</li><li>常量</li><li>静态变量</li><li>即时编译期编译后的代码</li></ul><h4 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h4><p>堆内存用来存储Java中的对象。无论是成员变量，局部变量，还是类变量，它们指向的对象都存储在堆内存中，堆是需要重点关注的一块区域，因为涉及到内存的分配(new关键字，反射等)与回收(回收算法，收集器等)，</p><p>几乎所有的对象都是在堆中分配，可用以下参数调整：</p><p>-Xms：堆的最小值；</p><p>-Xmx：堆的最大值；</p><p>-Xmn：新生代的大小；</p><p>-XX:NewSize；新生代最小值；</p><p>-XX:MaxNewSize：新生代最大值；</p><p>例如- Xmx256m</p><h4 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h4><p>Class 文件中的常量池（编译器生成的各种字面量和符号引用）会在类加载后被放入这个区域。</p><p>符号引用：通常是字符串，能根据这个字符串定位到指定的数据，比如java/lang/StringBuilder，用于存储：</p><ul><li>类和接口的全限定名</li><li>字段名称和描述符</li><li>方法名称和描述符</li></ul><p>字面量：在代码中直接出现的值，如：</p><ul><li>String a = “A”;</li><li>int b= 1;</li></ul><p>其中 “A”与1都是字面量</p><p>JDK1.6中运行时常量池存储在方法区</p><p>JDK1.7中运行时常量池存储在堆</p><p>JDK1.8中使用元空间替代永久代</p><p>永久代设置参数    -XX:PermSize；-XX:MaxPermSize =100M</p><p>元空间设置参数    -XX:MetaspaceSize； -XX:MaxMetaspaceSize</p><p>永久代的空间受制于MaxPermSize的大小，如果超过这个值就会OOM，所以永久代在存储类信息、常量、静态变量等数据，可能会遇到内存溢出的问题，而且对永久代进行调优是很困难的。</p><p>元空间的大小不会受制于堆内存的大小，而只受制于物理机的最大内存，因此如果元空间的占据了过多的物理机内存，就会挤压堆空间的大小。</p><h4 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h4><p>并不是JVM运行时数据区域的一部分，使用Native函数库直接分配堆外内存（NIO），如果使用了NIO会被频繁使用(可以通过-XX:MaxDirectMemorySize来设置（默认与堆内存最大值一样,也会出现OOM异常)。避免了在Java 堆和Native 堆中来回复制数据，能够提高效率。</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>JVM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>总复习和常见的并发面试题</title>
    <link href="/2020/03/04/%E6%80%BB%E5%A4%8D%E4%B9%A0%E5%92%8C%E5%B8%B8%E8%A7%81%E7%9A%84%E5%B9%B6%E5%8F%91%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <url>/2020/03/04/%E6%80%BB%E5%A4%8D%E4%B9%A0%E5%92%8C%E5%B8%B8%E8%A7%81%E7%9A%84%E5%B9%B6%E5%8F%91%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h2 id="总复习和常见并发面试题"><a href="#总复习和常见并发面试题" class="headerlink" title="总复习和常见并发面试题"></a>总复习和常见并发面试题</h2><h3 id="谈面试"><a href="#谈面试" class="headerlink" title="谈面试"></a>谈面试</h3><ol><li><p>面试主要分为两块：一块是考查工程师对基础知识（包括了技术广度、深度、对技术的热情度等）的掌握程度，因为<strong>基础知识决定了一个技术人员发展的上限</strong>；另一块是考察工程师的工程能力，比如：做过哪些项目？遇到最难的问题怎样解决的？说说最有成就感的一项任务？<strong>工程能力是考察工程师当下能为公司带来的利益</strong>。当然还有其它考核方面：抗压性、合作能力。</p></li><li><p>Java只是一门语言，即使是Java工程师也不能局限于Java，要从面向对象语言本身，甚至从整个计算机体系，从工程实际出发看Java。</p></li><li><p>很多知识在一般公司的开发中是用不到的，常有人戏称：“面试造火箭，工作拧螺丝”，但这只是通常情况下公司对程序员的标准——迅速产出，完成任务。所以，工程师为了自己职业的发展不能局限于公司对自己的要求，不能停留在应用层面，要能够很好地掌握基础知识，要多看源码，自己多实践，学成记得产出，比如多为开源社区贡献代码，帮助初学者指路等。</p></li></ol><h3 id="常见面试题"><a href="#常见面试题" class="headerlink" title="常见面试题"></a>常见面试题</h3><ul><li><p>在java中守护线程和用户线程的区别？</p><p>java中的线程分为两种：守护线程（Daemon）和用户线程（User）。</p><p>任何线程都可以设置为守护线程和用户线程，通过方法Thread.setDaemon(bool on)；true则把该线程设置为守护线程，反之则为用户线程。Thread.setDaemon()必须在Thread.start()之前调用，否则运行时会抛出异常。</p><p>两者的区别： </p><p>唯一的区别是判断虚拟机(JVM)何时离开，Daemon是为其他线程提供服务，如果全部的User Thread已经结束，Daemon 没有可服务的线程，JVM关闭。</p><p>扩展：Thread Dump打印出来的线程信息，含有daemon字样的线程即为守护进程</p></li><li><p>线程与进程的区别</p><p>进程是操作系统分配资源的最小单元，线程是操作系统调度的最小单元。</p><p>一个程序至少有一个进程,一个进程至少有一个线程。</p></li><li><p>什么是多线程中的上下文切换</p><p>多线程会共同使用一组计算机上的CPU，而线程数大于给程序分配的CPU数量时，为了让各个线程都有执行的机会，就需要轮转使用CPU。不同的线程切换使用CPU发生的切换数据等就是上下文切换。</p></li><li><p>死锁与活锁的区别，死锁与饥饿的区别？</p><p>死锁：是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。 </p><p>产生死锁的必要条件： </p><p>互斥条件：所谓互斥就是进程在某一时间内独占资源。</p><p>请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 </p><p>不剥夺条件:进程已获得资源，在末使用完之前，不能强行剥夺。 </p><p>循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。</p><p>活锁：任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。</p><p>活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，所谓的“活”， 而处于死锁的实体表现为等待；活锁有可能自行解开，死锁则不能。</p><p>饥饿：一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行的状态。</p></li><li><p>synchronized底层实现原理</p><p>synchronized (this)原理：涉及两条指令：monitorenter，monitorexit；再说同步方法，从同步方法反编译的结果来看，方法的同步并没有通过指令monitorenter和monitorexit来实现，相对于普通方法，其常量池中多了ACC_SYNCHRONIZED标示符。</p><p>JVM就是根据该标示符来实现方法的同步的：当方法被调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。</p><p>注意，这个问题可能会接着追问，java对象头信息，偏向锁，轻量锁，重量级锁及其他们相互间转化。</p></li><li><p>什么是线程组，为什么在Java中不推荐使用？</p><p>ThreadGroup类，可以把线程归属到某一个线程组中，线程组中可以有线程对象，也可以有线程组，组中还可以有线程，这样的组织结构有点类似于树的形式。</p><ol><li>线程组ThreadGroup对象中比较有用的方法是stop、resume、suspend等方法，由于这几个方法会导致线程的安全问题（主要是死锁问题），已经被官方废弃掉了，所以线程组本身的应用价值就大打折扣了。</li><li>线程组ThreadGroup不是线程安全的，这在使用过程中获取的信息并不全是及时有效的，这就降低了它的统计使用价值。</li></ol></li><li><p>什么是Executors框架？为什么使用Executor框架？</p><p>Executor框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架。</p><p>每次执行任务创建线程 new Thread()比较消耗性能，创建一个线程是比较耗时、耗资源的。</p><p>调用 new Thread()创建的线程缺乏管理，而且可以无限制的创建，线程之间的相互竞争会导致过多占用系统资源而导致系统瘫痪，还有线程之间的频繁交替也会消耗很多系统资源。</p><p>接使用new Thread() 启动的线程不利于扩展，比如定时执行、定期执行、定时定期执行、线程中断等都不便实现。</p></li><li><p>在Java中Executor和Executors的区别？</p><p>Executors 工具类的不同方法按照我们的需求创建了不同的线程池，来满足业务的需求。 </p><p>Executor 接口对象能执行我们的线程任务。 </p><p>ExecutorService接口继承了Executor接口并进行了扩展，提供了更多的方法我们能获得任务执行的状态并且可以获取任务的返回值。 </p><p>使用ThreadPoolExecutor 可以创建自定义线程池。</p></li><li><p>什么是原子操作？在Java Concurrency API中有哪些原子类(atomic classes)<strong>？</strong></p><p>原子操作（atomic operation）意为”不可被中断的一个或一系列操作” 。 </p><p>处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。 </p><p>在Java中可以通过锁和循环CAS的方式来实现原子操作。 CAS操作——Compare &amp; Set，或是 Compare &amp; Swap，现在几乎所有的CPU指令都支持CAS的原子操作。</p><p>java.util.concurrent.atomic下提供了大量的原子操作类，比如原子类：AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference ，原子数组：AtomicIntegerArray，AtomicLongArray，AtomicReferenceArray ，原子属性更新器：AtomicLongFieldUpdater，AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater</p></li><li><p>Java Concurrency API中的Lock接口(Lock interface)是什么？对比synchronized它有什么优势？</p><p>Lock接口比同步方法和同步块提供了更具扩展性的锁操作。 </p><p>他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。</p><p>它的优势有：可以使锁更公平，可以使线程在等待锁的时候响应中断，可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间，可以在不同的范围，以不同的顺序获取和释放锁。</p><p>整体上来说Lock是synchronized的扩展版，Lock提供了无条件的、可轮询的(tryLock方法)、定时的(tryLock带参方法)、可中断的(lockInterruptibly)、可多条件队列的(newCondition方法)锁操作。另外Lock的实现类基本都支持非公平锁(默认)和公平锁，synchronized只支持非公平锁，当然，在大部分情况下，非公平锁是高效的选择。</p></li><li><p>什么是阻塞队列？阻塞队列的实现原理是什么？如何使用阻塞队列来实现生产者-消费者模型？</p><p>阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。</p><p>这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。</p><p>阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。</p><p>JDK7提供了7个阻塞队列。在实现上，主要是利用了Condition和Lock的等待通知模式。</p></li><li><p>什么是Callable和Future?</p><p>Callable接口类似于Runnable，从名字就可以看出来了，但是Runnable不会返回结果，并且无法抛出返回结果的异常，而Callable功能更强大一些，被线程执行后，可以返回值，这个返回值可以被Future拿到，也就是说，</p><p>Future可以拿到异步执行任务的返回值，可以认为是带有回调的Runnable。</p><p>Future接口表示异步任务，是还没有完成的任务给出的未来结果。所以说Callable用于产生结果，Future用于获取结果。</p></li><li><p>什么是<strong>FutureTask?</strong></p><p>在Java并发程序中FutureTask表示一个可以取消的异步运算。它有启动和取消运算、查询运算是否完成和取回运算结果等方法。只有当运算完成的时候结果才能取回，如果运算尚未完成get方法将会阻塞。一个FutureTask对象可以对调用了Callable和Runnable的对象进行包装，由于FutureTask也是调用了Runnable接口所以它可以提交给Executor来执行。</p></li><li><p>什么是并发容器的实现？</p><p>何为同步容器：可以简单地理解为通过synchronized来实现同步的容器，如果有多个线程调用同步容器的方法，它们将会串行执行。比如Vector，Hashtable，以及Collections.synchronizedSet，synchronizedList等方法返回的容器。 </p><p>并发容器使用了与同步容器完全不同的加锁策略来提供更高的并发性和伸缩性，例如在ConcurrentHashMap中采用了一种粒度更细的加锁机制，可以称为分段锁，在这种锁机制下，允许任意数量的读线程并发地访问map，并且执行读操作的线程和写操作的线程也可以并发的访问map，同时允许一定数量的写操作线程并发地修改map，所以它可以在并发环境下实现更高的吞吐量。</p></li><li><p>多线程同步和互斥有几种实现方法，都是什么？</p><p>线程同步是指线程之间所具有的一种制约关系，一个线程的执行依赖另一个线程的消息，当它没有得到另一个线程的消息时应等待，直到消息到达时才被唤醒。 </p><p>线程互斥是指对于共享的进程系统资源，在各单个线程访问时的排它性。当有若干个线程都要使用某一共享资源时，任何时刻最多只允许一个线程去使用，其它要使用该资源的线程必须等待，直到占用资源者释放该资源。线程互斥可以看成是一种特殊的线程同步。</p><p>线程间的同步方法大体可分为两类：用户模式和内核模式。顾名思义，内核模式就是指利用系统内核对象的单一性来进行同步，使用时需要切换内核态与用户态，而用户模式就是不需要切换到内核态，只在用户态完成操作。 </p><p>用户模式下的方法有：原子操作（例如一个单一的全局变量），临界区。内核模式下的方法有：事件，信号量，互斥量。</p></li><li><p>什么是竞争条件？</p><p>当多个进程都企图对共享数据进行某种处理，而最后的结果又取决于进程运行的顺序时，则我们认为这发生了竞争条件（race condition）。</p></li><li><p>为什么我们调用start()方法时会执行run()方法，为什么我们不能直接调用run()方法？</p><p>当你调用start()方法时你将创建新的线程，并且执行在run()方法里的代码。 </p><p>但是如果你直接调用run()方法，它不会创建新的线程也不会执行调用线程的代码，只会把run方法当作普通方法去执行。</p></li><li><p>在Java中CycliBarriar和CountdownLatch有什么区别？</p><p>CyclicBarrier可以重复使用，而CountdownLatch不能重复使用。 </p></li><li><p>什么是不可变对象，它对写并发应用有什么帮助？</p><p>不可变对象(Immutable Objects)即对象一旦被创建它的状态（对象的数据，也即对象属性值）就不能改变，反之即为可变对象(Mutable Objects)。 </p><p>不可变对象的类即为不可变类(Immutable Class)。Java平台类库中包含许多不可变类，如String、基本类型的包装类、BigInteger和BigDecimal等。 </p><p>不可变对象天生是线程安全的。它们的常量（域）是在构造函数中创建的。既然它们的状态无法修改，这些常量永远不会变。</p><p>不可变对象永远是线程安全的。 </p><p>只有满足如下状态，一个对象才是不可变的； </p><p>它的状态不能在创建后再被修改； </p><p>所有域都是final类型；</p><p>它被正确创建；</p></li><li><p>notify()和notifyAll()有什么区别？</p><p>当一个线程进入wait之后，就必须等其他线程notify/notifyall,使用notifyall,可以唤醒所有处于wait状态的线程，使其重新进入锁的争夺队列中，而notify只能唤醒一个。</p><p>如果没把握，建议notifyAll，防止notigy因为信号丢失而造成程序异常。</p></li><li><p>什么是可重入锁（ReentrantLock）？谈谈它的实现。</p><p>线程可以重复进入任何一个它已经拥有的锁所同步着的代码块，synchronized、ReentrantLock都是可重入的锁。在实现上，就是线程每次获取锁时判定如果获得锁的线程是它自己时，简单将计数器累积即可，每 释放一次锁，进行计数器累减，直到计算器归零，表示线程已经彻底释放锁。</p></li><li><p>当一个线程进入某个对象的一个synchronized的实例方法后，其它线程是否可进入此对象的其它方法？</p><p>如果其他方法没有synchronized的话，其他线程是可以进入的。所以要开放一个线程安全的对象时，得保证每个方法都是线程安全的。</p></li><li><p>乐观锁和悲观锁的理解及如何实现，有哪些实现方式？</p><p><strong>悲观锁：</strong>总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。Java里面的同步原语synchronized关键字的实现是悲观锁。</p><p><strong>乐观锁：</strong>顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。在Java中j原子变量类就是使用了乐观锁的一种实现方式CAS实现的。</p><p>乐观锁的实现方式： </p><ul><li>使用版本标识来确定读到的数据与提交时的数据是否一致。提交后修改版本标识，不一致时可以采取丢弃和再次尝试的策略。 </li><li>java中的Compare and Swap即CAS ，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。</li></ul></li><li><p>什么是CAS操作，缺点是什么？</p><p>CAS的基本思路就是，如果这个地址上的值和期望的值相等，则给其赋予新值，否则不做任何事儿，但是要返回原值是多少。每一个CAS操作过程都包含三个运算符：一个内存地址V，一个期望的值A和一个新值B，操作的时候如果这个地址上存放的值等于这个期望的值A，则将地址上的值赋为新值B，否则不做任何操作。</p><p>CAS缺点： </p><p>ABA问题：比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但可能存在潜藏的问题。从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。 </p><p>循环时间长开销大： </p><p>对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。 </p><p>只能保证一个共享变量的原子操作： </p><p>当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。</p></li><li><p>SynchronizedMap和ConcurrentHashMap有什么区别？</p><p>SynchronizedMap一次锁住整张表来保证线程安全，所以每次只能有一个线程来访为map。</p><p>ConcurrentHashMap使用分段锁来保证在多线程下的性能。</p></li><li><p>写时复制容器可以用于什么应用场景？</p><p>CopyOnWrite并发容器用于对于绝大部分访问都是读，且<strong>偶尔写</strong>的并发场景。比如白名单，黑名单，商品类目的访问和更新场景。</p><p>透露的思想：</p><p>读写分离</p><p>最终一致性 </p><p>使用另外开辟空间的思路，来解决并发冲突</p></li><li><p>volatile有什么用？能否用一句话说明下volatile的应用场景？</p><p>volatile保证内存可见性和禁止指令重排。</p><p>volatile用于多线程环境下的一写多读，或者无关联的多写。</p></li><li><p>为什么代码会重排序？</p><p>在执行程序时，为了提供性能，处理器和编译器常常会对指令进行重排序，但是不能随意重排序，它需要满足以下两个条件：</p><p>在单线程环境下不能改变程序运行的结果；</p><p>存在数据依赖关系的不允许重排序</p></li><li><p>在java中wait和sleep方法的不同？</p><p>最大的不同是在等待时wait会释放锁，而sleep一直持有锁。Wait通常被用于线程间交互，sleep通常被用于暂停执行。</p></li><li><p>一个线程运行时发生异常会怎样？</p><p>如果异常没有被捕获该线程将会停止执行。Thread.UncaughtExceptionHandler是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。当一个未捕获异常将造成线程中断的时候JVM会使用Thread.getUncaughtExceptionHandler()来查询线程的UncaughtExceptionHandler并将线程和异常作为参数传递给handler的uncaughtException()方法进行处理。</p></li><li><p>为什么wait, notify 和 notifyAll这些方法不在thread类里面？</p><p>JAVA提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。如果线程需要等待某些锁那么调用对象中的wait()方法就有意义了。如果wait()方法定义在Thread类中，线程正在等待的是哪个锁就不明显了。简单的说，由于wait，notify和notifyAll都是锁级别的操作，所以把他们定义在Object类中因为锁属于对象。</p></li><li><p>什么是ThreadLocal变量？</p><p>ThreadLocal是Java里一种特殊的变量。每个线程都有一个ThreadLocal就是每个线程都拥有了自己独立的一个变量，竞争条件被彻底消除了。</p></li><li><p>Java中interrupted和isInterrupted方法的区别？</p><p>interrupted() 和 isInterrupted()的主要区别是前者会将中断状态清除而后者不会。Java多线程的中断机制是用内部标识来实现的，调用Thread.interrupt()来中断一个线程就会设置中断标识为true。当中断线程调用静态方法Thread.interrupted()来检查中断状态时，中断状态会被清零。而非静态方法isInterrupted()用来查询其它线程的中断状态且不会改变中断状态标识。</p></li><li><p>为什么wait和notify方法要在同步块中调用？</p><p>主要是因为Java API强制要求这样做，如果你不这么做，你的代码会抛出IllegalMonitorStateException异常。</p></li><li><p>为什么你应该在循环中检查等待条件<strong>?</strong></p><p>处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满足结束条件的情况下退出。因此，当一个等待线程醒来时，不能认为它原来的等待状态仍然是有效的，在notify()方法调用之后和等待线程醒来之前这段时间它可能会改变。这就是在循环中使用wait()方法效果更好的原因</p></li><li><p>怎么检测一个线程是否拥有锁？</p><p>在java.lang.Thread中有一个方法叫holdsLock()，它返回true如果当前线程拥有某个具体对象的锁。</p></li><li><p>你如何在Java中获取线程堆栈？</p><p>kill -3 [java pid] 不会在当前终端输出，它会输出到代码执行的或指定的地方去。比如，kill -3 tomcat pid, 输出堆栈到log目录下。</p><p>Jstack [java pid] 这个比较简单，在当前终端显示，也可以重定向到指定文件中。</p><p>或者使用Java提供的拟机线程系统的管理接口ManagementFactory.getThreadMXBean()。</p></li><li><p>Java线程池中submit() <strong>和</strong> execute()方法有什么区别？</p><p>两个方法都可以向线程池提交任务</p><p>execute()方法的返回类型是void，它定义在Executor接口中。</p><p>submit()方法可以返回持有计算结果的Future对象，它定义在ExecutorService接口中，它扩展了Executor接口</p></li><li><p>你对线程优先级的理解是什么？</p><p>每一个线程都是有优先级的，一般来说，高优先级的线程在运行时会具有优先权，但这依赖于线程调度的实现，这个实现是和操作系统相关的(OS dependent)。我们可以定义线程的优先级，但是这并不能保证高优先级的线程会在低优先级的线程前执行。线程优先级是一个int变量(从1-10)，1代表最低优先级，10代表最高优先级。</p><p>java的线程优先级调度会委托给操作系统去处理，所以与具体的操作系统优先级有关，如非特别需要，一般无需设置线程优先级。</p></li><li><p>你如何确保main()方法所在的线程是Java 程序最后结束的线程？</p><p>可以使用Thread类的join()方法（或者CountDownLatch工具类）来确保所有程序创建的线程在main()方法退出前结束。</p></li><li><p>为什么Thread类的sleep()和yield ()方法是静态的？</p><p>Thread类的sleep()和yield()方法将在当前正在执行的线程上运行。所以在其他处于等待状态的线程上调用这些方法是没有意义的。这就是为什么这些方法是静态的。它们可以在当前正在执行的线程中工作，并避免程序员错误的认为可以在其他非运行线程调用这些方法。</p></li><li><p>现在有T1、T2、T3三个线程，你怎样保证T2在T1执行完后执行，T3在T2执行完后执行？</p><p>可以用join方法实现。</p></li><li><p>你需要实现一个高效的缓存，它允许多个用户读，但只允许一个用户写，以此来保持它的完整性，你会怎样去实现它？</p><p>volatile关键字，读写锁，写时复制等等都可以实现。</p></li><li><p>用Java实现阻塞队列</p><p>见作业答案：包cn.enjoyedu.ch5.answer下</p></li><li><p>用Java写代码来解决生产者——消费者问题。</p><p>阻塞队列实现即可，也可以用wait和notify来解决这个问题，或者用Semaphore（信号量）</p></li><li><p>用Java编程一个会导致死锁的程序，你将怎么解决？</p><p> 参见代码cn.enjoyedu.ch7. NormalDeadLock，如何解决死锁，参见笔记。</p></li><li><p>Java中如何停止一个线程？</p><p>使用共享变量的方式 </p><p>在这种方式中，之所以引入共享变量，是因为该变量可以被多个执行相同任务的线程用来作为是否中断的信号，通知中断线程的执行。</p><p>使用interrupt方法终止线程 </p><p>如果一个线程由于等待某些事件的发生而被阻塞，比如当一个线程由于需要等候键盘输入而被阻塞，或者调用Thread.join()方法，或者Thread.sleep()方法，在网络中调用ServerSocket.accept()方法，或者调用了DatagramSocket.receive()方法时，都有可能导致线程阻塞，使线程处于处于不可运行状态时，即使主程序中将该线程的共享变量设置为true，但该线程此时根本无法检查循环标志，当然也就无法立即中断。所以应该尽量使用Thread提供的interrupt()方法，因为该方法虽然不会中断一个正在运行的线程，但是它可以使一个被阻塞的线程抛出一个中断异常，从而使线程提前结束阻塞状态。</p></li><li><p>JVM中哪个参数是用来控制线程的栈堆栈大小的</p><p>-Xss</p></li><li><p>如果同步块内的线程抛出异常锁会释放吗？</p><p>会</p></li><li><p>单例模式的双重检查实现是什么？为什么并不安全？如何在Java中创建线程安全的Singleton？</p><p>实现参见cn.enjoyedu.ch7.dcl. SingleDcl，不安全的根本原因是重排序会导致未初始化完成的对象可以被其他线程看见而导致错误。创建安全的单例模式有：延迟占位模式、在声明的时候就new这个类的实例、枚举</p></li><li><p>写出3条你遵循的多线程最佳实践</p><p>给你的线程起个有意义的名字。 这样可以方便找bug或追踪。OrderProcessor, QuoteProcessor or TradeProcessor 这种名字比 Thread-1. Thread-2 and Thread-3 好多了，给线程起一个和它要完成的任务相关的名字，所有的主要框架甚至JDK都遵循这个最佳实践。</p><p>避免锁定和缩小同步的范围 锁花费的代价高昂且上下文切换更耗费时间空间，试试最低限度的使用同步和锁，缩小临界区。因此相对于同步方法我更喜欢同步块，它给我拥有对锁的绝对控制权。</p><p>多用同步类少用wait 和 notify 首先，CountDownLatch, Semaphore, CyclicBarrier 和 Exchanger 这些同步类简化了编码操作，而用wait和notify很难实现对复杂控制流的控制。其次，这些类是由最好的企业编写和维护在后续的JDK中它们还会不断优化和完善，使用这些更高等级的同步工具你的程序可以不费吹灰之力获得优化。</p><p>多用并发集合少用同步集合 这是另外一个容易遵循且受益巨大的最佳实践，并发集合比同步集合的可扩展性更好，所以在并发编程时使用并发集合效果更好。</p><p>比如并发编程的黄金原则，尽量无锁化编程等等……..</p></li><li><p>请概述线程池的创建参数，怎么样合理配置一个线程池的参数？</p><p>参见笔记中线程池一章的内容</p></li><li><p>请概述锁的公平和非公平，JDK内部是如何实现的。</p><p>公平锁是指所有试图获得锁的线程按照获取锁的顺序依次获得锁，而非公平锁则是当前的锁状态没有被占用时,当前线程可以直接占用,而不需要等待。在实现上，非公平锁逻辑基本跟公平锁一致，唯一的区别是，当前线程不需要判断同步队列中是否有等待线程。</p><p>非公平锁性能高于公平锁性能。首先，在恢复一个被挂起的线程与该线程真正运行之间存在着严重的延迟。而且，非公平锁能更充分的利用cpu的时间片，尽量的减少cpu空闲的状态时间。</p><p>使用场景的话呢，其实还是和他们的属性一一相关，比如：如果业务中线程占用(处理)时间要远长于线程等待，那用非公平锁其实效率并不明显，但是用公平锁可以保证不会有线程被饿死。</p></li><li><p>请概述AQS</p><p>是用来构建锁或者其他同步组件的基础框架，比如ReentrantLock、ReentrantReadWriteLock和CountDownLatch就是基于AQS实现的。它使用了一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作。它是CLH队列锁的一种变体实现。它可以实现2种同步方式：独占式，共享式。</p><p>AQS的主要使用方式是继承，子类通过继承AQS并实现它的抽象方法来管理同步状态，同步器的设计基于模板方法模式，所以如果要实现我们自己的同步工具类就需要覆盖其中几个可重写的方法，如tryAcquire、tryReleaseShared等等。</p><p>这样设计的目的是同步组件（比如锁）是面向使用者的，它定义了使用者与同步组件交互的接口（比如可以允许两个线程并行访问），隐藏了实现细节；同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作。这样就很好地隔离了使用者和实现者所需关注的领域。</p><p>在内部，AQS维护一个共享资源state，通过内置的FIFO来完成获取资源线程的排队工作。该队列由一个一个的Node结点组成，每个Node结点维护一个prev引用和next引用，分别指向自己的前驱和后继结点，构成一个双端双向链表。</p><p>同时与Condition相关的等待队列，节点类型也是Node，构成一个单向链表。</p></li><li><p>请概述volatile</p><p>volatile关键字的作用主要有两点：</p><p>多线程主要围绕可见性和原子性两个特性而展开，使用volatile关键字修饰的变量，保证了其在多线程之间的可见性，即每次读取到volatile变量，一定是最新的数据。但是volatile只能以保证任意单个volatile变量的读/写具有原子性，但类似于++这种复合操作不具有原子性。</p><p>代码底层在执行时为了获取更好的性能会对指令进行重排序，多线程下可能会出现一些意想不到的问题。使用volatile则会对禁止重排序，当然这也一定程度上降低了代码执行效率。</p><p>同时在内存语义上，当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存，当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。</p><p>在Java中对于volatile修饰的变量，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序问题、强制刷新和读取。</p><p>在具体实现上，volatile关键字修饰的变量会存在一个“lock:”的前缀。它不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。</p><p>同时该指令会将当前处理器缓存行的数据直接写会到系统内存中，且这个写回内存的操作会使在其他CPU里缓存了该地址的数据无效。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程 - 面试题</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>java8新增的特性</title>
    <link href="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/"/>
    <url>/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/</url>
    
    <content type="html"><![CDATA[<h2 id="新增原子操作"><a href="#新增原子操作" class="headerlink" title="新增原子操作"></a>新增原子操作</h2><h3 id="LongAdder"><a href="#LongAdder" class="headerlink" title="LongAdder"></a>LongAdder</h3><p>JDK1.8时，java.util.concurrent.atomic包中提供了一个新的原子类：LongAdder。<br> 根据Oracle官方文档的介绍，LongAdder在高并发的场景下会比它的前辈AtomicLong 具有更好的性能，代价是消耗更多的内存空间。</p><p><strong>AtomicLong</strong>是利用了底层的CAS操作来提供并发性的，调用了<strong>Unsafe</strong>类的<strong>getAndAddLong</strong>方法，该方法是个<strong>native</strong>方法，它的逻辑是采用自旋的方式不断更新目标值，直到更新成功。</p><p>在并发量较低的环境下，线程冲突的概率比较小，自旋的次数不会很多。但是，高并发环境下，N个线程同时进行自旋操作，会出现大量失败并不断自旋的情况，此时<strong>AtomicLong</strong>的自旋会成为瓶颈。</p><p>这就是<strong>LongAdder</strong>引入的初衷——解决高并发环境下<strong>AtomicLong</strong>的自旋瓶颈问题。</p><p><strong>AtomicLong</strong>中有个内部变量<strong>value</strong>保存着实际的long值，所有的操作都是针对该变量进行。也就是说，高并发环境下，value变量其实是一个热点，也就是N个线程竞争一个热点。</p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic1.png" srcset="/img/loading.gif" class=""><p><strong>LongAdder</strong>的基本思路就是<strong>分散热点</strong>，将value值分散到一个数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行CAS操作，这样热点就被分散了，冲突的概率就小很多。如果要获取真正的long值，只要将各个槽中的变量值累加返回。</p><p>这种做法和ConcurrentHashMap中的“分段锁”其实就是类似的思路。</p><p><strong>LongAdder</strong>提供的API和<strong>AtomicLong</strong>比较接近，两者都能以原子的方式对long型变量进行增减。</p><p>但是<strong>AtomicLong</strong>提供的功能其实更丰富，尤其是<strong>addAndGet</strong>、<strong>decrementAndGet</strong>、<strong>compareAndSet</strong>这些方法。</p><p><strong>addAndGet</strong>、<strong>decrementAndGet</strong>除了单纯的做自增自减外，还可以立即获取增减后的值，而<strong>LongAdder</strong>则需要做同步控制才能精确获取增减后的值。如果业务需求需要精确的控制计数，做计数比较，<strong>AtomicLong</strong>也更合适。</p><p>另外，从空间方面考虑，<strong>LongAdder</strong>其实是一种“空间换时间”的思想，从这一点来讲<strong>AtomicLong</strong>更适合。</p><p>总之，低并发、一般的业务场景下AtomicLong是足够了。如果并发量很多，存在大量写多读少的情况，那LongAdder可能更合适。适合的才是最好的，如果真出现了需要考虑到底用AtomicLong好还是LongAdder的业务场景，那么这样的讨论是没有意义的，因为这种情况下要么进行性能测试，以准确评估在当前业务场景下两者的性能，要么换个思路寻求其它解决方案。</p><p>对于<strong>LongAdder</strong>来说，内部有一个base变量，一个Cell[]数组。</p><p>base变量：非竞态条件下，直接累加到该变量上。</p><p>Cell[]数组：竞态条件下，累加个各个线程自己的槽Cell[i]中。</p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic2.png" srcset="/img/loading.gif" class=""><p>所以，最终结果的计算应该是</p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic3.png" srcset="/img/loading.gif" class=""><p>在实际运用的时候，只有从未出现过并发冲突的时候，base基数才会使用到，一旦出现了并发冲突，之后所有的操作都只针对Cell[]数组中的单元Cell。</p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic4.png" srcset="/img/loading.gif" class=""><p>而LongAdder最终结果的求和，并没有使用全局锁，返回值不是绝对准确的，因为调用这个方法时还有其他线程可能正在进行计数累加，所以只能得到某个时刻的近似值，这也就是<strong>LongAdder</strong>并不能完全替代<strong>LongAtomic</strong>的原因之一。</p><p>而且从测试情况来看，线程数越多，并发操作数越大，LongAdder的优势越大，线程数较小时，AtomicLong的性能还超过了LongAdder。</p><h3 id="其他新增"><a href="#其他新增" class="headerlink" title="其他新增"></a>其他新增</h3><p>除了新引入LongAdder外，还有引入了它的三个兄弟类：<strong>LongAccumulator</strong>、<strong>DoubleAdder</strong>、<strong>DoubleAccumulator</strong>。</p><p>LongAccumulator是LongAdder的增强版。LongAdder只能针对数值的进行加减运算，而LongAccumulator提供了自定义的函数操作。</p><p>通过LongBinaryOperator，可以自定义对入参的任意操作，并返回结果（LongBinaryOperator接收2个long作为参数，并返回1个long）。</p><p>LongAccumulator内部原理和LongAdder几乎完全一样。</p><p>DoubleAdder和DoubleAccumulator用于操作double原始类型。</p><h2 id="新增显示锁"><a href="#新增显示锁" class="headerlink" title="新增显示锁"></a>新增显示锁</h2><h3 id="StampLock"><a href="#StampLock" class="headerlink" title="StampLock"></a>StampLock</h3><p>StampedLock是Java8引入的一种新的所机制,简单的理解,可以认为它是读写锁的一个改进版本,读写锁虽然分离了读和写的功能,使得读与读之间可以完全并发,但是读和写之间依然是冲突的,读锁会完全阻塞写锁,它使用的依然是悲观的锁策略.如果有大量的读线程,他也有可能引起写线程的饥饿。</p><p>而StampedLock则提供了一种乐观的读策略,这种乐观策略的锁非常类似于无锁的操作,使得乐观锁完全不会阻塞写线程。</p><p>它的思想是读写锁中读不仅不阻塞读，同时也不应该阻塞写。</p><h3 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h3><p>在读的时候如果发生了写，则应当重读而不是在读的时候直接阻塞写。即读写之间不会阻塞对方，但是写和写之间还是阻塞的。</p><p>StampedLock的内部实现是基于CLH的。</p><h3 id="CompletableFuture"><a href="#CompletableFuture" class="headerlink" title="CompletableFuture"></a>CompletableFuture</h3><h4 id="Future不足"><a href="#Future不足" class="headerlink" title="Future不足"></a>Future不足</h4><p>Future是Java 5添加的类，用来描述一个异步计算的结果。你可以使用isDone方法检查计算是否完成，或者使用get阻塞住调用线程，直到计算完成返回结果，你也可以使用cancel方法停止任务的执行。</p><p>虽然Future以及相关使用方法提供了异步执行任务的能力，但是对于结果的获取却是很不方便，只能通过阻塞或者轮询的方式得到任务的结果。阻塞的方式显然和我们的异步编程的初衷相违背，轮询的方式又会耗费无谓的CPU资源，而且也不能及时地得到计算结果，为什么不能用观察者设计模式当计算结果完成及时通知监听者呢？。</p><p>Java的一些框架，比如Netty，自己扩展了Java的 Future接口，提供了addListener等多个扩展方法，Google guava也提供了通用的扩展Future:ListenableFuture、SettableFuture 以及辅助类Futures等,方便异步编程。</p><p>同时Future接口很难直接表述多个Future 结果之间的依赖性。实际开发中，我们经常需要达成以下目的：</p><p>将两个异步计算合并为一个——这两个异步计算之间相互独立，同时第二个又依赖于第一个的结果。</p><p>等待 Future 集合中的所有任务都完成。</p><p>仅等待 Future集合中最快结束的任务完成（有可能因为它们试图通过不同的方式计算同一个值），并返回它的结果。</p><p>应对 Future 的完成事件（即当 Future 的完成事件发生时会收到通知，并能使用 Future 计算的结果进行下一步的操作，不只是简单地阻塞等待操作的结果）</p><h4 id="CompletableFuture-1"><a href="#CompletableFuture-1" class="headerlink" title="CompletableFuture"></a>CompletableFuture</h4><p>JDK1.8才新加入的一个实现类CompletableFuture，实现了Future<T>， CompletionStage<T>两个接口。实现了Future接口，意味着可以像以前一样通过阻塞或者轮询的方式获得结果。</p><h5 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h5><p>除了直接new出一个CompletableFuture的实例，还可以通过工厂方法创建CompletableFuture的实例</p><h5 id="工厂方法"><a href="#工厂方法" class="headerlink" title="工厂方法"></a>工厂方法</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic6.png" srcset="/img/loading.gif" class=""><p>Asynsc表示异步,而supplyAsync与runAsync不同在与前者异步返回一个结果,后者是void.第二个函数第二个参数表示是用我们自己创建的线程池,否则采用默认的ForkJoinPool.commonPool()作为它的线程池。</p><h5 id="获得结果的方法"><a href="#获得结果的方法" class="headerlink" title="获得结果的方法"></a>获得结果的方法</h5><p>public T get()</p><p>public T get(long timeout, TimeUnit unit)</p><p>public T getNow(T valueIfAbsent)</p><p>public T join()</p><p>getNow有点特殊，如果结果已经计算完则返回结果或者抛出异常，否则返回给定的valueIfAbsent值。</p><p>join返回计算的结果或者抛出一个unchecked异常(CompletionException)，它和get对抛出的异常的处理有些细微的区别。</p><h5 id="辅助方法"><a href="#辅助方法" class="headerlink" title="辅助方法"></a>辅助方法</h5><p>public static CompletableFuture<Void> allOf(CompletableFuture&lt;?&gt;… cfs)</p><p>public static CompletableFuture<Object> anyOf(CompletableFuture&lt;?&gt;… cfs)</p><p>allOf方法是当所有的CompletableFuture都执行完后执行计算。</p><p>anyOf方法是当任意一个CompletableFuture执行完后就会执行计算，计算的结果相同。</p><p>CompletionStage是一个接口，从命名上看得知是一个完成的阶段，它代表了一个特定的计算的阶段，可以同步或者异步的被完成。你可以把它看成一个计算流水线上的一个单元，并最终会产生一个最终结果，这意味着几个CompletionStage可以串联起来，一个完成的阶段可以触发下一阶段的执行，接着触发下一次，再接着触发下一次。</p><p>总结CompletableFuture几个关键点：</p><ol><li><p>计算可以由 Future ，Consumer 或者 Runnable 接口中的 apply，accept 或者 run等方法表示。</p></li><li><p>计算的执行主要有以下</p><p>a. 默认执行</p><p>b. 使用默认的CompletionStage的异步执行提供者异步执行。这些方法名使用someActionAsync这种格式表示。</p><p>c. 使用 Executor 提供者异步执行。这些方法同样也是someActionAsync这种格式，但是会增加一个Executor 参数。</p></li></ol><p>CompletableFuture中的方法归类</p><h5 id="变换类"><a href="#变换类" class="headerlink" title="变换类"></a>变换类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic7.png" srcset="/img/loading.gif" class=""><p>关键入参是函数式接口Function。它的入参是上一个阶段计算后的结果，返回值是经过转化后结果。</p><h5 id="消费类"><a href="#消费类" class="headerlink" title="消费类"></a>消费类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic8.png" srcset="/img/loading.gif" class=""><p>关键入参是函数式接口Consumer。它的入参是上一个阶段计算后的结果， 没有返回值。</p><h5 id="执行操作类"><a href="#执行操作类" class="headerlink" title="执行操作类"></a>执行操作类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic9.png" srcset="/img/loading.gif" class=""><p>对上一步的计算结果不关心，执行下一个操作，入参是一个Runnable的实例，表示上一步完成后执行的操作。</p><h5 id="结合转化类"><a href="#结合转化类" class="headerlink" title="结合转化类"></a>结合转化类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic10.png" srcset="/img/loading.gif" class=""><p>需要上一步的处理返回值，并且other代表的CompletionStage 有返回值之后，利用这两个返回值，进行转换后返回指定类型的值。</p><p>两个CompletionStage是并行执行的，它们之间并没有先后依赖顺序，other并不会等待先前的CompletableFuture执行完毕后再执行。</p><p><strong>结合转化类</strong></p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic11.png" srcset="/img/loading.gif" class=""><p>对于Compose可以连接两个CompletableFuture，其内部处理逻辑是当第一个CompletableFuture处理没有完成时会合并成一个CompletableFuture,如果处理完成，第二个future会紧接上一个CompletableFuture进行处理。</p><p>第一个CompletableFuture 的处理结果是第二个future需要的输入参数。</p><h5 id="结合消费类"><a href="#结合消费类" class="headerlink" title="结合消费类"></a>结合消费类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic12.png" srcset="/img/loading.gif" class=""><p>需要上一步的处理返回值，并且other代表的CompletionStage 有返回值之后，利用这两个返回值，进行消费</p><h5 id="运行后执行类"><a href="#运行后执行类" class="headerlink" title="运行后执行类"></a>运行后执行类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic13.png" srcset="/img/loading.gif" class=""><p>不关心这两个CompletionStage的结果，只关心这两个CompletionStage都执行完毕，之后再进行操作（Runnable）。</p><h5 id="取最快转换类"><a href="#取最快转换类" class="headerlink" title="取最快转换类"></a>取最快转换类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic14.png" srcset="/img/loading.gif" class=""><p>两个CompletionStage，谁计算的快，我就用那个CompletionStage的结果进行下一步的转化操作。现实开发场景中，总会碰到有两种渠道完成同一个事情，所以就可以调用这个方法，找一个最快的结果进行处理。</p><h5 id="取最快消费类"><a href="#取最快消费类" class="headerlink" title="取最快消费类"></a>取最快消费类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic15.png" srcset="/img/loading.gif" class=""><p>两个CompletionStage，谁计算的快，我就用那个CompletionStage的结果进行下一步的消费操作。</p><h5 id="取最快运行后执行类"><a href="#取最快运行后执行类" class="headerlink" title="取最快运行后执行类"></a>取最快运行后执行类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic16.png" srcset="/img/loading.gif" class=""><p>两个CompletionStage，任何一个完成了都会执行下一步的操作（Runnable）。</p><h5 id="异常补偿类"><a href="#异常补偿类" class="headerlink" title="异常补偿类"></a>异常补偿类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic17.png" srcset="/img/loading.gif" class=""><p>当运行时出现了异常，可以通过exceptionally进行补偿。</p><h5 id="运行后记录结果类"><a href="#运行后记录结果类" class="headerlink" title="运行后记录结果类"></a>运行后记录结果类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic18.png" srcset="/img/loading.gif" class=""><p>action执行完毕后它的结果返回原始的CompletableFuture的计算结果或者返回异常。所以不会对结果产生任何的作用。</p><h5 id="运行后处理结果类"><a href="#运行后处理结果类" class="headerlink" title="运行后处理结果类"></a>运行后处理结果类</h5><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic19.png" srcset="/img/loading.gif" class=""><p>运行完成时，对结果的处理。这里的完成时有两种情况，一种是正常执行，返回值。另外一种是遇到异常抛出造成程序的中断。</p><h2 id="Lambda表达式"><a href="#Lambda表达式" class="headerlink" title="Lambda表达式"></a>Lambda表达式</h2><p>在语法上，Lambda表达式包含三个部分，参数列表，箭头，主体，比如：</p><p> <strong>(parameters) -&gt; expression</strong></p><p>或</p><p> <strong>(parameters) -&gt; { statements; }</strong></p><p>Lambda表达式用在函数式接口上，所谓函数式接口，是只定义了一个抽象方法的接口（Interface），接口中是否有默认方法，不影响。注解@FunctionalInterface可以帮助我们在设计函数式接口时防止出错。</p><p><strong>函数描述符</strong>:函数式接口的抽象方法的签名基本上就是Lambda表达式的签名。我们将这种抽象方法叫作函数描述符。Runnable接口可以看作一个什么也不接受什么也不返回（void）的函数的签名，因为它只有一个叫作run的抽象方法，这个方法什么也不接受，什么也不返回（void）。我们可以用 () -&gt; void代表参数列表为空，且返回void的函数。这正是Runnable接口所代表的。我们于是可以称() -&gt; void是Runnable接口的函数描述符。</p><p>而Callable接口和Supplier接口的函数描述符是一样的，都是</p><p>() -&gt; X</p><p>所以同一个Lambda可以同时用在这两个函数式接口上，比如：</p><p>Callable&lt;Integer&gt; = () -&gt; 33;</p><p>Supplier&lt;Integer&gt; = () -&gt; 33;</p><p>我们常用的Runnable,Callable都是函数式接口，JDK8中新增了几个函数式接口：</p><p><strong>Predicate</strong></p><p>包含test方法，接受泛型的T，返回boolean，可以视为断言（检查）接口</p><p><strong>Consumer</strong></p><p>包含accept方法，接受泛型的T，无返回，可以视为数据消费接口</p><p><strong>Function&lt;T,R&gt;</strong></p><p>包含apply方法，接受泛型的T，返回R，可以视为映射转换接口</p><p><strong>Supplier</strong></p><p>包含get方法，无输入，返回T，可以视为创建一个新对象接口</p><p><strong>UnaryOperator</strong></p><p>扩展至Function&lt;T,T&gt;，所以这个本质上也是一个映射转换接口，只不过映射转换后的类型保持不变</p><p><strong>BiFunction</strong></p><p>包含apply方法，接受泛型的T、U，返回R，可以视为复合型映射转换接口</p><p><strong>BinaryOperator</strong></p><p>扩展至Function BiFunction&lt;T,T,T&gt;，所以这个本质上也是一个复合型映射转换接口，只不过映射转换后的类型保持不变</p><p><strong>BiPredicate</strong></p><p>包含test方法，接受泛型的T，U，返回boolean，可以视为复合型断言（检查）接口</p><p><strong>BiConsumer&lt;T,U&gt;</strong></p><p>包含accept方法，接受泛型的T，U，无返回，可以视为复合型数据消费接口</p><h2 id="扩充知识点-Disruptor"><a href="#扩充知识点-Disruptor" class="headerlink" title="扩充知识点- Disruptor"></a>扩充知识点- Disruptor</h2><h3 id="应用背景和介绍"><a href="#应用背景和介绍" class="headerlink" title="应用背景和介绍"></a>应用背景和介绍</h3><p>Disruptor是英国外汇交易公司LMAX开发的一个高性能队列，研发的初衷是解决内部的内存队列的延迟问题，而不是分布式队列。基于Disruptor开发的系统单线程能支撑每秒600万订单，2010年在QCon演讲后，获得了业界关注。</p><p>据目前资料显示：应用Disruptor的知名项目有如下的一些：Storm, Camel, Log4j2,还有目前的美团点评技术团队也有很多不少的应用，或者说有一些借鉴了它的设计机制。 </p><p>Disruptor是一个高性能的线程间异步通信的框架，即在同一个JVM进程中的多线程间消息传递。</p><h3 id="传统队列问题"><a href="#传统队列问题" class="headerlink" title="传统队列问题"></a>传统队列问题</h3><p>在JDK中，Java内部的队列BlockQueue的各种实现，仔细分析可以得知，队列的底层数据结构一般分成三种：数组、链表和堆，堆这里是为了实现带有优先级特性的队列暂且不考虑。 </p><p>在稳定性和性能要求特别高的系统中，为了防止生产者速度过快，导致内存溢出，只能选择有界队列；同时，为了减少Java的垃圾回收对系统性能的影响，会尽量选择 Array格式的数据结构。这样筛选下来，符合条件的队列就只有ArrayBlockingQueue。但是ArrayBlockingQueue是通过<strong>加锁</strong>的方式保证线程安全，而且ArrayBlockingQueue还存在<strong>伪共享</strong>问题，这两个问题严重影响了性能。</p><p>ArrayBlockingQueue的这个伪共享问题存在于哪里呢，分析下核心的部分源码，其中最核心的三个成员变量为</p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic20.png" srcset="/img/loading.gif" class=""><p>是在ArrayBlockingQueue的核心enqueue和dequeue方法中经常会用到的，这三个变量很容易放到同一个缓存行中，进而产生伪共享问题。</p><h3 id="高性能的原理"><a href="#高性能的原理" class="headerlink" title="高性能的原理"></a>高性能的原理</h3><ol><li><p>引入环形的数组结构：数组元素不会被回收，避免频繁的GC，</p></li><li><p>无锁的设计：采用CAS无锁方式，保证线程的安全性</p></li><li><p>属性填充：通过添加额外的无用信息，避免伪共享问题</p></li></ol><p>环形数组结构是整个Disruptor的核心所在。 </p><img src="/2020/03/04/java8%E6%96%B0%E5%A2%9E%E7%9A%84%E7%89%B9%E6%80%A7/pic21.png" srcset="/img/loading.gif" class=""><p>首先因为是数组，所以要比链表快，而且根据我们对上面缓存行的解释知道，数组中的一个元素加载，相邻的数组元素也是会被预加载的，因此在这样的结构中，cpu无需时不时去主存加载数组中的下一个元素。而且，你可以为数组预先分配内存，使得数组对象一直存在（除非程序终止）。这就意味着不需要花大量的时间用于垃圾回收。此外，不像链表那样，需要为每一个添加到其上面的对象创造节点对象—对应的，当删除节点时，需要执行相应的内存清理操作。环形数组中的元素采用覆盖方式，避免了jvm的GC。 </p><p>其次结构作为环形，数组的大小为2的n次方，这样元素定位可以通过位运算效率会更高，这个跟一致性哈希中的环形策略有点像。在disruptor中，这个牛逼的环形结构就是RingBuffer，既然是数组，那么就有大小，而且这个大小必须是2的n次方</p><p>其实质只是一个普通的数组，只是当放置数据填充满队列（即到达2^n-1位置）之后，再填充数据，就会从0开始，覆盖之前的数据，于是就相当于一个环。</p><p>每个生产者首先通过CAS竞争获取可以写的空间，然后再进行慢慢往里放数据，如果正好这个时候消费者要消费数据，那么每个消费者都需要获取最大可消费的下标。</p><p>同时，Disruptor 不像传统的队列，分为一个队头指针和一个队尾指针，而是只有一个角标（上图的seq），它属于一个volatile变量，同时也是我们能够不用锁操作就能实现Disruptor的原因之一，而且通过缓存行补充，避免伪共享问题。该指针是通过一直自增的方式来获取下一个可写或者可读数据。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JMM和底层实现原理</title>
    <link href="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
    <url>/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="JMM基础计算机原理"><a href="#JMM基础计算机原理" class="headerlink" title="JMM基础计算机原理"></a>JMM基础计算机原理</h2><p>Java内存模型即Java Memory Model，简称JMM。JMM定义了Java 虚拟机(JVM)在计算机内存(RAM)中的工作方式。JVM是整个计算机虚拟模型，所以JMM是隶属于JVM的。Java1.5版本对其进行了重构，现在的Java仍沿用了Java1.5的版本。Jmm遇到的问题与现代计算机中遇到的问题是差不多的。</p><p>物理计算机中的并发问题，物理机遇到的并发问题与虚拟机中的情况有不少相似之处，物理机对并发的处理方案对于虚拟机的实现也有相当大的参考意义。</p><p>根据《Jeff Dean在Google全体工程大会的报告》我们可以看到</p><table><thead><tr><th>操作</th><th>响应时间</th></tr></thead><tbody><tr><td>打开一个站点</td><td>几秒</td></tr><tr><td>数据库查询一条记录（有索引）</td><td>十几毫秒</td></tr><tr><td>1.6G的CPU执行一条指令</td><td>0.6纳秒</td></tr><tr><td>从机械磁盘顺序读取1M数据</td><td>2-10毫秒</td></tr><tr><td>从机械磁盘顺序读取1M数据</td><td>0.3毫秒</td></tr><tr><td>从机械磁盘顺序读取1M数据</td><td>250微秒</td></tr><tr><td>CPU读取一次内存</td><td>100纳秒</td></tr><tr><td>1G网卡，网络传输2Kb数据</td><td>20微秒</td></tr></tbody></table><p>计算机在做一些我们平时的基本操作时，需要的响应时间是不一样的。</p><p>如果从内存中读取1M的int型数据由CPU进行累加，耗时要多久？</p><p>做个简单的计算，1M的数据，Java里int型为32位，4个字节，共有1024<em>1024/4 = 262144个整数 ，则CPU 计算耗时：262144 *0.6 = 157 286 纳秒，而我们知道从内存读取1M数据需要250000纳秒，两者虽然有差距（当然这个差距并不小，十万纳秒的时间足够CPU执行将近二十万条指令了），但是还在一个数量级上。但是，没有任何缓存机制的情况下，意味着每个数都需要从内存中读取，这样加上CPU读取一次内存需要100纳秒，262144个整数从内存读取到CPU加上计算时间一共需要262144</em>100+250000 = 26 464 400 纳秒，这就存在着数量级上的差异了。</p><p>而且现实情况中绝大多数的运算任务都不可能只靠处理器“计算”就能完成，处理器至少要与内存交互，如读取运算数据、存储运算结果等，这个I/O操作是基本上是无法消除的（无法仅靠寄存器来完成所有运算任务）。早期计算机中cpu和内存的速度是差不多的，但在现代计算机中，cpu的指令速度远超内存的存取速度,由于计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（Cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic1.png" srcset="/img/loading.gif" class=""><p>在计算机系统中，寄存器划是L0级缓存，接着依次是L1，L2，L3（接下来是内存，本地磁盘，远程存储）。越往上的缓存存储空间越小，速度越快，成本也更高；越往下的存储空间越大，速度更慢，成本也更低。从上至下，每一层都可以看做是更下一层的缓存，即：L0寄存器是L1一级缓存的缓存，L1是L2的缓存，依次类推；每一层的数据都是来至它的下一层，所以每一层的数据是下一层的数据的子集。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic2.png" srcset="/img/loading.gif" class=""><p>在现代CPU上，一般来说L0， L1，L2，L3都集成在CPU内部，而L1还分为一级数据缓存（Data Cache，D-Cache，L1d）和一级指令缓存（Instruction Cache，I-Cache，L1i），分别用于存放数据和执行数据的指令解码。每个核心拥有独立的运算处理单元、控制器、寄存器、L1、L2缓存，然后一个CPU的多个核心共享最后一层CPU缓存L3</p><h2 id="物理内存模型带来的问题"><a href="#物理内存模型带来的问题" class="headerlink" title="物理内存模型带来的问题"></a>物理内存模型带来的问题</h2><p>基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是也为计算机系统带来更高的复杂度，因为它引入了一个新的问题：缓存一致性（Cache Coherence）。在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（MainMemory）。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic3.png" srcset="/img/loading.gif" class=""><p>现代的处理器使用写缓冲区临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读/写操作的执行顺序，不一定与内存实际发生的读/写操作顺序一致。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic5.png" srcset="/img/loading.gif" class=""><p>处理器A和处理器B按程序的顺序并行执行内存访问，最终可能得到x=y=0的结果。</p><p>处理器A和处理器B可以同时把共享变量写入自己的写缓冲区（步骤A1，B1），然后从内存中读取另一个共享变量（步骤A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（步骤A3，B3）。当以这种时序执行时，程序就可以得到x=y=0的结果。</p><p>从内存操作实际发生的顺序来看，直到处理器A执行A3来刷新自己的写缓存区，写操作A1才算真正执行了。虽然处理器A执行内存操作的顺序为：A1→A2，但内存操作实际发生的顺序却是A2→A1。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic4.png" srcset="/img/loading.gif" class=""><p>如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、MESI（Illinois Protocol）、MOSI、Synapse、Firefly及Dragon Protocol等。</p><h2 id="伪共享"><a href="#伪共享" class="headerlink" title="伪共享"></a>伪共享</h2><p>前面我们已经知道，CPU中有好几级高速缓存。但是CPU缓存系统中是以缓存行（cache line）为单位存储的。目前主流的CPU Cache的Cache Line大小都是64Bytes。Cache Line可以简单的理解为CPU Cache中的最小缓存单位，今天的CPU不再是按字节访问内存，而是以64字节为单位的块(chunk)拿取，称为一个缓存行(cache line)。当读一个特定的内存地址，整个缓存行将从主存换入缓存。</p><p>一个缓存行可以存储多个变量（存满当前缓存行的字节数）；而CPU对缓存的修改又是以缓存行为最小单位的，在多线程情况下，如果同时修改一个缓存行中的变量，就会无意中影响彼此的性能，这就是伪共享（False Sharing）。</p><p>为了避免伪共享，我们可以使用数据填充的方式来避免，即单个数据填充满一个CacheLine。这本质是一种空间换时间的做法。但是这种方式在Java7以后可能失效。</p><p>Java8中已经提供了官方的解决方案，Java8中新增了一个注解@sun.misc.Contended。</p><p>比如JDK的ConcurrentHashMap中就有使用</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic6.png" srcset="/img/loading.gif" class=""><h2 id="Java内存模型（JMM）"><a href="#Java内存模型（JMM）" class="headerlink" title="Java内存模型（JMM）"></a>Java内存模型（JMM）</h2><p>从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic9.png" srcset="/img/loading.gif" class=""><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic7.png" srcset="/img/loading.gif" class=""><h2 id="Java内存模型带来的问题"><a href="#Java内存模型带来的问题" class="headerlink" title="Java内存模型带来的问题"></a>Java内存模型带来的问题</h2><h3 id="可见性问题"><a href="#可见性问题" class="headerlink" title="可见性问题"></a>可见性问题</h3><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic8.png" srcset="/img/loading.gif" class=""><p>左边CPU中运行的线程从主存中拷贝共享对象obj到它的CPU缓存，把对象obj的count变量改为2。但这个变更对运行在右边CPU中的线程不可见，因为这个更改还没有flush到主存中。</p><p>在多线程的环境下，如果某个线程首次读取共享变量，则首先到主内存中获取该变量，然后存入工作内存中，以后只需要在工作内存中读取该变量即可。同样如果对该变量执行了修改的操作，则先将新值写入工作内存中，然后再刷新至主内存中。但是什么时候最新的值会被刷新至主内存中是不太确定，一般来说会很快，但具体时间不知。</p><p>要解决共享对象可见性这个问题，我们可以使用volatile关键字或者是加锁。</p><h3 id="竞争问题"><a href="#竞争问题" class="headerlink" title="竞争问题"></a>竞争问题</h3><p>线程A和线程B共享一个对象obj。假设线程A从主存读取Obj.count变量到自己的CPU缓存，同时，线程B也读取了Obj.count变量到它的CPU缓存，并且这两个线程都对Obj.count做了加1操作。此时，Obj.count加1操作被执行了两次，不过都在不同的CPU缓存中。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic10.png" srcset="/img/loading.gif" class=""><p>如果这两个加1操作是串行执行的，那么Obj.count变量便会在原始值上加2，最终主存中的Obj.count的值会是3。然而图中两个加1操作是并行的，不管是线程A还是线程B先flush计算结果到主存，最终主存中的Obj.count只会增加1次变成2，尽管一共有两次加1操作。 要解决上面的问题我们可以使用java synchronized代码块</p><h3 id="重排序问题"><a href="#重排序问题" class="headerlink" title="重排序问题"></a>重排序问题</h3><h4 id="重排序类型"><a href="#重排序类型" class="headerlink" title="重排序类型"></a>重排序类型</h4><p>除了共享内存和工作内存带来的问题，还存在重排序的问题：在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型。</p><ol><li><p>编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。</p></li><li><p>指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-LevelParallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。</p></li><li><p>内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。</p></li></ol><h4 id="数据依赖性"><a href="#数据依赖性" class="headerlink" title="数据依赖性"></a>数据依赖性</h4><p>数据依赖性：如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分为下列3种类型</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic11.png" srcset="/img/loading.gif" class=""><p>上面3种情况，只要重排序两个操作的执行顺序，程序的执行结果就会被改变。</p><p>例如</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic12.png" srcset="/img/loading.gif" class=""><p>很明显，A和C存在数据依赖，B和C也存在数据依赖，而A和B之间不存在数据依赖，如果重排序了A和C或者B和C的执行顺序，程序的执行结果就会被改变。</p><p>很明显，不管如何重排序，都必须保证代码在单线程下的运行正确，连单线程下都无法正确，更不用讨论多线程并发的情况，所以就提出了一个as-if-serial的概念。</p><p>as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。</p><p>为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。（强调一下，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。）但是，如果操作之间不存在数据依赖关系，这些操作依然可能被编译器和处理器重排序。</p><p>A和C之间存在数据依赖关系，同时B和C之间也存在数据依赖关系。因此在最终执行的指令序列中，C不能被重排序到A和B的前面（C排到A和B的前面，程序的结果将会被改变）。但A和B之间没有数据依赖关系，编译器和处理器可以重排序A和B之间的执行顺序。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic13.png" srcset="/img/loading.gif" class=""><p>as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器、runtime和处理器可以让我们感觉到：单线程程序看起来是按程序的顺序来执行的。asif-serial语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。</p><h4 id="控制依赖性"><a href="#控制依赖性" class="headerlink" title="控制依赖性"></a>控制依赖性</h4><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic14.png" srcset="/img/loading.gif" class=""><p>上述代码中，flag变量是个标记，用来标识变量a是否已被写入，在use方法中变量i的赋值依赖if (flag)的判断，这里就叫控制依赖，如果发生了重排序，结果就不对了。</p><p>操作1和操作2没有数据依赖关系，编译器和处理器可以对这两个操作重排序；同样，操作3和操作4没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。操作3和操作4则存在所谓<strong>控制依赖关系</strong>。</p><p>在程序中，当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算a*a，然后把计算结果临时保存到一个名为重排序缓冲（Reorder Buffer，ROB）的硬件缓存中。当操作3的条件判断为真时，就把该计算结果写入变量i中。猜测执行实质上对操作3和4做了重排序，问题在于这时候，a的值还没被线程A赋值。</p><p>在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是as-if-serial语义允许对存在控制依赖的操作做重排序的原因）。</p><p>但是对多线程来说就完全不同了：这里假设有两个线程A和B，A首先执行init ()方法，随后B线程接着执行use ()方法。线程B在执行操作4时，能否看到线程A在操作1对共享变量a的写入呢？答案是：不一定能看到。</p><p>让我们先来看看，当操作1和操作2重排序，操作3和操作4重排序时，可能会产生什么效果？操作1和操作2做了重排序。程序执行时，线程A首先写标记变量flag，随后线程B读这个变量。由于条件判断为真，线程B将读取变量a。此时，变量a还没有被线程A写入，这时就会发生错误！</p><p>所以在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。</p><h3 id="解决在并发下的问题"><a href="#解决在并发下的问题" class="headerlink" title="解决在并发下的问题"></a>解决在并发下的问题</h3><h4 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h4><p>Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序，从而让程序按我们预想的流程去执行。</p><ol><li><p>保证特定操作的执行顺序。</p></li><li><p>影响某些数据（或则是某条指令的执行结果）的内存可见性。</p></li></ol><p>编译器和CPU能够重排序指令，保证最终相同的结果，尝试优化性能。插入一条Memory Barrier会告诉编译器和CPU：不管什么指令都不能和这条Memory Barrier指令重排序。</p><p>Memory Barrier所做的另外一件事是强制刷出各种CPU cache，如一个Write-Barrier（写入屏障）将刷出所有在Barrier之前写入 cache 的数据，因此，任何CPU上的线程都能读取到这些数据的最新版本。</p><p>JMM把内存屏障指令分为4类</p><table><thead><tr><th>屏障类型</th><th>指令示例</th><th>说明</th></tr></thead><tbody><tr><td>LoadLoad Barriers</td><td>Load1;LoadLoad;Load2</td><td>确保Load1数据的装载，之前于Load2及所有后续装载指令的装载。</td></tr><tr><td>StoreStore Barriers</td><td>Store1;StoreStore;Store2</td><td>确保Store1数据对其他处理器可见（刷新到内存），之前于Store2及所有后续存储指令的存储。</td></tr><tr><td>LoadStore Barriers</td><td>Load1;LoadStore;Store2</td><td>确保Load1数据装载，之前于Store2及所有后续存储指令刷新到内存。</td></tr><tr><td>StoreLoad Barriers</td><td>Store1;StoreLoad;Load2</td><td>确保Strore1数据对其他处理器可见（刷新到内存），之前于Load2及所有后续装载指令的装载。StoreLoad Barriers会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令。</td></tr></tbody></table><p>StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。现代的多处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。</p><h4 id="临界区"><a href="#临界区" class="headerlink" title="临界区"></a>临界区</h4><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic15.png" srcset="/img/loading.gif" class=""><p>JMM会在退出临界区和进入临界区这两个关键时间点做一些特别处理，使得多线程在这两个时间点按某种顺序执行。</p><p>临界区内的代码则可以重排序（但JMM不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。虽然线程A在临界区内做了重排序，但由于监视器互斥执行的特性，这里的线程B根本无法“观察”到线程A在临界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。</p><p>因为临界区内的代码依然会重排序，所以线程安全的单例模式中一般的双重检查并不能保证真正的线程安全。</p><h2 id="Happens-Before"><a href="#Happens-Before" class="headerlink" title="Happens-Before"></a>Happens-Before</h2><p>在Java 规范提案中为让大家理解内存可见性的这个概念，提出了happens-before的概念来阐述操作之间的内存可见性。对应Java程序员来说，理解happens-before是理解JMM的关键。</p><p>JMM这么做的原因是：程序员对于这两个操作是否真的被重排序并不关心，程序员关心的是程序执行时的语义不能被改变（即执行结果不能被改变）。因此，happens-before关系本质上和as-if-serial语义是一回事。as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证<strong>正确同步</strong>的多线程程序的执行结果不被改变。</p><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>用happens-before的概念来阐述操作之间的内存可见性。在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系 。 </p><p>两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）</p><h3 id="加深理解"><a href="#加深理解" class="headerlink" title="加深理解"></a>加深理解</h3><ol><li><p>站在Java程序员的角度来说：JMM保证，如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。</p></li><li><p>站在编译器和处理器的角度来说：JMM允许，两个操作之间存在happens-before关系，不要求Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序是允许的。</p></li></ol><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><pre><code>double x = 0.03;  //Adouble y = 0.01;  //Bdouble z = x*x*y; //C</code></pre><p>此时代码的逻辑顺序：</p><ol><li><p>A happens-before B</p></li><li><p>B happens-before C</p></li><li><p>A happens-before C</p></li></ol><p>但是仔细考察，2、3是必需的，而1并不是必需的，因此JMM对这三个happens-before关系的处理就分为两类：</p><ol><li><p>会改变程序执行结果的重排序</p></li><li><p>不会改变程序执行结果的重排序</p></li></ol><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic16.png" srcset="/img/loading.gif" class=""><p>JMM对这两种不同性质的重排序，采用了不同的策略，如下：</p><ol><li><p>对于会改变程序执行结果的重排序，JMM要求编译器和处理器必须禁止这种重排序；</p></li><li><p>对于不会改变程序执行结果的重排序，JMM对编译器和处理器不做要求。</p></li></ol><p>于是，站在我们程序员的角度，看起来这个三个操作满足了happens-before关系，而站在编译器和处理器的角度，进行了重排序，而排序后的执行结果，也是满足happens-before关系的。</p><h3 id="Happens-Before规则"><a href="#Happens-Before规则" class="headerlink" title="Happens-Before规则"></a>Happens-Before规则</h3><p>JMM为我们提供了以下的Happens-Before规则：</p><ol><li><p>程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。</p></li><li><p>监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。</p></li><li><p>volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。</p></li><li><p>传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。</p></li><li><p>start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。</p></li><li><p>join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。 </p></li><li><p>线程中断规则：对线程interrupt方法的调用happens-before于被中断线程的代码检测到中断事件的发生。</p></li></ol><h2 id="volatile详解"><a href="#volatile详解" class="headerlink" title="volatile详解"></a>volatile详解</h2><h3 id="volatile特性"><a href="#volatile特性" class="headerlink" title="volatile特性"></a>volatile特性</h3><p>可以把对volatile变量的单个读/写，看成是使用同一个锁对这些单个读/写操作做了同步</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic17.png" srcset="/img/loading.gif" class=""><p>可以看成</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic18.png" srcset="/img/loading.gif" class=""><p>所以volatile变量自身具有下列特性：</p><ul><li><p>可见性。对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。</p></li><li><p>原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。</p></li></ul><h3 id="volatile的内存语义"><a href="#volatile的内存语义" class="headerlink" title="volatile的内存语义"></a>volatile的内存语义</h3><p>内存语义：可以简单理解为 volatile，synchronize，atomic，lock 之类的在 JVM 中的内存方面实现原则。</p><p>volatile写的内存语义如下：<br>当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。 </p><p>volatile读的内存语义如下：<br>当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。 </p><p>所以对于代码</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic19.png" srcset="/img/loading.gif" class=""><p>如果我们将<strong>flag</strong>变量以<strong>volatile</strong>关键字修饰，那么实际上：线程A在写flag变量后，本地内存A中被线程A更新过的两个共享变量的值都被刷新到主内存中。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic20.png" srcset="/img/loading.gif" class=""><p>在读flag变量后，本地内存B包含的值已经被置为无效。此时，线程B必须从主内存中读取共享变量。线程B的读取操作将导致本地内存B与主内存中的共享变量的值变成一致。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic21.png" srcset="/img/loading.gif" class=""><p>如果我们把volatile写和volatile读两个步骤综合起来看的话，在读线程B读一个volatile变量后，写线程A在写这个volatile变量之前所有可见的共享变量的值都将立即变得对读线程B可见。</p><h3 id="为何volatile不是线程安全的"><a href="#为何volatile不是线程安全的" class="headerlink" title="为何volatile不是线程安全的"></a>为何volatile不是线程安全的</h3><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic22.png" srcset="/img/loading.gif" class=""><p>由于volatile只对任意单个volatile变量的读/写具有原子性，但volatile++这种复合操作并不具有原子性，所以仅仅依靠volatile而不对使用过程进行同步控制是不能保证线程安全的。</p><h3 id="volatile内存语义的实现"><a href="#volatile内存语义的实现" class="headerlink" title="volatile内存语义的实现"></a>volatile内存语义的实现</h3><h4 id="volatile重排序规则表"><a href="#volatile重排序规则表" class="headerlink" title="volatile重排序规则表"></a>volatile重排序规则表</h4><table><thead><tr><th>第一个操作/第二个操作</th><th>普通读/写</th><th>volatile读</th><th>volatile写</th></tr></thead><tbody><tr><td><strong>普通读/写</strong></td><td></td><td></td><td>不允许</td></tr><tr><td><strong>volatile读</strong></td><td>不允许</td><td>不允许</td><td>不允许</td></tr><tr><td><strong>volatile写</strong></td><td></td><td>不允许</td><td>不允许</td></tr></tbody></table><h4 id="volatile的内存屏障"><a href="#volatile的内存屏障" class="headerlink" title="volatile的内存屏障"></a>volatile的内存屏障</h4><p>在Java中对于volatile修饰的变量，编译器在生成字节码时，会在指令序列中插入<strong>内存屏障</strong>来禁止特定类型的处理器重排序问题。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic23.png" srcset="/img/loading.gif" class=""><p>storestore屏障：对于这样的语句store1;storestore;store2，在store2及后续写入操作执行前，保证store1的写入操作对其它处理器可见。（也就是说如果出现storestore屏障，那么store1指令一定会在store2之前执行，CPU不会store1与store2进行重排序）</p><p>storeload屏障：对于这样的语句store1;storeload;load2，在load2及后续所有读取操作执行前，保证store1的写入对所有处理器可见。（也就是说如果出现storeload屏障，那么store1指令一定会在load2之前执行，CPU不会对store1与load2进行重排序）</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic24.png" srcset="/img/loading.gif" class=""><p>在每个volatile读操作的后面插入LoadLoad屏障、loadstore屏障。</p><p>loadload屏障：对于这样的语句load1; loadload; load2，在load2及后续读取操作要读取的数据被访问前，保证load1要读取的数据被读取完毕。（也就是说，如果出现loadload屏障，那么load1指令一定会在load2之前执行，CPU不会对load1与load2进行重排序） </p><p>loadstore屏障：对于这样的语句load1; loadstore; store2，在store2及后续写入操作被刷出前，保证load1要读取的数据被读取完毕。（也就是说，如果出现loadstore屏障，那么load1指令一定会在store2之前执行，CPU不会对load1与store2进行重排序）</p><h3 id="volatile的实现原理"><a href="#volatile的实现原理" class="headerlink" title="volatile的实现原理"></a>volatile的实现原理</h3><p>通过对OpenJDK中的unsafe.cpp源码的分析，会发现被volatile关键字修饰的变量会存在一个“lock:”的前缀。</p><p>Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。</p><p>同时该指令会将当前处理器缓存行的数据直接写会到系统内存中，且这个写回内存的操作会使在其他CPU里缓存了该地址的数据无效。</p><p>在具体的执行上，它先对总线和缓存加锁，然后执行后面的指令，最后释放锁后会把高速缓存中的脏数据全部刷新回主内存。在Lock锁住总线的时候，其他CPU的读写请求都会被阻塞，直到锁释放。</p><h2 id="final的内存语义"><a href="#final的内存语义" class="headerlink" title="final的内存语义"></a>final的内存语义</h2><h3 id="编译器和处理器要遵守的两个重排序规则"><a href="#编译器和处理器要遵守的两个重排序规则" class="headerlink" title="编译器和处理器要遵守的两个重排序规则"></a>编译器和处理器要遵守的两个重排序规则</h3><ol><li><p><strong>在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。</strong></p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic25.png" srcset="/img/loading.gif" class=""><p>我们假设一个线程A执行writer方法，随后另一个线程B执行reader方法。</p><p>write()方法中只包含一行代码 <em>obj</em> = new FinalMemory();。这一行代码包含两个步骤：</p><ol><li>构造一个FinalMemory类型的对象。</li><li>把这个对象的引用赋值给引用变量obj。</li></ol><p>假设线程B读对象引用（FinalMemory object = obj）与读对象的成员域之间（int a = object.i;int b = object.j）没有重排序，下面的图是一种可能的执行时序：</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic26.png" srcset="/img/loading.gif" class=""><p>从上面可能的时序图中我们可以看到，读普通域被编译器重排序到了构造函数执行之前，读线程B错误的读取了普通变量i初始化之前的值。而写final域的操作，被写final域的重排序规则“限制”到了构造函数之内，读线程B正确读取了final变量初始化之后的值。</p><p>总结：写final域的重排序规则可以确保在对象引用为任意线程可见之前，对象的final域已经被正常的初始化了，而普通域不具有这样的保证。</p></li><li><p><strong>初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。</strong></p><p>在一个线程中，初次读对象引用与初次读该对象包含的final域，JMM禁止处理器重排序这两个操作。编译器会在读final域操作的前面插入一个LoadLoad屏障。</p><p>reader()方法包含3个步骤：</p><ol><li><p>初次读引用变量obj</p></li><li><p>初次读引用变量obj指向对象的普通域 i</p></li><li><p>初次读引用变量obj指向对象的final域 j</p></li></ol><p>我们假设写线程A没有发生任何重排序，则下图是一种可能的时序：</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic27.png" srcset="/img/loading.gif" class=""><p>读对象的普通域的操作被处理器重排序到读对象引用之前。读普通域时，该域还没有被线程A写入，所以上面的是一个错误的读取操作。但是读final域的重排序规则把读对象final域的操作“限定”在读对象引用之后，该final域已经被A线程初始化了，是一个正确的读取操作。</p><p>总结：读final域的重排序规则可以确保在读一个对象的final域之前，一定会先读包含这个final域的对象的引用.</p></li></ol><h3 id="final域为引用类型"><a href="#final域为引用类型" class="headerlink" title="final域为引用类型"></a>final域为引用类型</h3><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic28.png" srcset="/img/loading.gif" class=""><p>在上面的代码中，final域是一个引用类型，它引用了一个int类型的数组，对于引用类型，写final域的重排序规则对编译器和处理器增加了一下的约束：在构造函数内对一个final引用的对象的成员域的写入，与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。</p><p>我们假设线程A先执行write0操作，执行完后线程B执行write1操作，执行完后线程C执行reader操作，下图是一种可能的执行时序：</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic29.png" srcset="/img/loading.gif" class=""><p>1是对final域的写入，2是对这个final域引用的对象的成员域的写入，3是把被构造的对象的引用赋值给某个引用变量。这里除了前面提到的1不能和3重排序外，2和3也不能重排序。</p><p>JMM可以确保读线程C至少能看到写线程A在构造函数中对final引用对象的成员域的写入。即C至少能看到数组下标0的值为1。而写线程B对数组元素的写入，读线程C可能看得到，也可能看不到。JMM不保证线程B的写入对读线程C可见，因为写线程B和读线程C之间存在数据竞争，此时的执行结果不可预知。</p><p>如果想要确保读线程C看到写线程B对数组元素的写入，写线程B和读线程C之间需要使用同步（lock或volatile）来确保内存可见性。</p><h3 id="final引用不能从构造函数内逃逸"><a href="#final引用不能从构造函数内逃逸" class="headerlink" title="final引用不能从构造函数内逃逸"></a>final引用不能从构造函数内逃逸</h3><p>写final域的重排序规则可以确保：在引用变量为任意线程可见之前，该引用变量指向的对象的final域已经在构造函数中被正确初始化过了。其实，要得到这个效果，还需要一个保证：在构造函数内部，不能让这个被构造对象的引用为其他线程所见，也就是对象引用不能在构造函数中逃逸。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic30.png" srcset="/img/loading.gif" class=""><p>假设一个线程A执行writer()方法，另一个线程B执行reader()方法。这里的操作2使得对象还未完成构造前就为线程B可见。即使这里的操作2是构造函数的最后一步，且在程序中操作2排在操作1后面，执行read()方法的线程仍然可能无法看到final域被初始化后的值，因为这里的操作1和操作2之间可能被重排序。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic31.png" srcset="/img/loading.gif" class=""><p>因此在构造函数返回前，被构造对象的引用不能为其他线程所见，因为此时的final域可能还没有被初始化。</p><h3 id="final语义的实现"><a href="#final语义的实现" class="headerlink" title="final语义的实现"></a>final语义的实现</h3><p>会要求编译器在final域的写之后，构造函数return之前插入一个StoreStore障屏。</p><p>读final域的重排序规则要求编译器在读final域的操作前面插入一个LoadLoad屏障</p><h2 id="锁的内存语义"><a href="#锁的内存语义" class="headerlink" title="锁的内存语义"></a>锁的内存语义</h2><p>当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中。</p><p>当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。 </p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic32.png" srcset="/img/loading.gif" class=""><p>如果我们回顾第一章的VolatileCase，我们知道，为了让子线程可以及时看到<em>ready</em>变量的修改，我们需要将ready变量以volatile来修饰。</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic33.png" srcset="/img/loading.gif" class=""><p>但是，当我们将程序做如下改造</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic34.png" srcset="/img/loading.gif" class=""><p>我们可以看见子线程同样可以中止，为何？我们观察System.out.println的实现，</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic35.png" srcset="/img/loading.gif" class=""><p>结合前面锁的内存语义，我们可以知道，当进入<strong>synchronized</strong>语句块时，子线程会被强制从主内存中读取共享变量，其中就包括了ready变量，所以子线程同样中止了。</p><h2 id="synchronized的实现原理"><a href="#synchronized的实现原理" class="headerlink" title="synchronized的实现原理"></a>synchronized的实现原理</h2><p>Synchronized在JVM里的实现都是基于进入和退出Monitor对象来实现方法同步和代码块同步，虽然具体实现细节不一样，但是都可以通过成对的MonitorEnter和MonitorExit指令来实现。</p><p>对同步块，MonitorEnter指令插入在同步代码块的开始位置，当代码执行到该指令时，将会尝试获取该对象Monitor的所有权，即尝试获得该对象的锁，而monitorExit指令则插入在方法结束处和异常处，JVM保证每个MonitorEnter必须有对应的MonitorExit。</p><p>对同步方法，从同步方法反编译的结果来看，方法的同步并没有通过指令monitorenter和monitorexit来实现，相对于普通方法，其常量池中多了ACC_SYNCHRONIZED标示符。</p><p>JVM就是根据该标示符来实现方法的同步的：当方法被调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。</p><p>synchronized使用的锁是存放在Java对象头里面。</p><table><thead><tr><th>长度</th><th>内容</th><th>说明</th></tr></thead><tbody><tr><td>32/64bit</td><td>Mark Word</td><td>存储对象的hashCode或锁信息等</td></tr><tr><td>32/64bit</td><td>Class Metadata Address</td><td>存储对象类型的数据的指针</td></tr><tr><td>32/64bit</td><td>Array length</td><td>数组的长度（如果当前对象是数组）</td></tr></tbody></table><p>具体位置是对象头里面的MarkWord，MarkWord里默认数据是存储对象的HashCode等信息，</p><table><thead><tr><th>锁状态</th><th>25bit</th><th>4bit</th><th>1bit是否是偏向锁</th><th>2bit锁标识位</th></tr></thead><tbody><tr><td>无锁状态</td><td>对象的hashCode</td><td>对象分代年龄</td><td>0</td><td>0</td></tr></tbody></table><p>但是会随着对象的运行改变而发生变化，不同的锁状态对应着不同的记录存储方式</p><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic36.png" srcset="/img/loading.gif" class=""><h2 id="了解各种锁"><a href="#了解各种锁" class="headerlink" title="了解各种锁"></a>了解各种锁</h2><h3 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。</p><p>但是线程自旋是需要消耗CPU的，说白了就是让CPU在做无用功，线程不能一直占用CPU自旋做无用功，所以需要设定一个自旋等待的最大时间。</p><p>如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。</p><h4 id="自旋锁的优缺点"><a href="#自旋锁的优缺点" class="headerlink" title="自旋锁的优缺点"></a>自旋锁的优缺点</h4><p>在锁的竞争不激烈，且占用锁的同步块执行时间非常短的情况下，自旋的消耗小于线程阻塞挂起操作的消耗，这时自旋锁能够尽可能的减少线程的阻塞，提升代码块性能。</p><p>但是如果锁的竞争激烈，或者占用锁的同步块执行时间比较长，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用cpu做无用功，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要cup的线程又不能获取到cpu，造成cpu的浪费。</p><h4 id="自旋锁时间阈值"><a href="#自旋锁时间阈值" class="headerlink" title="自旋锁时间阈值"></a>自旋锁时间阈值</h4><p>自旋锁的目的是为了占着CPU的资源不释放，等到获取到锁立即进行处理。但是如何去选择自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用CPU资源，进而会影响整体系统的性能。因此自旋次数很重要</p><p>JVM对于自旋次数的选择，jdk1.5默认为10次，在1.6引入了适应性自旋锁，适应性自旋锁意味着自旋的时间不在是固定的了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间。</p><p>JDK1.6中-XX:+UseSpinning开启自旋锁； JDK1.7后，去掉此参数，由jvm控制；</p><h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，只有一个线程访问锁，不存在多线程竞争的情况，则线程是不需要触发同步的，减少加锁／解锁的一些CAS操作（比如等待队列的一些CAS操作），这种情况下，就会给线程加一个偏向锁。 如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。它通过消除资源无竞争情况下的同步原语，进一步提高了程序的运行性能。</p><h4 id="引入背景"><a href="#引入背景" class="headerlink" title="引入背景"></a>引入背景</h4><p>大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁，减少不必要的CAS操作。</p><h4 id="锁的状态"><a href="#锁的状态" class="headerlink" title="锁的状态"></a>锁的状态</h4><p>一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，目的是为了提高获得锁和释放锁的效率。</p><h4 id="偏向锁获取过程"><a href="#偏向锁获取过程" class="headerlink" title="偏向锁获取过程"></a>偏向锁获取过程</h4><ol><li><p>访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，确认为可偏向状态。</p></li><li><p>如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤5，否则进入步骤3。</p></li><li><p>如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。</p></li><li><p>如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the word）</p></li><li><p>执行同步代码。</p></li></ol><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic37.png" srcset="/img/loading.gif" class=""><h4 id="偏向锁的释放"><a href="#偏向锁的释放" class="headerlink" title="偏向锁的释放"></a>偏向锁的释放</h4><p>偏向锁的撤销在上述第四步骤中有提到。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放偏向锁，线程不会主动去释放偏向锁。偏向锁的撤销需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。</p><h4 id="偏向锁的适用场景"><a href="#偏向锁的适用场景" class="headerlink" title="偏向锁的适用场景"></a>偏向锁的适用场景</h4><p>始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the word操作； </p><p>在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向所的时候会导致进入安全点，安全点会导致stw，导致性能下降，这种情况下应当禁用。</p><h4 id="jvm开启-关闭偏向锁"><a href="#jvm开启-关闭偏向锁" class="headerlink" title="jvm开启/关闭偏向锁"></a>jvm开启/关闭偏向锁</h4><p>开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0</p><p>关闭偏向锁：-XX:-UseBiasedLocking</p><h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>轻量级锁是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁。</p><h4 id="轻量级锁的加锁过程"><a href="#轻量级锁的加锁过程" class="headerlink" title="轻量级锁的加锁过程"></a>轻量级锁的加锁过程</h4><ol><li><p>在代码进入同步块的时候，如果同步对象锁状态为无锁状态且不允许进行偏向（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。</p></li><li><p>拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock record里的owner指针指向object mark word。</p></li><li><p>如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态</p></li><li><p>如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，当竞争线程尝试占用轻量级锁失败多次之后，轻量级锁就会膨胀为重量级锁，重量级线程指针指向竞争线程，竞争线程也会阻塞，等待轻量级线程释放锁后唤醒他。锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。</p></li></ol><img src="/2020/02/28/JMM%E5%92%8C%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/pic38.png" srcset="/img/loading.gif" class=""><h3 id="不同锁的比较"><a href="#不同锁的比较" class="headerlink" title="不同锁的比较"></a>不同锁的比较</h3><table><thead><tr><th>锁</th><th>优点</th><th>缺点</th><th>适用场景</th></tr></thead><tbody><tr><td>偏向锁</td><td>加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。</td><td>如果线程间存在锁竞争,会带来额外的锁撤销的消耗。</td><td>适用于只有一个线程访问同步块场景。</td></tr><tr><td>轻量级锁</td><td>竞争的线程不会阻塞，提高了程序的响应速度。</td><td>如果线程始终得不到锁，使用自旋会消耗CPU。</td><td>追求响应时间。同步块执行速度非常快</td></tr><tr><td>重量级锁</td><td>线程竞争不使用自旋，不会消耗CPU.</td><td>线程阻塞,响应时间缓慢。</td><td>追求吞吐量。同步块执行速度较长。</td></tr></tbody></table><h3 id="JDK对锁的更多优化措施"><a href="#JDK对锁的更多优化措施" class="headerlink" title="JDK对锁的更多优化措施"></a>JDK对锁的更多优化措施</h3><h4 id="逃逸分析"><a href="#逃逸分析" class="headerlink" title="逃逸分析"></a>逃逸分析</h4><p>如果证明一个对象不会逃逸方法外或者线程外，则可针对此变量进行优化。</p><p>同步消除synchronization Elimination，如果一个对象不会逃逸出线程，则对此变量的同步措施可消除。</p><h4 id="锁消除和粗化"><a href="#锁消除和粗化" class="headerlink" title="锁消除和粗化"></a>锁消除和粗化</h4><p>锁消除：虚拟机的运行时编译器在运行时如果检测到一些要求同步的代码上不可能发生共享数据竞争，则会去掉这些锁。</p><p>锁粗化：将临近的代码块用同一个锁合并起来。</p><p>消除无意义的锁获取和释放，可以提高程序运行性能。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>实战项目</title>
    <link href="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/"/>
    <url>/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/</url>
    
    <content type="html"><![CDATA[<h2 id="可查询进度的并发任务执行框架"><a href="#可查询进度的并发任务执行框架" class="headerlink" title="可查询进度的并发任务执行框架"></a>可查询进度的并发任务执行框架</h2><h3 id="需求的产生和分析"><a href="#需求的产生和分析" class="headerlink" title="需求的产生和分析"></a>需求的产生和分析</h3><p>公司里有两个项目组，考试组有批量的离线文档要生成，题库组则经常有批量的题目进行排重和根据条件批量修改题目的内容。</p><p>架构组通过对实际的上线产品进行用户调查，发现这些功能在实际使用时，用户都反应速度很慢，而且提交任务后，不知道任务的进行情况，做没做？做到哪一步了？有哪些成功？哪些失败了？都一概不知道。</p><p>架构组和实际的开发人员沟通，他们都说，因为前端提交任务到Web后台以后，是一次要处理多个文档和题目，所以速度快不起来。提示用多线程进行改进，实际的开发人员表示多线程没有用过，不知道如何使用，也担心用不好。综合以上情况，架构组决定在公司的基础构件库中提供一个并发任务执行框架，以解决上述用户和业务开发人员的痛点：</p><ol><li><p>对批量型任务提供统一的开发接口</p></li><li><p>在使用上尽可能的对业务开发人员友好  </p></li><li><p>要求可以查询批量任务的执行进度</p></li></ol><h3 id="如何实现"><a href="#如何实现" class="headerlink" title="如何实现"></a>如何实现</h3><p>要实现这么一个批量任务并发执行的框架，我们来分析一下我们要做些什么？</p><ol><li><p>提高批量任务性能。必然的我们要使用java里的多线程，为了在使用上尽可能的对业务开发人员友好和简单，需要屏蔽一些底层java并发编程中的细节，让他们不需要去了解并发容器，阻塞队列，异步任务，线程安全等等方面的知识，只要专心于自己的业务处理即可。</p></li><li><p>每个批量任务拥有自己的上下文环境。因为一个项目组里同时要处理的批量任务可能有多个，比如考试组，可能就会有不同的学校的批量的离线文档生成，而题库组则会不同的学科都会有老师同时进行工作，因此需要一个并发安全的容器保存每个任务的属性信息，</p></li><li><p>自动清除已完成和过期任务。因为要提供进度查询，系统需要在内存中维护每个任务的进度信息以供查询，但是这种查询又是有时间限制的，一个任务完成一段时间后，就不再提供进度查询了，则就需要我们自动清除已完成和过期任务，用定时轮询吗？</p></li></ol><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic1.png" srcset="/img/loading.gif" class=""><h3 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h3><ol><li><p>框架使用者业务方法的执行结果共有三种，成功：按预想的流程出了结果；失败：按预想的流程没出结果；异常：没按预想的流程抛出了预料之外的错误。因此我们定义了一个枚举，表示这三种情况。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic2.png" srcset="/img/loading.gif" class=""><p>业务方法的返回值有很多种可能，基本类型、系统定义的对象类型、框架使用者自定义的对象类型都是存在的，所以需要用泛型来说表示这个结果。如果方法执行失败了，还需要告诉用户或者框架使用者失败的原因，还需要再定义一个任务的执行结束后的返回值类。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic3.png" srcset="/img/loading.gif" class=""></li><li><p>定义执行业务方法的接口，框架就只执行这个方法，框架的使用者都应该来实现这个接口，由于用户业务的数据多样性，方法的参数也应该用泛型。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic4.png" srcset="/img/loading.gif" class=""></li><li><p>提供一种封装机制，让框架使用者可以将用户在前端提交的工作（JOB）提交给这个封装机制，当用户的需要查询进度的时候，也从这个封装机制中取得，同时封装机制内部也要负责清除已完成任务。</p><p>在这个封装机制里我们定义了一个类JobInfo，抽象了对用户工作（JOB）的封装，一个工作可以包含多个子任务（TASK），这个JobInfo中就包括了这个工作的相关信息，比如工作名，用以区分框架中唯一的工作，也可以避免重复提交，也方便查询时快速定位工作，除了工作名以外，工作中任务（TASK）的列表，工作中任务的处理器都在其中定义。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic5.png" srcset="/img/loading.gif" class=""><p>同时JobInfo还有相当多的关于这个工作的方法，比如查询工作进度，查询每个任务的处理结果，记录每个任务的处理结果等等</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic6.png" srcset="/img/loading.gif" class=""><p>负责清除已完成任务，我们则交给CheckJobProcesser类来完成，定时轮询的机制不够优雅，因此我们选用了DelayQueue来实现这个功能</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic7.png" srcset="/img/loading.gif" class=""><p>并且在其中定义了清除已完成任务的Runnable和相关的工作线程。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic8.png" srcset="/img/loading.gif" class=""></li><li><p>框架的主体类则是PendingJobPool，这也是框架使用者主要使用的类。这个类主要负责调度，例如工作（JOB）和任务（TASK）的提交，任务（TASK）的保存，任务（TASK）的并发执行，工作进度的查询接口和任务执行情况的查询等等。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic9.png" srcset="/img/loading.gif" class=""><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic10.png" srcset="/img/loading.gif" class=""></li></ol><h3 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h3><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic11.png" srcset="/img/loading.gif" class=""><p>如果需要spring集成的话，某些单例化的部分就不需要了。</p><h2 id="项目优化"><a href="#项目优化" class="headerlink" title="项目优化"></a>项目优化</h2><h3 id="项目背景和问题"><a href="#项目背景和问题" class="headerlink" title="项目背景和问题"></a>项目背景和问题</h3><p>这个项目来自为电信教育系统设计开发的一套自适应的考试学习系统，面向的用户主要是职业学院的的老师和学生以及短时间脱产学习的在职人员。什么叫自适应呢？就是当时提出一种教育理念，对学员的学习要求经常考试进行检查，学员的成绩出来以后，老师会要求系统根据每个学员的考卷上错误的题目从容量为10万左右的题库中抽取题目，为每个学员生成一套各自个性化的考后复习和练习的离线练习册。所以，每次考完试，特别是比较大型的考试后，要求生成的离线文档数量是比较多的，一个考试2000多人，就要求生成2000多份文档。当时我们在做这个项目的时候，因为时间紧，人员少，很快做出第一版就上线运营了。</p><p>当然，大家可以想到，问题是很多的，但是反应最大，用户最不满意的就是这个离线文档生成的功能，用户最不满意的点：离线文档生成的速度非常慢，慢到什么程度呢？一份离线文档的生成平均时长在50~55秒左右，遇到成绩不好的学生，文档内容多的，生成甚至需要3分钟，大家可以算一下，2000人，平均55秒，全部生成完，需要2000*55=110000秒，大约是30个小时。</p><p>为什么如此之慢？这跟离线文档的生成机制密切相关，对于每一个题目要从保存题库的数据库中找到需要的题目，单个题目的表现形式如图，数据库中存储则采用类html形式保存，对于每个题目而言，解析题目文本，找到需要下载的图片，每道题目都含有大量或大型的图片需要下载，等到文档中所有题目图片下载到本地完成后，整个文档才能继续进行处理。</p><h3 id="分析和改进"><a href="#分析和改进" class="headerlink" title="分析和改进"></a>分析和改进</h3><p>第一版的实现，服务器在接收到老师的请求后，就会把批量生成请求分解为一个个单独的任务，然后串行的完成。</p><img src="/2020/02/02/%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE/pic12.png" srcset="/img/loading.gif" class=""><p>于是在第二版的实现上，首先我们做了个服务拆分，将生成离线文档的功能拆了出来成为了单独的服务，对外提供RPC接口，在WEB服务器接收到了老师们提出的批量生成离线文档的要求以后，将请求拆分后再一一调用离线文档生成RPC服务，这个RPC服务在实现的时候有一个缓冲的机制，会将收到的请求进行缓存，然后迅速返回一个结果给调用者，告诉调用者已经收到了请求，这样WEB服务器也可以很快的对用户的请求进行应答。</p><p>所以我们有了第一次改进，参见cn.enjoyedu.ch8b. RpcServiceWebV1</p><p> 我们看这个离线文档，每份文档的生成独立性是很高的，天生就适用于多线程并发进行。所以在RPC服务实现的时候，使用了生产者消费者模式，RPC接口的实现收到了一个调用方的请求时，会把请求打包放入一个容器，然后会有多个线程进行消费处理，也就是生成每个具体文档。</p><p>当文档生成后，再使用一次生产者消费者模式，投入另一个阻塞队列，由另外的一组线程负责进行上传。当上传成功完成后，由上传线程返回文档的下载地址，表示当前文档已经成功完成。</p><p>文档具体的下载地址则由WEB服务器单独去数据库或者缓存中去查询。</p><p><img src="blob:file:///808f1ea5-3745-41ac-b3fb-dac06fe50317" srcset="/img/loading.gif" alt="pastedGraphic_1.png"></p><p>对于每个离线文档生成本身，我们来看看它的业务，</p><p>1、从容量为10万左右的题库中为每个学生抽取适合他的题目，</p><p>2、每道题目都含有大量的图片需要下载到本地，和文字部分一起渲染。</p><p>但是我们仔细考察整个系统的业务就会发现，我们是在一次考试后为学员生成自适应的练习册，换句话说，不管考试考察的内容如何，学生的成绩如何，每次考试的知识点是有限的，而从这些知识点中可以抽取的相关联的题目数也总是有限的，不同的学生之间所需要的题目会有很大的重复性。</p><p>举个例子我们为甲学生因为他考卷上的错误部分抽取了80个题目，有很大的概率其他学生跟甲学生错误的地方会有重复，相对应的题目也会有重复。对于这部分题目，我们是完全没有必要重复处理的，包括从数据库中重新获取题目、解析和下载图片。这也是我们可供优化的一大突破点。</p><p>其次，一篇练习册是由很多的题目组成的，每个题目相互之间是独立的，我们也可以完全并行的、异步的处理每个题目。</p><p>具体怎么做？要避免重复工作肯定是使用缓存机制，对已处理过的题目进行缓存。我们看看怎么使用缓存机制进行优化。这个业务，毋庸置疑，map肯定是最适合的，因为我们要根据题目的id来找题目的详情，用哪个map？我们现在是在多线程下使用，考虑的是并发安全的concurrentHashMap。</p><p>当我们的服务接收到处理一个题目的请求，首先会在缓存中get一次，没有找到，可以认为这是个新题目，准备向数据库请求题目数据并进行题目的解析，图片的下载。</p><p>这里有一个并发安全的点需要注意，因为是多线程的应用，会发生多个线程在处理多个文档时有同时进行处理相同题目的情况，这种情况下不做控制，一是会造成数据冲突和混乱，比如同时读写同一个磁盘文件，二是会造成计算资源的浪费，同时为了防止文档的生成阻塞在当前题目上，因此每个新题目的处理过程会包装成一个Callable投入一个线程池中 而把处理结果作为一个Future返回，等到线程在实际生成文档时再从Future中get出结果进行处理。因此在每个新题目实际处理前，还会检查当前是否有这个题目的处理任务正在进行。</p><p>如果题目在缓存中被找到，并不是直接引用就可以了，因为题库中的题目因为种种关系存在被修改的可能，比如存在错误，比如可能内容被替换，这个时候缓存中数据其实是失效过期的，所以需要先行检查一次。如何检查？</p><p>我们前面说过题库中的题目平均长度在800个字节左右，直接equals来检查题目正文是否变动过，明显效率比较低，所以我们这里又做了一番处理，什么处理？对题目正文事先做了一次SHA的摘要并保存在数据库，并且要求题库开发小组在处理题目数据入库的时候进行SHA摘要。</p><p>在本机缓存中同样保存了这个摘要信息，在比较题目是否变动过时，首先检查摘要是否一致，摘要一致说明题目不需要更新，摘要不一致时，才需要更新题目文本，将这个题目视为新题目，进入新题目的处理流程，这样的话就减少了数据的传输量，也降低了数据库的压力。</p><p>题目处理的流程就变为：</p><p><img src="blob:file:///5a45d7e5-6994-4eae-9ff7-7feb13186194" srcset="/img/loading.gif" alt="pastedGraphic_2.png"></p><p>所以我们有了第二次改进，</p><p>1、在题目实体类QuestionInDBVo中增加一个</p><p><img src="blob:file:///0d5213fa-8bc0-435c-8088-3bded0d7bd21" srcset="/img/loading.gif" alt="pastedGraphic_3.png"></p><p>2、增加一个题目保存在缓存中的实体类QuestionInCacheVo</p><p><img src="blob:file:///c567de1d-7575-4bd9-8a0b-ec9949b5aacd" srcset="/img/loading.gif" alt="pastedGraphic_4.png"></p><p>3、增加一个并发处理时返回的题目结果实体类TaskResultVo</p><p><img src="blob:file:///658f3823-8257-49ac-a425-0ed1517749e9" srcset="/img/loading.gif" alt="pastedGraphic_5.png"></p><p>按照我们前面的描述，我们可以得知，题目要么已经处理完成，要么正在处理，所以在获取题目结果时，先从questionDetail获取一次，获取为null，则从questionFuture获取。那么这个类的构造方法需要单独处理一下。</p><p><img src="blob:file:///e07738ef-3a22-46fa-9e04-43ce2bad9014" srcset="/img/loading.gif" alt="pastedGraphic_6.png"></p><p>4、在处理文档的服务的类ProduceDocService中增加一个处理文档的新方法makeDocAsyn</p><p><img src="blob:file:///40cc1cc3-ddc5-40ed-95fe-4dc65cfd87ae" srcset="/img/loading.gif" alt="pastedGraphic_7.png"></p><p>在这个方法中，会调用一个并发处理题目的方法。</p><p>5、增加一个优化题目处理的类ParallelQstService，其中提供了并发处理题目的方法，还包括了</p><p><img src="blob:file:///4f69b9df-654b-4d27-b6ca-0eb2ae208a22" srcset="/img/loading.gif" alt="pastedGraphic_8.png"></p><p>主程序参见cn.enjoyedu.ch8b. RpcServiceWebV2</p><p><strong>继续改进</strong></p><p><strong>数据结构的改进</strong></p><p>但是我们仔细分析就会发现，作为一个长期运行的服务，如果我们使用concurrentHashMap，意味着随着时间的推进，缓存对内存的占用会不断的增长。最极端的情况，十万个题目全部被加载到内存，这种情况下会占据多少内存呢？我们做了统计，题库中题目的平均长度在800个字节左右，十万个题目大约会使用75M左右的空间。</p><p>看起来还好，但是有几点，第一，我们除了题目本身还会有其他的一些附属信息需要缓存，比如题目图片在本地磁盘的存储位置等等，那就说，实际缓存的数据内容会远远超过800个字节，</p><p>第二，map类型的的内存使用效率是比较低的，以hashmap为例，内存利用率一般只有20%到40%左右，而concurrentHashMap只会更低，有时候只有hashmap的十分之一到4分之一，这也就是说十万个题目放在concurrentHashMap中会实际占据几百兆的内存空间，是很容易造成内存溢出的，也就是大家常见的OOM。</p><p>考虑到这种情况，我们需要一种数据结构有map的方便但同时可以限制内存的占用大小或者可以根据需要按照某种策略刷新缓存。最后，在实际的工作中，我们选择了ConcurrentLinkedHashMap，这是由Google开源一个线程安全的hashmap，它本身是对ConcurrentHashMap的封装，可以限定最大容量，并实现一个了基于LRU也就是最近最少使用算法策略的进行更新的缓存。很完美的契合了我们的要求，对于已经缓冲的题目，越少使用的就可以认为这个题目离当前考试考察的章节越远，被再次选中的概率就越小，在容量已满，需要腾出空间给新缓冲的题目时，越少使用就会优先被清除。</p><p><strong>线程数的设置</strong></p><p>原来我们设置的线程数按照我们通用的IO密集型任务，两个线程池设置的都是机器的CPU核心数<em>2，但是这个就是最佳的吗？不一定，通过反复试验我们发现，处理文档的线程池线程数设置为CPU核心数</em>4，继续提高线程数并不能带来性能上的提升。而因为我们改进后处理文档的时间和上传文档的时间基本在1：4到1：3的样子，所以处理文档的线程池线程数设置为CPU核心数<em>4</em>3。</p><p>这时我们有了第三次改进，参见cn.enjoyedu.ch8b. RpcServiceWebV3</p><p><strong>缓存的改进</strong></p><p>在这里我们除了本地内存缓存还使用了本地文件存储，启用了一个二级缓存机制。为什么要使用本地文件存储？因为考虑到服务器会升级、会宕机，已经在内存中缓存的数据会丢失，为了避免这一点，我们将相关的数据在本地进行了一个持久化的操作，保存在了本地磁盘。</p><p><strong>改进后的效果</strong></p><p>1、原单WEB串行处理，3个文档耗时</p><p><img src="blob:file:///be0c58ca-0688-4cb3-879c-44286023edc4" srcset="/img/loading.gif" alt="pastedGraphic_9.png"></p><p><strong>平均一个文档耗时**</strong>51<strong>**秒。</strong></p><p>2、服务化，文档生成并行化后，60个文档耗时</p><p><img src="blob:file:///ee6d333f-60d4-4c7e-a816-1b4f7952a0f4" srcset="/img/loading.gif" alt="pastedGraphic_10.png"></p><p><strong>平均一个文档耗时**</strong>3.5<strong><strong>秒，已经比单</strong></strong>WEB<strong>**串行版的实现有了数量级上的提高。</strong></p><p>3、引入缓存避免重复工作、题目处理并行和异步化后，60个文档耗时</p><p><img src="blob:file:///b7138258-6a03-4bf9-adba-85ccf901fa2e" srcset="/img/loading.gif" alt="pastedGraphic_11.png"></p><p><strong>平均一个文档耗时**</strong>0.65<strong>**秒，再次有了数量级上的提高。</strong></p><p>4、调整线程数后，60个文档耗时</p><p><img src="blob:file:///e71d7f5a-2eb8-494a-a6ba-abe801fcef1e" srcset="/img/loading.gif" alt="pastedGraphic_12.png"></p><p><strong>平均一个文档耗时**</strong>0.23<strong><strong>秒，再次提升了</strong></strong>3<strong><strong>倍的速度</strong></strong>,<strong><strong>而相对我们第一版的性能而言，平均一个文档处理性能提升了</strong></strong>51/0.23=221<strong>**倍。</strong></p><p><strong>这就是善用并发编程后威力！</strong></p><p><strong>用户体验的改进</strong></p><p>还可以和我们前面实战的并发任务执行框架中的思想相结合，在前端显示处理进度，給用户带来更好的使用体验。</p><p><strong>启示</strong></p><p>这次项目的优化给我们带来了什么样的启示呢？</p><p>性能优化一定要建立在对业务的深入分析上，比如我们在性能优化的切入点，在缓存数据结构的选择就建立在对业务的深入理解上；</p><p>性能优化要善于利用语言的高并发特性，</p><p>性能优化多多利用缓存，异步任务等机制，正是因为我们使用这些特性和机制，才让我们的应用在性能上有个了质的飞跃；</p><ol><li>引入各种机制的同时要注意避免带来新的不安全因素和瓶颈，比如说缓存数据过期的问题，并发时的线程安全问题，都是需要我们去克服和解决的。</li></ol>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程 - 实战项目</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>并发安全</title>
    <link href="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/"/>
    <url>/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="线程安全性"><a href="#线程安全性" class="headerlink" title="线程安全性"></a>线程安全性</h2><p>在《Java并发编程实战》中，定义如下：</p><p>当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且在调用代码中不需要任何额外的同步或者协同，这个类都能表现出正确的行为，那么就称这个类是线程安全的。</p><h2 id="线程封闭"><a href="#线程封闭" class="headerlink" title="线程封闭"></a>线程封闭</h2><p>实现好的并发是一件困难的事情，所以很多时候我们都想躲避并发。避免并发最简单的方法就是线程封闭。</p><p>线程封闭就是把对象封装到一个线程里，只有这一个线程能看到此对象。那么这个对象就算不是线程安全的也不会出现任何安全问题。</p><h3 id="ad-hoc线程封闭"><a href="#ad-hoc线程封闭" class="headerlink" title="ad-hoc线程封闭"></a>ad-hoc线程封闭</h3><p>Ad-Hoc线程封闭是完全靠实现者控制的线程封闭，线程封闭完全靠实现者实现。Ad-Hoc线程封闭非常脆弱，应该尽量避免使用。</p><h3 id="栈封闭"><a href="#栈封闭" class="headerlink" title="栈封闭"></a>栈封闭</h3><p>栈封闭是我们编程当中遇到的最多的线程封闭。栈封闭简单的说就是局部变量。多个线程访问一个方法，此方法中的局部变量都会被拷贝一份到线程栈中。所以局部变量是不被多个线程所共享的，也就不会出现并发问题。所以能用局部变量就别用全局的变量，全局变量容易引起并发问题。ThreadLocal本质上是每个线程内部都有一个value副本，相当于将value的副本封闭在栈中，所以使用ThreadLocal不会引发线程安全问题。</p><h3 id="无状态的类"><a href="#无状态的类" class="headerlink" title="无状态的类"></a>无状态的类</h3><p>成员变量被称为类的状态，没有任何成员变量的类，就是无状态的类，这种类一定是线程安全的。</p><p> 即使这个类的方法参数中使用了对象，也是线程安全的，比如：</p><img src="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/pic4.png" srcset="/img/loading.gif" class=""><p>因为多线程下的使用，虽然user这个对象的实例会出现问题，但是它并不被StatelessClass这个类的对象实例所持有，所以Stateless这个类还是线程安全的。如果要避免在使用过程中出现问题的话，可以在user类中实现线程安全。</p><h3 id="让类不可变"><a href="#让类不可变" class="headerlink" title="让类不可变"></a>让类不可变</h3><p>让状态不可变，两种方式：</p><ol><li><p>加final关键字：为该类的所有成员变量都应该加上final关键字，当成员变量是一个对象时，这个对象所对应的类也应该是不可变类，才能保证整个类是不可变的。</p></li><li><p>不提供任何可供修改成员变量的地方，同时成员变量也不作为方法的返回值。</p><p>注：反射不属于正常使用方式，不在考虑范围内</p></li></ol><p>注意：如果类的成员变量中有对象，final关键字是保证对user实例的引用不可变，并不能保证user实例的不可变，在多线程下，对象在堆上的实例是有可能被多个线程同时修改的，没有正确处理的情况下，对象实例在堆中的数据是不可预知的。这就牵涉到了如何安全的发布对象这个问题。</p><h3 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h3><p>并不能保证类的线程安全性，只能保证类的可见性，最适合一个线程写，多个线程读的情景。</p><h3 id="加锁和CAS"><a href="#加锁和CAS" class="headerlink" title="加锁和CAS"></a>加锁和CAS</h3><p>最常使用的保证线程安全的手段，包括使用<strong>synchronized</strong>关键字、使用显式锁、使用各种原子变量、修改数据时使用CAS机制等。</p><h3 id="安全的发布"><a href="#安全的发布" class="headerlink" title="安全的发布"></a>安全的发布</h3><p>类中持有的成员变量，如果是基本类型，可以直接发布出去，此时发布出去的其实是这个变量的一个副本。</p><p>如果类中持有的成员变量是对象的引用，这个成员对象不是线程安全的，通过get等方法发布出去，会造成这个成员对象本身持有的数据在多线程下不正确的修改，从而造成整个类线程不安全的问题。</p><pre><code>/** * 不安全的发布 */public class UnSafePublish {   private List&lt;Integer&gt; list = new ArrayList&lt;&gt;(3);    public UnSafePublish() {       list.add(1);       list.add(2);       list.add(3);    }   public List getList() {      return list;   }   public static void main(String[] args) {      UnSafePublish unSafePublish = new UnSafePublish();      List&lt;Integer&gt; list = unSafePublish.getList();      System.out.println(list);      list.add(4);      System.out.println(list);      System.out.println(unSafePublish.getList());   }}</code></pre><p>将list发布出去后，外部线程就可以修改这个list，如果有多个线程同时修改就会出现不安全的情况，所以在发布这对象出去的时，就应该用线程安全的方式包装这个对象。</p><pre><code>/** * 安全的发布 */public class SafePublishToo {    private List&lt;Integer&gt; list            = Collections.synchronizedList(new ArrayList&lt;&gt;(3));    public SafePublishToo() {        list.add(1);        list.add(2);        list.add(3);    }    public List getList() {        return list;    }    public static void main(String[] args) {        SafePublishToo safePublishToo = new SafePublishToo();        List&lt;Integer&gt; list = safePublishToo.getList();        System.out.println(list);        list.add(4);        System.out.println(list);        System.out.println(safePublishToo.getList());    }}</code></pre><p>将list用Collections.synchronizedList()进行包装以后，无论多少线程使用这个list，就都是线程安全的了。</p><p>对于我们自己使用或者声明的类，JDK自然没有提供这种包装类的办法，但是我们可以仿造这种模式或者委托给线程安全的类。</p><pre><code>/** * 仿Collections对容器的包装，将内部成员对象进行线程安全包装 */public class SoftPublicUser {    private final UserVo user;    public UserVo getUser() {        return user;    }    public SoftPublicUser(UserVo user) {        this.user = new SynUser(user);    }    private static class SynUser extends UserVo{        private final UserVo userVo;        private final Object lock = new Object();        public SynUser(UserVo userVo) {            this.userVo = userVo;        }        @Override        public int getAge() {            synchronized (lock){                System.out.println(&quot;lock success&quot;);                return userVo.getAge();            }        }        @Override        public void setAge(int age) {            synchronized (lock){                userVo.setAge(age);            }        }    }}</code></pre><p>如果为final类，则可以采用委托的方式，将一些方法委托给一个线程安全的类。</p><pre><code>/** * 类说明：委托给线程安全的类来做 */public class SafePublicFinalUser {    private final SynFinalUser user;    public SynFinalUser getUser() {        return user;    }    public SafePublicFinalUser(FinalUserVo user) {        this.user = new SynFinalUser(user);    }    public static class SynFinalUser{        private final FinalUserVo userVo;        private final Object lock = new Object();        public SynFinalUser(FinalUserVo userVo) {            this.userVo = userVo;        }        public int getAge() {            synchronized (lock){                return userVo.getAge();            }        }        public void setAge(int age) {            synchronized (lock){                userVo.setAge(age);            }        }    }}</code></pre><p>对这种通过get等方法发布出去的对象，最根本的解决办法还是应该在实现上就考虑到线程安全问题。</p><h3 id="TheadLocal"><a href="#TheadLocal" class="headerlink" title="TheadLocal"></a>TheadLocal</h3><p>ThreadLocal是实现线程封闭的最好方法。ThreadLocal内部维护了一个Map，Map的key是每个线程的名称，而Map的值就是我们要封闭的对象。每个线程中的对象都对应着Map中一个值，也就是ThreadLocal利用Map实现了对象的线程封闭。</p><h3 id="Servlet辨析"><a href="#Servlet辨析" class="headerlink" title="Servlet辨析"></a>Servlet辨析</h3><p>Servlet其实不是线程安全的类，但一般不会出现问题的原因：</p><ol><li>在需求上，很少有共享的需求即对Servlet中成员变量的写操作，但是一旦有多线程下写Servlet中的成员变量，就很容易产生线程安全问题。</li><li>接收到了请求，返回应答的时候，一般都是由一个线程来负责的。</li><li>spring在bean初始化放入map容器时通过sync关键字保证安全性。因为spring只在初始化时放入一次之后的使用都是只读，相对于使用ConcurrentHashMap性能会更高。</li></ol><h2 id="线程不安全引发的问题"><a href="#线程不安全引发的问题" class="headerlink" title="线程不安全引发的问题"></a>线程不安全引发的问题</h2><h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><p>是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁。</p><p>举个例子：A和B去按摩洗脚，都想在洗脚的时候，顺便做个头部按摩，13技师擅长足底按摩，14擅长头部按摩。这个时候A先抢到14，B先抢到13，两个人都想同时洗脚和头部按摩，于是就互不相让，扬言我死也不让你，这样的话，A抢到14，想要13，B抢到13，想要14，此时，如果没有外力作用，A和B都会死在这，这就是死锁。</p><p>此时有两种解决方法：</p><p>第一种，假如这个时候，来了个15，刚好也是擅长头部按摩的，A又没有两个脑袋，自然就归了B，于是B就美滋滋的洗脚和做头部按摩，剩下A在旁边气鼓鼓的，这个时候死锁这种情况就被打破了，不存在了。</p><p>第二种，C出场了，用武力强迫A和B，必须先做洗脚，再头部按摩，这种情况下，A和B谁先抢到13，谁就可以进行下去，另外一个没抢到的，就等着，这种情况下，也不会产生死锁。</p><p>所以总结一下：</p><p>死锁是必然发生在多操作者（M&gt;=2个）情况下，争夺多个资源（N&gt;=2个，且N&lt;=M）才会发生这种情况。很明显，单线程自然不会有死锁，只有B一个去就不会产生竞争；单资源情况下，A和B也只会产生激烈竞争，谁抢到就是谁的，但不会产生死锁。同时，死锁还有一个重要的要求，争夺资源的顺序不同，如果争夺资源的顺序是一样的，也不会产生死锁。</p><h4 id="学术化的定义"><a href="#学术化的定义" class="headerlink" title="学术化的定义"></a>学术化的定义</h4><p>死锁的发生必须具备以下四个必要条件。 </p><ol><li><p>互斥条件：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。</p></li><li><p>请求和保持条件：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。</p></li><li><p>不剥夺条件：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。</p></li><li><p>环路等待条件：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源。</p></li></ol><p>理解了死锁的原因，尤其是产生死锁的四个必要条件，就可以最大可能地避免、预防和解除死锁。只要打破四个必要条件之一就能有效预防死锁的发生。</p><ul><li>打破互斥条件：改造独占性资源为虚拟资源，大部分资源已无法改造。</li><li>打破不可抢占条件：当一进程占有一独占性资源后又申请一独占性资源而无法满足，则退出原占有的资源。</li><li>打破占有且申请条件：采用资源预先分配策略，即进程运行前申请全部资源，满足则运行，不然就等待，这样就不会占有且申请。</li><li>打破循环等待条件：实现资源有序分配策略，对所有设备实现分类编号，所有进程只能采用按序号递增的形式申请资源。</li></ul><p>避免死锁常见的算法有有序资源分配法、银行家算法。</p><h4 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h4><p>数据库里多事务而且要同时操作多个表的情况下就可能产生死锁。所以数据库设计的时候就考虑到了检测死锁和从死锁中恢复的机制。比如oracle提供了检测和处理死锁的语句，而mysql也提供了“循环依赖检测的机制”</p><img src="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/pic6.png" srcset="/img/loading.gif" class=""><h5 id="简单顺序死锁"><a href="#简单顺序死锁" class="headerlink" title="简单顺序死锁"></a>简单顺序死锁</h5><pre><code>/** *类说明：演示普通账户的死锁和解决 */public class NormalDeadLock {    private static Object valueFirst = new Object();//第一个锁    private static Object valueSecond = new Object();//第二个锁    //先拿第一个锁，再拿第二个锁    private static void fisrtToSecond() throws InterruptedException {        String threadName = Thread.currentThread().getName();        synchronized (valueFirst){            System.out.println(threadName+&quot; get 1st&quot;);            Thread.sleep(100);            synchronized (valueSecond){                System.out.println(threadName+&quot; get 2nd&quot;);            }        }    }    //先拿第二个锁，再拿第一个锁    private static void SecondToFisrt() throws InterruptedException {        String threadName = Thread.currentThread().getName();        synchronized (valueFirst){            System.out.println(threadName+&quot; get 2nd&quot;);            Thread.sleep(100);            synchronized (valueSecond){                System.out.println(threadName+&quot; get 1st&quot;);            }        }    }    private static class TestThread extends Thread{        private String name;        public TestThread(String name) {            this.name = name;        }        public void run(){            Thread.currentThread().setName(name);            try {                SecondToFisrt();            } catch (InterruptedException e) {                e.printStackTrace();            }        }    }    public static void main(String[] args) {        Thread.currentThread().setName(&quot;TestDeadLock&quot;);        TestThread testThread = new TestThread(&quot;SubTestThread&quot;);        testThread.start();        try {            fisrtToSecond();        } catch (InterruptedException e) {            e.printStackTrace();        }    }}</code></pre><h5 id="动态顺序死锁"><a href="#动态顺序死锁" class="headerlink" title="动态顺序死锁"></a>动态顺序死锁</h5><p>顾名思义也是和获取锁的顺序有关，但是比较隐蔽，不像简单顺序死锁，往往从代码一眼就看出获取锁的顺序不对。</p><pre><code>/** *类说明：不安全的转账动作的实现 */public class TrasnferAccount implements ITransfer {    @Override    public void transfer(UserAccount from, UserAccount to, int amount)          throws InterruptedException {        synchronized (from){            System.out.println(Thread.currentThread().getName()                  +&quot; get&quot;+from.getName());            Thread.sleep(100);            synchronized (to){                System.out.println(Thread.currentThread().getName()                      +&quot; get&quot;+to.getName());                from.flyMoney(amount);                to.addMoney(amount);            }        }    }}</code></pre><pre><code>/** *@author Mark老师   享学课堂 https://enjoy.ke.qq.com  * *类说明：模拟支付公司转账的动作 */public class PayCompany {   /*执行转账动作的线程*/    private static class TransferThread extends Thread{        private String name;        private UserAccount from;        private UserAccount to;        private int amount;        private ITransfer transfer;        public TransferThread(String name, UserAccount from, UserAccount to,                              int amount, ITransfer transfer) {            this.name = name;            this.from = from;            this.to = to;            this.amount = amount;            this.transfer = transfer;        }        public void run(){            Thread.currentThread().setName(name);            try {                transfer.transfer(from,to,amount);            } catch (InterruptedException e) {                e.printStackTrace();            }        }    }    public static void main(String[] args) {        PayCompany payCompany = new PayCompany();        UserAccount zhangsan = new UserAccount(&quot;zhangsan&quot;,20000);        UserAccount lisi = new UserAccount(&quot;lisi&quot;,20000);        ITransfer transfer = new SafeOperateToo();        TransferThread zhangsanToLisi = new TransferThread(&quot;zhangsanToLisi&quot;                ,zhangsan,lisi,2000,transfer);        TransferThread lisiToZhangsan = new TransferThread(&quot;lisiToZhangsan&quot;                ,lisi,zhangsan,4000,transfer);        zhangsanToLisi.start();        lisiToZhangsan.start();    }}</code></pre><h4 id="危害"><a href="#危害" class="headerlink" title="危害"></a>危害</h4><p>时间不定，不是每次必现；一旦出现没有任何异常信息，只知道这个应用的所有业务越来越慢，最后停止服务，无法确定是哪个具体业务导致的问题；测试部门也无法复现，并发量不够。</p><ol><li>线程不工作了，但是整个程序还是活着的</li><li>没有任何的异常信息可以供我们检查。</li><li>一旦程序发生了发生了死锁，是没有任何的办法恢复的，只能重启程序，对生产平台的程序来说，这是个很严重的问题。</li></ol><h4 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h4><h5 id="定位"><a href="#定位" class="headerlink" title="定位"></a>定位</h5><p>通过<strong>jps</strong> 查询应用的id，再通过<strong>jstack[id]</strong> 查看应用的锁的持有情况</p><img src="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/pic1.png" srcset="/img/loading.gif" class=""><img src="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/pic2.png" srcset="/img/loading.gif" class=""><img src="/2020/01/23/%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8/pic3.png" srcset="/img/loading.gif" class=""><h5 id="修正"><a href="#修正" class="headerlink" title="修正"></a>修正</h5><p>关键是保证拿锁的顺序一致</p><p>两种解决方式：</p><ol><li>内部通过顺序比较，确定拿锁的顺序；</li></ol><pre><code>/** *@author Mark老师   享学课堂 https://enjoy.ke.qq.com  * *类说明：不会产生死锁的安全转账 */public class SafeOperate implements ITransfer {    private static Object tieLock = new Object();//第三把锁    @Override    public void transfer(UserAccount from, UserAccount to, int amount)            throws InterruptedException {        int fromHash = System.identityHashCode(from);        int toHash = System.identityHashCode(to);        if(fromHash&lt;toHash){            synchronized (from){                System.out.println(Thread.currentThread().getName()+&quot; get &quot;+from.getName());                Thread.sleep(100);                synchronized (to){                    System.out.println(Thread.currentThread().getName()+&quot; get &quot;+to.getName());                    from.flyMoney(amount);                    to.addMoney(amount);                    System.out.println(from);                    System.out.println(to);                }            }        }else if(toHash&lt;fromHash){            synchronized (to){                System.out.println(Thread.currentThread().getName()+&quot; get&quot;+to.getName());                Thread.sleep(100);                synchronized (from){                    System.out.println(Thread.currentThread().getName()+&quot; get&quot;+from.getName());                    from.flyMoney(amount);                    to.addMoney(amount);                    System.out.println(from);                    System.out.println(to);                }            }        }else{            synchronized (tieLock){                synchronized (from){                    synchronized (to){                        from.flyMoney(amount);                        to.addMoney(amount);                    }                }            }        }    }}</code></pre><ol start="2"><li>采用尝试拿锁的机制。</li></ol><pre><code>/** * @author Mark老师   享学课堂 https://enjoy.ke.qq.com * &lt;p&gt; * 类说明：不会产生死锁的安全转账第二种方法 */public class SafeOperateToo implements ITransfer {    @Override    public void transfer(UserAccount from, UserAccount to, int amount)            throws InterruptedException {        Random r = new Random();        while (true) {            if (from.getLock().tryLock()) {                try {                    System.out.println(Thread.currentThread().getName()                            + &quot; get&quot; + from.getName());                    if (to.getLock().tryLock()) {                        try {                            System.out.println(Thread.currentThread().getName()                                    + &quot; get&quot; + to.getName());                            from.flyMoney(amount);                            to.addMoney(amount);                            System.out.println(from);                            System.out.println(to);                            break;                        } finally {                            to.getLock().unlock();                        }                    }                } finally {                    from.getLock().unlock();                }            }            Thread.sleep(r.nextInt(2));        }    }}</code></pre><h3 id="活锁"><a href="#活锁" class="headerlink" title="活锁"></a>活锁</h3><p>两个线程在尝试拿锁的机制中，发生多个线程之间互相谦让，不断发生同一个线程总是拿到同一把锁，在尝试拿另一把锁时因为拿不到，而将本来已经持有的锁释放的过程。</p><p>解决办法：每个线程休眠随机数，错开拿锁的时间。</p><h3 id="线程饥饿"><a href="#线程饥饿" class="headerlink" title="线程饥饿"></a>线程饥饿</h3><p>低优先级的线程，总是拿不到执行时间</p><h3 id="性能和思考"><a href="#性能和思考" class="headerlink" title="性能和思考"></a>性能和思考</h3><p>使用并发的目标是为了提高性能，引入多线程后，其实会引入额外的开销，如线程之间的协调、增加的上下文切换，线程的创建和销毁，线程的调度等等。过度的使用和不恰当的使用，会导致多线程程序甚至比单线程还要低。</p><p>衡量应用的程序的性能：服务时间，延迟时间，吞吐量，可伸缩性等等，其中服务时间，延迟时间（多快），吞吐量（处理能力的指标，完成工作的多少）。多快和多少，完全独立，甚至是相互矛盾的。</p><p>对服务器应用来说：多少（可伸缩性，吞吐量）这个方面比多快更受重视。</p><p>我们做应用的时候：</p><ol><li><p>先保证程序正确，确实达不到要求的时候，再提高速度（黄金原则）。</p></li><li><p>一定要以测试为基准。</p></li></ol><h4 id="线程引入的开销"><a href="#线程引入的开销" class="headerlink" title="线程引入的开销"></a>线程引入的开销</h4><h5 id="上下文切换"><a href="#上下文切换" class="headerlink" title="上下文切换"></a>上下文切换</h5><p>如果主线程是唯一的线程，那么它基本上不会被调度出去。另一方面,如果可运行的线程数大于CPU的数量,那么操作系统最终会将某个正在运行的线程调度出来，从而使其他线程能够使用CPU。这将导致一次上下文切换，在这个过程中将保存当前运行线程的执行上下文，并将新调度进来的线程的执行上下文设置为当前上下文。上下文切换有点像我们同时阅读几本书，在来回切换书本的同时我们需要记住每本书当前读到的页码。</p><p>切换上下文需要一定的开销，而在线程调度过程中需要访问由操作系统和JVM共享的数据结构。由于应用程序、操作系统以及JVM都使用同一组CPU，所以在JVM和操作系统中消耗越多的CPU时钟周期，应用程序的可用CPU时钟周期就越少。而且上下文切换的开销并不只是包含JVM和操作系统的开销，由于当一个新的线程被切换进来时，它所需要的数据可能不在当前处理器的本地缓存，所以上下文切换也将导致一些缓存缺失，线程在首次调度运行时会更加缓慢。</p><p>当线程由于等待某个发生竞争的锁而被阻塞时，JVM通常会将这个线程挂起，并允许它被交换出去。如果线程频繁地发生阻塞，那么它们将无法使用完整的调度时间片。在程序中发生越多的阻塞（包括阻塞IO、等待获取发生竞争的锁或者在条件变量上等待）与CPU密集型的程序就会发生越多的上下文切换，从而增加调度开销，降低吞吐量。</p><p>上下文切换是计算密集型操作。也就是说，它需要相当可观的处理器时间。所以上下文切换对系统来说意味着消耗大量的 CPU 时间，而且可能是操作系统中时间消耗最大的操作。上下文切换的实际开销会随着平台的不同而变化，按照实际经验来看，在大多数通用的处理器中，上下文切换的开销相当于50~10000个时钟周期,也就是几微秒。</p><p>UNIX系统的vmstat命令能报告上下文切换次数以及在内核中执行时间所占比例等信息。如果内核占用率较高（超过10%），那么通常表示调度活动发生得很频繁，这很可能是由IO或竞争锁导致的阻塞引起的。</p><h5 id="内存同步"><a href="#内存同步" class="headerlink" title="内存同步"></a>内存同步</h5><p>同步操作的性能开销包括多个方面。在 synchronized和 volatile提供的可见性保证中可能会使用一些特殊指令，即内存栅栏( Memory Barrier)。</p><p>内存栅栏可以刷新缓存，使缓存无效从而刷新硬件的写缓冲，以及停止执行管道。</p><p>内存栅栏可能同样会对性能带来间接的影响，因为它们将抑制一些编译器优化操作。在内存栅栏中，大多数操作都是不能被重排序的。</p><h5 id="阻塞"><a href="#阻塞" class="headerlink" title="阻塞"></a>阻塞</h5><p>引起阻塞的原因：包括阻塞IO，等待获取发生竞争的锁或者在条件变量上的等待等等。</p><p>阻塞会导致线程挂起，挂起进程在操作系统中可以定义为暂时被淘汰出内存的进程，机器的资源是有限的，在资源不足的情况下，操作系统对在内存中的程序进行合理的安排，其中有的进程被暂时调离出内存，当条件允许的时候，会被操作系统再次调回内存，重新进入等待被执行的状态即就绪态。这个操作至少包括两次额外的上下文切换，还有相关的操作系统级的操作等等。</p><h4 id="如何减少锁的竞争"><a href="#如何减少锁的竞争" class="headerlink" title="如何减少锁的竞争"></a>如何减少锁的竞争</h4><h5 id="减少锁的粒度"><a href="#减少锁的粒度" class="headerlink" title="减少锁的粒度"></a>减少锁的粒度</h5><p>使用锁的时候，锁所保护的对象是多个，当这些多个对象其实是独立变化的时候，不如用多个锁来一一保护这些对象。但是如果有同时要持有多个锁的业务方法，要注意避免发生死锁。</p><h5 id="缩小锁的范围"><a href="#缩小锁的范围" class="headerlink" title="缩小锁的范围"></a>缩小锁的范围</h5><p>对锁的持有实现快进快出，尽量缩短持由锁的的时间。将一些与锁无关的代码移出锁的范围，特别是一些耗时，可能阻塞的操作</p><h5 id="避免多余的锁"><a href="#避免多余的锁" class="headerlink" title="避免多余的锁"></a>避免多余的锁</h5><p>两次加锁之间的语句非常简单，导致加锁的时间比执行这些语句还长，这个时候应该进行锁粗化即扩大锁的范围。</p><h5 id="锁分段"><a href="#锁分段" class="headerlink" title="锁分段"></a>锁分段</h5><p>ConcurrrentHashMap就是典型的锁分段。</p><h5 id="替换独占锁"><a href="#替换独占锁" class="headerlink" title="替换独占锁"></a>替换独占锁</h5><p>在业务允许的情况下：</p><ol><li>使用读写锁，</li><li>用自旋CAS</li><li>使用系统的并发容器</li></ol><h2 id="线程安全的单例模式"><a href="#线程安全的单例模式" class="headerlink" title="线程安全的单例模式"></a>线程安全的单例模式</h2><h3 id="双重检查锁定"><a href="#双重检查锁定" class="headerlink" title="双重检查锁定"></a>双重检查锁定</h3><pre><code>/** * 懒汉式-双重检查 */public class SingleDcl {    private volatile static SingleDcl singleDcl;    //私有化    private SingleDcl(){    }    public static SingleDcl getInstance(){        if (singleDcl == null){ //第一次检查，不加锁            System.out.println(Thread.currentThread()+&quot; is null&quot;);            synchronized(SingleDcl.class){ //加锁                if (singleDcl == null){ //第二次检查，加锁情况下                    System.out.println(Thread.currentThread()+&quot; is null&quot;);                    singleDcl = new SingleDcl();                }            }        }        return singleDcl;    }}</code></pre><p>仅仅是双重检查无法保证多线程下使用的安全性，因为在创建对象时为内存中分配空间、对象在内存空间的初始化、把这个内存空间的地址赋值给引用这三个步骤是可能被重新排序的，只要引用指向了内存空间的地址判断条件singleDc1==null就会不成立，而此时对象很可能还没有完成初始化，所以还需要加入volatile关键字保证指令不会被重排序。</p><h3 id="饿汉式"><a href="#饿汉式" class="headerlink" title="饿汉式"></a>饿汉式</h3><pre><code>/** * 饿汉式 */public class SingleEHan {    private SingleEHan(){}    private static SingleEHan singleDcl = new SingleEHan();}</code></pre><p>JVM对类的加载和类初始化，由虚拟机保证线程安全。多个线程同时加载一个类时会为其加锁保证只有一个类加载成功，所以饿汉式单例模式是线程安全的。</p><h3 id="延迟初始化占位类模式"><a href="#延迟初始化占位类模式" class="headerlink" title="延迟初始化占位类模式"></a>延迟初始化占位类模式</h3><pre><code>/** * 懒汉式-延迟初始化占位类模式 */public class SingleInit {    private SingleInit(){}    private static class InstanceHolder{        private static SingleInit instance = new SingleInit();    }    public static SingleInit getInstance(){        return InstanceHolder.instance;    }}</code></pre><p>延迟初始化占位类模式其实也是利用JVM类加载的线程安全，在子类中完成实例的初始化，如果在其他地方没有对子类的引用，子类的初始化将只在首次获取实例时完成，以此来解决饿汉式单例模式资源占用的问题。延迟占位模式也可以用在多线程下实例域的延迟赋值。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线程池</title>
    <link href="/2020/01/16/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"/>
    <url>/2020/01/16/%E7%BA%BF%E7%A8%8B%E6%B1%A0/</url>
    
    <content type="html"><![CDATA[<h2 id="使用线程池的优势"><a href="#使用线程池的优势" class="headerlink" title="使用线程池的优势"></a>使用线程池的优势</h2><ol><li><p>降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。</p></li><li><p>提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。假设一个服务器完成一项任务所需时间为：T1 创建线程时间，T2 在线程中执行任务的时间，T3 销毁线程时间。  如果：T1 + T3 远大于 T2，则可以采用线程池，以提高服务器性能。线程池技术正是关注如何缩短或调整T1,T3时间的技术，从而提高服务器程序性能的。它把T1，T3分别安排在服务器程序的启动和结束的时间段或者一些空闲的时间段，这样在服务器程序处理客户请求时，不会有T1，T3的开销了。</p></li><li><p>提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。</p></li></ol><p>假设一个服务器一天要处理50000个请求，并且每个请求需要一个单独的线程完成。在线程池中，线程数一般是固定的，所以产生线程总数不会超过线程池中线程的数目，而如果服务器不利用线程池来处理这些请求则线程总数为50000。一般线程池大小是远小于50000，所以利用线程池的服务器程序不会为了创建50000而在处理请求时浪费时间，从而提高效率。</p><h2 id="自定义线程池的实现"><a href="#自定义线程池的实现" class="headerlink" title="自定义线程池的实现"></a>自定义线程池的实现</h2><pre><code>/** *类说明：自定义线程池实现 */public class MyThreadPool2 {    /*缺省线程数据量*/    private static int WORK_COUNT = 5;    /*存放任务*/    private final BlockingQueue&lt;Runnable&gt; taskQueue;    /*工作线程*/    private WorkThread[] workThreads;    private final int work_number;    public MyThreadPool2(){        this(100,WORK_COUNT);    }    /*任务数，线程的数量*/    public MyThreadPool2(int task_count,                         int work_number) {        if (work_number&lt;=0) work_number = WORK_COUNT;        if(task_count&lt;=0) task_count = 100;        this.taskQueue = new ArrayBlockingQueue&lt;&gt;(task_count);        this.work_number = work_number;        workThreads = new WorkThread[work_number];        /*工作线程准备好了*/        for(int i=0;i&lt;work_number;i++){            workThreads[i] = new WorkThread();            workThreads[i].start();        }    }    /*销毁线程池*/    public void destroy(){        System.out.println(&quot;ready close pool....&quot;);        for(int i=0;i&lt;work_number;i++){            workThreads[i].stopWorker();            workThreads[i] = null;//help gc        }        taskQueue.clear();    }    /*放入任务，但是只是加入队列*/    public void execute(Runnable task){        try {            taskQueue.put(task);        } catch (InterruptedException e) {            e.printStackTrace();        }    }    @Override    public String toString() {        return &quot;WorkThread number:&quot;+work_number                +&quot; wait task number:&quot;+taskQueue.size();    }    /*内部类，工作线程的实现*/    private class WorkThread extends Thread{        @Override        public void run() {            Runnable r = null;            try {                while(!isInterrupted()){                    r = taskQueue.take();                    if(r!=null){                        System.out.println(getId()+&quot; ready execute&quot;                                +((TestMyThreadPool.MyTask)r).getName());                        r.run();                    }                   r = null;                }            } catch (InterruptedException e) {                //e.printStackTrace();            }        }        /*停止工作*/        public void stopWorker() {            interrupt();        }    }}</code></pre><p>测试类</p><pre><code>/** *类说明：测试自定义线程池实现 */public class TestMyThreadPool {    public static void main(String[] args) throws InterruptedException {//         创建3个线程的线程池        MyThreadPool2 t = new MyThreadPool2(0,3);        t.execute(new MyTask(&quot;testA&quot;));        t.execute(new MyTask(&quot;testB&quot;));        t.execute(new MyTask(&quot;testC&quot;));        t.execute(new MyTask(&quot;testD&quot;));        t.execute(new MyTask(&quot;testE&quot;));        System.out.println(t);        Thread.sleep(10000);        t.destroy();// 所有线程都执行完成才destory        System.out.println(t);    }    // 任务类    static class MyTask implements Runnable {        private String name;        private Random r = new Random();        public MyTask(String name) {            this.name = name;        }        public String getName() {            return name;        }        @Override        public void run() {// 执行任务            try {                Thread.sleep(r.nextInt(1000)+2000);            } catch (InterruptedException e) {                System.out.println(Thread.currentThread().getId()+&quot; sleep InterruptedException:&quot;                        +Thread.currentThread().isInterrupted());            }            System.out.println(&quot;任务 &quot; + name + &quot; 完成&quot;);        }    }}</code></pre><h2 id="Executor框架"><a href="#Executor框架" class="headerlink" title="Executor框架"></a>Executor框架</h2><img src="/2020/01/16/%E7%BA%BF%E7%A8%8B%E6%B1%A0/pic1.png" srcset="/img/loading.gif" class=""><p>Executor是一个接口，它是Executor框架的基础，它将任务的提交与任务的执行分离开来；</p><p>ExecutorService接口继承了Executor，在其上做了一些shutdown()、submit()的扩展，可以说是真正的线程池接口；</p><p>AbstractExecutorService抽象类实现了ExecutorService接口中的大部分方法；</p><p>ThreadPoolExecutor是线程池的核心实现类，用来执行被提交的任务。</p><p>ScheduledExecutorService接口继承了ExecutorService接口，提供了带”周期执行”功能ExecutorService；</p><p>ScheduledThreadPoolExecutor是一个实现类，可以在给定的延迟后运行命令，或者定期执行命令。ScheduledThreadPoolExecutor比Timer更灵活，功能更强大。</p><h2 id="线程池的创建各个参数含义"><a href="#线程池的创建各个参数含义" class="headerlink" title="线程池的创建各个参数含义"></a>线程池的创建各个参数含义</h2><p>public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,BlockingQueue<Runnable> workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler)</p><ul><li><p><strong>corePoolSize</strong>：线程池中的核心线程数。当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize；如果当前线程数已经达到corePoolSize，继续提交的任务会被保存到阻塞队列中，等待被执行；如果执行了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有核心线程。</p></li><li><p><strong>maximumPoolSize</strong>：线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，前提是当前线程数小于maximumPoolSize</p></li><li><p><strong>keepAliveTime</strong>：线程空闲时的存活时间，即当线程没有任务执行时，继续存活的时间。默认情况下，该参数只在线程数大于corePoolSize时才有用</p></li><li><p><strong>unit</strong>：keepAliveTime的时间单位</p></li><li><p><strong>workQueue</strong>：workQueue必须是BlockingQueue阻塞队列，通过workQueue，线程池实现了阻塞功能。当线程池中的线程数超过它的corePoolSize的时候，线程会进入阻塞队列进行阻塞等待。一般来说，我们应该尽量使用有界队列，因为使用无界队列作为工作队列会对线程池带来如下影响：</p><ol><li>当线程池中的线程数达到corePoolSize后，新任务将在无界队列中等待，因此线程池中的线程数不会超过corePoolSize。</li><li>由于1，使用无界队列时maximumPoolSize将是一个无效参数。</li><li>由于1和2，使用无界队列时keepAliveTime将是一个无效参数。</li><li>更重要的，使用无界queue可能会耗尽系统资源，有界队列则有助于防止资源耗尽，同时即使使用有界队列，也要尽量控制队列的大小在一个合适的范围。</li></ol><p>所以我们一般会使用，ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue、PriorityBlockingQueue。</p></li><li><p><strong>threadFactory</strong>：创建线程的工厂，通过自定义的线程工厂可以给每个新建的线程设置一个具有识别度的线程名，当然还可以更加自由的对线程做更多的设置，比如设置所有的线程为守护线程。Executors静态工厂里默认的threadFactory，线程的命名规则是“pool-数字-thread-数字”。</p></li><li><p><strong>handler</strong>：线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，线程池提供了4种策略：</p><ol><li>AbortPolicy：直接抛出异常，默认策略；</li><li>CallerRunsPolicy：用调用者所在的线程来执行任务；</li><li>DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；</li><li>DiscardPolicy：直接丢弃任务；</li></ol><p>当然也可以根据应用场景实现RejectedExecutionHandler接口，自定义饱和策略，如记录日志或持久化存储不能处理的任务。</p></li></ul><h2 id="扩展线程池"><a href="#扩展线程池" class="headerlink" title="扩展线程池"></a>扩展线程池</h2><p>在JDK的线程池核心方法中预留出了三个空的方法，分别为任务执行前的方法、执行后的方法、线程池退出时执行的方法，我们可以通过这些方法执行我们自己的逻辑。如果要对Runnable任务做调整，如修改线程名字、设置线程为守护线程，则可以通过实现ThreadFactory接口，在newThread()方法中对runnable进行调整。</p><pre><code>/** * 类说明：扩展线程池的使用范例 */public class ThreadPoolExt {    static class Worker implements Runnable {        private String taskName;        private Random r = new Random();        public Worker(String taskName) {            this.taskName = taskName;        }        public String getName() {            return taskName;        }        @Override        public void run() {            System.out.println(Thread.currentThread().getName()                    + &quot; process the task : &quot; + taskName);            SleepTools.ms(r.nextInt(100) * 5);        }    }    public static void main(String[] args) throws InterruptedException, ExecutionException {        ExecutorService threadPool = new ThreadPoolExecutor(2, 4, 3,                TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(10),                new ThreadPoolExecutor.DiscardOldestPolicy()) {            @Override            protected void beforeExecute(Thread t, Runnable r) {                System.out.println(&quot;Ready Execute &quot; + ((Worker) r).getName());            }            @Override            protected void afterExecute(Runnable r, Throwable t) {                System.out.println(&quot;Complete Execute &quot; + ((Worker) r).getName());            }            @Override            protected void terminated() {                System.out.println(&quot;线程池退出&quot;);            }        };        for (int i = 0; i &lt;= 6; i++) {            Worker worker = new Worker(&quot;worker &quot; + i);            System.out.println(&quot;A new task has been added : &quot; + worker.getName());            threadPool.execute(worker);        }        threadPool.shutdown();    }}</code></pre><p>可以看到，每个任务执行前后都会调用 beforeExecute和 afterExecute方法。相当于执行了一个切面。而在调用shutdown 方法后则会调用 terminated 方法。</p><h2 id="线程池的工作机制"><a href="#线程池的工作机制" class="headerlink" title="线程池的工作机制"></a>线程池的工作机制</h2><ol><li>如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。</li><li>如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。</li><li>如果无法将任务加入BlockingQueue（队列已满），则创建新的线程来处理任务。</li><li>如果继续添加任务导致当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。</li></ol><img src="/2020/01/16/%E7%BA%BF%E7%A8%8B%E6%B1%A0/pic2.png" srcset="/img/loading.gif" class=""><p>内存资源相比线程资源要廉价一下，所以jdk优先使用阻塞队列容纳多余线程数，在阻塞队列容纳不下的情况下才会创建新的线程（个人猜测）。</p><h2 id="提交任务"><a href="#提交任务" class="headerlink" title="提交任务"></a>提交任务</h2><p>execute()方法用于提交不需要返回值的任务（Runnable），所以无法判断任务是否被线程池执行成功。</p><p>submit()方法用于提交需要返回值的任务（Callable）。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用get(long timeout，TimeUnit unit)方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。</p><h2 id="关闭线程池"><a href="#关闭线程池" class="headerlink" title="关闭线程池"></a>关闭线程池</h2><p>可以通过调用线程池的shutdown()或shutdownNow()方法来关闭线程池。它们的原理是遍历线程池中的工作线程，然后逐个调用线程的interrupt()方法来中断线程，所以无法响应中断的任务可能永远无法终止。但是它们存在一定的区别，shutdownNow()首先将线程池的状态设置成STOP，然后尝试停止所有的正在执行或暂停任务的线程，并返回等待执行任务的列表，而shutdown()只是将线程池的状态设置成SHUTDOWN状态，然后中断所有<strong>没有正在执行任务的线程</strong>。</p><p>只要调用了这两个关闭方法中的任意一个，isShutdown方法就会返回true。当所有的任务都已关闭后，才表示线程池关闭成功，这时调用isTerminaed方法会返回true。至于应该调用哪一种方法来关闭线程池，应该由提交到线程池的任务特性决定，通常调用shutdown()方法来关闭线程池，如果任务不一定要执行完，则可以调用shutdownNow()方法。</p><h2 id="合理地配置线程池"><a href="#合理地配置线程池" class="headerlink" title="合理地配置线程池"></a>合理地配置线程池</h2><p>要想合理地配置线程池，就必须首先分析任务特性，可以从以下几个角度来分析：</p><ul><li><p>任务的性质：CPU密集型任务、IO密集型任务和混合型任务。</p></li><li><p>任务的优先级：高、中和低。</p></li><li><p>任务的执行时间：长、中和短。</p></li><li><p>任务的依赖性：是否依赖其他系统资源，如数据库连接。</p></li></ul><p>性质不同的任务可以用不同规模的线程池分开处理：</p><ul><li><p>CPU密集型任务（字符串的正则匹配、加密解密，数据的计算）应配置尽可能小的线程，如配置Ncpu+1个线程的线程池。</p></li><li><p>IO密集型任务（读写文件，数据库，http请求）线程并不是一直在执行任务，则应配置尽可能多的线程，如Ncpu*2，如果此时CPU占用率比较低的话可以尝试Ncpu*3。</p></li><li><p>混合型的任务（包括CPU密集及IO密集），如果将其拆分成一个CPU密集型任务和一个IO密集型任务，这两个任务执行的时间相差不是太大，那么分解后执行的吞吐量将高于串行执行的吞吐量，如果这两个任务执行时间相差太大，则没必要进行分解。</p></li></ul><p>可以通过Runtime.getRuntime().availableProcessors()方法获得当前设备的CPU个数。</p><p>优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高的任务先执行。</p><p>执行时间不同的任务可以交给不同规模的线程池来处理，或者可以使用优先级队列，让执行时间短的任务先执行。</p><p>依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，等待的时间越长，则CPU空闲时间就越长，那么线程数应该设置得越大，这样才能更好地利用CPU。</p><p>在有界队列和无界队列的选择上，建议使用有界队列。有界队列能增加系统的稳定性和预警能力，队列的长度可以设置的大一些，比如几千。假设，我们现在有一个Web系统，里面使用了线程池来处理业务，在某些情况下，系统里后台任务线程池的队列和线程池全满了，不断抛出抛弃任务的异常，通过排查发现是数据库出现了问题，导致执行SQL变得非常缓慢，因为后台任务线程池里的任务全是需要向数据库查询和插入数据的，所以导致线程池里的工作线程全部阻塞，任务积压在线程池里。如果当时我们设置成无界队列，那么线程池的队列就会越来越多，有可能会撑满内存，导致整个系统不可用，而不只是后台任务出现问题。</p><h2 id="预定义线程池"><a href="#预定义线程池" class="headerlink" title="预定义线程池"></a>预定义线程池</h2><p>JDK在Executor中为我们提供了一些预定义的线程池，可以通过Executors.newFixedThreadPool()等方法来获取，但尽量还是自己通过构造方法根据当前场景创建。</p><h3 id="FixedThreadPool"><a href="#FixedThreadPool" class="headerlink" title="FixedThreadPool"></a>FixedThreadPool</h3><p>创建使用固定线程数的FixedThreadPool的API。适用于为了满足资源管理的需求，而需要限制当前线程数量的应用场景，它适用于负载比较重的服务器。FixedThreadPool的corePoolSize和maximumPoolSize都被设置为创建FixedThreadPool时指定的参数nThreads。</p><p>当线程池中的线程数大于corePoolSize时，keepAliveTime为多余的空闲线程等待新任务的最长时间，超过这个时间后多余的线程将被终止。这里把keepAliveTime设置为0L，意味着多余的空闲线程会被立即终止。</p><p>FixedThreadPool使用有界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为Integer.MAX_VALUE）。</p><h3 id="SingleThreadExecutor"><a href="#SingleThreadExecutor" class="headerlink" title="SingleThreadExecutor"></a>SingleThreadExecutor</h3><p>创建使用单个线程的SingleThread-Executor的API，于需要保证顺序地执行各个任务；并且在任意时间点，不会有多个线程是活动的应用场景。</p><p>corePoolSize和maximumPoolSize被设置为1。其他参数与FixedThreadPool相同。SingleThreadExecutor使用有界队列LinkedBlockingQueue作为线程池的工作队列（队列的容量为Integer.MAX_VALUE）。</p><h3 id="CachedThreadPool"><a href="#CachedThreadPool" class="headerlink" title="CachedThreadPool"></a>CachedThreadPool</h3><p>创建一个为所有任务创建新线程的CachedThreadPool的API。大小无界的线程池，适用于执行很多的短期异步任务的小程序，或者是负载较轻的服务器。</p><p>corePoolSize被设置为0，即corePool为空；maximumPoolSize被设置为Integer.MAX_VALUE。这里把keepAliveTime设置为60L，意味着CachedThreadPool中的空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被终止。</p><p>FixedThreadPool和SingleThreadExecutor使用有界队列LinkedBlockingQueue作为线程池的工作队列。CachedThreadPool使用没有容量的SynchronousQueue作为线程池的工作队列，但CachedThreadPool的maximumPool是无界的。这意味着，如果主线程提交任务的速度高于maximumPool中线程处理任务的速度时，CachedThreadPool会不断创建新线程。极端情况下，CachedThreadPool会因为创建过多线程而耗尽CPU和内存资源。</p><h3 id="WorkStealingPool"><a href="#WorkStealingPool" class="headerlink" title="WorkStealingPool"></a>WorkStealingPool</h3><p>利用所有运行的处理器数目来创建一个工作窃取的线程池，使用forkjoin实现</p><h3 id="ScheduledThreadPoolExecutor"><a href="#ScheduledThreadPoolExecutor" class="headerlink" title="ScheduledThreadPoolExecutor"></a>ScheduledThreadPoolExecutor</h3><p>使用工厂类Executors来创建。Executors可以创建2种类型的ScheduledThreadPoolExecutor，如下。</p><ul><li><p>ScheduledThreadPoolExecutor。包含若干个线程的ScheduledThreadPoolExecutor。</p></li><li><p>SingleThreadScheduledExecutor。只包含一个线程的ScheduledThreadPoolExecutor。</p></li></ul><p>ScheduledThreadPoolExecutor适用于需要多个后台线程执行周期任务，同时为了满足资源管理的需求而需要限制后台线程的数量的应用场景。</p><p>SingleThreadScheduledExecutor适用于需要单个后台线程执行周期任务，同时需要保证顺序地执行各个任务的应用场景。</p><p>提交定时任务：</p><ul><li><p>public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit)：向定时任务线程池提交一个延时Runnable任务（仅执行一次）</p></li><li><p>public <V> ScheduledFuture<V> schedule(Callable<V> callable, long delay, TimeUnit unit)：向定时任务线程池提交一个延时的Callable任务（仅执行一次）</p></li><li><p>public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay,   long period, TimeUnit unit)：向定时任务线程池提交一个固定时间间隔执行的任务</p></li><li><p>public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit)：向定时任务线程池提交一个固定延时间隔执行的任务</p></li></ul><p>固定延时间隔的任务是指每次执行完任务以后都延时一个固定的时间。由于操作系统调度以及每次任务执行的语句可能不同，所以每次任务执行所花费的时间是不确定的，也就导致了每次任务的执行周期存在一定的波动。</p><p>固定时间间隔的任务不论每次任务花费多少时间，下次任务开始执行时间从理论上讲是确定的，当然执行任务的时间不能超过执行周期。</p><p>定时任务异常问题：</p><p>如果任务在执行过程中出现了异常而且不进行捕捉的话，next周期将不会运行。</p><p>定时任务超时问题：</p><p>scheduleAtFixedRate中，若任务处理时长超出设置的定时频率时长，本次任务执行完才开始下次任务，下次任务已经处于超时状态，会马上开始执行。若任务处理时长小于定时频率时长，任务执行完后，定时器等待，下次任务会在定时器等待频率时长后执行。</p><p>如下例子：</p><p>设置定时任务每60s执行一次，那么从理论上应该第一次任务在第0s开始,第二次任务在第60s开始，第三次任务在120s开始，但实际运行时第一次任务时长80s，第二次任务时长30s，第三次任务时长50s，则实际运行结果为：</p><p>第一次任务第0s开始,第80s结束；</p><p>第二次任务第80s开始,第110s结束(上次任务已超时,本次不会再等待60s,会马上开始)；</p><p>第三次任务第120s开始,第170s结束.</p><p>第四次任务第180s开始…..</p><h2 id="Executor框架的基本使用流程"><a href="#Executor框架的基本使用流程" class="headerlink" title="Executor框架的基本使用流程"></a>Executor框架的基本使用流程</h2><img src="/2020/01/16/%E7%BA%BF%E7%A8%8B%E6%B1%A0/pic3.png" srcset="/img/loading.gif" class=""><h3 id="了解CompletionService"><a href="#了解CompletionService" class="headerlink" title="了解CompletionService"></a>了解CompletionService</h3><p>CompletionService实际上可以看做是Executor和BlockingQueue的结合体。CompletionService在接收到要执行的任务时，通过类似BlockingQueue的put()和take()获得任务执行的结果。</p><p>CompletionService的一个实现是ExecutorCompletionService，ExecutorCompletionService把具体的计算任务交给Executor完成。</p><p>在实现上，ExecutorCompletionService在构造函数中会创建一个BlockingQueue（使用的基于链表的LinkedBlockingQueue），该BlockingQueue的作用是保存Executor执行的结果。</p><p>当提交一个任务到ExecutorCompletionService时，首先将任务包装成QueueingFuture，它是FutureTask的一个子类，然后改写FutureTask的done方法，之后把Executor执行的计算结果放入BlockingQueue中。</p><p>与ExecutorService最主要的区别在于submit的task不一定是按照加入时的顺序完成的。CompletionService对ExecutorService进行了包装，内部维护一个保存Future对象的BlockingQueue。只有当这个Future对象状态是结束的时候，才会加入到这个Queue中，take()方法其实就是Producer-Consumer中的Consumer。它会从Queue中取出Future对象，如果Queue是空的，就会阻塞在那里，直到有完成的Future对象加入到Queue中。所以，先完成的必定先被取出。这样就减少了不必要的等待时间。</p><p>使用方法一，自己创建一个集合来保存Future存根并循环调用其返回结果的时候，主线程并不能保证首先获得的是最先完成任务的线程返回值。它只是按加入线程池的顺序返回。因为take方法是阻塞方法，后面的任务完成了，前面的任务却没有完成，主程序就那样等待在那儿，只到前面的完成了，它才知道原来后面的也完成了。</p><p>使用方法二，使用CompletionService来维护处理线程不的返回结果时，主线程总是能够拿到最先完成的任务的返回值，而不管它们加入线程池的顺序。</p><pre><code>/** *类说明： */public class CompletionCase {    private final int POOL_SIZE = Runtime.getRuntime().availableProcessors();    private final int TOTAL_TASK = Runtime.getRuntime().availableProcessors()*10;    // 方法一，自己写集合来实现获取线程池中任务的返回结果    public void testByQueue() throws Exception {       long start = System.currentTimeMillis();       AtomicInteger count = new AtomicInteger(0);        // 创建线程池        ExecutorService pool = Executors.newFixedThreadPool(POOL_SIZE);        // 拿任务的执行结果        BlockingQueue&lt;Future&lt;Integer&gt;&gt; queue =              new LinkedBlockingQueue&lt;Future&lt;Integer&gt;&gt;();        // 向里面扔任务        for (int i = 0; i &lt; TOTAL_TASK; i++) {            Future&lt;Integer&gt; future = pool.submit(new WorkTask(&quot;ExecTask&quot; + i));            queue.add(future);        }        // 检查线程池任务执行结果        for (int i = 0; i &lt; TOTAL_TASK; i++) {           int sleptTime = queue.take().get();           //System.out.println(&quot; slept &quot;+sleptTime+&quot; ms ...&quot;);           count.addAndGet(sleptTime);        }        // 关闭线程池        pool.shutdown();        System.out.println(&quot;-------------tasks sleep time &quot;+count.get()              +&quot;ms,and spend time &quot;              +(System.currentTimeMillis()-start)+&quot; ms&quot;);    }    public void testByCompletion() throws InterruptedException, ExecutionException {        long start = System.currentTimeMillis();        AtomicInteger count = new AtomicInteger(0);        // 创建线程池        ExecutorService pool = Executors.newFixedThreadPool(POOL_SIZE);        CompletionService&lt;Integer&gt; cService = new ExecutorCompletionService&lt;&gt;(pool);        // 向里面扔任务        for (int i = 0; i &lt; TOTAL_TASK; i++) {            cService.submit(new WorkTask(&quot;ExecTask&quot; + i));        }        // 检查线程池任务执行结果        for (int i = 0; i &lt; TOTAL_TASK; i++) {            int sleptTime = cService.take().get();            //System.out.println(&quot; slept &quot;+sleptTime+&quot; ms ...&quot;);            count.addAndGet(sleptTime);        }        // 关闭线程池        pool.shutdown();        System.out.println(&quot;-------------tasks sleep time &quot;+count.get()                +&quot;ms,and spend time &quot;                +(System.currentTimeMillis()-start)+&quot; ms&quot;);    }    public static void main(String[] args) throws Exception {        CompletionCase t = new CompletionCase();        t.testByQueue();        t.testByCompletion();    }}</code></pre><p>两种方法对比</p><pre><code>-------------tasks sleep time 38314ms,and spend time 5136 ms-------------tasks sleep time 40876ms,and spend time 5707 ms</code></pre>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Tomcat性能优化</title>
    <link href="/2020/01/10/tomcat%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    <url>/2020/01/10/tomcat%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h2 id="Tomcat内存优化"><a href="#Tomcat内存优化" class="headerlink" title="Tomcat内存优化"></a>Tomcat内存优化</h2><p>tomcat默认参数是为开发环境制定，而非适合生产环境，尤其是内存和线程的配置，默认都很低，容易成为性能瓶颈。</p><p>TOMCAT_HOME/bin/catalina.sh，在前面加入</p><pre><code>JAVA_OPTS=&quot;-XX:PermSize=64M -XX:MaxPermSize=128m -Xms512m -Xmx1024m -Duser.timezone=Asia/Shanghai&quot;</code></pre><p>此设置将最大堆内存改为1024m，实际调整时还是按照服务器的具体配置优化。</p><ul><li>JVM初始化堆大小：Xms</li><li>JVM堆的最大值：Xmx</li><li>JVM初始分配的非堆内存：PermSize</li><li>JVM最大允许分配的非堆内存：MaxPermSize</li></ul><h2 id="Tomcat线程优化"><a href="#Tomcat线程优化" class="headerlink" title="Tomcat线程优化"></a>Tomcat线程优化</h2><p>在TOMCAT_HOME/conf/server.xml中设置</p><pre><code>&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; maxThreads=&quot;600&quot; minSpareThreads=&quot;100&quot; maxSpareThreads=&quot;500&quot; acceptCount=&quot;700&quot;connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt;</code></pre><ul><li>maxThreads：最大线程数</li><li>minSpareThreads：最小空闲线程数（tomcat初始化时创建的线程数）</li><li>maxSpareThreads：最大空闲线程数（超过这个值之后，tomcat会关闭多余的socket线程）</li><li>acceptCount：等待队列长度。超过这个数的请求将不予处理，http请求将返回502状态码</li></ul><p>如果使用apache和tomcat做集群的负载均衡，并且使用ajp协议做apache和tomcat的协议转发，那么还需要优化ajp connector。</p><pre><code>&lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; maxThreads=&quot;600&quot; minSpareThreads=&quot;100&quot; maxSpareThreads=&quot;500&quot; acceptCount=&quot;700&quot;connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; /&gt;</code></pre><p>由于tomcat有多个connector，所以tomcat线程的配置可以支持多个connector共享一个线程池。</p><pre><code>&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot; maxThreads=&quot;500&quot; minSpareThreads=&quot;20&quot; maxIdleTime=&quot;60000&quot; /&gt;</code></pre><p>修改Connector节点，增加executor属性设置为线程池的名字</p><pre><code>&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;80&quot; protocol=&quot;HTTP/1.1&quot;  connectionTimeout=&quot;60000&quot; keepAliveTimeout=&quot;15000&quot; maxKeepAliveRequests=&quot;1&quot;  redirectPort=&quot;443&quot; /&gt;</code></pre><p>可以多个connector公用1个线程池，所以ajp connector也同样可以设置使用tomcatThreadPool线程池。</p><h2 id="Tomcat的连接器优化"><a href="#Tomcat的连接器优化" class="headerlink" title="Tomcat的连接器优化"></a>Tomcat的连接器优化</h2><p>Tomcat Connector(Tomcat连接器)有bio、nio、apr三种运行模式</p><h3 id="BIO"><a href="#BIO" class="headerlink" title="BIO"></a>BIO</h3><p>bio（blocking I/O，阻塞式I/O操作），表示Tomcat使用的是传统的Java I/O操作(即java.io包及其子包)。<br><strong>默认的模式，性能最差，没有经过任何优化处理和支持。</strong></p><h3 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h3><p>nio(non-blocking I/O，非阻塞式I/O操作)，也被看成是<code>non-blocking I/O</code>的缩写，是Java SE 1.4及后续版本提供的一种新的I/O操作方式(即java.nio包及其子包)。Java nio是一个基于缓冲区、并能提供非阻塞I/O操作的Java API。拥有比传统I/O操作(bio)更好的并发运行性能。 tomcat在8.0之后已经将nio作为默认运行模式，在8.0之前要让tomcat以nio方式来运行也比较简单，只需要修改tomcat目录下的/conf/servcer.xml中的protocol设置为<code>org.apache.coyote.http11.Http11NioProtocol</code>即可</p><pre><code>&lt;Connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot;connectionTimeout=&quot;20000&quot;redirectPort=&quot;8443&quot; /&gt;</code></pre><p>点击tomcat管理页面的server status之后就可以看到当前的运行模式</p><img src="/2020/01/10/tomcat%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic1.png" srcset="/img/loading.gif" class=""><h3 id="APR"><a href="#APR" class="headerlink" title="APR"></a>APR</h3><p>apr(Apache Portable Runtime/Apache可移植运行时库)，Tomcat将以JNI(Java Native Interface)的形式调用Apache HTTP服务器的核心动态链接库来处理文件读取或网络传输操作，从而大大地提高Tomcat对静态文件的处理性能。使用操作系统的部分本地操作，解决异步的IO问题，大幅度的提高性能。 Tomcat apr也是在Tomcat上运行高并发应用的首选模式。</p><p>Tomcat apr运行模式的配置是三种运行模式之中相对比较麻烦的一种。据官方文档所述，Tomcat apr需要以下三个组件的支持：</p><ul><li>APR library[APR库]</li><li>JNI wrappers for APR used by Tomcat (libtcnative)[简单地说，如果是在Windows操作系统上，就是一个名为tcnative-1.dll的动态链接库文件]</li><li>OpenSSL libraries[OpenSSL库]</li></ul><h3 id="centos7下tomcat8开启APR步骤"><a href="#centos7下tomcat8开启APR步骤" class="headerlink" title="centos7下tomcat8开启APR步骤"></a>centos7下tomcat8开启APR步骤</h3><ol><li>下载APR组件依赖</li></ol><img src="/2020/01/10/tomcat%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/pic2.png" srcset="/img/loading.gif" class=""><ol start="2"><li>安装apr</li></ol><pre><code>tar zxvf apr-1.6.5.tar.gzcd apr-1.6.5./configure --prefix=/usr/local/aprmake &amp;&amp; make install</code></pre><ol start="3"><li>安装apr-iconv</li></ol><pre><code>tar zxvf apr-iconv.1.2.2.tar.gzcd apr-iconv-1.2.2./configure --prefix=/usr/local/apr-iconv --with-apr=/usr/local/aprmake &amp;&amp; make install</code></pre><ol start="4"><li>安装apr-util</li></ol><pre><code>tar zxvf apr-util.1.6.1.tar.gzcd apr-util-1.6.1./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr --with-apr-iconv=/usr/local/apr-iconv/bin/apriconvmake &amp;&amp; make install</code></pre><ol start="5"><li>安装tomcat的bin目录下的tomcat-native-1.2.21-src.tar.gz</li></ol><pre><code>tar zxf tomcat-native-1.2.21-src.tar.gzcd tomcat-native-1.2.21cd native./configure --with-apr=/usr/local/apr --with-java-home=/usr/java/jdk1.8.0_65make &amp;&amp; make install</code></pre><ol start="6"><li>在tomcat的bin目录下的catalina.sh的最后一行添加变量</li></ol><pre><code>JAVA_OPTS=”$JAVA_OPTS -Djava.library.path=/usr/local/apr/lib”</code></pre><ol start="7"><li>重启tomcat启动日志中出现以下内容证明APR模式启动</li></ol><pre><code>10-Jan-2020 17:23:29.744 信息 [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [&quot;http-apr-9080&quot;]</code></pre><p>同理，通过tomcat的启动日志也可以判断出其运行状态</p><ul><li>bio</li></ul><pre><code>INFO: Initializing ProtocolHandler [&quot;http-bio-8080&quot;]Aug 04, 2015 10:20:35 PM org.apache.coyote.AbstractProtocol init</code></pre><ul><li>nio</li></ul><pre><code>INFO: Initializing ProtocolHandler [&quot;http-nio-8080&quot;]Aug 04, 2015 10:27:58 PM org.apache.coyote.AbstractProtocol init</code></pre><ul><li>apr</li></ul><pre><code>INFO: Initializing ProtocolHandler [&quot;http-apr-8080&quot;]Aug 04, 2015 10:33:45 PM org.apache.coyote.AbstractProtocol init</code></pre><h2 id="禁用DNS查询"><a href="#禁用DNS查询" class="headerlink" title="禁用DNS查询"></a>禁用DNS查询</h2><p>当web应用程序向要记录客户端的信息时，它也会记录客户端的IP地址或者通过域名服务器查找机器名 转换为IP地址。</p><p>DNS查询需要占用网络，并且包括可能从很多很远的服务器或者不起作用的服务器上去获取对应的IP的过程，这样会消耗一定的时间。</p><p>修改server.xml文件中的Connector元素，修改属性enableLookups参数值: enableLookups=”false”</p><p>如果为true，则可以通过调用request.getRemoteHost()进行DNS查询来得到远程客户端的实际主机名，若为false则不进行DNS查询，而是返回其ip地址</p><h2 id="设置session过期时间"><a href="#设置session过期时间" class="headerlink" title="设置session过期时间"></a>设置session过期时间</h2><p>在tomcat目录下的conf\web.xml中通过参数指定，单位为分钟。</p><pre><code>&lt;session-config&gt;       &lt;session-timeout&gt;180&lt;/session-timeout&gt;     &lt;/session-config&gt;</code></pre><h2 id="Maven项目远程部署到Tomcat"><a href="#Maven项目远程部署到Tomcat" class="headerlink" title="Maven项目远程部署到Tomcat"></a>Maven项目远程部署到Tomcat</h2><p>其实本节内容并不属于tomcat性能调优，但内容较少不足以再开一篇文章，凑合凑合塞到这吧。</p><ol><li>在tomcat根目录下的/conf/tomcat-users.xml添加用户</li></ol><pre><code>&lt;tomcat-users version=&quot;1.0&quot; xmlns=&quot;http://tomcat.apache.org/xml&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://tomcat.apache.org/xml tomcat-users.xsd&quot;&gt;&lt;role rolename=&quot;manager-gui&quot; /&gt;&lt;role rolename=&quot;manager-script&quot; /&gt;&lt;role rolename=&quot;admin-gui&quot; /&gt;&lt;role rolename=&quot;admin-script&quot; /&gt;&lt;user username=&quot;admin&quot; password=&quot;tomcat&quot; roles=&quot;manager-gui,manager-script,admin-gui,admin-script&quot; /&gt;&lt;/tomcat-users&gt;</code></pre><ol start="2"><li>pom文件中加入maven插件</li></ol><pre><code>&lt;plugin&gt;    &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt;    &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt;    &lt;version&gt;2.2&lt;/version&gt;    &lt;configuration&gt;        &lt;charset&gt;utf-8&lt;/charset&gt;        &lt;update&gt;true&lt;/update&gt;        &lt;url&gt;http://{yourIP}:8080/manager/text&lt;/url&gt;        &lt;mode&gt;war&lt;/mode&gt;        &lt;username&gt;username&lt;/username&gt;        &lt;password&gt;password&lt;/password&gt;        &lt;path&gt;/${project.artifactId}&lt;/path&gt;    &lt;/configuration&gt;&lt;/plugin&gt;</code></pre><p>tomcat7-maven-plugin是很久以前的插件版本，默认支持到Tomcat7，但是对于目前最新的Tomcat9同样可以使用该插件</p><p>官方介绍文档为：<code>http://tomcat.apache.org/maven-plugin-2.1/index.html</code></p><p>参数说明：</p><p>以下参数必选，但是可以在pom中空缺，空缺时将采用默认值</p><table><thead><tr><th>名称</th><th>描述</th><th>默认值</th></tr></thead><tbody><tr><td>charset</td><td>在与Tomcat Manager通信是的URL编 码字符集</td><td>ISO-8859-1</td></tr><tr><td>mode</td><td>部署的模式，值可为：war,context,both</td><td>war</td></tr><tr><td>path</td><td>应用程序运行的上下文路径，必须以’/‘开始</td><td>/${project.artifactId}</td></tr><tr><td>update</td><td>当部署已存在的应用时，是否自动 undeploy该应用</td><td>false</td></tr><tr><td>url</td><td>Tomcat Manager实例使用的全路径</td><td>tomcat的根路径/manager/text</td></tr><tr><td>warFile</td><td>部署warFile的路径</td><td>${project.build.directory} ${project.build.finalName}.war</td></tr></tbody></table><p>对于个性化的需求，tomcat7插件提供了可配置的参数</p><table><thead><tr><th>名称</th><th>描述</th></tr></thead><tbody><tr><td>contextFile</td><td>Tomcat的context的XML路径，对于mode=war不适用，默认为 ${project.build.directory}/${project.build.finalName}/ META-INF/context.xml</td></tr><tr><td>ignorePackaging</td><td>如果设置为true，忽略类型不是war的项目</td></tr><tr><td>username</td><td>部署到Tomcat的username</td></tr><tr><td>password</td><td>部署到Tomcat的password</td></tr><tr><td>server</td><td>指定Maven的setting.xml中配置的server id用于Tomcat认证</td></tr><tr><td>tag</td><td>应用程序在Tomcat中使用的标签的名字</td></tr></tbody></table><p>还可以在maven目录中的conf/setting.xml中添加tomcat的用户名和密码</p><pre><code>&lt;servers&gt;    &lt;server&gt;        &lt;id&gt;tomcatServer&lt;/id&gt;        &lt;username&gt;username&lt;/username&gt;        &lt;password&gt;password&lt;/password&gt;    &lt;/server&gt;&lt;/servers&gt;</code></pre><p>之后在pom文件中指定server的id即可，不在需要用户名密码</p><pre><code>&lt;plugin&gt;    &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt;    &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt;    &lt;version&gt;2.2&lt;/version&gt;    &lt;configuration&gt;        &lt;url&gt;http://{yourIP}:8080/manager/text&lt;/url&gt;        &lt;server&gt;tomcatServer&lt;/server&gt;        &lt;update&gt;true&lt;/update&gt;        &lt;path&gt;/${project.artifactId}&lt;/path&gt;    &lt;/configuration&gt;        &lt;/plugin&gt;</code></pre><ol start="3"><li>idea部署项目</li></ol><p>idea可以直接在右侧边栏中的plugins中找到tomcat7，第一次部署时选择deploy之后选择redeploy就可以了</p><p>mvn命令</p><pre><code>mvn tomcat7:deploymvn tomcat7:redeploymvn tomcat7:undeploy</code></pre>]]></content>
    
    
    <categories>
      
      <category>性能优化</category>
      
    </categories>
    
    
    <tags>
      
      <tag>tomcat</tag>
      
      <tag>性能优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>并发容器</title>
    <link href="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/"/>
    <url>/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="Hash算法"><a href="#Hash算法" class="headerlink" title="Hash算法"></a>Hash算法</h2><p>Hash一般译做“散列”，就是把任意长度的输入（又叫做预映射， pre-image），通过散列算法，变换成固定长度的输出，该输出就是散列值。这种转换是一种压缩映射，也就是散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能从散列值来确定唯一的输入值（不可逆）。简单的说Hash算法就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。因为其不可逆的特性，Hash算法也可以用来作为加密算法。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic1.png" srcset="/img/loading.gif" class=""><p>处理冲突方法:</p><ol><li>开放寻址法：出现hash冲突时，从当前地址向后寻找</li><li>再散列法：出现hash冲突时，再次进行hash运算</li><li>链地址法(拉链法)：将有hash冲突的元素存储在链表或其他数据结构中</li></ol><p>常用hash算法的介绍：</p><ol><li>MD4 </li><li>MD5（常被用为加密算法）</li><li>SHA-1及其他。</li></ol><h2 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h2><h3 id="常用位运算"><a href="#常用位运算" class="headerlink" title="常用位运算"></a>常用位运算</h3><ul><li><p>位与 &amp; (1&amp;1=1 0&amp;0=0 1&amp;0=0)</p></li><li><p>位或 | (1|1=1 0|0=0 1|0=1)</p></li><li><p>位非 <del>(</del>1=0 ~0=1)</p></li><li><p>位异或 ^ (1^1=0 1^0=1 0^0=0)</p></li><li><p>有符号右移&gt;&gt;(若正数,高位补0,负数,高位补1)</p></li><li><p>有符号左移&lt;&lt;(低位补0)</p></li><li><p>无符号右移&gt;&gt;&gt;(不论正负,高位均补0)</p></li></ul><p>有趣的取模性质：取模a % (2^n) 等价于 a &amp; (2^n - 1)，所以在map里的数组个数一定是2的乘方数，计算key值在哪个元素中的时候，就用位运算来快速定位。</p><pre><code>public class IntToBinary {    public static void main(String[] args) throws UnsupportedEncodingException {        System.out.println(&quot;the 4 is : &quot; + Integer.toBinaryString(4));        System.out.println(&quot;the 6 is : &quot; + Integer.toBinaryString(6));        //位与&amp;(真真为真 真假为假 假假为假)        System.out.println(&quot;the 4&amp;6 is : &quot; + Integer.toBinaryString(6&amp;4));        //位或|(真真为真 真假为真 假假为假)        System.out.println(&quot;the 4|6 is : &quot; + Integer.toBinaryString(6|4));        //位非~        System.out.println(&quot;the ~4 is : &quot; + Integer.toBinaryString(~4));        //位异或^(真真为假 真假为真 假假为假)        System.out.println(&quot;the 4^6 is : &quot; + Integer.toBinaryString(6^4));        //有符号右移&gt;&gt;(若正数,高位补0,负数,高位补1)        System.out.println(&quot;the 4&gt;&gt;1 is : &quot; + Integer.toBinaryString(4&gt;&gt;1));        //有符号左移&lt;&lt;(若正数,高位补0,负数,高位补1)        System.out.println(&quot;the 4&lt;&lt;1 is : &quot; + Integer.toBinaryString(4&lt;&lt;1));        //无符号右移&gt;&gt;&gt;(不论正负,高位均补0)        System.out.println(&quot;the 234567 is : &quot; + Integer.toBinaryString(234567));        System.out.println(&quot;the 234567&gt;&gt;&gt;4 is : &quot; + Integer.toBinaryString(234567&gt;&gt;&gt;4));        //无符号右移&gt;&gt;&gt;(不论正负,高位均补0)        System.out.println(&quot;the -4 is : &quot; + Integer.toBinaryString(-4));        System.out.println(&quot;the -4&gt;&gt;&gt;4 is : &quot; + Integer.toBinaryString(-4&gt;&gt;&gt;4));        System.out.println(Integer.parseInt(Integer.toBinaryString(-4&gt;&gt;&gt;4), 2));        //取模a % (2^n) 等价于 a &amp; (2^n - 1)         System.out.println(&quot;the 345 % 16 is : &quot; + (345%16)+&quot; or &quot;+(345&amp;(16-1)));        System.out.println(&quot;Mark hashCode is : &quot;+&quot;Mark&quot;.hashCode()+&quot;=&quot;              +Integer.toBinaryString(&quot;Mark&quot;.hashCode()));        System.out.println(&quot;Bill hashCode is : &quot;+&quot;Bill&quot;.hashCode()+&quot;=&quot;              +Integer.toBinaryString(&quot;Bill&quot;.hashCode()));            } }</code></pre><h3 id="位运算运用场景"><a href="#位运算运用场景" class="headerlink" title="位运算运用场景"></a>位运算运用场景</h3><ul><li><p>Java中的类修饰符、成员变量修饰符、方法修饰符，比如Class类中</p></li><li><p>Java容器中的HashMap和ConcurrentHashMap的实现</p></li><li><p>权限控制或者商品属性</p></li><li><p>简单可逆加密，比如异或运算(1^1=0 ; 0^1=1 )</p></li></ul><p>实战：权限控制</p><pre><code>public class Permission {    private static final int ALLOW_SELECT = 1 &lt;&lt; 0;    private static final int ALLOW_INSERT = 1 &lt;&lt; 1;    private static final int ALLOW_UPDATE = 1 &lt;&lt; 2;    private static final int ALLOW_DELETE = 1 &lt;&lt; 3;    // 当前状态    private int flag;    public void setPermission(int permission) {        this.flag = permission;    }    // 增加权限，可以一项或者多项    public void addPermission(int permission) {        this.flag = flag | permission;    }    // 删除权限，可以一项或者多项    public void disablePermission(int permission) {        this.flag = flag &amp; ~permission;    }    // 是否拥有权限    public boolean isAllow(int permission) {        return (this.flag &amp; permission) == permission;    }    // 是否不拥有权限    public boolean isNotAllow(int permission) {        return (this.flag &amp; permission) == 0;    }    public static void main(String[] args) {      int flag = 15;      Permission permission = new Permission();      permission.setPermission(flag);      permission.disablePermission(ALLOW_DELETE|ALLOW_INSERT);      System.out.println(&quot;ALLOW_SELECT=&quot;+permission.isAllow(ALLOW_SELECT));      System.out.println(&quot;ALLOW_INSERT=&quot;+permission.isAllow(ALLOW_INSERT));      System.out.println(&quot;ALLOW_UPDATE=&quot;+permission.isAllow(ALLOW_UPDATE));      System.out.println(&quot;ALLOW_DELETE=&quot;+permission.isAllow(ALLOW_DELETE));    }</code></pre><p>使用位运算的优劣势：</p><p>节省很多代码量、效率高、属性变动影响小、不直观</p><h2 id="JDK1-7中HashMap死循环分析"><a href="#JDK1-7中HashMap死循环分析" class="headerlink" title="JDK1.7中HashMap死循环分析"></a>JDK1.7中HashMap死循环分析</h2><p>在多线程环境下，HashMap在并发执行put操作时会导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry，导致CPU利用率接近100%。</p><h3 id="HashMap扩容流程"><a href="#HashMap扩容流程" class="headerlink" title="HashMap扩容流程"></a>HashMap扩容流程</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>正常的扩容操作是这个流程。HashMap的扩容在put操作中会触发扩容，主要是三个方法：</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic2.png" srcset="/img/loading.gif" class=""><p>综合来说，HashMap一次扩容的过程：</p><ol><li><p>取当前table的2倍作为新table的大小</p></li><li><p>根据算出的新table的大小new出一个新的Entry数组来，名为newTable</p></li><li><p>轮询原table的每一个位置，将每个位置上连接的Entry，算出在新table上的位置，并以链表形式连接</p></li><li><p>原table上的所有Entry全部轮询完毕之后，意味着原table上面的所有Entry已经移到了新的table上，HashMap中的table指向newTable</p></li></ol><h4 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h4><p>现在hashmap中有三个元素，key分别为3、7、5，Hash表的size=2, 通过hash计算后这三个元素都将分配到table[1]。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic3.png" srcset="/img/loading.gif" class=""><p>按照方法中的代码</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic4.png" srcset="/img/loading.gif" class=""><p>对table[1]中的链表来说，进入while循环，此时e=key(3)，那么next=key(7)，经过计算重新定位e=key(3)在新表中的位置，并把e=key(3)分配newTable[3]的位置</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic5.png" srcset="/img/loading.gif" class=""><p>这样循环下去，将table[1]中的链表循环完成后，于是HashMap就完成了扩容</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic6.png" srcset="/img/loading.gif" class=""><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic7.png" srcset="/img/loading.gif" class=""><p>HashMap在hash冲突插入元素时采用的是头插法，先将新的元素的next指向当前table[i]，之后再将table[i]指向当前元素</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic8.png" srcset="/img/loading.gif" class=""><h3 id="并发下的扩容"><a href="#并发下的扩容" class="headerlink" title="并发下的扩容"></a>并发下的扩容</h3><p>初始的HashMap还是：</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic9.png" srcset="/img/loading.gif" class=""><p>现在假设有两个线程并发操作，都进入了扩容操作线程1执行到Entry&lt;K,V&gt; next = e.next;时被操作系统调度挂起了，而线程2执行完成了扩容操作:</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic10.png" srcset="/img/loading.gif" class=""><p>于是，在线程1,2看来，就应该是这个样子</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic11.png" srcset="/img/loading.gif" class=""><p>接下来，线程1被调度回来执行： </p><ol><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic12.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic13.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic14.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic15.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic16.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic17.png" srcset="/img/loading.gif" class=""></li><li><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic18.png" srcset="/img/loading.gif" class=""></li></ol><p>循环列表产生后，一旦线程1调用get（11,15之类的元素）时，就会进入一个死循环的情况，将CPU的消耗到100%。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>HashMap之所以在并发下的扩容造成死循环，是因为多个线程并发进行时，一个线程先期完成了扩容，将原Map的链表重新散列到自己的表中，并将链表变成了倒序，后一个线程再扩容时，又进行自己的散列，再次将倒序链表变为正序链表，于是形成了一个环形链表，当get表中不存在的元素时，会去遍历链表造成死循环。</p><h2 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h2><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>除了Map系列应该有的线程安全的get，put等方法外，ConcurrentHashMap还提供了一个在并发下比较有用的方法 putIfAbsent，如果传入key对应的value已经存在，就返回存在的value，不进行替换。如果不存在，就添加key和value，返回null。在代码层面它的作用类似于：</p><pre><code>synchronized(map){    if (map.get(key) == null){         return map.put(key, value);    } else{         return map.get(key);    }}</code></pre><p>它让上述代码的整个操作是线程安全的。</p><h3 id="ConcurrentHashMap实现分析"><a href="#ConcurrentHashMap实现分析" class="headerlink" title="ConcurrentHashMap实现分析"></a>ConcurrentHashMap实现分析</h3><h4 id="在1-7下的实现"><a href="#在1-7下的实现" class="headerlink" title="在1.7下的实现"></a>在1.7下的实现</h4><h5 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic19.png" srcset="/img/loading.gif" class=""><p>ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁（ReentrantLock），在ConcurrentHashMap里扮演锁的角色；HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组。Segment的结构和HashMap类似，是一种数组和链表结构。一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素，每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得与它对应的Segment锁。Segment数组初始化之后大小不再改变，当需要扩容时Segment下的table数组进行扩容。</p><h5 id="初始化方法"><a href="#初始化方法" class="headerlink" title="初始化方法"></a>初始化方法</h5><p>ConcurrentHashMap初始化方法是通过initialCapacity（初始化容量）、loadFactor（负载因子）和concurrencyLevel（并发级别）来初始化segment数组、段偏移量segmentShift、段掩码segmentMask和每个segment里的HashEntry数组来实现的。</p><p>参数concurrencyLevel（并发度）可以理解为程序运行时能够同时更新ConccurentHashMap且不产生锁竞争的最大线程数，实际上就是ConcurrentHashMap中的分段锁个数，即Segment[]的数组长度。ConcurrentHashMap默认的并发度为16，用户也可以在构造函数中设置并发度，设置之后将不再改变。当用户设置并发度时，ConcurrentHashMap会使用大于等于该值的最小2幂指数作为实际并发度（假如用户设置并发度为17，实际并发度则为32）。如果设置的过小，会带来严重的锁竞争问题；如果设置的过大，原本位于同一个Segment内的访问会扩散到不同的Segment中，CPU cache命中率会下降，从而引起程序性能下降。大小可以通过cpu核心数或实际使用该Map的线程数量来确定。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic20.png" srcset="/img/loading.gif" class=""><p>参数initialCapacity是ConcurrentHashMap的初始化容量，loadfactor是每个Segment的负载因子，在构造方法里需要通过这两个参数来初始化数组中的每个Segment。上面代码中的变量cap就是Segment里HashEntry数组的长度，它等于initialCapacity除以ssize的倍数c，如果c大于1，就会取大于等于c的2的N次方值，所以segment里HashEntry数组的长度不是1，就是2的N次方。</p><p>在默认情况下， ssize = 16，initialCapacity = 16，loadFactor = 0.75f，那么cap = 1，threshold = (int) cap * loadFactor = 0。</p><p>在初始化时，默认只初始化Segment[0]中的table，其他Segment中的table在put时再进行初始化。</p><p>初始化segmentShift和segmentMask（了解即可，无需深究）这两个全局变量需要在定位segment时的散列算法里使用，shift等于size从1向左移位的次数，在默认情况下concurrencyLevel等于16，1需要向左移位移动4次，所以sshift等于4。segmentShift用于定位参与散列运算的位数，segmentShift等于32减sshift，所以等于28，这里之所以用<em>32</em>是因为ConcurrentHashMap里的hash()方法输出的最大数是<em>32</em>位的。segmentMask是散列运算的掩码，等于ssize减1，即15，掩码的二进制各个位的值都是<em>1</em>。因为ssize的最大长度是65536，所以segmentShift最大值是16，segmentMask最大值是65535，对应的二进制是16位，每个位都是1。</p><h5 id="get方法"><a href="#get方法" class="headerlink" title="get方法"></a>get方法</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic21.png" srcset="/img/loading.gif" class=""><p>既然ConcurrentHashMap使用分段锁Segment来保护不同段的数据，那么在插入和获取元素的时候，必须先通过散列算法定位到Segment。get操作先获取hash值，然后使用这个hash值通过hash运算定位到Segment(使用了hash值的高位部分)，再通过hash算法定位到table(使用了散列值的全部)。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic22.png" srcset="/img/loading.gif" class=""><p>整个get过程没有加锁，而是通过volatile保证get总是可以拿到最新值。</p><p>ConcurrentHashMap中使用的hash算法为Wang/Jenkins hash的变种算法，其产生的hash的值更加均匀，减少了hash冲突</p><h5 id="put方法"><a href="#put方法" class="headerlink" title="put方法"></a>put方法</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic24.png" srcset="/img/loading.gif" class=""><p>put方法首先会根据key计算出所在的Segment，然后调用ensureSegment()方法获取Segment。因为ConcurrentHashMap初始化时只会初始化第一个槽 segment[0]，所以其他槽在插入第一个值时会在ensureSegment()方法中进行初始化。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic25.png" srcset="/img/loading.gif" class=""><p>ensureSegment方法考虑了并发情况，当多个线程同时进入初始化同一个槽 segment[k]会进行循环CAS操作保证只有一个线程成功。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic26.png" srcset="/img/loading.gif" class=""><p>put方法在获取到Segment之后会调用Segment中的put方法，Segment中的put方法会通过tryLock()方法尝试获得锁，如果成功获得锁会将node置为null然后进入try语句块，如果没有获得锁会调用scanAndLockForPut()方法自旋等待获得锁。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic27.png" srcset="/img/loading.gif" class=""><p>scanAndLockForPut方法里在尝试获得锁的过程中会对对应HashEntity链表进行遍历，如果遍历完毕仍然找不到与key相同的HashEntry节点，则为后续的put操作提前创建一个HashEntry。当tryLock一定次数（当cpu可用核心数大于1时重试64次，否则只重试1次）后仍无法获得锁，则通过lock()阻塞式申请锁。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic28.png" srcset="/img/loading.gif" class=""><p>在获得锁之后，Segment对链表进行遍历，如果某个HashEntry节点具有相同的key，则更新该HashEntry的value值</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic29.png" srcset="/img/loading.gif" class=""><p>否则新建一个HashEntry节点，采用头插法，将它设置为链表的新head节点并将原头节点设为新head的下一个节点。新建过程中如果节点总数（含新建的HashEntry）超过threshold，则调用rehash()方法对Segment进行扩容，最后将新建HashEntry写入到数组中。</p><h5 id="rehash方法"><a href="#rehash方法" class="headerlink" title="rehash方法"></a>rehash方法</h5><p>rehash方法扩容时会先创建数组newTable，然后进行将table中的节点迁移至newTable，最后用newTable取代table。</p><p>由于扩容是基于2的幂指来操作，假设扩容前某HashEntry对应到Segment中数组的index为i，数组的容量为capacity，那么扩容后该HashEntry对应到新数组中的index只可能为i或者i+capacity，因此很多HashEntry节点在扩容前后index可以保持不变，避免让所有的节点都进行复制操作。</p><p>假设原来table长度为4，那么元素在table中的分布是这样的</p><table><thead><tr><th>Hash值</th><th>15</th><th>23</th><th>34</th><th>56</th><th>77</th></tr></thead><tbody><tr><td>在table中的下标</td><td>3 = 15%4</td><td>3=23%4</td><td>2 = 34%4</td><td>0= 56%4</td><td>1 =77 %4</td></tr></tbody></table><p>扩容后table长度变为8，那么元素在table中的分布变成：</p><table><thead><tr><th>Hash值</th><th>15</th><th>23</th><th>34</th><th>56</th><th>77</th></tr></thead><tbody><tr><td>在table中的下标</td><td>7</td><td>7</td><td>2</td><td>0</td><td>5</td></tr></tbody></table><p>可以看见 hash值为34和56的下标保持不变，而15,23,77的下标都是在原来下标的基础上+4即可，可以快速定位和减少重排次数。</p><p>该方法没有考虑并发，因为执行该方法之前已经获取了锁。</p><h5 id="remove方法"><a href="#remove方法" class="headerlink" title="remove方法"></a>remove方法</h5><p>与put方法类似，都是在操作前需要拿到锁，以保证操作的线程安全性。</p><h5 id="size、containsValue方法"><a href="#size、containsValue方法" class="headerlink" title="size、containsValue方法"></a>size、containsValue方法</h5><p>这些方法都是基于整个ConcurrentHashMap来进行操作的，他们的原理也基本类似：首先不加锁循环执行以下操作：循环所有的Segment，获得对应的值以及所有Segment的modcount之和。在 put、remove 和 clean 方法里操作元素前都会将变量 modCount 进行变动，如果连续两次所有Segment的modcount和相等，则过程中没有发生其他线程修改ConcurrentHashMap的情况，返回获得的值。</p><p>当循环次数超过预定义的值时，这时需要对所有的Segment依次进行加锁，获取返回值后再依次解锁。所以一般来说，应该避免在多线程环境下使用size和containsValue方法。</p><h5 id="ConcurrentHashMap的弱一致性"><a href="#ConcurrentHashMap的弱一致性" class="headerlink" title="ConcurrentHashMap的弱一致性"></a>ConcurrentHashMap的弱一致性</h5><p>ConcurrentHashMap的get()和containsKey()方法并没有加锁，在遍历链表节点判断key是否相同以及获得该节点的value时，其他线程对链表结构做的调整（put新的key或者remove操作）会由于HashEntity数组并不是volita修饰的导致返回的可能是过时的数据。如果要求强一致性，那么必须使用Collections.synchronizedMap()方法。</p><h4 id="在1-8下的实现"><a href="#在1-8下的实现" class="headerlink" title="在1.8下的实现"></a>在1.8下的实现</h4><h5 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h5><ol><li>取消segments字段，直接采用transient volatile HashEntry&lt;K,V&gt;[] table保存数据，使用table数组元素作为锁，由于table是可以扩容的，数据的增加时锁的粒度也会缩小以减少并发冲突的概率，同时大量使用了使用 CAS + synchronized 来保证并发安全性。</li><li>将原本的table数组＋单向链表的数据结构，变更为table数组＋单向链表＋红黑树的结构。hash表最核心的能力在于将key hash之后能均匀的分布在数组中，理想的情况下table数组中的每个队列长度主要为0或者1，但实际情况并非如此。在数据量过大的情况下，即使ConcurrentHashMap类会依据默认的加载因子0.75进行扩容、增加table数组长度，但是如果hash结果不均匀，也会使数据集中在某个队列导致队列过长。此时查询某个节点的时间复杂度为O(n)。所以对于个数超过8(默认值)的列表jdk1.8中采用了红黑树的结构，查询的时间复杂度可以降低到O(logN)，从而改进性能。</li><li>使用 Node（jdk1.7 为 HashEntry）作为链表的数据结点，仍然包含 key，value，hash 和 next 四个属性。 红黑树中使用的是 TreeNode（extends Node）。所以根据数组元素中第一个结点数据类型是 Node 还是 TreeNode 可以判断该位置下是链表还是红黑树。</li></ol><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic30.png" srcset="/img/loading.gif" class=""><p>当链表的长度大于8时会转为红黑树</p><p>当红黑树的大小小于6时会转为链表</p><h5 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h5><p>Node是最核心的内部类，它包装了key-value键值对。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic31.png" srcset="/img/loading.gif" class=""><p>定义基本和1.7中的HashEntry相同。Map本身所持有的也是一个Node型的数组</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic32.png" srcset="/img/loading.gif" class=""><p>增加了一个find方法来用以辅助map.get()方法。其实就是遍历链表，子类中会覆盖这个方法。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic35.png" srcset="/img/loading.gif" class=""><p>在map中还定义了Segment这个类，不过只是为了向前兼容而已，不做过多考虑。</p><h5 id="TreeNode"><a href="#TreeNode" class="headerlink" title="TreeNode"></a>TreeNode</h5><p>树节点类，另外一个核心的数据结构。当链表长度过长的时候，会转换为TreeNode。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic33.png" srcset="/img/loading.gif" class=""><p>与1.8中HashMap不同点：</p><ol><li><p>它并不是直接转换为红黑树，而是把这些结点放在TreeBin对象中，由TreeBin完成对红黑树的包装。</p></li><li><p>TreeNode在ConcurrentHashMap继承Node类，HashMap中的继承LinkedHashMap.Entry&lt;K,V&gt;类，ConcurrentHashMap中的TreeNode带有next指针。</p></li></ol><h5 id="TreeBin"><a href="#TreeBin" class="headerlink" title="TreeBin"></a>TreeBin</h5><p>负责TreeNode节点。它代替了TreeNode的根节点，也就是说在实际ConcurrentHashMap的table数组中存放的是TreeBin对象，而不是TreeNode对象。另外这个类还带有了读写锁机制。</p><h5 id="特殊的ForwardingNode"><a href="#特殊的ForwardingNode" class="headerlink" title="特殊的ForwardingNode"></a>特殊的ForwardingNode</h5><p>ForwardingNode是一个特殊的 Node 结点，hash 值为 -1，内部存储nextTable的引用。在table发生扩容的时作为一个占位符放在 table 中表示当前结点为 null 或者已经被移动。</p><h5 id="sizeCtl"><a href="#sizeCtl" class="headerlink" title="sizeCtl"></a>sizeCtl</h5><p>用来控制 table 的初始化和扩容操作。</p><p>负数代表正在进行初始化或扩容操作：-1代表正在初始化，-N 表示有N-1个线程正在进行扩容操作，0为默认值，代表当时的table还没有被初始化。</p><p>正数表示初始化大小或Map中的元素达到这个数量时，需要进行扩容了。</p><h5 id="核心方法"><a href="#核心方法" class="headerlink" title="核心方法"></a>核心方法</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic36.png" srcset="/img/loading.gif" class=""><h5 id="构造方法"><a href="#构造方法" class="headerlink" title="构造方法"></a>构造方法</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic37.png" srcset="/img/loading.gif" class=""><p>可以发现，在new出一个map的实例时，并不会创建其中的数组等等相关的部件，只是进行简单的属性设置而已。同样的，table的大小也被规定为必须是2的乘方数。</p><p>真正的初始化在放在了是在向ConcurrentHashMap中插入元素的时候发生的。如调用put()、computeIfAbsent()、compute()、merge()等方法的时候，调用时机是检查table==null。</p><h5 id="get操作"><a href="#get操作" class="headerlink" title="get操作"></a>get操作</h5><p>get方法比较简单，给定一个key来确定value的时候，必须满足两个条件 key相同 hash值相同，对于节点可能在链表或树上的情况，需要分别去查找。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic38.png" srcset="/img/loading.gif" class=""><h5 id="put操作"><a href="#put操作" class="headerlink" title="put操作"></a>put操作</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic40.png" srcset="/img/loading.gif" class=""><p>总结来说，put方法也继续沿用HashMap的put方法的思想，首先不允许key或value为null的情况放入，对于每一个放入的值，利用spread方法对key的hashcode进行一次hash计算，由此来确定这个值在table中的位置i，如果i位置是空的，直接放进去且不需要加锁操作，否则对i位置节点进行加锁，然后对节点进行判断，如果是树节点则按照树的方式插入新的节点，如果是链表节点，则得到的结点就是由hash值相同的节点组成的链表的头节点。此时需要向后遍历链表，如果遇到key值一致的情况，则需要更新其value值，否则依次向后遍历，到链表尾插入这个结点（尾插法）。如果加入这个节点以后链表长度大于8，就把这个链表转换成红黑树。</p><h5 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h5><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic39.png" srcset="/img/loading.gif" class=""><p>前面说过，构造方法中并没有真正初始化，真正的初始化在放在了是在向ConcurrentHashMap中插入元素的时候发生的。具体实现的方法就是initTable</p><h5 id="transfer"><a href="#transfer" class="headerlink" title="transfer"></a>transfer</h5><p>当ConcurrentHashMap容量不足的时需要对table进行扩容。这个方法的基本思想跟HashMap是很像的，但是由于它是支持并发扩容的，所以要复杂的多。我们不深入源码去讲述，只讲述其大概原理。</p><p>扩容的时总是会涉及到从一个“数组”到另一个“数组”拷贝的操作，并发扩容就是使这个操作能够并发进行，利用并发处理去减少扩容带来的时间影响。transfer中的并发扩容就是将数据迁移任务根据变量stride作为步长拆分成多个小迁移任务，每个线程每次负责迁移其中的一部分。</p><p>整个扩容操作分为两个部分：</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic41.png" srcset="/img/loading.gif" class=""><p>第一部分是构建一个nextTable,它的容量是原来的2倍。</p><p>第二个部分就是将原来table中的元素复制到nextTable中，这里允许多线程进行操作。</p><p>整个扩容流程就是遍历和复制：</p><p>为null或者已经处理过的节点，会被设置为forwardNode节点，当线程准备扩容时，发现节点是forwardNode节点，跳过这个节点，继续寻找未处理的节点，找到之后对节点上锁。</p><p>如果这个位置是Node节点（fh&gt;=0），说明它是一个链表，就构造一个反序链表，把他们分别放在nextTable的i和i+n的位置上</p><p>如果这个位置是TreeBin节点（fh&lt;0），也做一个反序处理，并且判断是否需要红黑树转链表，把处理的结果分别放在nextTable的i和i+n的位置上</p><p>遍历过所有的节点以后就完成了复制工作，这时让nextTable作为新的table，并且更新sizeCtl为新容量的0.75倍 ，完成扩容。</p><h5 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h5><p>移除方法的基本流程和put方法很类似，只不过操作由插入数据变为移除数据而已，而且如果存在红黑树的情况下，会检查是否需要将红黑树转为链表的步骤。不再重复讲述。</p><h5 id="treeifyBin"><a href="#treeifyBin" class="headerlink" title="treeifyBin"></a>treeifyBin</h5><p>用于将过长的链表转换为TreeBin对象。但是他并不是直接转换，而是进行一次容量判断，没有达到转换的要求，直接进行扩容操作并返回；如果满足条件才将链表的结构转换为TreeBin ，这与HashMap不同的是，它并没有把TreeNode直接放入红黑树，而是利用了TreeBin这个小容器来封装所有的TreeNode。</p><h5 id="size"><a href="#size" class="headerlink" title="size"></a>size</h5><p>JDK1.8中，调用put()方法时就会调用addCount()方法计算size的数量，扩容过程也会修改size的数量，因此在调用size()方法时可以直接返回，JDK1.7是调用size()方法时才会去计算。</p><p>调用addCount()方法时，会使用CAS更新baseCount，因为CAS只允许一个线程做修改，如果修改失败就会使用counterCells，大致的流程就是：</p><ol><li><p>对 baseCount 做 CAS 自增操作。</p></li><li><p>如果并发导致 baseCount CAS 失败了，则使用 counterCells。</p></li><li><p>如果counterCells CAS 失败了，在 fullAddCount 方法中，会继续死循环操作，直到成功。</p></li></ol><p>在具体实现上，计算大小的核心方法都是 sumCount()</p><p>JDK1.8中sumCount()会获取baseCount和CounterCell数组然后遍历CounterCell数组，将baseCount与CounterCell的值累加后返回。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic42.png" srcset="/img/loading.gif" class=""><p>其实去计算并发集合中实时在变的size是没有多大的意义的，但Doug Lea仍花费了很多心思去优化他的性能。</p><h2 id="HashTable"><a href="#HashTable" class="headerlink" title="HashTable"></a>HashTable</h2><p>HashTable容器使用synchronized来保证线程安全，这会导致在线程竞争激烈的情况下HashTable的效率非常低下。当一个线程访问HashTable的同步方法，其他线程也访问HashTable的同步方法时，会进入阻塞或轮询状态。如线程1使用put进行元素添加，线程2不但不能使用put方法添加元素，也不能使用get方法来获取元素，所以竞争越激烈效率越低。</p><h2 id="并发下的Map常见面试题汇总"><a href="#并发下的Map常见面试题汇总" class="headerlink" title="并发下的Map常见面试题汇总"></a>并发下的Map常见面试题汇总</h2><h3 id="HashMap-和-HashTable-有什么区别？"><a href="#HashMap-和-HashTable-有什么区别？" class="headerlink" title="HashMap 和 HashTable 有什么区别？"></a>HashMap 和 HashTable 有什么区别？</h3><ol><li><p>HashMap 是线程不安全的，HashTable 是线程安全的；</p></li><li><p>由于线程安全，所以 HashTable 的效率比不上 HashMap；</p></li><li><p>HashMap是允许key为value的，HashTable是不允许的，ConcurrentHashMap也是不允许的。</p></li><li><p>HashMap最多只允许一条记录的键为null，允许多条记录的值为null，而 HashTable 不允许；</p></li><li><p>HashMap 默认初始化数组的大小为16，HashTable 为 11，前者扩容时，扩大两倍，后者扩大两倍+1；</p></li><li><p>HashMap 需要重新计算 hash 值，而 HashTable 直接使用对象的 hashCode</p></li></ol><h3 id="Java-中的另一个线程安全的与-HashMap-极其类似的类是什么？同样是线程安全，它与-HashTable-在线程同步上有什么不同？"><a href="#Java-中的另一个线程安全的与-HashMap-极其类似的类是什么？同样是线程安全，它与-HashTable-在线程同步上有什么不同？" class="headerlink" title="Java 中的另一个线程安全的与 HashMap 极其类似的类是什么？同样是线程安全，它与 HashTable 在线程同步上有什么不同？"></a>Java 中的另一个线程安全的与 HashMap 极其类似的类是什么？同样是线程安全，它与 HashTable 在线程同步上有什么不同？</h3><p>ConcurrentHashMap 类（是 Java并发包 java.util.concurrent 中提供的一个线程安全且高效的 HashMap 实现）。</p><p>HashTable 是使用 synchronize 关键字加锁的原理（就是对对象加锁）；</p><p>而针对 ConcurrentHashMap，在 JDK 1.7 中采用Segment分段锁的方式；JDK 1.8 中直接采用了CAS（无锁算法）+ synchronized，也采用分段锁的方式但1.8中的分段锁是使用synchronized锁住table中的节点来实现的，缩小了锁的粒度。</p><h3 id="HashMap-amp-ConcurrentHashMap-的区别？"><a href="#HashMap-amp-ConcurrentHashMap-的区别？" class="headerlink" title="HashMap &amp; ConcurrentHashMap 的区别？"></a>HashMap &amp; ConcurrentHashMap 的区别？</h3><p>除了加锁，原理上无太大区别。</p><p>另外，HashMap 的键值对允许有null，但是ConCurrentHashMap 都不允许。</p><p>在数据结构上，红黑树相关的节点类不同继承的类不同</p><h3 id="为什么ConcurrentHashMap比HashTable效率要高？"><a href="#为什么ConcurrentHashMap比HashTable效率要高？" class="headerlink" title="为什么ConcurrentHashMap比HashTable效率要高？"></a>为什么ConcurrentHashMap比HashTable效率要高？</h3><p>HashTable 使用一把锁（锁住整个链表结构）处理并发问题，多个线程竞争一把锁，容易阻塞ConcurrentHashMap在JDK 1.7 中使用分段锁（ReentrantLock + Segment + HashEntry），相当于把一个 HashMap 分成多个段，每段分配一把锁，这样支持多线程访问。锁粒度基于 Segment，Segment中包含多个 HashEntry。JDK 1.8 中使用 CAS + synchronized + Node + 红黑树。锁粒度基于Node（首结点）（实现 Map.Entry&lt;K,V&gt;），锁粒度相对1.7降低了。</p><h3 id="针对ConcurrentHashMap-锁机制具体分析？"><a href="#针对ConcurrentHashMap-锁机制具体分析？" class="headerlink" title="针对ConcurrentHashMap 锁机制具体分析？"></a>针对ConcurrentHashMap 锁机制具体分析？</h3><p>JDK 1.7 中，采用分段锁的机制，实现并发的更新操作，底层采用数组+链表的存储结构，包括两个核心静态内部类 Segment 和 HashEntry。Segment 继承 ReentrantLock（重入锁） 用来充当锁的角色，每个 Segment 对象守护每个散列映射表的若干个桶；HashEntry 用来封装映射表的键-值对；每个桶是由若干个 HashEntry 对象链接起来的链表。</p><p>JDK 1.8 中，采用Node + CAS + Synchronized来保证并发安全。取消类 Segment，当需要锁时直接用synchronized锁住table数组中的对象，键值对直接存储在table中；当 Node 对象组成的链表长度超过 TREEIFY_THRESHOLD 时，链表转换为红黑树，Node对象被包装为TreeNode，以提升检索性能。此时底层变更为数组 + 链表 + 红黑树。</p><h3 id="ConcurrentHashMap在JDK-1-8中，为什么要使用内置锁-synchronized-来代替重入锁-ReentrantLock？"><a href="#ConcurrentHashMap在JDK-1-8中，为什么要使用内置锁-synchronized-来代替重入锁-ReentrantLock？" class="headerlink" title="ConcurrentHashMap在JDK 1.8中，为什么要使用内置锁 synchronized 来代替重入锁 ReentrantLock？"></a>ConcurrentHashMap在JDK 1.8中，为什么要使用内置锁 synchronized 来代替重入锁 ReentrantLock？</h3><ol><li><p>JVM 开发团队在1.8中对 synchronized做了大量性能上的优化，而且基于 JVM 的 synchronized 优化空间更大，更加自然。</p></li><li><p>在大量的数据操作下，对于 JVM 的内存压力，基于 API 的 ReentrantLock 会开销更多的内存。</p></li></ol><h3 id="ConcurrentHashMap简单介绍？"><a href="#ConcurrentHashMap简单介绍？" class="headerlink" title="ConcurrentHashMap简单介绍？"></a>ConcurrentHashMap简单介绍？</h3><ol><li><p>重要的常量：<strong>private transient volatile int sizeCtl</strong>，当为负数时，-1 表示正在初始化，-N 表示 N - 1 个线程正在进行扩容；当为 0 时，表示 table 还没有初始化；当为其他正数时，表示初始化或者下一次进行扩容的大小。</p></li><li><p>数据结构：<strong>Node 是存储结构的基本单元</strong>，继承 HashMap 中的 Entry，用于存储数据；TreeNode 继承 Node，但是数据结构换成了二叉树结构，是红黑树的存储结构，用于红黑树中存储数据；TreeBin 是封装 TreeNode 的容器，提供转换红黑树的一些条件和锁的控制。</p></li><li><p>put()方法：如果没有初始化，就调用 initTable() 方法来进行初始化；如果没有 hash 冲突就直接 CAS 无锁插入；如果需要扩容，就先进行扩容；如果存在 hash 冲突，就加锁来保证线程安全，两种情况：一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入；如果该链表的数量大于阀值 8，就要先转换成红黑树的结构，break 再一次进入循环如果添加成功就调用 addCount() 方法统计 size，并且检查是否需要扩容。</p></li><li><p>扩容方法 transfer()：默认容量为 16，扩容时，容量变为原来的两倍。helpTransfer()：调用多个工作线程一起帮助进行扩容，这样的效率就会更高。</p></li><li><p>get()方法：计算 hash 值，定位到该 table 索引位置，如果是首结点符合就返回；如果遇到扩容时，会调用标记正在扩容结点 ForwardingNode.find()方法，查找该结点，匹配就返回；以上都不符合的话，就往下遍历结点，匹配就返回，否则最后就返回 null。</p></li></ol><h3 id="ConcurrentHashMap的并发度是什么？"><a href="#ConcurrentHashMap的并发度是什么？" class="headerlink" title="ConcurrentHashMap的并发度是什么？"></a>ConcurrentHashMap的并发度是什么？</h3><p>1.7中程序运行时能够同时更新 ConccurentHashMap 且不产生锁竞争的最大线程数。默认为 16即Segment的数量，可以在构造函数中设置。当用户设置并发度时，ConcurrentHashMap 会使用大于等于该值的最小2幂指数作为实际并发度（假如用户设置并发度为17，实际并发度则为32）。1.8中由于直接使用table中的节点数量作为分段锁的数量，并发度已经没有太大的实际意义了，主要用处就是当设置的初始容量小于并发度，将初始容量提升至并发度大小。 </p><h2 id="ConcurrentSkipListMap和ConcurrentSkipListSet"><a href="#ConcurrentSkipListMap和ConcurrentSkipListSet" class="headerlink" title="ConcurrentSkipListMap和ConcurrentSkipListSet"></a>ConcurrentSkipListMap和ConcurrentSkipListSet</h2><p>TreeMap和TreeSet使用红黑树按照key的顺序（自然顺序、自定义顺序）来使得键值对有序存储，但是只能在单线程下安全使用；多线程下想要使键值对按照key的顺序来存储，则需要使用ConcurrentSkipListMap和ConcurrentSkipListSet，分别用以代替TreeMap和TreeSet，存入的数据按key排序。在实现上，ConcurrentSkipListSet 本质上就是ConcurrentSkipListMap，ConcurrentSkipListMap实际上就是一个跳表的实现。</p><p>ConcurrentSkipListMap和ConcurrentHashMap都是线程安全的Map实现，ConcurrentHashMap的性能和存储空间要优于ConcurrentSkipListMap，但是ConcurrentSkipListMap有一个功能： 它会按照键的顺序进行排序。</p><h3 id="二分查找和AVL树查找"><a href="#二分查找和AVL树查找" class="headerlink" title="二分查找和AVL树查找"></a>二分查找和AVL树查找</h3><p>二分查找要求元素可以随机访问，所以决定了需要把元素存储在连续内存。这样查找确实很快，但是插入和删除元素的时候，为了保证元素的有序性，就需要大量的移动元素了。</p><p>如果需要的是一个能够进行二分查找，又能快速添加和删除元素的数据结构，首先就是二叉查找树，二叉查找树在最坏情况下可能变成一个链表。</p><p>于是，就出现了平衡二叉树，根据平衡算法的不同有AVL树，B-Tree，B+Tree，红黑树等，但是AVL树实现起来比较复杂，平衡操作较难理解，这时候就可以用SkipList跳跃表结构。</p><h3 id="跳表（SkipList）"><a href="#跳表（SkipList）" class="headerlink" title="跳表（SkipList）"></a>跳表（SkipList）</h3><p>传统意义的单链表是一个线性结构，向有序的链表中插入一个节点需要O(n)的时间，查找操作需要O(n)的时间。</p><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic43.png" srcset="/img/loading.gif" class=""><p>如果我们使用上图所示的跳跃表，就可以减少查找所需时间为O(n/2)，因为我们可以先通过每个节点的最上面的指针先进行查找，这样子就能跳过一半的节点。</p><p>比如我们想查找50，首先和20比较，大于20之后，在和40进行比较，然后在和70进行比较，发现70大于50，说明查找的点在40和50之间，从这个过程中，我们可以看出，查找的时候跳过了30。</p><p>跳跃表其实也是一种通过“空间来换取时间”的一个算法，令链表的每个结点不仅记录next结点位置，还可以按照level层级分别记录后继第level个结点。此法使用的就是“<strong>先大步查找确定范围，再逐渐缩小迫近</strong>”的思想进行的查找。跳跃表在算法效率上很接近红黑树。</p><p>跳跃表又被称为概率，或者说是随机化的数据结构，目前开源软件 Redis 和 lucence都有用到它。</p><h2 id="CopyOnWriteArrayList和CopyOnWriteArraySet"><a href="#CopyOnWriteArrayList和CopyOnWriteArraySet" class="headerlink" title="CopyOnWriteArrayList和CopyOnWriteArraySet"></a>CopyOnWriteArrayList和CopyOnWriteArraySet</h2><h3 id="什么是写时复制容器"><a href="#什么是写时复制容器" class="headerlink" title="什么是写时复制容器"></a>什么是写时复制容器</h3><p>CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。</p><p>这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。如果读的时候有多个线程正在向CopyOnWriteArrayList添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的CopyOnWriteArrayList。</p><p>CopyOnWrite容器用于对于绝大部分访问都是读，且只是偶尔写的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单当中，黑名单每天晚上更新一次。当用户搜索时，会检查当前关键字在不在黑名单当中，如果在，则提示不能搜索。</p><h3 id="使用CopyOnWriteMap需要注意两件事情："><a href="#使用CopyOnWriteMap需要注意两件事情：" class="headerlink" title="使用CopyOnWriteMap需要注意两件事情："></a>使用CopyOnWriteMap需要注意两件事情：</h3><ol><li><p>减少扩容开销。根据实际需要，初始化CopyOnWriteMap的大小，避免写时CopyOnWriteMap扩容的开销。</p></li><li><p>使用批量添加。因为每次添加，容器每次都会进行复制，所以减少添加次数，可以减少容器的复制次数。</p></li></ol><h3 id="写时复制容器的问题："><a href="#写时复制容器的问题：" class="headerlink" title="写时复制容器的问题："></a>写时复制容器的问题：</h3><ol><li><p>性能问题：每次修改都创建一个新数组，然后复制所有内容，如果数组比较大，修改操作又比较频繁，可以想象，性能是很低的，而且内存开销会很大。</p></li><li><p>数据一致性问题：CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，不要使用CopyOnWrite容器。</p></li></ol><h2 id="BlockingQueue"><a href="#BlockingQueue" class="headerlink" title="BlockingQueue"></a>BlockingQueue</h2><h3 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h3><img src="/2020/01/06/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/pic44.png" srcset="/img/loading.gif" class=""><p>队列是一种特殊的线性表，特殊之处在于它只允许在表的前端（front）进行删除操作，而在表的后端（rear）进行插入操作，和栈一样，队列是一种操作受限制的线性表。进行插入操作的端称为队尾，进行删除操作的端称为队头。</p><p>在队列中插入一个队列元素称为入队，从队列中删除一个队列元素称为出队。因为队列只允许在一端插入，在另一端删除，所以只有最早进入队列的元素才能最先从队列中删除，故队列又称为先进先出（FIFO—first in first out）线性表。</p><h3 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h3><table><thead><tr><th>方法/处理方式</th><th>抛出异常</th><th>返回特殊值</th><th>一直阻塞</th><th>超时退出</th></tr></thead><tbody><tr><td><strong>插入方法</strong></td><td>add(e)</td><td>offer(e)</td><td>put(e)</td><td>offer(e,time,unit)</td></tr><tr><td><strong>移除方法</strong></td><td>remove()</td><td>poll()</td><td>take()</td><td>poll(time, unit)</td></tr><tr><td><strong>检查方法</strong></td><td>element()</td><td>peek()</td><td>不可用</td><td>不可用</td></tr></tbody></table><ul><li><p>支持阻塞的插入方法：当队列满时，队列会阻塞插入元素的线程直到队列不满。</p></li><li><p>支持阻塞的移除方法：在队列为空时，获取元素的线程会被阻塞直到队列变为非空。</p></li><li><p>抛出异常：当队列满时，如果再往队列里插入元素，会抛出IllegalStateException（”Queuefull”）异常。当队列空时，从队列里获取元素会抛出NoSuchElementException异常。</p></li><li><p>返回特殊值：当往队列插入元素时，会返回元素是否插入成功，成功返回true。如果是移除方法，则是从队列里取出一个元素，如果没有则返回null。</p></li><li><p>一直阻塞：当阻塞队列满时，如果线程往队列里put元素，队列会一直阻塞线程，直到队列可用或者响应中断退出。当队列空时，如果线程从队列里take元素，队列会阻塞住消费者线程，直到队列不为空。</p></li><li><p>超时退出：当阻塞队列满时，如果线程往队列里插入元素，队列会阻塞生产者线程一段时间，如果超过了指定的时间，线程就会退出。</p></li></ul><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线程的工作能力来提高程序整体处理数据的速度。</p><p>在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。</p><p>为了解决这种生产消费能力不均衡的问题，便有了生产者和消费者模式。生产者和消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通信，而是通过阻塞队列来进行通信，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。</p><p>阻塞队列常用于生产者和消费者的场景，生产者是向队列里添加元素的线程，消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器。</p><h3 id="有界无界"><a href="#有界无界" class="headerlink" title="有界无界"></a>有界无界</h3><p>有限队列就是长度有限，满了以后生产者会阻塞，无界队列就是里面能放无数的东西而不会因为队列长度限制被阻塞，当然空间限制来源于系统资源的限制，如果处理不及时，导致队列越来越大越来越大，超出一定的限制致使内存超限，操作系统或者JVM帮你解决烦恼，直接把你 OOM kill 省事了。</p><h3 id="阻塞队列的实现原理"><a href="#阻塞队列的实现原理" class="headerlink" title="阻塞队列的实现原理"></a>阻塞队列的实现原理</h3><p>使用了等待通知模式实现。所谓通知模式，就是当生产者往满的队列里添加元素时会阻塞住生产者，当消费者消费了一个队列中的元素后，会通知生产者当前队列可用。通过查看JDK源码发现ArrayBlockingQueue使用了Condition来实现。其余队列的实现，大家可以自行查看，队列的实现的代码总体来说，并不复杂。</p><h3 id="常用阻塞队列"><a href="#常用阻塞队列" class="headerlink" title="常用阻塞队列"></a>常用阻塞队列</h3><ul><li><p>ArrayBlockingQueue：是一个用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下不保证线程公平的访问队列，所谓公平访问队列是指阻塞的线程，可以按照阻塞的先后顺序访问队列，即先阻塞线程先访问队列。非公平性是对先等待的线程是非公平的，当队列可用时，阻塞的线程都可以争夺访问队列的资格，有可能先阻塞的线程最后才访问队列。初始化时有参数可以设置</p></li><li><p>LinkedBlockingQueue：是一个用链表实现的有界阻塞队列。此队列的默认和最大长度为Integer.MAX_VALUE，按照先进先出的原则对元素进行排序。和ArrayBlockingQueue实现的区别：</p><ol><li><p>队列中锁的实现不同ArrayBlockingQueue实现的队列中的锁是没有分离的，即生产和消费用的是同一个锁；LinkedBlockingQueue实现的队列中的锁是分离的，即生产用的是putLock，消费是takeLock。</p></li><li><p>在生产或消费时操作不同：ArrayBlockingQueue实现的队列中在生产和消费的时候，是直接将枚举对象插入或移除的；LinkedBlockingQueue实现的队列中在生产和消费的时候，需要把枚举对象转换为Node<E>进行插入或移除，会影响性能。</p></li><li><p>队列大小初始化方式不同：ArrayBlockingQueue实现的队列中必须指定队列的大小LinkedBlockingQueue实现的队列中可以不指定队列的大小，但是默认是Integer.MAX_VALUE（20来个亿）一般的服务器是扛不住的，所以在使用LinkedBlockingQueue时还是尽量指定大小。</p></li></ol></li><li><p>PriorityBlockingQueue：是一个支持优先级的无界阻塞队列。默认情况下元素采取自然顺序升序排列。也可以自定义类实现compareTo()方法来指定元素排序规则，或者初始化PriorityBlockingQueue时，指定构造参数Comparator来对元素进行排序。需要注意的是不能保证同优先级元素的顺序。</p></li><li><p>DelayQueue：是一个支持延时获取元素的无界阻塞队列。队列使用PriorityQueue来实现。队列中的元素必须实现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。DelayQueue非常有用，可以将DelayQueue运用在以下应用场景。缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。还有订单到期，限时支付等等</p></li><li><p>SynchronousQueue：是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。SynchronousQueue可以看成是一个传球手，负责把生产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常适合传递性场景。SynchronousQueue的吞吐量高于LinkedBlockingQueue和ArrayBlockingQueue。</p></li><li><p>LinkedTransferQueue：一个由链表结构组成的无界阻塞队列，多了tryTransfer和transfer方法。如果当前有消费者正在等待接收元素（消费者使用take()方法或带时间限制的poll()方法时），transfer方法可以把生产者传入的元素立刻transfer（传输）给消费者。如果没有消费者在等待接收元素，transfer方法会将元素存放在队列的tail节点，并等到该元素被消费者消费了才返回。tryTransfer方法是用来试探生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回false。和transfer方法的区别是tryTransfer方法无论消费者是否接收，方法立即返回，而transfer方法是必须等到消费者消费了才返回。</p></li><li><p>LinkedBlockingDeque：是一个由链表结构组成的双向阻塞队列。所谓双向队列指的是可以从队列的两端插入和移出元素。双向队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。多了addFirst、addLast、offerFirst、offerLast、peekFirst和peekLast等方法，以First单词结尾的方法，表示插入、获取（peek）或移除双端队列的第一个元素。以Last单词结尾的方法，表示插入、获取或移除双端队列的最后一个元素。另外，插入方法add等同于addLast，移除方法remove等效于removeFirst。但是take方法却等同于takeFirst，不知道是不是JDK的bug，使用时还是用带有First和Last后缀的方法更清楚。在初始化LinkedBlockingDeque时可以设置容量防止其过度膨胀。另外，双向阻塞队列可以运用在“工作窃取”模式中。</p></li></ul><h2 id="ConcurrentLinkedQueue"><a href="#ConcurrentLinkedQueue" class="headerlink" title="ConcurrentLinkedQueue"></a>ConcurrentLinkedQueue</h2><p>ConcurrentLinkedQueue是一个无界非阻塞队列，它是基于链表的无界线程安全队列。该队列的元素遵循先进先出的原则。头是最先加入的，尾是最近加入的。插入元素是追加到尾上，提取一个元素是从头提取。</p><p>可以看成是LinkedList的并发版本，常用方法：</p><ul><li><p>add(e):插入指定元素</p></li><li><p>offer(e):将指定元素插入到此队列的尾部。  </p></li><li><p>peek():检索此队列的头但并不移除，如果此队列为空，则返回 null。  </p></li><li><p>poll(): 检索并移除此队列的头，如果此队列为空，则返回 null。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>显式锁和AQS</title>
    <link href="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/"/>
    <url>/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/</url>
    
    <content type="html"><![CDATA[<h2 id="显式锁"><a href="#显式锁" class="headerlink" title="显式锁"></a>显式锁</h2><p>Java程序是靠synchronized关键字实现锁功能的，synchronized关键字将会隐式地获取和释放锁，而且获取和释放锁的过程是固化的，也被称为内置锁。Lock是手动的获取和释放锁，这就是显式锁名称的由来。</p><h3 id="Lock接口和synchronized的比较"><a href="#Lock接口和synchronized的比较" class="headerlink" title="Lock接口和synchronized的比较"></a>Lock接口和synchronized的比较</h3><p>synchronized获取锁时会一直等待直到获取锁为止。Lock提供lockInterruptibly()方法可以在等待获取到锁的过程中能够响应中断，tryLock()方法尝试获取锁时如果失败会返回false，然后线程可以做其他的事，之后再进行tryLock()，tryLock()方法还可以接收long类型及TimeUnit类型的参数超时的获取锁。</p><p>如果尝试取锁及中断取锁尽量使用synchronized关键字，在目前的发展趋势jdk一直在对synchronized进行优化，synchronized的开销要比Lock接口更少。</p><h3 id="Lock的标准用法"><a href="#Lock的标准用法" class="headerlink" title="Lock的标准用法"></a>Lock的标准用法</h3><pre><code>lock.lock()try{    count++;}finally{    lock.unlock();}</code></pre><p>在finally块中释放锁，目的是保证在获取到锁之后，最终能够被释放。</p><p>不能将获取锁的过程写在try块中，如果在获取锁（自定义锁的实现）时发生了异常，异常抛出的同时会导致锁的无故释放。</p><h3 id="可重入锁ReentrantLock、锁的公平和非公平"><a href="#可重入锁ReentrantLock、锁的公平和非公平" class="headerlink" title="可重入锁ReentrantLock、锁的公平和非公平"></a>可重入锁ReentrantLock、锁的公平和非公平</h3><h4 id="可重入"><a href="#可重入" class="headerlink" title="可重入"></a>可重入</h4><p>同一个线程对于已经获得到的锁，可以多次继续申请到该锁的使用权。synchronized关键字也支持隐式的支持重进入，比如一个synchronized修饰的递归方法，在方法执行时，执行线程在获取了锁之后仍能连续多次地获得该锁。ReentrantLock在调用lock()方法时，如果当前线程已经获取到锁就能够再次调用lock()方法获取锁而不被阻塞。</p><h4 id="公平和非公平"><a href="#公平和非公平" class="headerlink" title="公平和非公平"></a>公平和非公平</h4><p>如果在时间上，先对锁进行获取的线程即等待时间最长的线程一定先获取到锁，那么这个锁是公平的，也可以说锁获取是顺序的，反之就是不公平的。 ReentrantLock提供了一个构造函数，能够控制锁是否是公平的，synchronized也是非公平锁。事实上，公平的锁机制往往没有非公平的效率高。  </p><p>线程被唤醒的上下文切换时间周期在5000-10000之间，在激烈竞争的情况下，非公平锁的性能高于公平锁的性能的一个原因是：在恢复一个被挂起的线程与该线程真正开始运行之间存在着严重的延迟。假设线程A持有一个锁，并且线程B请求这个锁。由于这个锁已被线程A持有，因此B将被挂起。当A释放锁时，B将被唤醒，B完全唤醒后会再次尝试获取锁。与此同时，如果C也请求这个锁，那么C很可能会在B被完全唤醒之前获得、使用以及释放这个锁。这样的情况是一种“双赢”的局面：B获得锁的时刻并没有推迟，C更早地获得了锁，并且吞吐量也获得了提高。</p><h3 id="读写锁ReentrantReadWriteLock"><a href="#读写锁ReentrantReadWriteLock" class="headerlink" title="读写锁ReentrantReadWriteLock"></a>读写锁ReentrantReadWriteLock</h3><p>之前提到锁（如synchronized和ReentrantLock）基本都是排他锁即独占锁，这些锁在同一时刻只允许一个线程进行访问，而读写锁在同一时刻可以允许多个读线程访问，但是在写线程访问时，所有的读线程和其他写线程均被阻塞。读写锁维护了一对锁，一个读锁和一个写锁，通过分离读锁和写锁，使得并发性相比一般的排他锁有了很大提升。写锁为独占锁，读锁为共享锁，但读写之前相互排斥。</p><p>除了保证写操作对读操作的可见性以及并发性的提升之外，读写锁能够简化读写交互场景的编程方式。假设在程序中定义一个共享的用作缓存数据结构，它大部分时间提供读服务（例如查询和搜索），而写操作占有的时间很少，但是写操作完成之后的更新需要对后续的读服务可见。</p><p>ReentrantReadWriteLock实现的为ReadAndWriteLock接口，ReadAndWriteLock接口提供了readLock()方法获取读锁，writeLock()方法获取写锁。在没有读写锁支持的（Java 5之前）时候，如果需要完成上述工作就要使用Java的等待通知机制，就是当写操作开始时，所有晚于写操作的读操作均会进入等待状态，只有写操作完成并进行通知之后，所有等待的读操作才能继续执行（写操作之间依靠synchronized关键进行同步），这样做的目的是使读操作能读取到正确的数据，不会出现脏读。改用读写锁实现上述功能，只需要在读操作时获取读锁，写操作时获取写锁即可。当写锁被获取到时，后续（非当前写操作线程）的读写操作都会被阻塞，写锁释放之后，所有操作继续执行，编程方式相对于使用等待通知机制的实现方式而言，变得简单明了。 </p><p>一般情况下，读写锁的性能都会比排它锁好，因为大多数场景读是多于写的，读写的比例约为10:1。在读多于写的情况下，读写锁能够提供比排它锁更好的并发性和吞吐量。</p><h3 id="Condition接口"><a href="#Condition接口" class="headerlink" title="Condition接口"></a>Condition接口</h3><p>任意一个Java对象，都拥有一组监视器方法（定义在java.lang.Object上），主要包括wait()、wait(long timeout)、notify()以及notifyAll()方法，这些方法与synchronized同步关键字配合，可以实现等待/通知模式。Condition接口也提供了类似Object的监视器方法await()，signal()，与Lock配合可以实现等待/通知模式。</p><h3 id="用Lock和Condition实现等待通知"><a href="#用Lock和Condition实现等待通知" class="headerlink" title="用Lock和Condition实现等待通知"></a>用Lock和Condition实现等待通知</h3><pre><code>/** * 类说明： */public class ExpressCond {    public final static String CITY = &quot;ShangHai&quot;;    /**     * 快递运输里程数     */    private int km;    /**     * 快递到达地点     */    private String site;    private Lock kmLock = new ReentrantLock();    private Lock siteLock = new ReentrantLock();    private Condition kmCondition = kmLock.newCondition();    private Condition siteCondition = siteLock.newCondition();    public ExpressCond(int km, String site) {        this.km = km;        this.site = site;    }    /**     * 变化公里数，然后通知处于wait状态并需要处理公里数的线程进行业务处理     */    public void changeKm() {        kmLock.lock();        try {            this.km = 101;            kmCondition.signal();        } finally {            kmLock.unlock();        }    }    /**     * 变化地点，然后通知处于wait状态并需要处理地点的线程进行业务处理     */    public void changeSite() {        siteLock.lock();        try {            this.site = &quot;BeiJing&quot;;            siteCondition.signal();        } finally {            siteLock.unlock();        }    }    /**     * 当快递的里程数大于100时更新数据库     */    public void waitKm() {        kmLock.lock();        try {            while (this.km &lt; 100) {                try {                    kmCondition.await();                    System.out.println(&quot;check Site thread[&quot; + Thread.currentThread().getId()                            + &quot;] is be notified&quot;);                } catch (InterruptedException e) {                    e.printStackTrace();                }            }        } finally {            kmLock.unlock();        }        System.out.println(&quot;the Km is &quot; + this.km + &quot;,I will change db&quot;);    }    /**     * 当快递到达目的地时通知用户     */    public void waitSite() {        siteLock.lock();        try {            while (this.site.equals(CITY)) {                try {                    siteCondition.await();//当前线程进行等待                    System.out.println(&quot;check Site thread[&quot; + Thread.currentThread().getName()                            + &quot;] is be notify&quot;);                } catch (InterruptedException e) {                    e.printStackTrace();                }            }        } finally {            siteLock.unlock();        }        System.out.println(&quot;the site is &quot; + this.site + &quot;,I will call user&quot;);    }    private static ExpressCond express = new ExpressCond(0, ExpressCond.CITY);    /**     * 检查里程数变化的线程,不满足条件，线程一直等待     */    private static class CheckKm extends Thread {        @Override        public void run() {            express.waitKm();        }    }    /**     * 检查地点变化的线程,不满足条件，线程一直等待     */    private static class CheckSite extends Thread {        @Override        public void run() {            express.waitSite();        }    }    public static void main(String[] args) throws InterruptedException {        for (int i = 0; i &lt; 3; i++) {            new ExpressCond.CheckSite().start();        }        for (int i = 0; i &lt; 3; i++) {            new ExpressCond.CheckKm().start();        }        Thread.sleep(1000);        express.changeKm();//快递里程变化    }}    </code></pre><h2 id="了解LockSupport工具"><a href="#了解LockSupport工具" class="headerlink" title="了解LockSupport工具"></a>了解LockSupport工具</h2><p>LockSupport定义了一组的公共静态方法，这些方法提供了最基本的线程阻塞和唤醒功能，而LockSupport也成为构建同步组件的基础工具。</p><p>LockSupport定义了一组以park开头的方法用来阻塞当前线程，以及unpark(Thread thread)方法来唤醒一个被阻塞的线程。在JDK1.6之后LockSupport增加了park(Object blocker)、parkNanos(Object blocker,long nanos)和parkUntil(Object blocker,long deadline)3个方法，便于问题排查和系统监控，其中参数blocker是用来标识当前线程在等待的对象即被阻塞对象。</p><h2 id="CLH队列锁"><a href="#CLH队列锁" class="headerlink" title="CLH队列锁"></a>CLH队列锁</h2><p>CLH队列锁即Craig, Landin, and Hagersten (CLH) locks。</p><p>CLH队列锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程仅仅在本地变量上自旋，它不断轮询前驱的状态，假设发现前驱释放了锁就结束自旋。</p><p>当一个线程需要获取锁时会创建一个的QNode，将其中的locked设置为true表示需要获取锁，myPred表示对其前驱结点的引用</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic1.png" srcset="/img/loading.gif" class=""><p>线程A对tail域调用getAndSet方法，使自己成为队列的尾部，同时获取一个指向其前驱结点的引用myPred</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic2.png" srcset="/img/loading.gif" class=""><p>线程B需要获得锁，同样的流程再来一遍</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic3.png" srcset="/img/loading.gif" class=""><p>线程就在前驱结点的locked字段上旋转，直到前驱结点释放锁(前驱节点的锁值 locked == false)</p><p>当一个线程需要释放锁时，将当前结点的locked域设置为false，同时回收前驱结点</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic4.png" srcset="/img/loading.gif" class=""><p>如上图所示，前驱结点释放锁，线程A的myPred所指向的前驱结点的locked字段变为false，线程A就可以获取到锁。</p><p>CLH队列锁的优点是空间复杂度低（如果有n个线程，L个锁，每个线程每次只获取一个锁，那么需要的存储空间是O（L+n），n个线程有n个myNode，L个锁有L个tail）。CLH队列锁常用在SMP体系结构下。</p><p>Java中的AQS是CLH队列锁的一种变体实现。</p><p><strong>扩展知识点</strong></p><p>SMP(Symmetric Multi-Processor)。即对称多处理器结构，指server中多个CPU对称工作，每一个CPU访问内存地址所需时间同样。其主要特征是共享，包括对CPU，内存，I/O等进行共享。SMP的长处是可以保证内存一致性。缺点是这些共享的资源非常可能成为性能瓶颈。随着CPU数量的添加，每一个CPU都要访问同样的内存资源，可能导致内存访问冲突，可能会导致CPU资源的浪费。经常使用的PC机就属于这样的。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic5.png" srcset="/img/loading.gif" class=""><p>非一致存储访问，将CPU分为CPU模块，每个CPU模块由多个<em>CPU*组成，并且具有独立的本地内存、I/O槽口等，模块之间可以通过互联模块相互访问，访问本地内存（本CPU模块的内存）的速度将远远高于访问远地内存</em>(<em>其他CPU模块的内存</em>)*的速度，这也是非一致存储访问的由来。NUMA较好地解决SMP的扩展问题，当CPU数量增加时，因为访问远地内存的延时远远超过本地内存，系统性能无法线性增加。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic6.png" srcset="/img/loading.gif" class=""><p>CLH唯一的缺点是在NUMA系统结构下性能很差，但是在SMP系统结构下该法还是非常有效的。解决NUMA系统结构的思路是MCS队列锁。</p><h2 id="AbstractQueuedSynchronizer深入分析"><a href="#AbstractQueuedSynchronizer深入分析" class="headerlink" title="AbstractQueuedSynchronizer深入分析"></a>AbstractQueuedSynchronizer深入分析</h2><h3 id="学习AQS的必要性"><a href="#学习AQS的必要性" class="headerlink" title="学习AQS的必要性"></a>学习AQS的必要性</h3><p>队列同步器AbstractQueuedSynchronizer（以下简称同步器或AQS），是用来构建锁或者其他同步组件的基础框架，它使用了一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作。并发包的大师（Doug Lea）期望它能够成为实现大部分同步需求的基础。</p><h3 id="AQS使用方式和其中的设计模式"><a href="#AQS使用方式和其中的设计模式" class="headerlink" title="AQS使用方式和其中的设计模式"></a>AQS使用方式和其中的设计模式</h3><p>AQS的主要使用方式是继承，子类通过继承AQS并实现它的抽象方法来管理同步状态，在AQS里由一个int型的state来代表这个状态，在抽象方法的实现过程中免不了要对同步状态进行更改，这时就需要使用同步器提供的3个方法（getState()、setState(int newState)和compareAndSetState(int expect,int update)）来进行操作，因为它们能够保证状态的改变是安全的。</p><p>AQS自身没有实现任何同步接口，它仅仅是定义了若干同步状态获取和释放的方法来供自定义同步组件使用，同步器既可以支持独占式地获取同步状态，也可以支持共享式地获取同步状态，这样就可以方便实现不同类型的同步组件（ReentrantLock、ReentrantReadWriteLock和CountDownLatch等）。</p><p>同步器是实现锁（也可以是任意同步组件）的关键，在锁的实现中聚合同步器。可以这样理解二者之间的关系：锁是面向使用者的，它定义了使用者与锁交互的接口（比如可以允许两个线程并行访问），隐藏了实现细节；同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作。锁和同步器很好地隔离了使用者和实现者所需关注的领域。</p><p>实现者需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法。</p><h3 id="模板方法模式"><a href="#模板方法模式" class="headerlink" title="模板方法模式"></a>模板方法模式</h3><p>同步器的设计基于模板方法模式。模板方法模式的意图是，定义一个操作中的算法的骨架，而将一些步骤的实现延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。我们最常见的就是Spring框架里的各种Template。</p><p>实际例子</p><p>假设蛋糕店中奶油蛋糕，芝士蛋糕和慕斯蛋糕。这三种蛋糕在制作方式上一样，都包括造型，烘焙和涂抹蛋糕上的东西。所以可以定义一个抽象蛋糕模型</p><pre><code>/** * 类说明：抽象蛋糕模型 */public abstract class AbstractCake {    protected abstract void shape();    protected abstract void apply();    protected abstract void brake();    /*模板方法*/    public final void run(){        this.shape();        this.apply();        this.brake();    }    protected boolean shouldApply(){        return true;    }}</code></pre><p>然后就可以批量生产三种蛋糕</p><pre><code>/** * 类说明：芝士蛋糕 */public class CheeseCake  extends AbstractCake {    @Override    protected void shape() {        System.out.println(&quot;芝士蛋糕造型&quot;);    }    @Override    protected void apply() {        System.out.println(&quot;芝士蛋糕涂抹&quot;);    }    @Override    protected void brake() {        System.out.println(&quot;芝士蛋糕烘焙&quot;);    }}</code></pre><p>这样一来，不但可以批量生产三种蛋糕，而且如果日后有扩展，只需要继承抽象蛋糕方法就可以了，突然有一天，我们发现市面有一种最简单的小蛋糕销量很好，这种蛋糕就是简单烘烤成型就可以卖，并不需要涂抹什么食材，于是我们也想要生产这种蛋糕。但是我们发现了一个问题，抽象蛋糕是定义了抽象的涂抹方法的，也就是说扩展的这种蛋糕是必须要实现涂抹方法，这时可以将原来的模板修改为带钩子的模板。</p><pre><code>/** * 类说明：抽象蛋糕模型 */public abstract class AbstractCake {    protected abstract void shape();    protected abstract void apply();    protected abstract void brake();    /*模板方法*/    public final void run() {        this.shape();        if (shouldApply()) {            this.apply();        }        this.brake();    }    protected boolean shouldApply(){        return true;    }}</code></pre><p>做小蛋糕的时候通过flag来控制是否涂抹，其余已有的蛋糕制作不需要任何修改可以照常进行。</p><pre><code>/** * 类说明：小蛋糕 */public class SmallCake extends AbstractCake {    private boolean flag = false;    public void setFlag(boolean shouldApply){        flag = shouldApply;    }    @Override    protected boolean shouldApply() {        return this.flag;    }    @Override    protected void shape() {        System.out.println(&quot;小蛋糕造型&quot;);    }    @Override    protected void apply() {        System.out.println(&quot;小蛋糕涂抹&quot;);    }    @Override    protected void brake() {        System.out.println(&quot;小蛋糕烘焙&quot;);    }}</code></pre><h3 id="AQS中的方法"><a href="#AQS中的方法" class="headerlink" title="AQS中的方法"></a>AQS中的方法</h3><h4 id="模板方法"><a href="#模板方法" class="headerlink" title="模板方法"></a>模板方法</h4><p>实现自定义同步组件时，将会调用同步器提供的模板方法，</p><table><thead><tr><th align="center">方法名称</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">void acquire(int arg)</td><td align="center">独占式获取同步状态，如果当前线程获取同步状态成功，则由该方法返回，否则，将会进人同步队列等待，该方法将会调用重写的tryAcquire(int  arg)方法</td></tr><tr><td align="center">void acquireInterruptibly(int arg)</td><td align="center">与acquire(int arg)相同，但是该方法响应中断，当前线程未获取到同步状态而进入同步队列中，如果当前线程被中断，则该方法会抛出InterruptedException并返回</td></tr><tr><td align="center">boolean tryAcquireNanos(int arg,long nanos)</td><td align="center">在acquireInterruptibly(int arg)基础上增加了超时限制，如果当前线程在超时时间内没有获取到同步状态，那么将会返回false.如果获取到了返回true</td></tr><tr><td align="center">void acquireShared(int arg)</td><td align="center">共享式的获取同步状态，如果当前线程未获取到同步状态,将会进人同步队列等待，与独占式获取的主要区别是在同一时刻可以有多个线程获取到同步状态</td></tr><tr><td align="center">void acquireSharedInteruptibly(int arg)</td><td align="center">与acquireShared(int arg)相同，该方法响应中断</td></tr><tr><td align="center">boolean tryAcquireSharedNanos(int arg, long nanos)</td><td align="center">在acquireSharedInterruptibly(int arg)基础上增加了超时限制</td></tr><tr><td align="center">boolean release(int arg)</td><td align="center">独占式的释放同步状态，该方法会在释放同步状态之后，将同步队列中第一个节点包含的线程唤醒</td></tr><tr><td align="center">boolean releaseShared(int arg)</td><td align="center">共享式的释放同步状态</td></tr><tr><td align="center">Collection&lt; Thread&gt; getQueuedThreads()</td><td align="center">获取等待在同步队列上的线程集合</td></tr></tbody></table><p>这些模板方法同步器提供的模板方法基本上分为3类：独占式获取与释放同步状态、共享式获取与释放、同步状态和查询同步队列中的等待线程情况。</p><h4 id="可重写的方法"><a href="#可重写的方法" class="headerlink" title="可重写的方法"></a>可重写的方法</h4><table><thead><tr><th align="center">方法名称</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">protected boolean tryAcquire(int arg)</td><td align="center">独占式获取同步状态，实现该方法需要查询当前状态并判断同步状态是否符合预期，然后再进行CAS设置同步状态</td></tr><tr><td align="center">protected boolean tryRelease(int arg)</td><td align="center">独占式释放同步状态，等待获取同步状态的线程将有机会获取同步状态</td></tr><tr><td align="center">protected int tryAcquireShared(int arg)</td><td align="center">共享式获取同步状态，返回大于等于0的值，表示获取成功，反之，获取失败</td></tr><tr><td align="center">protected boolean tryReleaseShared(int arg)</td><td align="center">共享式释放同步状态</td></tr><tr><td align="center">protected boolean isHeldExclusively()</td><td align="center">当前同步器是否在独占模式下被线程占用，一般该方法表示是否被当前线程所独占</td></tr></tbody></table><h4 id="访问或修改同步状态的方法"><a href="#访问或修改同步状态的方法" class="headerlink" title="访问或修改同步状态的方法"></a>访问或修改同步状态的方法</h4><p>重写同步器指定的方法时，需要使用同步器提供的如下3个方法来访问或修改同步状态。</p><ul><li><p>getState()：获取当前同步状态。</p></li><li><p>setState(int newState)：设置当前同步状态。</p></li><li><p>compareAndSetState(int expect,int update)：使用CAS设置当前状态，该方法能够保证状态设置的原子性。 </p></li></ul><h3 id="实现一个自己的独占锁"><a href="#实现一个自己的独占锁" class="headerlink" title="实现一个自己的独占锁"></a>实现一个自己的独占锁</h3><pre><code>public class SelfLock implements Lock {    /**     * 静态内部类，自定义同步器     */    private static class Sync extends AbstractQueuedSynchronizer {        //private static final long serialVersionUID = -4387327721959839431L;        /**         * 是否处于占用状态         */        @Override        protected boolean isHeldExclusively() {            return getState() == 1;        }        /**         * 获得锁         */        @Override        protected boolean tryAcquire(int arg) {            if (compareAndSetState(0, 1)) {                setExclusiveOwnerThread(Thread.currentThread());                return true;            }            return false;        }        /**         * 释放锁         */        @Override        protected boolean tryRelease(int arg) {            if (getState() == 0) {                throw new IllegalMonitorStateException();            }            setExclusiveOwnerThread(null);            setState(0);            return true;        }        /**         * 返回一个Condition，每个condition都包含了一个condition队列         */        Condition newCondition() {            return new ConditionObject();        }    }    /**     * 仅需要将操作代理到Sync上即可     */    private final Sync sync = new Sync();    @Override    public void lock() {        System.out.println(Thread.currentThread().getName() + &quot; ready get lock&quot;);        sync.acquire(1);        System.out.println(Thread.currentThread().getName() + &quot; already got lock&quot;);    }    @Override    public boolean tryLock() {        return sync.tryAcquire(1);    }    @Override    public void unlock() {        System.out.println(Thread.currentThread().getName() + &quot; ready release lock&quot;);        sync.release(1);        System.out.println(Thread.currentThread().getName() + &quot; already released lock&quot;);    }    @Override    public Condition newCondition() {        return sync.newCondition();    }    public boolean isLocked() {        return sync.isHeldExclusively();    }    public boolean hasQueuedThreads() {        return sync.hasQueuedThreads();    }    @Override    public void lockInterruptibly() throws InterruptedException {        sync.acquireInterruptibly(1);    }    @Override    public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {        return sync.tryAcquireNanos(1, unit.toNanos(timeout));    }}</code></pre><p><strong>测试类</strong></p><pre><code>public class TestMyLock {    public void test() {        final Lock lock = new SelfLock();        class Worker extends Thread {         @Override            public void run() {                lock.lock();                System.out.println(Thread.currentThread().getName());                try {                    SleepTools.second(1);                } finally {                    lock.unlock();                }            }        }        // 启动4个子线程        for (int i = 0; i &lt; 4; i++) {            Worker w = new Worker();            //w.setDaemon(true);            w.start();        }        // 主线程每隔1秒换行        for (int i = 0; i &lt; 10; i++) {           SleepTools.second(1);            //System.out.println();        }    }    public static void main(String[] args) {        TestMyLock testMyLock = new TestMyLock();        testMyLock.test();    }}</code></pre><h3 id="AQS中的数据结构节点和同步队列"><a href="#AQS中的数据结构节点和同步队列" class="headerlink" title="AQS中的数据结构节点和同步队列"></a>AQS中的数据结构节点和同步队列</h3><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic8.png" srcset="/img/loading.gif" class=""><h4 id="节点Node"><a href="#节点Node" class="headerlink" title="节点Node"></a>节点Node</h4><p>既然说Java中的AQS是CLH队列锁的一种变体实现，毫无疑问，作为队列来说，必然要有一个节点的数据结构来保存我们前面所说的各种域，比如前驱节点，节点的状态等，这个数据结构就是AQS中的内部类Node。作为这个数据结构应该保存的信息：</p><ol><li>前驱和后继线程，因为是一个等待队列，那么也就需要知道当前线程前面的是哪个线程，当前线程后面的是哪个线程（因为当前线程释放锁以后，理当立马通知后继线程去获取锁）。</li><li>线程信息</li><li>队列中线程状态，是取消了“获锁”请求，还是在“”等待中”，或者说“即将得到锁”</li></ol><h4 id="Node类的设计"><a href="#Node类的设计" class="headerlink" title="Node类的设计"></a>Node类的设计</h4><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic7.png" srcset="/img/loading.gif" class=""><p>线程的2种等待模式：</p><ul><li><p>SHARED：表示线程以共享的模式等待锁（如ReadLock）</p></li><li><p>EXCLUSIVE：表示线程以互斥的模式等待锁（如ReetrantLock）</p></li></ul><p>线程在队列中的状态枚举：</p><ul><li><p>CANCELLED：值为1，表示线程已经取消获取锁的请求</p></li><li><p>SIGNAL：值为-1，表示该线程已经准备就绪，等待获取锁</p></li><li><p>CONDITION：值为-2，表示线程等待某一个条件（Condition）被满足</p></li><li><p>PROPAGATE：值为-3，表示下一个的acquireShared值应该被无条件的传播下去，在线程处于SHARED模式时才会被用到。</p></li></ul><p>成员变量：</p><ul><li><p>waitStatus：该int变量表示线程在队列中的状态，其值就是上述提到的CANCELLED、SIGNAL、CONDITION、PROPAGATE</p></li><li><p>prev：该变量类型为Node对象，表示该节点的前一个Node节点（前驱）</p></li><li><p>next：该变量类型为Node对象，表示该节点的后一个Node节点（后继）</p></li><li><p>thread：该变量类型为Thread对象，表示该节点的代表的线程</p></li><li><p>nextWaiter：该变量类型为Node对象，表示等待condition条件的Node节点</p></li></ul><p>当前线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成为一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒，使其再次尝试获取同步状态。同步队列中的节点（Node）用来保存获取同步状态失败的线程引用、等待状态以及前驱和后继节点。</p><h4 id="head和tail"><a href="#head和tail" class="headerlink" title="head和tail"></a>head和tail</h4><p>AQS还拥有首节点（head）和尾节点（tail）两个引用，一个指向队列头节点，而另一个指向队列尾节点。</p><p>注意 ：因为首节点<em>head</em>是不保存线程信息的节点，仅仅是因为数据结构设计上的需要，在数据结构上，这种做法往往叫做“空头节点链表”，对应的就有“非空头结点链表”。</p><h4 id="节点在同步队列中的增加和移出"><a href="#节点在同步队列中的增加和移出" class="headerlink" title="节点在同步队列中的增加和移出"></a>节点在同步队列中的增加和移出</h4><h5 id="节点加入到同步队列"><a href="#节点加入到同步队列" class="headerlink" title="节点加入到同步队列"></a>节点加入到同步队列</h5><p>当一个线程成功地获取了同步状态（或者锁），其他线程将无法获取到同步状态，也就是获取同步状态失败，AQS会通过addWaiter()方法将这个线程以及等待状态等信息构造成为一个节点（Node）并将其加入同步队列的尾部。而这个加入队列的过程必须要保证线程安全，因此同步器提供了一个基于CAS的设置尾节点的方法：compareAndSetTail(Node expect,Nodeupdate)，AQS它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic9.png" srcset="/img/loading.gif" class=""><h5 id="首节点的变化"><a href="#首节点的变化" class="headerlink" title="首节点的变化"></a>首节点的变化</h5><p>首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点。设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节点的方法并不需要使用CAS来保证，它只需要将首节点设置成为原首节点的后继节点并断开原首节点的next引用即可。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic10.png" srcset="/img/loading.gif" class=""><h5 id="独占式同步状态获取与释放"><a href="#独占式同步状态获取与释放" class="headerlink" title="独占式同步状态获取与释放"></a>独占式同步状态获取与释放</h5><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic11.png" srcset="/img/loading.gif" class=""><h6 id="获取"><a href="#获取" class="headerlink" title="获取"></a>获取</h6><p>通过调用同步器的acquire(int arg)方法可以获取同步状态，主要完成了同步状态获取、节点构造、加入同步队列以及在同步队列中自旋等待的相关工作，其主要逻辑是：</p><p>首先调用自定义同步器实现的tryAcquire(int arg)方法，该方法需要保证线程安全的获取同步状态。</p><p>如果同步状态获取失败（tryAcquire返回false），则构造同步节点（独占式Node.EXCLUSIVE，同一时刻只能有一个线程成功获取同步状态）并通过addWaiter(Node node)方法将该节点加入到同步队列的尾部，在addWaiter()方法中会尝试通过compareAndSetTail()方法设置首尾节点关系，如果设置不成功才会进入enq()方法循环尝试设置节点关系。</p><p>最后调用acquireQueued(Node node,int arg)方法，使得该节点以“死循环”的方式获取同步状态。如果获取不到则阻塞节点中的线程，而被阻塞线程的唤醒主要依靠前驱节点的出队或阻塞线程被中断来实现。</p><p>addWaiter(Node node)方法中</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic12.png" srcset="/img/loading.gif" class=""><p>将当前线程包装成Node后，队列不为空的情况下，先尝试把当前节点加入队列并成为尾节点，如果不成功或者队列为空进入enq(final Node node)方法。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic13.png" srcset="/img/loading.gif" class=""><p>在enq(final Node node)方法中，同步器通过“死循环”来保证节点的正确添加，这个死循环中，做了两件事，第一件，如果队列为空，初始化队列，new出一个空节点，并让<strong>首节点</strong>（head）和<strong>尾节点</strong>（tail）两个引用都指向这个空节点；第二件事，把当前节点加入队列。</p><p>在“死循环”中只有通过CAS将节点设置成为尾节点之后，当前线程才能从该方法返回，否则，当前线程不断地尝试设置。</p><p>节点进入同步队列之后，观察acquireQueued(Node node,int arg)方法</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic14.png" srcset="/img/loading.gif" class=""><p>其实就是一个自旋的过程，每个节点（或者说每个线程）都在自省地观察，当条件满足，获取到了同步状态，就可以从这个自旋过程中退出，否则依旧留在这个自旋过程中（并会阻塞节点的线程）。</p><p>在acquireQueued(final Node node,int arg)方法中，当前线程在“死循环”中尝试获取同步状态，而只有前驱节点是头节点才能够尝试获取同步状态，这是为什么？原因有两个。</p><p>第一，头节点是成功获取到同步状态的节点，而头节点的线程释放了同步状态之后，将会唤醒其后继节点，后继节点的线程被唤醒后需要检查自己的前驱节点是否是头节点。</p><p>第二，维护同步队列的FIFO原则。</p><p>当前线程获取到同步状态后，让<strong>首节点</strong>（head）这个引用指向自己所在节点。当同步状态获取成功后，当前线程就从acquire方法返回了。如果同步器实现的是锁，那就代表当前线程获得了锁。</p><h6 id="释放"><a href="#释放" class="headerlink" title="释放"></a>释放</h6><p>当前线程获取同步状态并执行了相应逻辑之后，就需要释放同步状态，使得后续节点能够继续获取同步状态。通过调用同步器的release(int arg)方法可以释放同步状态，该方法在释放了同步状态之后，会唤醒其后继节点（进而使后继节点重新尝试获取同步状态）。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic15.png" srcset="/img/loading.gif" class=""><p>该方法执行时，会唤醒<strong>首节点</strong>（head）所指向节点的后继节点线程，unparkSuccessor(Node node)方法使用LockSupport来唤醒处于等待状态的线程。</p><p>而在unparkSuccessor中， </p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic16.png" srcset="/img/loading.gif" class=""><p>这段代码的意思，一般情况下，被唤醒的是head指向节点的后继节点线程，如果这个后继节点处于被cancel状态，（我推测开发者的思路这样的：后继节点处于被cancel状态，意味着当锁竞争激烈时，队列的第一个节点等了很久（一直被还未加入队列的节点抢走锁），包括后续的节点cancel的几率都比较大，所以）先从尾开始遍历，找到最前面且没有被cancel的节点。</p><h6 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h6><p>在获取同步状态时，同步器维护一个同步队列，获取状态失败的线程都会被加入到队列中并在队列中进行自旋；移出队列（或停止自旋）的条件是前驱节点为头节点且成功获取了同步状态。在释放同步状态时，同步器调用tryRelease(int arg)方法释放同步状态，然后唤醒head指向节点的后继节点。</p><h5 id="共享式同步状态获取与释放"><a href="#共享式同步状态获取与释放" class="headerlink" title="共享式同步状态获取与释放"></a>共享式同步状态获取与释放</h5><p>共享式获取与独占式获取最主要的区别在于同一时刻能否有多个线程同时获取到同步状态。以读写为例，如果一个程序在进行读操作，那么这一时刻写操作均被阻塞，而读操作能够同时进行。写操作要求对资源的独占式访问，而读操作可以是共享式访问。</p><p>在acquireShared(int arg)方法中，同步器调用tryAcquireShared(int arg)方法尝试获取同步状态，tryAcquireShared(int arg)方法返回值为int类型，当返回值大于等于0时，表示能够获取到同步状态。因此，在共享式获取的自旋过程中，成功获取到同步状态并退出自旋的条件就是tryAcquireShared(int arg)方法返回值大于等于0。可以看到，在doAcquireShared(int arg)方法的自旋过程中，如果当前节点的前驱为头节点时，尝试获取同步状态，如果返回值大于等于0，表示该次获取同步状态成功并从自旋过程中退出。</p><p>该方法在释放同步状态之后，将会唤醒后续处于等待状态的节点。对于能够支持多个线程同时访问的并发组件（比如Semaphore），它和独占式主要区别在于tryReleaseShared(int arg)方法必须确保同步状态（或者资源数）线程安全释放，一般是通过循环和CAS来保证的，因为释放同步状态的操作会同时来自多个线程。</p><h5 id="共享式的同步工具类"><a href="#共享式的同步工具类" class="headerlink" title="共享式的同步工具类"></a>共享式的同步工具类</h5><p>设计一个同步工具：该工具在同一时刻，只允许至多3个线程同时访问，超过3个线程的访问将被阻塞。</p><p>首先，确定访问模式。TrinityLock能够在同一时刻支持多个线程的访问，这显然是共享式访问，因此，需要使用同步器提供的acquireShared(int args)方法等和Shared相关的方法，这就要求TwinsLock必须重写tryAcquireShared(int args)方法和tryReleaseShared(int args)方法，这样才能保证同步器的共享式同步状态的获取与释放方法得以执行。</p><p>其次，定义资源数。TrinityLock在同一时刻允许至多三个线程的同时访问，表明同步资源数为3，这样可以设置初始状态status为3，当一个线程进行获取，status减1，该线程释放，则status加1，状态的合法范围为0、1和2,3，其中0表示当前已经有3个线程获取了同步资源，此时再有其他线程对同步状态进行获取，该线程只能被阻塞。在同步状态变更时，需要使用compareAndSet(int expect,int update)方法做原子性保障。</p><p>最后，组合自定义同步器。前面的章节提到，自定义同步组件通过组合自定义同步器来完成同步功能，一般情况下自定义同步器会被定义为自定义同步组件的内部类。</p><pre><code>/** *类说明：共享同步工具类 */public class TrinityLock  implements Lock {    //为n表示允许n个线程同时获得锁    private final Sync sync = new Sync(4);    private static final class Sync extends AbstractQueuedSynchronizer {        //private static final long serialVersionUID = -7889272986162341211L;        Sync(int count) {            if (count &lt;= 0) {                throw new IllegalArgumentException(&quot;count must large than zero.&quot;);            }            setState(count);        }        /**         *         * @param reduceCount  扣减个数         * @return  返回小于0，表示当前线程获得同步状态失败         * 大于0，表示当前线程获得同步状态成功         */        public int tryAcquireShared(int reduceCount) {            for (;;) {                int current = getState();                int newCount = current - reduceCount;                if (newCount &lt; 0 || compareAndSetState(current, newCount)) {                    return newCount;                }            }        }        /**         *         * @param returnCount 归还个数         * @return         */        public boolean tryReleaseShared(int returnCount) {            for (;;) {                int current = getState();                int newCount = current + returnCount;                if (compareAndSetState(current, newCount)) {                    return true;                }            }        }        final ConditionObject newCondition() {            return new ConditionObject();        }    }    public void lock() {        sync.acquireShared(1);    }    public void unlock() {        sync.releaseShared(1);    }    public void lockInterruptibly() throws InterruptedException {        sync.acquireSharedInterruptibly(1);    }    public boolean tryLock() {        return sync.tryAcquireShared(1) &gt;= 0;    }    public boolean tryLock(long time, TimeUnit unit) throws InterruptedException {        return sync.tryAcquireSharedNanos(1, unit.toNanos(time));    }    @Override    public Condition newCondition() {        return sync.newCondition();    }}</code></pre><h3 id="Condition分析"><a href="#Condition分析" class="headerlink" title="Condition分析"></a>Condition分析</h3><h4 id="Condition的数据结构"><a href="#Condition的数据结构" class="headerlink" title="Condition的数据结构"></a>Condition的数据结构</h4><p>等待队列是一个FIFO的队列，在队列中的每个节点都包含了一个线程引用，该线程就是在Condition对象上等待的线程，如果一个线程调用了Condition.await()方法，那么该线程将会释放锁、构造成节点加入等待队列并进入等待状态。事实上，节点的定义复用了同步器中节点的定义，也就是说，同步队列和等待队列中节点类型都是同步器的静态内部类。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic17.png" srcset="/img/loading.gif" class=""><p>一个Condition包含一个等待队列，Condition拥有首节点（firstWaiter）和尾节点（lastWaiter）。当前线程调用Condition.await()方法，将会以当前线程构造节点，并将节点从尾部加入等待队列。Condition拥有首尾节点的引用，而新增节点只需要将原有的尾节点nextWaiter指向它，并且更新尾节点即可。上述节点引用更新的过程并没有使用CAS保证，原因在于调用await()方法的线程必定是获取了锁的线程，也就是说该过程是由锁来保证线程安全的。</p><p>Lock（更确切地说是同步器）拥有一个同步队列和多个等待队列。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic18.png" srcset="/img/loading.gif" class=""><p>调用Condition的await()方法（或者以await开头的方法），会使当前线程进入等待队列并释放锁，同时线程状态变为等待状态。当从await()方法返回时，当前线程一定获取了Condition相关联的锁。</p><p>如果从队列（同步队列和等待队列）的角度看await()方法，当调用await()方法时，相当于同步队列的首节点（获取了锁的节点）移动到Condition的等待队列中。调用该方法的线程成功获取了锁的线程，也就是同步队列中的首节点，该方法会将当前线程构造成节点并加入等待队列中，然后释放同步状态，唤醒同步队列中的后继节点，然后当前线程会进入等待状态。当等待队列中的节点被唤醒，则唤醒节点的线程开始尝试获取同步状态。如果不是通过其他线程调用Condition.signal()方法唤醒，而是对等待线程进行中断，则会抛出InterruptedException。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic19.png" srcset="/img/loading.gif" class=""><p>如图所示，同步队列的首节点并不会直接加入等待队列，而是通过addConditionWaiter()方法把当前线程构造成一个新的节点并将其加入等待队列中。</p><img src="/2019/12/30/%E6%98%BE%E5%BC%8F%E9%94%81%E5%92%8CAQS/pic20.png" srcset="/img/loading.gif" class=""><p>调用Condition的signal()方法，将会唤醒在等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节点移到同步队列中。</p><p>调用该方法的前置条件是当前线程必须获取了锁，可以看到signal()方法进行了isHeldExclusively()检查，也就是当前线程必须是获取了锁的线程。接着获取等待队列的首节点，将其移动到同步队列并使用LockSupport唤醒节点中的线程。</p><p>通过调用同步器的enq(Node node)方法，等待队列中的头节点线程安全地移动到同步队列。当节点移动到同步队列后，当前线程再使用LockSupport唤醒该节点的线程。</p><p>被唤醒后的线程，将从await()方法中的while循环中退出（isOnSyncQueue(Node node)方法返回true，节点已经在同步队列中），进而调用同步器的acquireQueued()方法加入到获取同步状态的竞争中。</p><p>成功获取同步状态（或者说锁）之后，被唤醒的线程将从先前调用的await()方法返回，此时该线程已经成功地获取了锁。</p><p>Condition的signalAll()方法，相当于对等待队列中的每个节点均执行一次signal()方法，效果就是将等待队列中所有节点全部移动到同步队列中，并唤醒每个节点的线程。</p><h2 id="Lock的实现"><a href="#Lock的实现" class="headerlink" title="Lock的实现"></a>Lock的实现</h2><h3 id="ReentrantLock的实现"><a href="#ReentrantLock的实现" class="headerlink" title="ReentrantLock的实现"></a>ReentrantLock的实现</h3><h4 id="锁的可重入"><a href="#锁的可重入" class="headerlink" title="锁的可重入"></a>锁的可重入</h4><p>重进入是指任意线程在获取到锁之后能够再次获取该锁而不会被锁所阻塞，该特性的实现需要解决以下两个问题。</p><ol><li><p>线程再次获取锁。锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取。</p></li><li><p>锁的最终释放。线程重复n次获取了锁，随后在第n次释放该锁后，其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增，计数表示当前锁被重复获取的次数，而锁被释放时，计数自减，当计数等于0时表示锁已经成功释放。</p></li></ol><p>nonfairTryAcquire方法增加了再次获取同步状态的处理逻辑：通过判断当前线程是否为获取锁的线程来决定获取操作是否成功，如果是获取锁的线程再次请求，则将同步状态值进行增加并返回true，表示获取同步状态成功。同步状态表示锁被一个线程重复获取的次数。</p><p>如果该锁被获取了n次，那么前(n-1)次tryRelease(int releases)方法必须返回false，而只有同步状态完全释放了，才能返回true。可以看到，该方法将同步状态是否为0作为最终释放的条件，当同步状态为0时，将占有线程设置为null，并返回true，表示释放成功。</p><h4 id="公平和非公平锁"><a href="#公平和非公平锁" class="headerlink" title="公平和非公平锁"></a>公平和非公平锁</h4><p>ReentrantLock的构造函数中，默认的无参构造函数将会把Sync对象创建为NonfairSync对象，这是一个“非公平锁”；而另一个构造函数ReentrantLock(boolean fair)传入参数为true时将会把Sync对象创建为“公平锁”FairSync。公平锁的tryAcquire()方法与非公平锁的nonfairTryAcquire(int acquires)相比，唯一不同的位置为判断条件多了hasQueuedPredecessors()方法，即加入了同步队列中当前节点是否有前驱节点的判断，如果该方法返回true，则表示有线程比当前线程更早地请求获取锁，因此需要等待前驱线程获取并释放锁之后才能继续获取锁，而非公平锁只要CAS设置同步状态成功，则表示当前线程获取了锁。</p><h4 id="改造之前的独占锁为可重入"><a href="#改造之前的独占锁为可重入" class="headerlink" title="改造之前的独占锁为可重入"></a>改造之前的独占锁为可重入</h4><pre><code>/** *类说明：实现我们自己独占锁,可重入 */public class ReenterSelfLock implements Lock {    // 静态内部类，自定义同步器    private static class Sync extends AbstractQueuedSynchronizer {        // 是否处于占用状态        protected boolean isHeldExclusively() {            return getState() &gt; 0;        }        // 当状态为0的时候获取锁        public boolean tryAcquire(int acquires) {            if (compareAndSetState(0, 1)) {                setExclusiveOwnerThread(Thread.currentThread());                return true;            }else if(getExclusiveOwnerThread()==Thread.currentThread()){                setState(getState()+1);                return  true;            }            return false;        }        // 释放锁，将状态设置为0        protected boolean tryRelease(int releases) {            if(getExclusiveOwnerThread()!=Thread.currentThread()){                throw new IllegalMonitorStateException();            }            if (getState() == 0)                throw new IllegalMonitorStateException();            setState(getState()-1);            if(getState()==0){                setExclusiveOwnerThread(null);            }            return true;        }        // 返回一个Condition，每个condition都包含了一个condition队列        Condition newCondition() {            return new ConditionObject();        }    }    // 仅需要将操作代理到Sync上即可    private final Sync sync = new Sync();    public void lock() {       System.out.println(Thread.currentThread().getName()+&quot; ready get lock&quot;);        sync.acquire(1);        System.out.println(Thread.currentThread().getName()+&quot; already got lock&quot;);    }    public boolean tryLock() {        return sync.tryAcquire(1);    }    public void unlock() {       System.out.println(Thread.currentThread().getName()+&quot; ready release lock&quot;);        sync.release(1);        System.out.println(Thread.currentThread().getName()+&quot; already released lock&quot;);    }    public Condition newCondition() {        return sync.newCondition();    }    public boolean isLocked() {        return sync.isHeldExclusively();    }    public boolean hasQueuedThreads() {        return sync.hasQueuedThreads();    }    public void lockInterruptibly() throws InterruptedException {        sync.acquireInterruptibly(1);    }    public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {        return sync.tryAcquireNanos(1, unit.toNanos(timeout));    }}</code></pre><p>测试类</p><pre><code>/** *类说明： */public class TestReenterSelfLock {    static final Lock lock = new ReenterSelfLock();    public void reenter(int x){        lock.lock();        try {            System.out.println(Thread.currentThread().getName()+&quot;:递归层级:&quot;+x);            int y = x - 1;            if (y==0) return;            else{                reenter(y);            }        } finally {            lock.unlock();        }    }    public void test() {        class Worker extends Thread {            public void run() {                System.out.println(Thread.currentThread().getName());                SleepTools.second(1);                reenter(3);            }        }        // 启动3个子线程        for (int i = 0; i &lt; 3; i++) {            Worker w = new Worker();            w.start();        }        // 主线程每隔1秒换行        for (int i = 0; i &lt; 100; i++) {            SleepTools.second(1);        }    }    public static void main(String[] args) {        TestReenterSelfLock testMyLock = new TestReenterSelfLock();        testMyLock.test();    }}</code></pre><h3 id="ReentrantReadWriteLock的实现"><a href="#ReentrantReadWriteLock的实现" class="headerlink" title="ReentrantReadWriteLock的实现"></a>ReentrantReadWriteLock的实现</h3><h4 id="读写状态的设计"><a href="#读写状态的设计" class="headerlink" title="读写状态的设计"></a>读写状态的设计</h4><p>读写锁同样依赖自定义同步器来实现同步功能，而读写状态就是其同步器的同步状态。</p><p>回想ReentrantLock中自定义同步器的实现，同步状态表示锁被一个线程重复获取的次数，而读写锁的自定义同步器需要在同步状态（一个整型变量）上维护多个读线程和一个写线程的状态，使得该状态的设计成为读写锁实现的关键。</p><p>如果在一个整型变量上维护多种状态，就一定需要“按位切割使用”这个变量，读写锁将变量切分成了两个部分，高16位表示读，低16位表示写，读写锁通过位运算来维护各自的运算。假设当前同步状态值为S，写状态等于S&amp;0x0000FFFF（将高16位全部抹去），读状态等于S&gt;&gt;&gt;16（无符号补0右移16位）。当写状态增加1时，等于S+1，当读状态增加1时，等于S+(1&lt;&lt;16)，也就是S+0x00010000。根据状态的划分能得出一个推论：S不等于0时，当写状态（S&amp;0x0000FFFF）等于0时，则读状态（S&gt;&gt;&gt;16）大于0，即读锁已被获取。</p><h4 id="写锁的获取与释放"><a href="#写锁的获取与释放" class="headerlink" title="写锁的获取与释放"></a>写锁的获取与释放</h4><p>写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。读写锁在内部有一个ThreadLocal记录写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态。</p><p>该方法除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。如果存在读锁，则写锁不能被获取，原因在于：读写锁要确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。</p><p>写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，从而等待的读写线程能够继续访问读写锁，同时前次写线程的修改对后续读写线程可见。</p><h4 id="读锁的获取与释放"><a href="#读锁的获取与释放" class="headerlink" title="读锁的获取与释放"></a>读锁的获取与释放</h4><p>读锁是一个支持重进入的共享锁，它能够被多个线程同时获取，在没有其他写线程访问（或者写状态为0）时，读锁总会被成功地获取，而所做的也只是（线程安全的）增加读状态。如果当前线程已经获取了读锁，则增加读状态。</p><p>如果当前线程在获取读锁时，写锁已被其他线程获取，则进入等待状态。读状态是所有线程获取读锁次数的总和，而每个线程各自获取读锁的次数只能选择保存在ThreadLocal中，由线程自身维护。在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态。</p><h4 id="锁的升降级"><a href="#锁的升降级" class="headerlink" title="锁的升降级"></a>锁的升降级</h4><p>锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。</p><p>锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。</p><p>RentrantReadWriteLock不支持锁升级（把持读锁、获取写锁，最后释放读锁的过程）。目的是保证数据可见性，如果读锁已被多个线程获取，其中任意线程成功获取了写锁并更新了数据，则其更新对其他获取到读锁的线程是不可见的。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>原子操作CAS(Compare And Swap)</title>
    <link href="/2019/12/24/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9CCAS/"/>
    <url>/2019/12/24/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9CCAS/</url>
    
    <content type="html"><![CDATA[<h2 id="什么是原子操作，如何实现？"><a href="#什么是原子操作，如何实现？" class="headerlink" title="什么是原子操作，如何实现？"></a>什么是原子操作，如何实现？</h2><p>假定有两个操作A和B，如果从执行A的线程来看，当另一个线程执行B时，要么将B全部执行完，要么完全不执行B，那么A和B对彼此来说是原子的。</p><p>实现原子操作可以使用锁机制即synchronized关键字来实现，但synchronized关键字是基于阻塞的锁机制，也就是说当一个线程拥有锁的时候，访问同一资源的其它线程需要等待该线程执行完毕释放锁。显然，这种机制不是很灵活。比如被阻塞的线程优先级比较高，或者获得锁的线程一直不释放锁，还有大量的线程来竞争资源CPU将会花费更多的时间和资源来处理这些竞争，还可能出现一些例如死锁之类的情况，这些都会严重影响程序的性能。其实锁机制是一种比较粗糙，粒度比较大的机制，相对于像计数器这样的需求过于笨重。</p><p>CAS是利用CPU的多处理能力，实现硬件层面的阻塞，再加上volatile变量的特性即可实现基于原子操作的线程安全。当前的处理器基本都支持CAS指令，只不过每个厂家所实现的算法并不一样，每一个CAS操作过程都包含三个运算符：一个内存地址V，一个期望的值A和一个新值B，操作的时候如果这个地址上存放的值等于这个期望的值A，则将地址上的值赋为新值B，否则将循环这个指令直到成功为止。</p><img src="/2019/12/24/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9CCAS/pic1.png" srcset="/img/loading.gif" class=""><h2 id="CAS实现原子操作的三大问题"><a href="#CAS实现原子操作的三大问题" class="headerlink" title="CAS实现原子操作的三大问题"></a>CAS实现原子操作的三大问题</h2><h3 id="ABA问题"><a href="#ABA问题" class="headerlink" title="ABA问题"></a>ABA问题</h3><p>因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。</p><p>ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A→B→A就会变成1A→2B→3A。</p><h3 id="循环时间长开销大"><a href="#循环时间长开销大" class="headerlink" title="循环时间长开销大"></a>循环时间长开销大</h3><p>多个线程争夺同一个资源时，如果自旋一直不成功，将会一直占用CPU。</p><p>解决方法：破坏掉for死循环，当超过一定时间或者一定次数时，return退出。JDK8新增的LongAddr,和ConcurrentHashMap类似的方法。当多个线程竞争时，将粒度变小，将一个变量拆分为多个变量，达到多个线程访问多个资源的效果，最后再调用sum把它合起来。</p><h3 id="只能保证一个共享变量的原子操作"><a href="#只能保证一个共享变量的原子操作" class="headerlink" title="只能保证一个共享变量的原子操作"></a>只能保证一个共享变量的原子操作</h3><p>CAS指令同时刻只能保证对一个地址是原子的，当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。还有一个取巧的办法，就是把多个共享变量合并成一个共享变量或者封装为对象来操作。比如，有两个共享变量i＝2，j=a，合并一下ij=2a，然后用CAS来操作ij。从Java 1.5开始，JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。</p><h2 id="Jdk中相关原子操作类的使用"><a href="#Jdk中相关原子操作类的使用" class="headerlink" title="Jdk中相关原子操作类的使用"></a>Jdk中相关原子操作类的使用</h2><h3 id="jdk中提供的原子操作类"><a href="#jdk中提供的原子操作类" class="headerlink" title="jdk中提供的原子操作类"></a>jdk中提供的原子操作类</h3><ul><li>更新基本类型：AtomicBoolean,AtomicInteger,AtomicLong</li><li>更新数组类型：AtomicIntegerArray,AtomicLongArray,AtomicReferenceArray</li><li>更新基本引用类型：AtomicReference,AtomicMarkableReference,AtomicStampedReference</li><li>更新字段类型：AtomicReferenceFieldUpdater,AtomicIntegerFieldUpdater,AtomicLongFieldUpdater</li></ul><h3 id="更新基本类型"><a href="#更新基本类型" class="headerlink" title="更新基本类型"></a>更新基本类型</h3><p><strong>AtomicInteger</strong></p><ul><li><p>int addAndGet(int delta)：以原子方式将输入的数值与实例中的值相加，并返回结果。</p></li><li><p>Int  (int delta)：返回实例中的值之后，以原子操作与输入的值相加。</p></li><li><p>int getAndIncrement()：返回实例中的值之后以原子方式加1</p></li><li><p>int incrementAndGet()：以原子操作将实例中的值加1之后返回</p></li><li><p>int getAndDecrement()：返回实例中的值之后以原子方式减1</p></li><li><p>int decrementAndGet()：以原子操作将实例中的值减1之后返回</p></li><li><p>int getAndSet(int newValue)：返回实例中的值之后以原子方式设置为newValue的值。</p></li><li><p>boolean compareAndSet(int expect，int update)：如果实例中的值等于expect值，则以原子方式设置为update的值。</p></li></ul><h3 id="更新数组类型"><a href="#更新数组类型" class="headerlink" title="更新数组类型"></a>更新数组类型</h3><p><strong>AtomicIntegerArray</strong></p><p>主要是提供原子的方式更新数组里的整型，其常用方法如下。</p><ul><li><p>int addAndGet(int i，int delta)：以原子方式将输入值与实例中索引i的元素相加后返回。</p></li><li><p>boolean compareAndSet(int i，int expect，int update)：如果实例中索引i的元素等于预期值，则以原子方式将实例中索引i的元素设置成update值。</p></li><li><p>int getAndAccumulate(int i, int x,IntBinaryOperator accumulatorFunction)：将实例中索引i的元素返回之后以原子方式设置为accumulatorFunction中的操作返回的值，accumulatorFunction的left为原始值，left为传入的值。</p></li></ul><p>需要注意的是，AtomicIntegerArray中存储的数组是复制之后的原数组，当使用AtomicIntegerArray对内部的数组元素进行修改时，不会影响原数组。</p><h3 id="更新引用类型"><a href="#更新引用类型" class="headerlink" title="更新引用类型"></a>更新引用类型</h3><p>原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包提供了以下3个类。</p><p><strong>AtomicReference</strong></p><p>原子更新引用类型（不能解决ABA问题）。</p><ul><li>boolean compareAndSet(V expect，V update)：如果实例中对象等于预期值，则以原子方式将实例中对象替换为输入的对象</li></ul><p><strong>AtomicMarkableReference</strong></p><p>可以解决ABA问题，  可以记录更新过程中有没有变化</p><ul><li>AtomicMarkableReference(V initialRef, boolean initialMark)：initialRef（要关联的对象），initialMark（版本戳）</li></ul><p>AtomicStampedReference利用版本戳的形式记录了每次改变以后的版本号，版本戳为boolean类型，可以记录值是否被修改过。</p><p><strong>AtomicStampedReference</strong></p><p>能够解决ABA问题，并且可以记录变化次数</p><ul><li>AtpmicStampedReference(V initialRef,int initialStamp)：构造函数，initialRef（要关联的对象），initialStamp（版本戳）</li><li>V getStamp()：获取当前版本号</li><li>V getReference()：获取当前对象</li><li>boolean compareAndSet(V   expectedReference,V   newReference,int expectedStamp,int newStamp) ：更新当前对象及版本号</li></ul><p>AtomicStampedReference跟AtomicMarkableReference差不多， AtomicStampedReference是使用int类型的值作为版本戳，AtomicMarkableReference使用boolean mark作为版本戳。 </p><h3 id="原子更新字段类"><a href="#原子更新字段类" class="headerlink" title="原子更新字段类"></a>原子更新字段类</h3><p>如果需原子地更新某个类里的某个字段时，就需要使用原子更新字段类，Atomic包提供了以下3个类进行原子字段更新。</p><ul><li><p>AtomicIntegerFieldUpdater：原子更新整型的字段的更新器。</p></li><li><p>AtomicLongFieldUpdater：原子更新长整型字段的更新器。</p></li><li><p>AtomicReferenceFieldUpdater：原子更新引用类型里的字段。</p></li></ul><p>要想原子地更新字段类需要两步。第一步，因为原子更新字段类都是抽象类，每次使用的时候必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。第二步，更新类的字段（属性）必须使用public volatile修饰符。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线程的并发工具类</title>
    <link href="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/"/>
    <url>/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<h1 id="Fork-Join"><a href="#Fork-Join" class="headerlink" title="Fork-Join"></a>Fork-Join</h1><p>forkjoin体现了分而治之的策略，java下多线程的开发可以我们自己启用多线程，线程池，还可以使用forkjoin，forkjoin可以让我们不去了解诸如Thread，Runnable等相关的知识，只要遵循forkjoin的开发模式，就可以写出很好的多线程并发程序。</p><h3 id="分而治之"><a href="#分而治之" class="headerlink" title="分而治之"></a>分而治之</h3><p>分治策略是：对于一个规模为n的问题，若该问题可以容易地解决（比如说规模n较小）则直接解决，否则将其分解为k个规模较小的子问题，这些子问题互相独立且与原问题形式相同（子问题相互之间有联系就会变为动态规范算法），递归地解这些子问题，然后将各子问题的解合并得到原问题的解，这种算法设计策略叫做分治法。</p><p>归并排序，快速排序，二分查找及大数据中M/R都体现了分而治之的策略。</p><h3 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h3><p>若将两个有序表合并成一个有序表，称为2-路归并，与之对应的还有多路归并。</p><p>对于给定的一组数据，利用递归与分治技术将数据序列划分成为越来越小的半子表，在对半子表排序后，再用递归方法将排好序的半子表合并成为越来越大的有序序列。</p><p>为了提升性能，有时我们在半子表的个数小于某个数（比如15）的情况下，对半子表的排序采用其他排序算法，比如插入排序。</p><h3 id="归并排序（降序）示例"><a href="#归并排序（降序）示例" class="headerlink" title="归并排序（降序）示例"></a>归并排序（降序）示例</h3><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic1.png" srcset="/img/loading.gif" class=""><p>先讲数组划分为左右两个子表：</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic2.png" srcset="/img/loading.gif" class=""> <img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic3.png" srcset="/img/loading.gif" class=""><p>然后继续左右两个子表拆分：</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic4.png" srcset="/img/loading.gif" class=""><p>对最后的拆分的子表，两两进行排序</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic5.png" srcset="/img/loading.gif" class=""><p>对有序的子表进行排序和比较合并</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic6.png" srcset="/img/loading.gif" class=""><p>对合并后的子表继续比较合并</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic7.png" srcset="/img/loading.gif" class=""><h2 id="Fork-Join原理"><a href="#Fork-Join原理" class="headerlink" title="Fork-Join原理"></a>Fork-Join原理</h2><p>Fork/Join框架：就是在必要的情况下，讲一个大任务，进行拆分（fork）成若干个小任务（拆到不可在拆时），再将一个个小任务进行join汇总。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic8.png" srcset="/img/loading.gif" class=""><h3 id="工作密取"><a href="#工作密取" class="headerlink" title="工作密取"></a>工作密取</h3><p>即当前线程的Task已经全被执行完毕，则自动取到其他线程的Task池中取出Task继续执行。</p><p>ForkJoinPool中维护着多个线程（一般为CPU核数）在不断地执行Task，每个线程除了执行自己职务内的Task之外，还会根据自己工作线程的闲置情况去获取其他繁忙的工作线程的Task，如此一来就能能够减少线程阻塞或是闲置的时间，提高CPU利用率。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic9.png" srcset="/img/loading.gif" class=""><h2 id="Fork-Join实战"><a href="#Fork-Join实战" class="headerlink" title="Fork-Join实战"></a>Fork-Join实战</h2><h3 id="Fork-Join使用的标准范式"><a href="#Fork-Join使用的标准范式" class="headerlink" title="Fork/Join使用的标准范式"></a>Fork/Join使用的标准范式</h3><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic10.png" srcset="/img/loading.gif" class=""><p>要使用ForkJoin框架，必须首先创建一个ForkJoin任务，创建方式为继承ForkJoin的子类：RecursiveAction或RecursiveTask，然后实现其中的compute方法。ForkJoin框架将compute()中的逻辑来进行fork或join操作。</p><ol><li><p><strong>RecursiveAction：</strong>没有返回结果的任务</p></li><li><p><strong>RecursiveTask：</strong>有返回值的任务</p></li></ol><p>在compute方法里，首先需要判断任务是否足够小，如果足够小就直接执行任务。如果不足够小，就必须分割成两个并创建子任务，然后调用invokeAll()方法将创建的子任务提交，如果子任务有返回值，则调用join()方法获取子任务的执行结果之后需要将执行结果合并并返回，提交之后的子任务会再次进入compute，判断子任务是否需要继续拆分，如果不需要继续分割，则执行当前子任务并返回结果。</p><p> 继承之后的子类要提交到ForkJoinPool中执行，可以使用invoke()，submit()，execture()提交，区别是：invoke()是同步执行，调用之后当前线程阻塞，等待任务完成；submit()和execture()是异步执行不会阻塞当前线程，submit()可以返回结果值，execute()不会返回结果值。之后可以通过join()或get()方法获取执行结果，如果是异步执行，join()和get()方法会阻塞当前线程直到所有任务执行完毕。</p><h3 id="实现数组排序"><a href="#实现数组排序" class="headerlink" title="实现数组排序"></a>实现数组排序</h3><pre><code>public class MergeSort {    //数组长度    public static final int ARRAY_LENGTH  = 40000000;    public final static int THRESHOLD = 47;    public static int[] makeArray() {        //new一个随机数发生器        Random r = new Random();        int[] result = new int[ARRAY_LENGTH];        for(int i=0;i&lt;ARRAY_LENGTH;i++){            //用随机数填充数组            result[i] =  r.nextInt(ARRAY_LENGTH*3);        }        return result;    }    /**     * 归并排序——将两段排序好的数组结合成一个排序数组     *     * @param left     * @param right     * @return     */    public static int[] merge(int[] left, int[] right) {        int[] result = new int[left.length + right.length];        for (int index = 0, i = 0, j = 0; index &lt; result.length; index++) {            if (i &gt;= left.length)/*左边数组已经取完，完全取右边数组的值即可*/                result[index] = right[j++];            else if (j &gt;= right.length)/*右边数组已经取完，完全取左边数组的值即可*/                result[index] = left[i++];            else if (left[i] &gt; right[j])/*左边数组的元素值大于右边数组，取右边数组的值*/                result[index] = right[j++];            else/*右边数组的元素值大于左边数组，取左边数组的值*/                result[index] = left[i++];        }        return result;    }     /**     * 插入排序     *     * @param array     * @return     */    public static int[] sort(int[] array) {        if (array.length == 0)            return array;        int currentValue;/*当前待排序数据，该元素之前的元素均已被排序过*/        for (int i = 0; i &lt; array.length - 1; i++) {            int preIndex = i;/*已被排序数据的索引*/            currentValue = array[preIndex + 1];            /*在已被排序过数据中倒序寻找合适的位置，如果当前待排序数据比比较的元素要小，            将比较的元素元素后移一位*/            while (preIndex &gt;= 0 &amp;&amp; currentValue &lt; array[preIndex]) {                //将当前元素后移一位                array[preIndex + 1] = array[preIndex];                preIndex--;            }            /*while循环结束时，说明已经找到了当前待排序数据的合适位置，插入*/            array[preIndex + 1] = currentValue;        }        return array;    }    public static void main(String[] args) {        System.out.println(&quot;============================================&quot;);        long start = System.currentTimeMillis();        ForkJoinPool forkJoinPool = new ForkJoinPool();        MergeSortTask sortTask = new MergeSortTask(MakeArray.makeArray());        forkJoinPool.invoke(sortTask);        //forkJoinPool.submit(sortTask);        //int[] array = sortTask.join();        System.out.println(&quot; spend time:&quot;+(System.currentTimeMillis()-start)+&quot;ms&quot;);        System.out.println(&quot;============================================&quot;);    }    private static class MergeSortTask extends RecursiveTask&lt;int[]&gt;{        private int[] array;        public MergeSortTask(int[] array){            this.array = array;        }        @Override        protected int[] compute() {            if (array.length&lt;= THRESHOLD) {                return sort(array);            }else{                int mid = array.length / 2;                int[] leftArray = Arrays.copyOfRange(array, 0, mid);                int[] rightArray = Arrays.copyOfRange(array, mid, array.length);                MergeSortTask leftTask = new MergeSortTask(leftArray);                MergeSortTask rightTask = new MergeSortTask(rightArray);                invokeAll(leftTask, rightTask);                return merge(leftTask.join(), rightTask.join());            }        }    }}</code></pre><h3 id="异步寻找目录下的文件"><a href="#异步寻找目录下的文件" class="headerlink" title="异步寻找目录下的文件"></a>异步寻找目录下的文件</h3><pre><code>public class FindDirsFiles extends RecursiveAction {    private File path;    public FindDirsFiles(File path) {        this.path = path;    }    @Override    protected void compute() {        List&lt;FindDirsFiles&gt; subTasks = new ArrayList&lt;&gt;();        File[] files = path.listFiles();        if (files!=null){            for (File file : files) {                if (file.isDirectory()) {                    // 对每个子目录都新建一个子任务。                    subTasks.add(new FindDirsFiles(file));                } else {                    // 遇到文件，检查。                    if (file.getAbsolutePath().endsWith(&quot;txt&quot;)){                        System.out.println(&quot;文件:&quot; + file.getAbsolutePath());                    }                }            }            if (!subTasks.isEmpty()) {                // 在当前的 ForkJoinPool 上调度所有的子任务。                for (FindDirsFiles subTask : invokeAll(subTasks)) {                    subTask.join();                }            }        }    }    public static void main(String [] args){        try {            // 用一个 ForkJoinPool 实例调度总任务            ForkJoinPool pool = new ForkJoinPool();            FindDirsFiles task = new FindDirsFiles(new File(&quot;./&quot;));            /*异步提交*/            pool.execute(task);            /*主线程做自己的业务工作*/            System.out.println(&quot;Task is Running......&quot;);            Thread.sleep(1);            int otherWork = 0;            for(int i=0;i&lt;100;i++){                otherWork = otherWork+i;            }            System.out.println(&quot;Main Thread done sth......,otherWork=&quot;                    +otherWork);            task.join();//阻塞方法            System.out.println(&quot;Task end&quot;);        } catch (Exception e) {            // TODO Auto-generated catch block            e.printStackTrace();        }    }}</code></pre><h1 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h1><p>闭锁，CountDownLatch这个类能够使一个线程或多个线程等待其他线程完成后再执行。例如，应用程序的主线程希望在负责启动框架服务的线程已经完成之后再执行。</p><p>CountDownLatch是通过一个计数器来实现的，计数器的初始值为初始任务的数量（也可以大于线程数即线程中可以多次执行countDown()，线程执行countDown()之后也可以继续执行）。每当完成了一个任务后，计数器的值就会减1（CountDownLatch.countDown()方法）。当计数器值到达0时，它表示所有的已经完成了任务，然后在闭锁上等待CountDownLatch.await()方法的线程就可以继续执行。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic11.png" srcset="/img/loading.gif" class=""><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>实现最大的并行性：有时我们想同时启动多个线程，实现最大程度的并行性。例如，我们想测试一个单例类。如果我们创建一个初始计数为1的CountDownLatch，并让所有线程都在这个锁上等待，那么我们可以很轻松地完成测试。我们只需调用 一次countDown()方法就可以让所有的等待线程同时恢复执行。</p><p>开始执行前等待n个线程完成各自任务：例如应用程序启动类要确保在处理用户请求前，所有N个外部系统已经启动和运行了，例如处理excel中多个表单。</p><h3 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h3><pre><code>/** *类说明：演示CountDownLatch用法， * 共5个初始化子线程，6个闭锁扣除点，扣除完毕后，主线程和业务线程才能继续执行 */public class UseCountDownLatch {    static CountDownLatch latch = new CountDownLatch(6);    /*初始化线程*/    private static class InitThread implements Runnable{        public void run() {            System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                    +&quot; ready init work......&quot;);            latch.countDown();            for(int i =0;i&lt;2;i++) {                System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                        +&quot; ........continue do its work&quot;);            }        }    }    /*业务线程等待latch的计数器为0完成*/    private static class BusiThread implements Runnable{        public void run() {            try {                latch.await();            } catch (InterruptedException e) {                e.printStackTrace();            }            for(int i =0;i&lt;3;i++) {                System.out.println(&quot;BusiThread_&quot;+Thread.currentThread().getId()                        +&quot; do business-----&quot;);            }        }    }    public static void main(String[] args) throws InterruptedException {        new Thread(new Runnable() {            public void run() {                SleepTools.ms(1);                System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                        +&quot; ready init work step 1st......&quot;);                latch.countDown();                System.out.println(&quot;begin step 2nd.......&quot;);                SleepTools.ms(1);                System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                        +&quot; ready init work step 2nd......&quot;);                latch.countDown();            }        }).start();        new Thread(new BusiThread()).start();        for(int i=0;i&lt;=3;i++){            Thread thread = new Thread(new InitThread());            thread.start();        }        latch.await();        System.out.println(&quot;Main do ites work........&quot;);    }}</code></pre><h1 id="CyclicBarrier"><a href="#CyclicBarrier" class="headerlink" title="CyclicBarrier"></a>CyclicBarrier</h1><p>CyclicBarrier的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到所有线程到达屏障时，解除屏障，所有被屏障拦截的线程才会继续运行。CyclicBarrier默认的构造方法是CyclicBarrier（int parties），其参数表示屏障拦截的线程数量，每个线程调用await()方法告诉CyclicBarrier当前线程已经到达了屏障，然后这个线程被阻塞。</p><p>CyclicBarrier还提供一个更高级的构造函数CyclicBarrier（int parties，Runnable barrierAction），用于在线程到达屏障时，执行barrierAction，方便处理更复杂的业务场景。</p><p>await()方法可以执行多次，当满足条件屏障解除之后，CyclicBarrier就会被复位。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic12.png" srcset="/img/loading.gif" class=""><h3 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h3><p>CyclicBarrier可以用于多线程计算数据，最后合并计算结果的场景。</p><h3 id="用法-1"><a href="#用法-1" class="headerlink" title="用法"></a>用法</h3><pre><code>/** * 类说明：演示CyclicBarrier用法,共4个子线程，他们全部完成工作后，交出自己结果， * 再被统一释放去做自己的事情，而交出的结果被另外的线程拿来拼接字符串 */public class UseCyclicBarrier {    private static CyclicBarrier barrier = new CyclicBarrier(4, new CollectThread());    //存放子线程工作结果的容器    private static ConcurrentHashMap&lt;String, Long&gt; resultMap            = new ConcurrentHashMap&lt;&gt;();    public static void main(String[] args) {        for (int i = 0; i &lt; 4; i++) {            Thread thread = new Thread(new SubThread());            thread.start();        }    }    /*汇总的任务*/    private static class CollectThread implements Runnable {        @Override        public void run() {            StringBuilder result = new StringBuilder();            for (Map.Entry&lt;String, Long&gt; workResult : resultMap.entrySet()) {                result.append(&quot;[&quot; + workResult.getValue() + &quot;]&quot;);            }            System.out.println(&quot; the result = &quot; + result);            System.out.println(&quot;do other business........&quot;);        }    }    /*相互等待的子线程*/    private static class SubThread implements Runnable {        @Override        public void run() {            long id = Thread.currentThread().getId();            resultMap.put(Thread.currentThread().getId() + &quot;&quot;, id);            try {                Thread.sleep(1000 + id);                System.out.println(&quot;Thread_&quot; + id + &quot; ....do something &quot;);                barrier.await();                Thread.sleep(1000 + id);                System.out.println(&quot;Thread_&quot; + id + &quot; ....do its business &quot;);            } catch (Exception e) {                e.printStackTrace();            }        }    }}</code></pre><h3 id="CountDownLatch和CyclicBarrier辨析"><a href="#CountDownLatch和CyclicBarrier辨析" class="headerlink" title="CountDownLatch和CyclicBarrier辨析"></a>CountDownLatch和CyclicBarrier辨析</h3><ul><li><p>CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以反复使用。</p></li><li><p>CountDownLatch.await()会阻塞当前线程，等待所有工作线程执行countDown()之后继续执行，而CyclicBarrier通过线程调用await()阻塞工作线程，直到所有工作线程达到指定屏障，所有工作线程再继续执行。</p></li><li><p>在控制多个线程同时运行上，CountDownLatch可以不限线程数量，而CyclicBarrier是固定线程数。</p></li><li><p>CyclicBarrier还可以提供一个barrierAction，用于进行到达屏障后的工作，如：合并多线程计算结果。</p></li></ul><h1 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h1><p>Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。应用场景Semaphore可以用于做流量控制，特别是公用资源有限的应用场景，比如数据库连接。假如有一个需求，要读取几万个文件的数据，因为都是IO密集型任务，我们可以启动几十个线程并发地读取，但是如果读到内存后，还需要存储到数据库中，而数据库的连接数只有10个，这时我们必须控制只有10个线程同时获取数据库连接保存数据，否则会报错无法获取数据库连接。这个时候，就可以使用Semaphore来做流量控制。Semaphore的构造方法Semaphore（int permits）接受一个整型的数字，表示可用的许可证数量。Semaphore的用法也很简单，首先线程使用Semaphore的acquire()方法获取一个许可证 ，使用完之后调用release()方法归还许可证。还可以用tryAcquire()方法尝试获取许可证。</p><p>Semaphore还提供一些其他方法，具体如下。</p><ul><li><p><strong>int availablePermits()：</strong>返回此信号量中当前可用的许可证数。</p></li><li><p><strong>int getQueueLength()：</strong>返回正在等待获取许可证的线程数。</p></li><li><p><strong>boolean hasQueuedThreads()：</strong>是否有线程正在等待获取许可证。</p></li><li><p><strong>void reducePermits(int reduction)：</strong>减少reduction个许可证，是个protected方法。</p></li><li><p><strong>Collection getQueuedThreads()</strong>：返回所有等待获取许可证的线程集合，是个protected方法。</p></li></ul><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic13.png" srcset="/img/loading.gif" class=""><h3 id="用Semaphore实现数据库连接池"><a href="#用Semaphore实现数据库连接池" class="headerlink" title="用Semaphore实现数据库连接池"></a>用Semaphore实现数据库连接池</h3><pre><code>/** *类说明：演示Semaphore用法，一个数据库连接池的实现 */public class DBPoolSemaphore {    private final static int POOL_SIZE = 10;    //两个指示器，分别表示池子还有可用连接和已用连接    private final Semaphore useful, useless;    //存放数据库连接的容器    private static LinkedList&lt;Connection&gt; pool = new LinkedList&lt;Connection&gt;();    //初始化池    static {        for (int i = 0; i &lt; POOL_SIZE; i++) {            pool.addLast(SqlConnectImpl.fetchConnection());        }    }    public DBPoolSemaphore() {        this.useful = new Semaphore(10);        this.useless = new Semaphore(10);    }    /*归还连接*/    public void returnConnect(Connection connection) throws InterruptedException {        if(connection!=null) {            System.out.println(&quot;当前有&quot;+useful.getQueueLength()+&quot;个线程等待数据库连接!!&quot;                    +&quot;可用连接数：&quot;+useful.availablePermits());            useless.acquire();            synchronized (pool) {                pool.addLast(connection);            }            useful.release();        }    }    /*从池子拿连接*/    public Connection takeConnect() throws InterruptedException {        useful.acquire();        Connection connection;        synchronized (pool) {            connection = pool.removeFirst();        }        useless.release();        return connection;    }    private static DBPoolSemaphore dbPool = new DBPoolSemaphore();    private static class BusiThread extends Thread{        @Override        public void run() {            Random r = new Random();//让每个线程持有连接的时间不一样            long start = System.currentTimeMillis();            try {                Connection connect = dbPool.takeConnect();                System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                        +&quot;_获取数据库连接共耗时【&quot;+(System.currentTimeMillis()-start)+&quot;】ms.&quot;);                SleepTools.ms(100+r.nextInt(100));//模拟业务操作，线程持有连接查询数据                System.out.println(&quot;查询数据完成，归还连接！&quot;);                dbPool.returnConnect(connect);            } catch (InterruptedException e) {            }        }    }    public static void main(String[] args) {        for (int i = 0; i &lt; 50; i++) {            Thread thread = new BusiThread();            thread.start();        }    }}</code></pre><h3 id="Semaphore注意事项"><a href="#Semaphore注意事项" class="headerlink" title="Semaphore注意事项"></a>Semaphore注意事项</h3><p>当只有不使用userless控制可归还链接数，在归还链接时，Semaphore允许归还并不是通过线程池获取而是通过其他方式创建的链接，这就会导致Semaphore的数量增加。</p><pre><code>/** *类说明：演示Semaphore用法，一个数据库连接池的实现 */public class DBPoolNoUseless {    private final static int POOL_SIZE = 10;    private final Semaphore useful;    //存放数据库连接的容器    private static LinkedList&lt;Connection&gt; pool = new LinkedList&lt;Connection&gt;();    //初始化池    static {        for (int i = 0; i &lt; POOL_SIZE; i++) {            pool.addLast(SqlConnectImpl.fetchConnection());        }    }    public DBPoolNoUseless() {        this.useful = new Semaphore(10);    }    /*归还连接*/    public void returnConnect(Connection connection) throws InterruptedException {        if(connection!=null) {            System.out.println(&quot;当前有&quot;+useful.getQueueLength()+&quot;个线程等待数据库连接!!&quot;                    +&quot;可用连接数：&quot;+useful.availablePermits());            synchronized (pool) {                pool.addLast(connection);            }            useful.release();        }    }    /*从池子拿连接*/    public Connection takeConnect() throws InterruptedException {        useful.acquire();        Connection connection;        synchronized (pool) {            connection = pool.removeFirst();        }        return connection;    }    private static DBPoolNoUseless dbPoolNoUseless = new DBPoolNoUseless();    private static class BusiThread extends Thread{        @Override        public void run() {            Random r = new Random();//让每个线程持有连接的时间不一样            long start = System.currentTimeMillis();            try {                System.out.println(&quot;Thread_&quot;+Thread.currentThread().getId()                        +&quot;_获取数据库连接共耗时【&quot;+(System.currentTimeMillis()-start)+&quot;】ms.&quot;);                SleepTools.ms(100+r.nextInt(100));//模拟业务操作，线程持有连接查询数据                System.out.println(&quot;查询数据完成，归还连接！&quot;);                dbPoolNoUseless.returnConnect(new SqlConnectImpl());            } catch (InterruptedException e) {            }        }    }    public static void main(String[] args) {        for (int i = 0; i &lt; 50; i++) {            Thread thread = new BusiThread();            thread.start();        }    }}</code></pre><h1 id="Exchange"><a href="#Exchange" class="headerlink" title="Exchange"></a>Exchange</h1><p>Exchanger（交换者）是一个用于线程间协作的工具类。Exchanger用于进行线程间的数据交换。它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过exchange方法交换数据，如果第一个线程先执行exchange()方法，它会一直等待第二个线程也执行exchange()方法，当两个线程都到达同步点时，这两个线程就可以交换数据，将本线程生产出来的数据传递给对方。交换过程由jdk保证线程安全。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic14.png" srcset="/img/loading.gif" class=""><h3 id="用法-2"><a href="#用法-2" class="headerlink" title="用法"></a>用法</h3><pre><code>/** * 类说明：演示CyclicExchange用法 */public class UseExchange {    private static final Exchanger&lt;Set&lt;String&gt;&gt; exchange = new Exchanger&lt;Set&lt;String&gt;&gt;();    public static void main(String[] args) {        new Thread(new Runnable() {            @Override            public void run() {                Set&lt;String&gt; setA = new HashSet&lt;String&gt;();//存放数据的容器                try {                    setA.add(&quot;A&quot;);                    setA = exchange.exchange(setA);//交换set                    System.out.println(&quot;A:&quot; + setA);                    /*处理交换后的数据*/                } catch (InterruptedException e) {                }            }        }).start();        new Thread(new Runnable() {            @Override            public void run() {                Set&lt;String&gt; setB = new HashSet&lt;String&gt;();//存放数据的容器                try {                    setB.add(&quot;B&quot;);                    setB = exchange.exchange(setB);//交换set                    System.out.println(&quot;B:&quot; + setB);                    /*处理交换后的数据*/                } catch (InterruptedException e) {                }            }        }).start();    }}</code></pre><h1 id="Callable、Future和FutureTask"><a href="#Callable、Future和FutureTask" class="headerlink" title="Callable、Future和FutureTask"></a>Callable、Future和FutureTask</h1><p>Runnable是一个接口，在它里面只声明了一个run()方法，由于run()方法返回值为void类型，所以在执行完任务之后无法返回任何结果。</p><p>Callable位于java.util.concurrent包下，它也是一个接口，在它里面也只声明了一个call()方法，这是一个泛型接口，call()函数返回的类型就是传递进来的V类型。 但Callable无法直接交给Thread执行，这时就需要一个类来包装Callable使其能够被Thread类执行。</p><p>RunnableFuture继承了Runnable接口和Future接口所以RunnableFuture接口可以被Thread执行，FutureTask类实现了RunnableFuture接口，所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。</p><p>Future就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。但Future只是一个接口，所以是无法直接用来创建对象使用的，就有了上面的FutureTask。</p><img src="/2019/12/20/%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB/pic15.png" srcset="/img/loading.gif" class=""><p>因此我们通过一个线程运行Callable，但是Thread不支持构造方法中传递Callable的实例，所以我们需要通过FutureTask把一个Callable包装成Runnable，然后再通过这个FutureTask拿到Callable运行后的返回值。</p><h3 id="用法-3"><a href="#用法-3" class="headerlink" title="用法"></a>用法</h3><pre><code>/** * 类说明：演示Future等的使用 */public class UseFuture {    /*实现Callable接口，允许有返回值*/    private static class UseCallable implements Callable&lt;Integer&gt; {        private int sum;        @Override        public Integer call() throws Exception {            System.out.println(&quot;Callable子线程开始计算！&quot;);            for (int i = 0; i &lt; 500; i++) {                if (Thread.currentThread().isInterrupted()) {                    System.out.println(&quot;Callable子线程计算任务中断！&quot;);                    return null;                }                sum = sum + i;            }            System.out.println(&quot;Callable子线程计算结束！结果为: &quot; + sum);            return sum;        }    }    public static void main(String[] args) throws InterruptedException, ExecutionException {        UseCallable useCallable = new UseCallable();        FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(useCallable);        new Thread(futureTask).start();        Random r = new Random();        if (r.nextInt(100) &gt; 50) {            System.out.println(&quot;result = &quot; + futureTask.get());        } else {            System.out.println(&quot;cancel&quot;);            futureTask.cancel(true);        }    }}</code></pre>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线程基础、线程之间的共享和合作</title>
    <link href="/2019/12/17/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B1%E4%BA%AB%E5%92%8C%E5%90%88%E4%BD%9C/"/>
    <url>/2019/12/17/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B1%E4%BA%AB%E5%92%8C%E5%90%88%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><ul><li><strong>CPU核心和线程数的关系</strong>：核心数比线程数一般为1:1，超线程技术1:2</li><li><strong>CPU时间片轮转机制(RR调度)</strong>：古老、简单、公平、应用最广泛的算法。在时间片用完、线程阻塞、线程完成时会剥夺线程cpu使用权。在进行线程调度时会产生上下文切换，上下文切换时需要保存上个线程在寄存器中的数据，同时载入下个线程的数据，这个步骤大约需要5000-20000个cpu时钟周期。如果线程过多导致上下文切换频繁进行，多线程的效率可能不如单线程。</li><li><strong>进程和线程</strong>：进程是程序进行资源分配的最小单位，一个进程可能会有多个线程会共享这个进程的资源。线程是cpu资源调度的最小单位。</li><li><strong>并行和并发</strong>：并行是指同一时刻的处理能力、并发和事件相关是指在单位时间内处理事件的能力。</li><li><strong>高并发编程的意义、好处和注意事项</strong>：提高资源利用效率，但由于共享资源可能存在冲突、死锁，过多的线程还会造成服务器崩溃。</li></ul><h2 id="Java中的线程"><a href="#Java中的线程" class="headerlink" title="Java中的线程"></a>Java中的线程</h2><p>java中的程序天生就是多线程的，线程间的关系为协作式。可以通过虚拟机的线程管理接口查看当前进行的线程。</p><pre><code>public static void main(String[] args) {    ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();    ThreadInfo[] threadInfos=threadMXBean.dumpAllThreads(false, false);    for(ThreadInfo threadInfo:threadInfos){        System.out.println(&quot;[&quot;+threadInfo.getThreadId()+&quot;]&quot;+&quot; &quot;+threadInfo.getThreadName());    }}</code></pre><h3 id="启动线程的方式"><a href="#启动线程的方式" class="headerlink" title="启动线程的方式"></a>启动线程的方式</h3><ol><li>继承Thread类后通过start()方法启动。</li><li>实现Runable接口后通过new Thread(runable).start()启动。</li><li>实现Callable接口之后使用new FutureTask&lt;&gt;(callable)创建task后通过new Thread(task).start()启动，启动后可以通过futureTask的get()方法获取线程返回值，获取返回值时当前线程会阻塞直至task执行结束。</li></ol><p>注：</p><ul><li><p>start()方法会判断线程是否被启动，如果已经被启动会抛出异常。</p></li><li><p>Thread是线程的抽象，Runnable是任务的抽象。</p></li></ul><h3 id="停止线程的方式"><a href="#停止线程的方式" class="headerlink" title="停止线程的方式"></a>停止线程的方式</h3><ol><li>thread中的stop()，resume()，suspend()方法都可以停止线程，但是这三个方法过于强势，stop()无法保证线程资源释放可能导致不可知的错误，suspend()挂起线程时不会释放资源可能导致死锁问题。</li><li>interrupt()可以中断一个线程，并不是强行关闭这个线程，调用interrupt()方法后，讲线程的中断标识为置为true，线程是否停止由线程决定，以此确保每个线程有充足的时间做好后续工作。</li><li>isInterrupted()、interrupted()都可以判断当前线程是否处于中断状态（中断标志位是否为true），但是interrupted()调用之后将中断标识为改为flase。</li><li>如果使用自定义标志位停止线程，如果线程被挂起，标识位的判断就无法进行，但调用interrupt()方法会使中断方法抛出InterruptException，此时可以捕获这个异常，然后进行资源的释放，但要注意抛出异常后interrupt标志位将重新设置为false，如果要中断线程还需要在调用一次interrupt()方法。</li></ol><h3 id="interrupt-的使用示例"><a href="#interrupt-的使用示例" class="headerlink" title="interrupt()的使用示例"></a>interrupt()的使用示例</h3><pre><code>public class Main {    private static class UserThread extends Thread{        public UserThread(String name){            super(name);        }        @Override        public void run() {            String threadName=Thread.currentThread().getName();            while(!isInterrupted()){                System.out.println(threadName);            }            System.out.println(threadName+&quot; interrput flag is &quot;+isInterrupted());        }    }    // 实现Runnable中断的方法    private static class UserThread implements Runnable{        @Override        public void run() {            String threadName=Thread.currentThread().getName();            while(!Thread.currentThread().isInterrupted()){                System.out.println(threadName);            }            System.out.println(threadName+&quot; interrput flag is &quot;+Thread.currentThread().isInterrupted());        }    }    public static void main(String[] args) throws InterruptedException {        Thread endThread=new UserThread(&quot;endThread&quot;);        endThread.start();        Thread.sleep(20L);        endThread.interrupt();    }}</code></pre><p>当线程处于阻塞状态时调用interrupted方法时会抛出InterruptedExcetion异常时，抛出异常后，线程的中断标识为会被复位为false。</p><pre><code>public class Main {    private static class UserThread extends Thread {        public UserThread(String name) {            super(name);        }        @Override        public void run() {            String threadName = Thread.currentThread().getName();            while (!isInterrupted()) {                try {                    Thread.sleep(100);                } catch (InterruptedException e) {                    System.out.println(threadName+&quot; interrput flag is &quot;+isInterrupted());                    interrupt();                    e.printStackTrace();                }                System.out.println(threadName);            }            System.out.println(threadName+&quot; interrput flag is &quot;+isInterrupted());        }    }    public static void main(String[] args) throws InterruptedException {        Thread endThread=new UserThread(&quot;endThread&quot;);        endThread.start();        Thread.sleep(500);        endThread.interrupt();    }}</code></pre><h3 id="线程常用方法和线程的状态"><a href="#线程常用方法和线程的状态" class="headerlink" title="线程常用方法和线程的状态"></a>线程常用方法和线程的状态</h3><img src="/2019/12/17/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B1%E4%BA%AB%E5%92%8C%E5%90%88%E4%BD%9C/pic1.png" srcset="/img/loading.gif" class=""><ul><li><p>线程处于阻塞态时，系统不会进行资源分配。</p></li><li><p>守护线程大多用来支持程序，可以用线程的setDaemon()方法设置，当用户线程停止后，所有的守护线程也将停止。守护线程大多用于资源管理，当用户线程结束后，作为资源管理的守护线程也就没有必要释放资源。操作系统在判定当前线程被结束时就不会分配资源，但也有可能在终止进程关闭时有一段很短的时间使守护线程执行finally中的方法。 守护线程中的finally不一定会执行，用户线程中的finally一定会执行。</p></li><li><p>线程从阻塞态唤醒时会进入就绪态，等待cpu使用权。</p></li><li><p>interrupt()：改变线程中断标识位，对线程的影响取决于开发者对标志位的处理。</p></li><li><p>yield()：让出当前线程的cpu使用权进入就绪态，并参与下次cpu时间片分配。与sleep()方法的区别在于 sleep()是让出线程资源及cpu使用权进入阻塞态，且不会参与时间片分配直至休眠结束。</p></li><li><p>join()：让出当前线程资源及cpu使用权后进入阻塞态，等待join的线程执行完之后唤醒当前线程。</p></li><li><p>setPriority()：设置线程的优先级但不一定会起作用。范围为1-10，有些系统范围为1-3，优先级是否发挥作用完全由操作系统决定。 通常将需要休眠或者io操作比较多的设置高优先级，计算操作设置低优先级，确保处理器时间不会被计算型的线程占据。</p></li><li><p><strong>run()方法和start()方法</strong>：调用run()方法后，run()方法会被打包为栈帧在当前线程所在栈进行入栈，调用start()方法后，虚拟机会创建新的线程，在新线程中调用run()方法，此时打包后的栈帧会在新线程所在的栈进行入栈。</p></li></ul><h3 id="线程间的共享"><a href="#线程间的共享" class="headerlink" title="线程间的共享"></a>线程间的共享</h3><h4 id="synchronized内置锁"><a href="#synchronized内置锁" class="headerlink" title="synchronized内置锁"></a>synchronized内置锁</h4><p>synchronized可以修饰方法或者设置同步块，确保在同一时刻只有一个线程处于同步方法或者同步块中，保证线程对变量访问的可见性和排它性，又称为内置锁机制。</p><h5 id="实例锁和类锁"><a href="#实例锁和类锁" class="headerlink" title="实例锁和类锁"></a>实例锁和类锁</h5><p>实例锁是加在实例对象上的，实例对象是存储在堆上的，每个实例都有自己的堆内存空间，所以不同实例间的实例锁互不影响。实例锁的用法共有三种：锁住类的非静态变量、锁住this对象、直接在非静态方法上加synchronized。类锁是加在类上的，JVM会为每个类创建类对象，类对象是存储在在方法区的，且整个JVM只有一份，所以类锁所有线程共享的。类锁的用法也有三种：锁住类中的静态变量、直接在静态方法上加 synchronized、锁住 xxx.class。</p><h5 id="错误的加锁和原因分析"><a href="#错误的加锁和原因分析" class="headerlink" title="错误的加锁和原因分析"></a>错误的加锁和原因分析</h5><p>通常是在线程执行过程中，锁住的对象被改变，导致加锁的对象并不是同一个。</p><h4 id="volatile关键字"><a href="#volatile关键字" class="headerlink" title="volatile关键字"></a>volatile关键字</h4><p>volatile是<strong>最轻量的同步机制</strong>。volatile保证多个线程对volatile变量的可见性，但不能保证原子性。当一个线程改变了volatile变量的值，改变后的值对其他线程是可见的，但volatile变量在多个线程写的情况下是不安全的，volatile最适用的场景为一写多读。</p><h2 id="ThreadLocal辨析"><a href="#ThreadLocal辨析" class="headerlink" title="ThreadLocal辨析"></a>ThreadLocal辨析</h2><h3 id="与Synchronized的比较"><a href="#与Synchronized的比较" class="headerlink" title="与Synchronized的比较"></a>与Synchronized的比较</h3><p>ThreadLocal和Synchonized都用于解决多线程并发访问，ThreadLocal与synchronized有本质的差别。synchronized是利用锁的机制，使变量或代码块在某一时该仅仅能被一个线程访问，而ThreadLocal为每个线程都提供了变量的副本，使得每个线程在某一时间访问到的并非同一个对象，相当于就隔离了多个线程的数据共享。</p><p>spring事务就借助了ThreadLocal类来实现。jdbc事务是以对connection的操作为整体，tomcat会为每一次请求创建一个单独的线程，spring事务使用ThreadLocal保证每一个线程的connection都互不影响，这样就保证每个请求对数据库所有的操作在不同的connection中进行，从而保证事务的边界。</p><h3 id="ThreadLocal的使用"><a href="#ThreadLocal的使用" class="headerlink" title="ThreadLocal的使用"></a>ThreadLocal的使用</h3><p>ThreadLocal类接口很简单，只有4个方法</p><ul><li><p><strong>void set(Object value)</strong> ：设置当前线程的线程局部变量的值。</p></li><li><p><strong>public Object get()</strong> ：返回当前线程所对应的线程局部变量。</p></li><li><p><strong>public void remove()</strong> ：将当前线程局部变量的值删除，目的是为了减少内存的占用，该方法是JDK 5.0新增的方法。需要指出的是，当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显式调用该方法清除线程的局部变量并不是必须的操作，但它可以加快内存回收的速度。</p></li><li><p><strong>protected Object initialValue()</strong>： 返回该线程局部变量的初始值，该方法是一个protected的方法，显然是为了让子类覆盖而设计的。这个方法是一个延迟调用方法，在线程第1次调用get()或set(Object)时才执行，并且仅执行1次。ThreadLocal中的缺省实现直接返回一个null。</p></li><li><p><strong>public final static ThreadLocal<String> RESOURCE = new ThreadLocal<String>();</strong>RESOURCE代表一个能够存放String类型的ThreadLocal对象。此时不论什么一个线程能够并发访问这个变量，对它进行写入、读取操作，都是线程安全的。</p></li></ul><h3 id="实现解析"><a href="#实现解析" class="headerlink" title="实现解析"></a>实现解析</h3><img src="/2019/12/17/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B1%E4%BA%AB%E5%92%8C%E5%90%88%E4%BD%9C/pic2.png" srcset="/img/loading.gif" class=""><p>Thread中有一个ThreadLocalMap对象，ThreadLocalMap是ThreadLocal的静态内部类，存储的对象为Entry类型的数组，Entry类型的键为ThreadLocal对象，值为ThreadLocal对象的值，ThreadLocal的get方法会获取当前Thread，然后调用getMap()获取当前Thread的ThreadLocalMap，再从ThreadLocalMap中通过ThreadLocal找到对应的值。</p><h3 id="引发的内存泄露分析"><a href="#引发的内存泄露分析" class="headerlink" title="引发的内存泄露分析"></a>引发的内存泄露分析</h3><h4 id="jvm中的引用类型"><a href="#jvm中的引用类型" class="headerlink" title="jvm中的引用类型"></a>jvm中的引用类型</h4><p><strong>强引用：</strong>常用的Object o = new Object()就是强引用，在线程中执行方法时， 方法会被打包为栈帧在栈上运行，方法中创建的对象实例存储在在堆上，而方法中对象的命名指向堆上的实例，这就是引用（类似于c++的指针）。当强引用存在时即栈上有一个引用指向堆中的对象实例，gc就不会回收该对象实例。</p><p><strong>软引用：</strong>用来描述一些还有用但并非必需的对象。将要发生内存溢出时，会把软引用对象实例列入回收范围，进入第二次回收。如果回收之后还是没有足够的内存才会抛出内存溢出异常。在JDK 1.2之后，提供了SoftReference类来实现软引用。</p><p><strong>弱饮用</strong>：用来描述非必需对象的，强度低于软引用，只要发生垃圾回收，弱引用指向的对象实例就一定会被回收掉，不管是否将要发生内存溢出。在JDK 1.2之后，提供了WeakReference类来实现弱引用。</p><p><strong>虚引用</strong>：也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象实例是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象实例被收集器回收时收到一个系统通知。在JDK 1.2之后，提供了PhantomReference类来实现虚引用。</p><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><img src="/2019/12/17/%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E3%80%81%E7%BA%BF%E7%A8%8B%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B1%E4%BA%AB%E5%92%8C%E5%90%88%E4%BD%9C/pic3.png" srcset="/img/loading.gif" class=""><p>Thread维护的ThreadLocalMap中的Entry的key使用的是ThreadLocal的的弱引用 ，方法执行完出栈后，threadLocal变量会被置为null，此时强引用消失，没有强引用指向ThreadLocal实例，ThreadLocal会被gc回收即Entry中的key被回收，但Thread对ThreadLocalMap的应用是强引用，所以Entry中的value会依然存在，这就有可能造成内存泄漏。只有当前thread结束以后，ThreadLocalMap强引用断开才会被GC回收。</p><p>jdk对此提供了相应的补偿机制，ThreadLocal的get()，set()有可能会去调用expungeStaleEntry()，replaceStaleEntry()方法去清除key为null（ThreadLocal为null）的value值。但最好还是在使用完threadLocal变量后，手动调用它的remove()方法清除数据。</p><p>如果对key的引用为强引用的话，set()，get()方法中对Model的释放就一定不会触发，必然会造成内存泄漏。</p><h3 id="ThreadLocal线程不安全"><a href="#ThreadLocal线程不安全" class="headerlink" title="ThreadLocal线程不安全"></a>ThreadLocal线程不安全</h3><p> 当多个线程的ThreadLocalMap的value保存的是同一个对象实例的引用时，线程通过这个引用对对象实例做修改，也同样会影响了其他线程中引用的这个对象实例。显然要避免ThreadLocal线程不安全就应该让每个线程中的ThreadLocal都应该持有一个新的对象。</p><h2 id="线程间的协作"><a href="#线程间的协作" class="headerlink" title="线程间的协作"></a>线程间的协作</h2><p>是指线程之间相互配合，完成某项工作。如一个线程对对象做了初步处理，另一个线程感知到初步处理完成，然后进行下一步的处理。整个过程开始于一个线程，而继续执行又是另一个线程。相对而言，前者是生产者，后者就是消费者，简单的办法是让消费者线程轮询检查变量是否符合预期，如果条件满足则退出循环，从而完成消费者的工作。但如果要确保及时性就要缩短轮询的间隔，就会不可避免的消耗更多资源。</p><h3 id="等待和通知"><a href="#等待和通知" class="headerlink" title="等待和通知"></a>等待和通知</h3><p> 是指一个线程调用Object的wait()方法后，释放占有的资源进入阻塞态，另一个线程调用Object的notify()或者notifyAll()之后阻塞的线程被唤醒，但notify()和notifyAll()不会立即释放锁，而是等待之后的业务代码执行完之后才会释放锁，阻塞的线程被唤醒之后继续执行后续操作。上述两个线程必须通过一个Object进行操作完成交互，而wait()和notify()用来构建等待方和通知方的通信。</p><ul><li><p>notify()：随机通知一个在对象上等待的线程，使其结束wait()。返回的前提是该线程获取到了对象的锁，没有获得锁的线程重新进入阻塞态。</p></li><li><p>notifyAll()：通知所有等待在该对象上的线程。</p></li><li><p>wait()：调用该方法的线程进入阻塞态，调用wait()方法后,会释放对象的锁。</p></li><li><p>wait(long)：设置一个最大等待时长，如果n毫秒之后没有通知，就会自动唤醒等待锁。</p></li><li><p>wait (long,int)：对于超时时间更细粒度的控制，可以达到纳秒。</p></li></ul><h4 id="等待标准范式"><a href="#等待标准范式" class="headerlink" title="等待标准范式"></a>等待标准范式</h4><pre><code>synchronized(对象){    while(预期不满足){        对象.wait();    }}</code></pre><h4 id="通知标准范式"><a href="#通知标准范式" class="headerlink" title="通知标准范式"></a>通知标准范式</h4><pre><code>synchronized(对象){    //业务逻辑，改变条件    对象.notify()/notifyAll();}</code></pre><p>在调用wait()、notify()系列方法之前，线程必须要获得该对象的对象级别锁，即只能在同步方法或同步块中调用wait()、notify()。进入wait()方法后，当前线程释放锁，在从wait()返回前，线程与其他线程竞争重新获得锁。执行notify()系列方法的线程退出后，释放对象锁，其他线程就回去竞争对象锁。如果其中一个线程获得了该对象锁，它就会继续往下执行，在它退出synchronized代码块，释放锁后，其他的已经被唤醒的线程将会继续竞争获取该锁，一直进行下去，直到所有被唤醒的线程都执行完毕。</p><h4 id="notify和notifyAll应该用谁"><a href="#notify和notifyAll应该用谁" class="headerlink" title="notify和notifyAll应该用谁"></a>notify和notifyAll应该用谁</h4><p>尽可能用notifyAll()，谨慎使用notify()，因为notify()只会唤醒一个线程，我们无法确保被唤醒的这个线程一定就是需要唤醒的线程</p><h4 id="等待超时模式实现-一个连接池"><a href="#等待超时模式实现-一个连接池" class="headerlink" title="等待超时模式实现 一个连接池"></a>等待超时模式实现 一个连接池</h4><p>DBPool.java</p><pre><code>package cn.enjoyedu.ch1.pool;import java.sql.Connection;import java.util.LinkedList;/** *类说明：连接池的实现 */public class DBPool {    /*容器，存放连接*/    private static LinkedList&lt;Connection&gt; pool = new LinkedList&lt;Connection&gt;();    /*限制了池的大小=20*/    public DBPool(int initialSize) {        if (initialSize &gt; 0) {            for (int i = 0; i &lt; initialSize; i++) {                pool.addLast(SqlConnectImpl.fetchConnection());            }        }    }    /*释放连接,通知其他的等待连接的线程*/    public void releaseConnection(Connection connection) {        if (connection != null) {            synchronized (pool){                pool.addLast(connection);                //通知其他等待连接的线程                pool.notifyAll();            }        }    }    /*获取*/    // 在mills内无法获取到连接，将会返回null 1S    public Connection fetchConnection(long mills)            throws InterruptedException {        synchronized (pool){            //永不超时            if(mills&lt;=0){                while(pool.isEmpty()){                    pool.wait();                }                return pool.removeFirst();            }else{                /*超时时刻*/                long future = System.currentTimeMillis()+mills;                /*等待时长*/                long remaining = mills;                while(pool.isEmpty()&amp;&amp;remaining&gt;0){                    pool.wait(remaining);                    /*唤醒一次，重新计算等待时长*/                    remaining = future-System.currentTimeMillis();                }                Connection connection = null;                if(!pool.isEmpty()){                    connection = pool.removeFirst();                }                return connection;            }        }    }}</code></pre><p>DBPoolTest.java</p><pre><code>package cn.enjoyedu.ch1.pool;import java.sql.Connection;import java.util.concurrent.CountDownLatch;import java.util.concurrent.atomic.AtomicInteger;/** *类说明： */public class DBPoolTest {    static DBPool pool  = new DBPool(10);    // 控制器:控制main线程将会等待所有Woker结束后才能继续执行    static CountDownLatch end;    public static void main(String[] args) throws Exception {        // 线程数量        int threadCount = 50;        end = new CountDownLatch(threadCount);        int count = 20;//每个线程的操作次数        AtomicInteger got = new AtomicInteger();//计数器：统计可以拿到连接的线程        AtomicInteger notGot = new AtomicInteger();//计数器：统计没有拿到连接的线程        for (int i = 0; i &lt; threadCount; i++) {            Thread thread = new Thread(new Worker(count, got, notGot),                     &quot;worker_&quot;+i);            thread.start();        }        end.await();// main线程在此处等待        System.out.println(&quot;总共尝试了: &quot; + (threadCount * count));        System.out.println(&quot;拿到连接的次数：  &quot; + got);        System.out.println(&quot;没能连接的次数： &quot; + notGot);    }    static class Worker implements Runnable {        int           count;        AtomicInteger got;        AtomicInteger notGot;        public Worker(int count, AtomicInteger got,                               AtomicInteger notGot) {            this.count = count;            this.got = got;            this.notGot = notGot;        }        public void run() {            while (count &gt; 0) {                try {                    // 从线程池中获取连接，如果1000ms内无法获取到，将会返回null                    // 分别统计连接获取的数量got和未获取到的数量notGot                    Connection connection = pool.fetchConnection(1000);                    if (connection != null) {                        try {                            connection.createStatement();//                            PreparedStatement preparedStatement//                                    = connection.prepareStatement(&quot;&quot;);//                            preparedStatement.execute();                            connection.commit();                        } finally {                            pool.releaseConnection(connection);                            got.incrementAndGet();                        }                    } else {                        notGot.incrementAndGet();                        System.out.println(Thread.currentThread().getName()                                +&quot;等待超时!&quot;);                    }                } catch (Exception ex) {                } finally {                    count--;                }            }            end.countDown();        }    }}</code></pre><h4 id="调用yield-，sleep-，wait-，notify-notifyAll-方法对锁的影响"><a href="#调用yield-，sleep-，wait-，notify-notifyAll-方法对锁的影响" class="headerlink" title="调用yield()，sleep()，wait()，notify()/notifyAll()方法对锁的影响"></a>调用yield()，sleep()，wait()，notify()/notifyAll()方法对锁的影响</h4><p>yield()调用之后只是让出cpu使用权进入就绪态，sleep()不会释放任何资源包括cpu使用权，所以yield()跟sleep()都不会释放锁，wait()方法被调用之后会释放当前线程所持有的所有资源进入阻塞态，等待唤醒，当线程被唤醒之后会去竞争锁，竞争到锁之后才会去继续执行。notify()也不会释放锁，而是等notify()/notifyAll()所在的同步代码块执行完之后才会释放锁，所以notify()/notifyAll()通常在同步代码块的最后一行。</p>]]></content>
    
    
    <categories>
      
      <category>并发编程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>并发编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>springboot2+shiro+token认证</title>
    <link href="/2019/12/13/springboot2-shiro-token%E8%AE%A4%E8%AF%81/"/>
    <url>/2019/12/13/springboot2-shiro-token%E8%AE%A4%E8%AF%81/</url>
    
    <content type="html"><![CDATA[<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>从shiro过滤器的源码中可以看到，shiro过滤器拦截请求之后会调用isAccessAllowed()和onAccessDenied()方法，只要其中一个方法返回true，这次请求就会被放行。本文的实现方法是在onAccessDenied()中的执行登录验证即执行executeLogin()方法，这个方法会去执行AuthorizingRealm中的doGetAuthenticationInfo()方法，所以我们只需要在doGetAuthenticationInfo()里实现token的合法性检查，而doGetAuthenticationInfo()中需要AuthenticationToken类，这个类一般是存用户的用户名和密码，所以要重写这个类，把等待验证的token放入这个类，在executeLogin()方法会调用shiro过滤器中的createToken()方法创建AuthenticationToken实例，所以我们只需要重写createToken()方法创建带有token的重写之后的AuthenticationToken类即可。如果验证失败，因为我们是在executeLogin()方法中执行的登录，所以登录失败后会进入shiro过滤器中的onLoginFailure()方法，我们再重写这个方法，将验证失败的结果写入response就可以实现返回json而不是shiro默认的重定向到登录页。</p><p>多点登录限制是借助于redis实现，在用户登录时会将用户id作为键，当前token作为值存入redis中，在验证时获取token中的用户id，然后根据用户id去取redis中的token后对比，如果不同则当前token已经失效，提醒用户重新登录。</p><h2 id="pom文件"><a href="#pom文件" class="headerlink" title="pom文件"></a>pom文件</h2><pre><code>        &lt;!--shiro--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt;            &lt;artifactId&gt;shiro-core&lt;/artifactId&gt;            &lt;version&gt;1.4.0&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt;            &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt;            &lt;version&gt;1.4.0&lt;/version&gt;        &lt;/dependency&gt;        &lt;!--jwt--&gt;        &lt;dependency&gt;            &lt;groupId&gt;com.auth0&lt;/groupId&gt;            &lt;artifactId&gt;java-jwt&lt;/artifactId&gt;            &lt;version&gt;3.3.0&lt;/version&gt;        &lt;/dependency&gt;        &lt;!--redis--&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;        &lt;/dependency&gt;</code></pre><h2 id="重写shiro过滤器"><a href="#重写shiro过滤器" class="headerlink" title="重写shiro过滤器"></a>重写shiro过滤器</h2><pre><code>import com.alibaba.fastjson.JSON;import com.minte.english.security.common.utils.JwtUtil;import com.minte.english.security.common.utils.R;import org.apache.commons.lang3.StringUtils;import org.apache.shiro.authc.AuthenticationException;import org.apache.shiro.authc.AuthenticationToken;import org.apache.shiro.web.filter.authc.AuthenticatingFilter;import org.springframework.web.bind.annotation.RequestMethod;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;public class OAuth2Filter extends AuthenticatingFilter {    @Override    protected AuthenticationToken createToken(ServletRequest request, ServletResponse response) throws Exception {        //获取请求token        String token = JwtUtil.getRequestToken((HttpServletRequest) request);        if(StringUtils.isBlank(token)){            return null;        }        return new OAuth2Token(token);    }    @Override    protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) {        if(((HttpServletRequest) request).getMethod().equals(RequestMethod.OPTIONS.name())){            return true;        }        return false;    }    @Override    protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception {        //获取请求token，如果token不存在，直接返回401        String token = JwtUtil.getRequestToken((HttpServletRequest) request);        if(StringUtils.isBlank(token)){            HttpServletResponse httpResponse = (HttpServletResponse) response;            httpResponse.setHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;);            String json = JSON.toJSONString(R.failed(&quot;false&quot;, &quot;获取token信息失败&quot;));            httpResponse.getWriter().print(json);            return false;        }        return executeLogin(request, response);    }    @Override    protected boolean onLoginFailure(AuthenticationToken token, AuthenticationException e, ServletRequest request, ServletResponse response) {        HttpServletResponse httpResponse = (HttpServletResponse) response;        httpResponse.setContentType(&quot;application/json;charset=utf-8&quot;);        try {            //处理登录失败的异常            Throwable throwable = e.getCause() == null ? e : e.getCause();            R r = R.reLogin(throwable.getMessage());            String json = JSON.toJSONString(r);            httpResponse.getWriter().print(json);        } catch (IOException e1) {        }        return false;    }}</code></pre><h2 id="重写AuthorizingRealm"><a href="#重写AuthorizingRealm" class="headerlink" title="重写AuthorizingRealm"></a>重写AuthorizingRealm</h2><pre><code>import com.auth0.jwt.exceptions.TokenExpiredException;import com.minte.english.security.common.utils.JwtUtil;import com.minte.english.security.module.sys.redis.UserRedis;import com.minte.english.security.module.user.pojo.Role;import com.minte.english.security.module.user.pojo.User;import com.minte.english.security.module.user.service.IRoleService;import com.minte.english.security.module.user.service.IUserRoleService;import org.apache.shiro.authc.*;import org.apache.shiro.authc.pam.UnsupportedTokenException;import org.apache.shiro.authz.AuthorizationInfo;import org.apache.shiro.authz.SimpleAuthorizationInfo;import org.apache.shiro.authz.UnauthenticatedException;import org.apache.shiro.realm.AuthorizingRealm;import org.apache.shiro.subject.PrincipalCollection;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import java.io.UnsupportedEncodingException;import java.util.Arrays;import java.util.HashSet;import java.util.Set;@Componentpublic class OAuth2Realm extends AuthorizingRealm {    @Autowired    private IUserRoleService userRoleService;    @Autowired    private IRoleService roleService;    @Autowired    private UserRedis userRedis;    @Override    public boolean supports(AuthenticationToken token) {        return token instanceof OAuth2Token;    }    /**     * 授权(验证权限时调用)     */    @Override    protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) {        User user = (User) principals.getPrimaryPrincipal();        Long userId = user.getId();        Integer roleId = userRoleService.getRoleIdByUserId(userId);        Role role = roleService.getById(roleId);        //用户权限列表        Set&lt;String&gt; permsSet = new HashSet&lt;&gt;(Arrays.asList(role.getPermissions().split(&quot;,&quot;)));        SimpleAuthorizationInfo info = new SimpleAuthorizationInfo();        info.setStringPermissions(permsSet);        return info;    }    /**     * 认证(登录时调用)     */    @Override    protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException {        String accessToken = (String) token.getPrincipal();        // 验证token信息        try {            JwtUtil.verify(accessToken);        } catch (TokenExpiredException e) {            throw new ExpiredCredentialsException();        } catch (UnsupportedEncodingException e) {            throw new UnsupportedTokenException(&quot;token已失效&quot;);        }        // 检测是否在其他设备登录        Long userId = JwtUtil.getUserId(accessToken);        String onlineToken = userRedis.getOnlineUserToken(userId);        if (!onlineToken.equals(accessToken)) {            throw new ConcurrentAccessException(&quot;该账号已在其他设备登录&quot;);        }        // 检查用户授权天数，是否被冻结        User user = userRedis.get(accessToken);        if (user.getValidityDays() &lt;= 0) {            throw new UnauthenticatedException(&quot;授权天数不足&quot;);        }        //账号锁定        if (!user.getEnabled()) {            throw new DisabledAccountException(&quot;该账号已被禁用&quot;);        }        SimpleAuthenticationInfo info = new SimpleAuthenticationInfo(user, accessToken, getName());        return info;    }}</code></pre><h2 id="Config类"><a href="#Config类" class="headerlink" title="Config类"></a>Config类</h2><pre><code>@Configurationpublic class ShiroConfig {    @Bean(&quot;securityManager&quot;)    public SecurityManager securityManager(OAuth2Realm oAuth2Realm) {        DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager();        securityManager.setRealm(oAuth2Realm);        securityManager.setRememberMeManager(null);        return securityManager;    }    /**     * setUsePrefix(false)用于解决一个奇怪的bug。在引入spring aop的情况下。     * 在@Controller注解的类的方法中加入@RequiresRole注解，会导致该方法无法映射请求，导致返回404。 加入这项配置能解决这个bug     * 在使用@Transaction注解时出现无法注入bug解决     *     * @return     */    @Bean    public static DefaultAdvisorAutoProxyCreator getDefaultAdvisorAutoProxyCreator() {        DefaultAdvisorAutoProxyCreator creator = new DefaultAdvisorAutoProxyCreator();        creator.setProxyTargetClass(true);        creator.setUsePrefix(false);        return creator;    }    @Bean(&quot;shiroFilter&quot;)    public ShiroFilterFactoryBean shirFilter(SecurityManager manager) {        ShiroFilterFactoryBean shiroFilterFactory = new ShiroFilterFactoryBean();        shiroFilterFactory.setSecurityManager(manager);        Map&lt;String, Filter&gt; filterMap = shiroFilterFactory.getFilters();        filterMap.put(&quot;oauth2&quot;, new OAuth2Filter());        shiroFilterFactory.setFilters(filterMap);        Map&lt;String, String&gt; filterChainDefinitionMap = new LinkedHashMap&lt;&gt;();        filterChainDefinitionMap.put(&quot;/login&quot;, &quot;anon&quot;);        filterChainDefinitionMap.put(&quot;/actuator&quot;, &quot;anon&quot;);        filterChainDefinitionMap.put(&quot;/actuator/**&quot;, &quot;anon&quot;);        filterChainDefinitionMap.put(&quot;/validate/**&quot;, &quot;anon&quot;);        filterChainDefinitionMap.put(&quot;/user/getByUsername&quot;, &quot;anon&quot;);        filterChainDefinitionMap.put(&quot;/**&quot;, &quot;oauth2&quot;);        shiroFilterFactory.setFilterChainDefinitionMap(filterChainDefinitionMap);        return shiroFilterFactory;    }    @Bean(&quot;lifecycleBeanPostProcessor&quot;)    public LifecycleBeanPostProcessor lifecycleBeanPostProcessor() {        return new LifecycleBeanPostProcessor();    }    @Bean    public AuthorizationAttributeSourceAdvisor authorizationAttributeSourceAdvisor(SecurityManager securityManager) {        AuthorizationAttributeSourceAdvisor advisor = new AuthorizationAttributeSourceAdvisor();        advisor.setSecurityManager(securityManager);        return advisor;    }}</code></pre><h2 id="重写AuthenticationToken类"><a href="#重写AuthenticationToken类" class="headerlink" title="重写AuthenticationToken类"></a>重写AuthenticationToken类</h2><pre><code>import org.apache.shiro.authc.AuthenticationToken;/** * token * * @author Mark sunlightcs@gmail.com */public class OAuth2Token implements AuthenticationToken {    private String token;    public OAuth2Token(String token){        this.token = token;    }    @Override    public String getPrincipal() {        return token;    }    @Override    public Object getCredentials() {        return token;    }}</code></pre><h2 id="userRedis的配置"><a href="#userRedis的配置" class="headerlink" title="userRedis的配置"></a>userRedis的配置</h2><pre><code>import com.minte.english.security.common.utils.JwtUtil;import com.minte.english.security.common.utils.RedisKeys;import com.minte.english.security.common.utils.RedisUtil;import com.minte.english.security.module.sys.service.ISysConfigService;import com.minte.english.security.module.user.pojo.User;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;/** * @author zgc * @since 2019/12/5 */@Componentpublic class UserRedis {    @Autowired    private RedisUtil redisUtil;    @Autowired    private ISysConfigService sysConfigService;    public void saveOrUpdate(User user, String token) {        String imgPath = sysConfigService.getValue(&quot;ICON_PATH&quot;) + user.getImagePath();        user.setImagePath(imgPath);        redisUtil.set(RedisKeys.getUserKey(token), user, JwtUtil.getExpiresTime(token));    }    public void delete(String token) {        redisUtil.delete(RedisKeys.getUserKey(token));    }    public User get(String token) {        return redisUtil.get(RedisKeys.getUserKey(token), User.class);    }    public void saveOrUpdateOnlineUser(Long userId, String token) {        redisUtil.set(RedisKeys.getOnlineUserKey(userId), token, JwtUtil.getExpiresTime(token));    }    public String getOnlineUserToken(Long userId) {        return redisUtil.get(RedisKeys.getOnlineUserKey(userId), String.class);    }    public void deleteOnlineUser(Long userId, String token) {        if (getOnlineUserToken(userId).equals(token)) {            redisUtil.delete(RedisKeys.getOnlineUserKey(userId));        }    }    public boolean isOnline(Long userId) {        return userId == null ? false : redisUtil.containsKey(RedisKeys.getOnlineUserKey(userId));    }    public void update(User user) {        Long userId = user.getId();        if (isOnline(userId)) {            String token = getOnlineUserToken(userId);            saveOrUpdate(user, token);        }    }}</code></pre><h2 id="Shiro的异常"><a href="#Shiro的异常" class="headerlink" title="Shiro的异常"></a>Shiro的异常</h2><ul><li>AuthenticationException:身份验证异常<ul><li>CredentitalsException:凭证异常<ul><li>IncorrectCredentialsException:不支持的凭证</li><li>ExpiredCredentialsException:凭证过期</li></ul></li><li>AccountException:账号异常<ul><li>ConcurrentAccessException:并发访问异常</li><li>UnknownAccountException:未知的账号</li><li>ExcessiveAttemptsException:认证次数超限</li><li>DisabledAccountException:账号被禁用</li><li>LockedAccountException:账号被锁定</li></ul></li><li>UnsupportedTokenException:Token异常</li></ul></li><li>AuthorizationException:授权异常<ul><li>UnauthorizedException:抛出以指示请求的操作或对请求的资源的访问是不允许的</li><li>UnanthenticatedException:当尚未完成成功认证时，尝试执行授权操作时引发异常</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>shiro</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>shiro</tag>
      
      <tag>token</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ajax跨域访问shiro问题</title>
    <link href="/2019/12/06/ajax%E8%B7%A8%E5%9F%9F%E8%AE%BF%E9%97%AEshiro%E9%97%AE%E9%A2%98/"/>
    <url>/2019/12/06/ajax%E8%B7%A8%E5%9F%9F%E8%AE%BF%E9%97%AEshiro%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1 id="ajax跨域访问shiro问题"><a href="#ajax跨域访问shiro问题" class="headerlink" title="ajax跨域访问shiro问题"></a>ajax跨域访问shiro问题</h1><p>因为之前的ssm项目要做一次迭代，将前后端不分离改为前后端分离，但是做了跨域设置之后登录可以成功，但其他接口仍然访问不到，前端控制台报错为跨域错误：预请求被重定向。既然登录访问可以成功，说明跨域已经成功，但依然访问不到登录其他接口应该是shiro的问题。查看代码后发现，之前的shiro并没有对预请求进行处理，而且也没有做cookie的跨域，因为shiro所需要的sessionId依赖于cookie或url中的sessionId，但前端没有对sessionId进行处理，cookie也不允许跨域，shiro依然会对登录成功之后的请求进行拦截。所以这次要解决两个问题</p><ol><li>shiro过滤器中放行预请求</li><li>做关于cookie跨域的设置</li></ol><h2 id="ajax参考"><a href="#ajax参考" class="headerlink" title="ajax参考"></a>ajax参考</h2><pre><code>$.ajax({    url:url,    data:{        unitId:&quot;801&quot;    },    // 允许携带cookie跨域    crossDomain: true,     xhrFields:{              withCredentials:true          },    type:&quot;GET&quot;,    success:function(data){        console.log(data);    }})</code></pre><h2 id="后端跨域处理"><a href="#后端跨域处理" class="headerlink" title="后端跨域处理"></a>后端跨域处理</h2><p>因为项目为ssm项目，所以跨域的处理使用filter实现</p><ol><li>添加跨域cookie后，Allow-Origin不能设置为*</li><li>Allow-Method根据情况而定</li></ol><pre><code>@WebFilter(&quot;/*&quot;)public class CORSFilter implements Filter {    public CORSFilter() {    }    public void destroy() {    }    public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException, ServletException {        //设置跨域请求        response.setHeader(&quot;Access-Control-Allow-Headers&quot;, &quot;x-requested-with&quot;);        response.setHeader(&quot;Access-Control-Allow-Method&quot;, &quot;POST, GET, OPTIONS&quot;);        response.setHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;http://localhost:8090&quot;);        response.setHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;);        filterChain.doFilter(request, response);        chain.doFilter(req, response);    }    public void init(FilterConfig fConfig) throws ServletException {    }}</code></pre><h2 id="重写shiro过滤器"><a href="#重写shiro过滤器" class="headerlink" title="重写shiro过滤器"></a>重写shiro过滤器</h2><p>配置中没有定义自己的shiro过滤器，所以都是默认过滤器</p><table><thead><tr><th>Filter Name</th><th>Class</th></tr></thead><tbody><tr><td>anon</td><td>org.apache.shiro.web.filter.authc.AnonymousFilter</td></tr><tr><td>authc</td><td>org.apache.shiro.web.filter.authc.FormAuthenticationFilter</td></tr><tr><td>authcBasic</td><td>org.apache.shiro.web.filter.authc.BasicHttpAuthenticationFilter</td></tr><tr><td>perms</td><td>org.apache.shiro.web.filter.authz.PermissionsAuthorizationFilter</td></tr><tr><td>port</td><td>org.apache.shiro.web.filter.authz.PortFilter</td></tr><tr><td>rest</td><td>org.apache.shiro.web.filter.authz.HttpMethodPermissionFilter</td></tr><tr><td>roles</td><td>org.apache.shiro.web.filter.authz.RolesAuthorizationFilter</td></tr><tr><td>ssl</td><td>org.apache.shiro.web.filter.authz.SslFilter</td></tr><tr><td>user</td><td>org.apache.shiro.web.filter.authc.UserFilter</td></tr></tbody></table><p>根据以上表格，我们需要重写FormAuthenticationFilter及RolesAuthorizationFilter</p><p>FormAuthenticationFilter</p><pre><code>package com.yaoxx.base.shiro;import java.io.PrintWriter;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.apache.commons.lang3.StringUtils;import org.apache.shiro.web.filter.authc.FormAuthenticationFilter;import org.apache.shiro.web.util.WebUtils;import org.springframework.http.HttpStatus;public class MyAuthenticationFilter extends FormAuthenticationFilter {   @Override   protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) {       boolean allowed = super.isAccessAllowed(request, response, mappedValue);       if (!allowed) {           // 判断请求是否是options请求           String method = WebUtils.toHttp(request).getMethod();           if (StringUtils.equalsIgnoreCase(&quot;OPTIONS&quot;, method)) {               return true;           }       }       return allowed;   }   @Override   protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception {   // 判断是否登录       if (isLoginRequest(request, response)) {          // 判断是否为post访问           if (isLoginSubmission(request, response)) {                return executeLogin(request, response);           } else {               // sessionID已经注册,但是并没有使用post方式提交               return true;           }       } else {           HttpServletRequest req = (HttpServletRequest) request;           HttpServletResponse resp = (HttpServletResponse) response;           String ajaxHeader = req.getHeader(CustomSessionManager.AUTHORIZATION);           if (StringUtils.isNotBlank(ajaxHeader)) {               // 前端Ajax请求，则不会重定向               resp.setHeader(&quot;Access-Control-Allow-Origin&quot;, req.getHeader(&quot;Origin&quot;));               resp.setHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;);               resp.setContentType(&quot;application/json; charset=utf-8&quot;);               resp.setCharacterEncoding(&quot;UTF-8&quot;);               //设置未登录状态码               resp.setStatus(HttpStatus.UNAUTHORIZED.value());               PrintWriter out = resp.getWriter();               String result = &quot;{\&quot;MESSAGE\&quot;:\&quot;未登录用户\&quot;}&quot;;               out.println(result);               out.flush();               out.close();           } else {               // == 如果是普通访问重定向至shiro配置的登录页面 == //               saveRequestAndRedirectToLogin(request, response);           }       }       return false;   }}</code></pre><p>RolesAuthorizationFilter</p><pre><code>package com.yaoxx.base.shiro;import java.io.IOException;import java.io.PrintWriter;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.apache.commons.lang3.StringUtils;import org.apache.shiro.web.filter.authz.RolesAuthorizationFilter;import org.apache.shiro.web.util.WebUtils;import org.springframework.http.HttpStatus;import org.springframework.web.bind.annotation.RequestMethod;public class MyAuthorizationFilter extends RolesAuthorizationFilter {   @Override   public boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue)throws IOException {       boolean allowed =super.isAccessAllowed(request, response, mappedValue);       if (!allowed) {           String method = WebUtils.toHttp(request).getMethod();           if (StringUtils.equalsIgnoreCase(&quot;OPTIONS&quot;, method)) {               return true;           }       }       return allowed;   }   @Override   protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws IOException {       HttpServletRequest req = (HttpServletRequest) request;       HttpServletResponse resp = (HttpServletResponse) response;       // 前端Ajax请求时requestHeader里面带一些参数，用于判断是否是前端的请求       String ajaxHeader = req.getHeader(CustomSessionManager.AUTHORIZATION);       if (StringUtils.isNotBlank(ajaxHeader)) {           // 前端Ajax请求，则不会重定向           resp.setHeader(&quot;Access-Control-Allow-Origin&quot;, req.getHeader(&quot;Origin&quot;));           resp.setHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;);           resp.setContentType(&quot;application/json; charset=utf-8&quot;);           resp.setCharacterEncoding(&quot;UTF-8&quot;);           PrintWriter out = resp.getWriter();           String result = &quot;{\&quot;MESSAGE\&quot;:\&quot;角色，权限不足\&quot;}&quot;;           out.println(result);           out.flush();           out.close();           return false;       }       return super.onAccessDenied(request, response);   }}</code></pre>]]></content>
    
    
    <categories>
      
      <category>shiro</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>shiro</tag>
      
      <tag>bug</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>summernote文本编辑器的使用</title>
    <link href="/2019/08/26/summernote%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2019/08/26/summernote%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>summernote是一款Jquery文本编辑器的插件，本文只是简单的实现文本编辑及图片上传下载功能，更多api请参考<a href="https://summernote.org/getting-started/" target="_blank" rel="noopener">summernote官方文档</a></p><h2 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h2><p>summernote依赖于bootstrap和jquery所以也需要引入bootstrap和jquery</p><pre><code>&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;/assets/css/lib/bootstrap.min.css&quot; &gt;&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;/css/summernote.css&quot;&gt;&lt;script src=&quot;/assets/js/lib/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;/assets/js/lib/bootstrap.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;/js/summernote.js&quot;&gt;&lt;/script&gt;</code></pre><h2 id="html"><a href="#html" class="headerlink" title="html"></a>html</h2><pre><code>&lt;div id=&quot;summernote&quot;&gt;&lt;/div&gt;</code></pre><h2 id="js"><a href="#js" class="headerlink" title="js"></a>js</h2><pre><code>// summernote的初始化方法$(&quot;#summernote&quot;).summernote({    placeholder: &quot;输入内容&quot;,    tabsize: 2,    height: 300,    lang: &#39;zh-CN&#39;,    focus: true,    callbacks: {        onImageUpload: function (files) {                // 上传图片            uploadFile(files[0]);        },        onMediaDelete: function (target){                // 删除图片            deleteFile(target);        }    }});// 上传文件function uploadFile(file){    var imgPath = sendFile(file);    $(&#39;#summernote&#39;).summernote(&#39;insertImage&#39;, imgPath);}// 用于summernote内容回显function getContent(){    var content = $(&#39;#summernote&#39;).summernote(&#39;code&#39;);    if (content==&quot;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&quot;){        return &#39;&#39;;    }    return content;}// 获取summernote的内容function addContent(content){    $(&#39;#summernote&#39;).summernote(&#39;code&#39;, content);}// 上传图片至服务器function sendFile(file) {    if (file == null||file==undefined) {        return null;    }    var formData = new FormData();    formData.append(&quot;file&quot;, file);    console.log(formData);    var filePath = &quot;&quot;;    $.ajax({        url: &quot;/file/upload&quot;,        type: &quot;POST&quot;,        data: formData,        async: false,        contentType: false,        processData: false,        success: function (result) {            filePath = result.data.filePath;        }    });    return filePath;}// 删除服务器图片function deleteFile(filePath) {    $.ajax({        url: &quot;/file/delete&quot;,        type: &quot;POST&quot;,        data: {            &quot;filePath&quot;: filePath        },        success: function (result) {            console.log(result);        }    })}</code></pre><h2 id="java接口"><a href="#java接口" class="headerlink" title="java接口"></a>java接口</h2><pre><code>    @RequestMapping(&quot;/addImg&quot;)    public Map addImg(@RequestParam(&quot;file&quot;) MultipartFile file, HttpServletRequest request) throws IOException {        String fileName = file.getOriginalFilename();        fileName.split(&quot;.&quot;);        System.out.println(&quot;接收到文件:&quot; + fileName);        String fileType = fileName.substring(fileName.lastIndexOf(&quot;.&quot;));        String filePath = new File(&quot;&quot;).getCanonicalFile().getPath() + &quot;/static/images/&quot;;        filePath = filePath + UUID.randomUUID().toString() + fileType;        File dest = new File(filePath);        if (dest.getParentFile() != null) {            dest.getParentFile().mkdirs();        }        try {            file.transferTo(dest);        } catch (IOException e) {            log.warning(&quot;文件上传失败:&quot; + e);            return ResultMap.failed(&quot;文件上传失败&quot;);        }        String path = request.getScheme() + &quot;://&quot; + request.getServerName() + &quot;:&quot;                + request.getServerPort() + request.getContextPath() + &quot;/images/&quot; + dest.getName();        return ResultMap.success(path);    }    @RequestMapping(&quot;deleteImg&quot;)    public Map deleteImg(String imgSrc) {        String fileName = imgSrc.substring(imgSrc.lastIndexOf(&quot;/&quot;) + 1);        System.out.println(fileName);        String filePath = Thread.currentThread().getContextClassLoader().getResource(&quot;&quot;).getPath() + &quot;static/images/&quot;;        filePath = filePath + fileName;        File dest = new File(filePath);        return dest.delete() ? ResultMap.success() : ResultMap.failed();    }</code></pre>]]></content>
    
    
    <categories>
      
      <category>html插件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>html</tag>
      
      <tag>富文本编辑器</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>vim的使用</title>
    <link href="/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="vim介绍"><a href="#vim介绍" class="headerlink" title="vim介绍"></a>vim介绍</h2><p>Vim是从 vi 发展出来的一个文本编辑器。代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。 </p><p>简单的来说， vi 是老式的字处理器，不过功能已经很齐全了，但是还是有可以进步的地方。 vim 则可以说是程序开发者的一项很好用的工具。 </p><p>连 vim 的官方网站 (<a href="http://www.vim.org/" target="_blank" rel="noopener">http://www.vim.org</a>) 自己也说 vim 是一个程序开发工具而不是文字处理软件。（这段是复制来的，不说点啥的话不好看）</p><h2 id="1-vim模式"><a href="#1-vim模式" class="headerlink" title="1. vim模式"></a>1. vim模式</h2><pre><code class="text">正常模式（按Esc或Ctrl+[进入） 左下角显示文件名或为空插入模式（按i进入） 左下角显示--INSERT--可视模式（按v进入） 左下角显示--VISUAL--替换模式（按r或R开始） 左下角显示 --REPLACE--命令行模式（按:或者/或者?开始）ex模式 没用过，有兴趣的同学可以自行了解</code></pre><h2 id="2-打开文件"><a href="#2-打开文件" class="headerlink" title="2. 打开文件"></a>2. 打开文件</h2><pre><code class="text"># 打开单个文件vim file    # 同时打开多个文件vim file1 file2..  # 在vim窗口中打开一个新文件:open [file]       【举个例子】# 当前打开1.txt，做了一些编辑没保存:open!         放弃这些修改，并重新打开未修改的文件# 当前打开1.txt，做了一些编辑并保存:open 2.txt    直接退出对1.txt的编辑，直接打开2.txt编辑，省了退出:wq再重新vim 2.txt的步骤# 打开远程文件，比如ftp或者share folder:e ftp://192.168.10.76/abc.txt:e \qadrive\test\1.txt# 以只读形式打开文件，但是仍然可以使用 :wq! 写入vim -R file # 强制性关闭修改功能，无法使用 :wq! 写入vim -M file</code></pre><h2 id="3-插入命令"><a href="#3-插入命令" class="headerlink" title="3. 插入命令"></a>3. 插入命令</h2><pre><code class="text">i 在当前位置生前插入I 在当前行首插入a 在当前位置后插入A 在当前行尾插入o 在当前行之后插入一行O 在当前行之前插入一行</code></pre><h2 id="4-查找命令"><a href="#4-查找命令" class="headerlink" title="4. 查找命令"></a>4. 查找命令</h2><p>最简单的查找</p><pre><code class="text">/text　　查找text，按n健查找下一个，按N健查找前一个。?text　　查找text，反向查找，按n健查找下一个，按N健查找前一个。vim中有一些特殊字符在查找时需要转义　　.*[]^%/?~$:set ignorecase　　忽略大小写的查找:set noignorecase　　不忽略大小写的查找</code></pre><p>快速查找，不需要手打字符即可查找</p><pre><code class="text">*        向后（下）寻找游标所在处的单词#        向前（上）寻找游标所在处的单词以上两种查找，n,N 的继续查找命令依然可以适用</code></pre><p>精准查找：匹配单词查找</p><p>如果文本中有 <code>hello</code>，<code>helloworld</code>，<code>hellopython</code></p><p>那我使用 /hello ，这三个词都会匹配到。</p><p>有没有办法实现精准查找呢？可以使用</p><pre><code class="text">/hello\&gt;</code></pre><p>精准查找：匹配行首、行末</p><pre><code class="text"># hello位于行首/^hello# world位于行末/world$</code></pre><h2 id="5-替换命令"><a href="#5-替换命令" class="headerlink" title="5. 替换命令"></a>5. 替换命令</h2><pre><code class="text">~  反转游标字母大小写r&lt;字母&gt;           将当前字符替换为所写字母R&lt;字母&gt;&lt;字母&gt;...  连续替换字母cc    替换整行（就是删除当前行，并在下一行插入）cw    替换一个单词（就是删除一个单词，就进入插入模式），前提是游标处于单词第一个字母（可用b定位）C     (大写C)替换至行尾（和D有所区别，D是删除（剪切）至行尾，C是删除至行位并进入插入模式）:s/old/new/    用old替换new，替换当前行的第一个匹配:s/old/new/g   用old替换new，替换当前行的所有匹配:%s/old/new/   用old替换new，替换所有行的第一个匹配:%s/old/new/g  用old替换new，替换整个文件的所有匹配:10,20 s/^/ /g 在第10行至第20行每行前面加四个空格，用于缩进。ddp    交换光标所在行和其下紧邻的一行。</code></pre><h2 id="6-撤销与重做"><a href="#6-撤销与重做" class="headerlink" title="6. 撤销与重做"></a>6. 撤销与重做</h2><pre><code class="text">u 撤销（Undo）U 撤销对整行的操作Ctrl + r 重做（Redo），即撤销的撤销。</code></pre><h2 id="7-删除命令"><a href="#7-删除命令" class="headerlink" title="7. 删除命令"></a>7. 删除命令</h2><p>需要说明的是，vim 其实并没有单纯的删除命令，下面你或许理解为剪切更加准确。</p><p>以字符为单位删除</p><pre><code class="text">x   删除当前字符3x  删除当前字符3次X   删除当前字符的前一个字符。3X  删除当前光标向前三个字符dl  删除当前字符， dl=xdh  删除前一个字符，X=dhD   删除当前字符至行尾。D=d$d$  删除当前字符至行尾d^  删除当前字符之前至行首</code></pre><p>以单词为单位删除</p><pre><code class="text">dw  删除当前字符到单词尾daw 删除当前字符所在单词</code></pre><p>以行为单位删除</p><pre><code class="text">dd  删除当前行dj  删除下一行dk  删除上一行dgg  删除当前行至文档首部d1G  删除当前行至文档首部dG   删除当前行至文档尾部kdgg  删除当前行之前所有行（不包括当前行）jdG   删除当前行之后所有行（不包括当前行）10d     删除当前行开始的10行。:1,10d  删除1-10行:11,$d  删除11行及以后所有的行:1,$d   删除所有行J　　   删除两行之间的空行，实际上是合并两行。</code></pre><h2 id="8-复制粘贴"><a href="#8-复制粘贴" class="headerlink" title="8. 复制粘贴"></a>8. 复制粘贴</h2><p>普通模式中使用y复制</p><pre><code class="text">yy   复制游标所在的整行（3yy表示复制3行）y^   复制至行首，或y0。不含光标所在处字符。y$   复制至行尾。含光标所在处字符。yw   复制一个单词。y2w  复制两个单词。yG   复制至文本末。y1G  复制至文本开头。</code></pre><p>普通模式中使用p粘贴</p><pre><code class="text">p(小写)：代表粘贴至光标后（下边，右边）P(大写)：代表粘贴至光标前（上边，左边）</code></pre><h2 id="9-剪切粘贴"><a href="#9-剪切粘贴" class="headerlink" title="9. 剪切粘贴"></a>9. 剪切粘贴</h2><pre><code class="text">dd    其实就是剪切命令，剪切当前行ddp   剪切当前行并粘贴，可实现当前行和下一行调换位置正常模式下按v（逐字）或V（逐行）进入可视模式然后用jklh命令移动即可选择某些行或字符，再按d即可剪切ndd 剪切当前行之后的n行。利用p命令可以对剪切的内容进行粘贴:1,10d 将1-10行剪切。利用p命令可将剪切后的内容进行粘贴。:1, 10 m 20 将第1-10行移动到第20行之后。</code></pre><h2 id="10-退出保存"><a href="#10-退出保存" class="headerlink" title="10. 退出保存"></a>10. 退出保存</h2><pre><code class="text">:wq 保存并退出ZZ 保存并退出:q! 强制退出并忽略所有更改:e! 放弃所有修改，并打开原来文件。ZZ 保存并退出:sav(eas) new.txt  另存为一个新文件，退出原文件的编辑且不会保存:f(ile) new.txt    新开一个文件，并不保存，退出原文件的编辑且不会保存</code></pre><h2 id="11-移动命令"><a href="#11-移动命令" class="headerlink" title="11. 移动命令"></a>11. 移动命令</h2><p>以字符为单位移动</p><pre><code class="text">h   左移一个字符l   右移一个字符k   上移一个字符j   下移一个字符# 【定位字符】f和Ffx    找到光标后第一个为x的字符3fd   找到光标后第三个为d的字符F   同f，反向查找。</code></pre><p>以行为单位移动</p><pre><code class="text"># 10指代所有数字，可任意指定10h  左移10个字符10l  右移10个字符10k  上移10行10j  下移10行$   移动到行尾 3$  移动到下面3行的行尾</code></pre><p>以单词为单位移动</p><pre><code class="text">w  向前移动一个单词（光标停在单词首部）b  向后移动一个单词e，同w，只不过是光标停在单词尾部ge 同b，光标停在单词尾部。</code></pre><p>以句为单位移动</p><pre><code class="text">(   移动到句首)   移动到句尾</code></pre><p>跳转到文件的首尾</p><pre><code class="text">gg  移动到文件头。 = [[  == ``G   移动到文件尾。 = ]]</code></pre><p>其他移动方法</p><pre><code class="text">^   移动到本行第一个非空白字符上。0   移动到本行第一个字符上(可以是空格)</code></pre><p>使用 <code>具名标记</code> 跳转，个人感觉这个很好用，因为可以跨文件。</p><pre><code class="text">使用 ma ，可以将此处标记为 a，使用 &#39;a 进行跳转使用 :marks 可以查看所有的标记使用 :delm！可以删除所有的标记</code></pre><p>当在查看错误日志时，正常的步骤是，vim打开文件，然后使用 <code>shift+g</code> 再跳转到最后一行，这里有个更简单的操作可以在打开文件时立即跳到最后一行。只要在 vim 和 文件 中间加个 <code>+</code>即可。</p><pre><code class="text">vim + you.log</code></pre><p>举一反三，当你想打开文件立即跳转到指定行时，可以这样</p><pre><code class="text"># 打开文件并跳转到 20 行vim you.log +20</code></pre><p>当你使用 <code>/</code> 搜索定位跳转或者使用 <code>:行号</code> 进行精准跳转时，有时我们想返回到上一次的位置，如何实现？</p><p>只要使用 Ctrl+o 即可返回上一次的位置。</p><h2 id="12-排版功能"><a href="#12-排版功能" class="headerlink" title="12. 排版功能"></a>12. 排版功能</h2><p><strong>缩进</strong></p><pre><code class="text">:set shiftwidth?   查看缩进值:set shiftwidth=4  设置缩进值为4# 缩进相关 最好写到配置文件中  ~/.vimrc:set tabstop=4:set softtabstop=4:set shiftwidth=4:set expandtab&gt;&gt;   向右缩进&lt;&lt;   取消缩进</code></pre><p>如何你要对代码进行缩进，还可以用 <code>==</code> 对当前行缩进，如果要对多行对待缩进，则使用 n<code>==</code>，这种方式要求你所编辑的文件的扩展名是被vim所识别的，比如<code>.py</code>文件。</p><p><strong>排版</strong></p><pre><code class="text">:ce   居中:le   靠左:ri   靠右</code></pre><h2 id="13-注释命令"><a href="#13-注释命令" class="headerlink" title="13. 注释命令"></a>13. 注释命令</h2><p><strong>多行注释</strong></p><pre><code class="text">进入命令行模式，按ctrl + v进入 visual block模式，然后按j, 或者k选中多行，把需要注释的行标记起来按大写字母I，再插入注释符，例如//按esc键就会全部注释了</code></pre><p><strong>取消多行注释</strong></p><pre><code class="text">进入命令行模式，按ctrl + v进入 visual block模式，按字母l横向选中列的个数，例如 // 需要选中2列按字母j，或者k选中注释符号按d键就可全部取消注释</code></pre><p><strong>复杂注释</strong></p><pre><code class="text">:3,5 s/^/#/g 注释第3-5行:3,5 s/^#//g 解除3-5行的注释:1,$ s/^/#/g 注释整个文档:1,$ s/^#//g 取消注释整个文档:%s/^/#/g 注释整个文档，此法更快:%s/^#//g 取消注释整个文档</code></pre><h2 id="14-调整视野"><a href="#14-调整视野" class="headerlink" title="14. 调整视野"></a>14. 调整视野</h2><pre><code class="text">&quot;zz&quot;：命令会把当前行置为屏幕正中央，&quot;zt&quot;：命令会把当前行置于屏幕顶端&quot;zb&quot;：则把当前行置于屏幕底端.Ctrl + e 向下滚动一行Ctrl + y 向上滚动一行Ctrl + d 向下滚动半屏Ctrl + u 向上滚动半屏Ctrl + f 向下滚动一屏Ctrl + b 向上滚动一屏【跳到指定行】：两种方法可以先把行号打开:set nu  打开行号:20    跳到第20行20G    跳到第20行</code></pre><h2 id="15-区域选择"><a href="#15-区域选择" class="headerlink" title="15. 区域选择"></a>15. 区域选择</h2><pre><code class="text">要进行区域选择，要先进入可视模式v   以字符为单位，上下左右选择V   以行为单位，上下选择选择后可进行操作d   剪切/删除y   复制Ctrl+v   如果当前是V(大写)模式，就变成v(小写)         如果当前是v(小写)模式，就变成普通模式。         如果当前是普通模式，就进入v(小写)模式利用这个，可以进行多行缩进。ggVG   选择全文</code></pre><h2 id="16-窗口控制"><a href="#16-窗口控制" class="headerlink" title="16. 窗口控制"></a>16. 窗口控制</h2><p><strong>新建窗口</strong></p><pre><code class="text"># 打开两个文件分属两个窗口vim -o 1.txt 2.txt# 假设现在已经打开了1.txt:sp 2.txt   开启一个横向的窗口，编辑2.txt:vsp 2.txt  开启一个竖向的窗口，编辑2.txt:split        将当前窗口再复制一个窗口出来，内容同步，游标可以不同:split 2.txt  在新窗口打开2.txt的横向窗口# 需要注意：内容同步，但是游标位置是独立的Ctrl-w s    将当前窗口分成水平窗口Ctrl-w v    将当前窗口分成竖直窗口Ctrl-w q    等同:q 结束分割出来的视窗。Ctrl-w q!   等同:q! 结束分割出来的视窗。Ctrl-w o    打开一个视窗并且隐藏之前的所有视窗</code></pre><p><strong>窗口切换</strong></p><pre><code class="text"># 特别说明：Ctrl w &lt;字母&gt; 不需要同时按Ctrl-w h    切换到左边窗口Ctrl-w l    切换到右边窗口Ctrl-w j    切换到下边窗口Ctrl-w k    切换到上边窗口# 特别说明：全屏模式下:n    切换下一个窗口:N    切换上一个窗口:bp   切换上一个窗口# 特别说明：非全屏模式:bn    切换下一个窗口，就当前位置的窗口的内容变了，其他窗口不变:bN    切换上一个窗口，就当前位置的窗口的内容变了，其他窗口不变</code></pre><p><strong>窗口移动</strong></p><pre><code class="text"># 特别说明：Ctrl w &lt;字母&gt; 不需要同时按Ctrl-w J   将当前视窗移至最下面Ctrl-w K   将当前视窗移最上面Ctrl-w H   将当前视窗移至最左边Ctrl-w L   将当前视窗移至最右边Ctrl-ww    按顺序切换窗口</code></pre><p><strong>调整尺寸</strong></p><pre><code class="text"># 友情提示：键盘切记不要处于中文状态Ctrl-w +   增加窗口高度Ctrl-w -   减少窗口高度</code></pre><p><strong>退出窗口</strong></p><pre><code class="text">:close    关闭当前窗口:close!   强制关闭当前窗口:q       退出，不保存:q!      强制退出，不保存:x       保存退出:wq      保存退出:wq!     强制保存退出:w &lt;[路径/]文件名&gt;        另存为:savesa &lt;[路径/]文件名&gt;   另存为ZZ 保存并退出。:only    关闭所有窗口，只保留当前窗口(前提：其他窗口内容有改变的话都要先保存):only!   关闭所有窗口，只保留当前窗口:qall 放弃所有操作并退出:wall 保存所有，:wqall 保存所有并退出。</code></pre><h2 id="17-文档加密"><a href="#17-文档加密" class="headerlink" title="17. 文档加密"></a>17. 文档加密</h2><pre><code class="text">vim -x file_name然后输入密码：确认密码：如果不修改内容也要保存。:wq，不然密码设定不会生效。</code></pre><h2 id="18-录制宏"><a href="#18-录制宏" class="headerlink" title="18. 录制宏"></a>18. 录制宏</h2><p>按q键加任意字母开始录制，再按q键结束录制（这意味着vim中的宏不可嵌套），使用的时候@加宏名，比如qa。。。q录制名为a的宏，@a使用这个宏。</p><h2 id="19-执行命令"><a href="#19-执行命令" class="headerlink" title="19. 执行命令"></a>19. 执行命令</h2><pre><code class="text"># 重复前一次命令. # 执行shell命令:!command# 比如列出当前目录下文件:!ls # 执行脚本:!perl -c script.pl 检查perl脚本语法，可以不用退出vim，非常方便。:!perl script.pl 执行perl脚本，可以不用退出vim，非常方便。:suspend或Ctrl - Z 挂起vim，回到shell，按fg可以返回vim。</code></pre><h2 id="20-帮助命令"><a href="#20-帮助命令" class="headerlink" title="20. 帮助命令"></a>20. 帮助命令</h2><pre><code class="text">在Unix/Linux系统上$ vimtutor# 普通模式下键盘输入vim或F1# 命令行模式下:help     显示整个帮助:help xxx 显示xxx的帮助，比如 :help i, :help CTRL-[（即Ctrl+[的帮助）。:help &#39;number&#39; Vim选项的帮助用单引号括起在Windows系统上:help tutor</code></pre><h2 id="21-配置命令"><a href="#21-配置命令" class="headerlink" title="21. 配置命令"></a>21. 配置命令</h2><p>显示当前设定</p><pre><code class="text">:set或者:se显示所有修改过的配置:set all 显示所有的设定值:set option? 显示option的设定值:set nooption 取消当期设定值:ver   显示vim的所有信息（包括版本和参数等）# 需要注意：全屏模式下:args   查看当前打开的文件列表，当前正在编辑的文件会用[]括起来</code></pre><p>更改设定</p><pre><code class="text">:set nu   显示行号set autoindent(ai)   设置自动缩进set autowrite(aw)    设置自动存档，默认未打开set backup(bk) 设置自动备份，默认未打开set background=dark或light，设置背景风格set cindent(cin) 设置C语言风格缩进:set ts=4   设置tab键转换为4个空格:set ff=unix   # 修改文件dos文件为unix:set shiftwidth?   查看缩进值:set shiftwidth=4  设置缩进值为4:set ignorecase　　忽略大小写的查找:set noignorecase　　不忽略大小写的查找:set paste  # insert模式下，粘贴格式不会乱掉:set ruler?　　查看是否设置了ruler，在.vimrc中，使用set命令设制的选项都可以通过这个命令查看:scriptnames　　查看vim脚本文件的位置，比如.vimrc文件，语法文件及plugin等。:set list 显示非打印字符，如tab，空格，行尾等。如果tab无法显示，请确定用set lcs=tab:&gt;-命令设置了.vimrc文件，并确保你的文件中的确有tab，如果开启了expendtab，那么tab将被扩展为空格。:syntax        列出已经定义的语法项:syntax clear  清除已定义的语法规则:syntax case match    大小写敏感，int和Int将视为不同的语法元素:syntax case ignore   大小写无关，int和Int将视为相同的语法元素，并使用同样的配色方案</code></pre><img src="/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/pic1.png" srcset="/img/loading.gif" class=""><img src="/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/pic2.png" srcset="/img/loading.gif" class=""><img src="/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/pic3.png" srcset="/img/loading.gif" class=""><img src="/2018/12/19/vim%E7%9A%84%E4%BD%BF%E7%94%A8/pic4.png" srcset="/img/loading.gif" class="">]]></content>
    
    
    <categories>
      
      <category>快速开发</category>
      
    </categories>
    
    
    <tags>
      
      <tag>开发技巧</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
